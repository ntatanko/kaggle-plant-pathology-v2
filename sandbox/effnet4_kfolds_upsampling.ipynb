{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from PIL import Image\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    f1_score,\n",
    "    plot_confusion_matrix,\n",
    "    precision_recall_curve,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    StratifiedKFold,\n",
    "    StratifiedShuffleSplit,\n",
    "    train_test_split,\n",
    ")\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB4, EfficientNetB7\n",
    "from tensorflow.keras.layers import (\n",
    "    AveragePooling2D,\n",
    "    AvgPool2D,\n",
    "    Conv2D,\n",
    "    Dense,\n",
    "    Flatten,\n",
    "    GlobalAveragePooling2D,\n",
    "    MaxPooling2D,\n",
    ")\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tqdm import notebook, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/app/_data/\"\n",
    "BATCH_SIZE = 32\n",
    "SEED = 1488\n",
    "IMAGE_SIZE = (380, 380)\n",
    "NUM_CLASSES = 6\n",
    "INPUT_SHAPE = (380, 380, 3)\n",
    "TRAIN_IMG_PATH = \"/app/_data/train_images/\"\n",
    "TEST_IMG_PATH = \"/app/_data/test_images/\"\n",
    "# MODEL_PATH = '/app/_data/models/effnet7_2_6cl_frozen_40ep_42.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(PATH + \"train_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(PATH + \"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.join(labels[\"labels\"].str.get_dummies(sep=\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>labels</th>\n",
       "      <th>complex</th>\n",
       "      <th>frog_eye_leaf_spot</th>\n",
       "      <th>healthy</th>\n",
       "      <th>powdery_mildew</th>\n",
       "      <th>rust</th>\n",
       "      <th>scab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>800113bb65efe69e.jpg</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  image   labels  complex  frog_eye_leaf_spot  healthy  \\\n",
       "0  800113bb65efe69e.jpg  healthy        0                   0        1   \n",
       "\n",
       "   powdery_mildew  rust  scab  \n",
       "0               0     0     0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['complex', 'frog_eye_leaf_spot', 'healthy', 'powdery_mildew', 'rust', 'scab']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns = labels.columns[2:].tolist()\n",
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['complex', 'frog_eye_leaf_spot', 'healthy', 'powdery_mildew', 'rust', 'scab']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_images',\n",
       " 'images',\n",
       " 'train_0.csv',\n",
       " 'models',\n",
       " 'train_labels.csv',\n",
       " 'cache',\n",
       " '380',\n",
       " 'list_to_drop.csv',\n",
       " 'duplicates_08.csv',\n",
       " 'plant-pathology-2020-fgvc7.zip',\n",
       " 'test_images',\n",
       " 'sample_submission.csv',\n",
       " 'train.csv',\n",
       " 'duplicates_09.csv',\n",
       " 'duplicates_only_08.csv',\n",
       " '.ipynb_checkpoints']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>healthy</th>\n",
       "      <th>multiple_diseases</th>\n",
       "      <th>rust</th>\n",
       "      <th>scab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train_2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train_3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train_4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1816</th>\n",
       "      <td>Train_1816</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817</th>\n",
       "      <td>Train_1817</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>Train_1818</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1819</th>\n",
       "      <td>Train_1819</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820</th>\n",
       "      <td>Train_1820</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1821 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        image_id  healthy  multiple_diseases  rust  scab\n",
       "0        Train_0        0                  0     0     1\n",
       "1        Train_1        0                  1     0     0\n",
       "2        Train_2        1                  0     0     0\n",
       "3        Train_3        0                  0     1     0\n",
       "4        Train_4        1                  0     0     0\n",
       "...          ...      ...                ...   ...   ...\n",
       "1816  Train_1816        0                  0     0     1\n",
       "1817  Train_1817        1                  0     0     0\n",
       "1818  Train_1818        1                  0     0     0\n",
       "1819  Train_1819        0                  0     1     0\n",
       "1820  Train_1820        0                  0     0     1\n",
       "\n",
       "[1821 rows x 5 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_20 = pd.read_csv(PATH+'train_20.csv')\n",
    "labels_20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_to_labels(pred, thresh=0.5, labels=feature_columns):\n",
    "\n",
    "    pred = [labels[i] for i in range(len(labels)) if pred[i] > thresh]\n",
    "    pred = ' '.join(pred)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.experimental.preprocessing.RandomFlip(\n",
    "            \"horizontal_and_vertical\", seed=SEED\n",
    "        ),\n",
    "        keras.layers.experimental.preprocessing.RandomRotation(0.15, seed=SEED),\n",
    "        keras.layers.experimental.preprocessing.RandomZoom(0.25, 0.25, seed=SEED),\n",
    "        keras.layers.experimental.preprocessing.RandomContrast(factor=0.05, seed=SEED),\n",
    "        keras.layers.experimental.preprocessing.RandomTranslation(\n",
    "            height_factor=0.2, width_factor=0.2, seed=SEED\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def write_np(file_path):\n",
    "#     img = tf.io.read_file(TRAIN_IMG_PATH + file_path)\n",
    "#     img = tf.image.decode_jpeg(img, channels=3)\n",
    "#     img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "#     img = tf.image.resize(\n",
    "#         img,\n",
    "#         IMAGE_SIZE,\n",
    "#     )\n",
    "#     img = tf.image.convert_image_dtype(img, tf.uint8)\n",
    "#     img = Image.fromarray(np.array(img))\n",
    "#     img.save(PATH + '380/'+file_path)\n",
    "#     return img\n",
    "#     np.save(PATH + 'cache/'+file_path[:-4], img)\n",
    "# labels['image'].apply(write_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       <PIL.Image.Image image mode=RGB size=380x380 a...\n",
       "1       <PIL.Image.Image image mode=RGB size=380x380 a...\n",
       "2       <PIL.Image.Image image mode=RGB size=380x380 a...\n",
       "3       <PIL.Image.Image image mode=RGB size=380x380 a...\n",
       "4       <PIL.Image.Image image mode=RGB size=380x380 a...\n",
       "                              ...                        \n",
       "1816    <PIL.Image.Image image mode=RGB size=380x380 a...\n",
       "1817    <PIL.Image.Image image mode=RGB size=380x380 a...\n",
       "1818    <PIL.Image.Image image mode=RGB size=380x380 a...\n",
       "1819    <PIL.Image.Image image mode=RGB size=380x380 a...\n",
       "1820    <PIL.Image.Image image mode=RGB size=380x380 a...\n",
       "Name: image_id, Length: 1821, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def write_np(file_path):\n",
    "#     img = tf.io.read_file(PATH+'images/' + file_path+'.jpg')\n",
    "#     img = tf.image.decode_jpeg(img, channels=3)\n",
    "#     img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "#     img = tf.image.resize(\n",
    "#         img,\n",
    "#         IMAGE_SIZE,\n",
    "#     )\n",
    "#     img = tf.image.convert_image_dtype(img, tf.uint8)\n",
    "#     img = Image.fromarray(np.array(img))\n",
    "#     img.save(PATH + '380/'+file_path+'.jpg')\n",
    "#     return img\n",
    "# #     np.save(PATH + 'cache/'+file_path[:-4], img)\n",
    "# labels_20['image_id'].apply(write_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=SEED)\n",
    "X = labels[\"image\"]\n",
    "y = labels[feature_columns]\n",
    "for train_index, valid_index in sss.split(labels[\"image\"], labels['labels']):\n",
    "    train, valid = labels.loc[train_index], labels.loc[valid_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from 380 uint8\n",
    "def parse_image2(file_path):\n",
    "    img = tf.io.read_file(PATH+'380/'+file_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v1 from orig\n",
    "def parse_image(file_path):\n",
    "    img = tf.io.read_file(TRAIN_IMG_PATH+file_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img = tf.image.resize(\n",
    "        img,\n",
    "        IMAGE_SIZE,\n",
    "    )\n",
    "    img = tf.image.convert_image_dtype(img, tf.uint8)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(df, augmentation=False):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (df[\"image\"].values, df[feature_columns].astype('uint8').values)\n",
    "    )\n",
    "    dataset = dataset.map(lambda x, y: (parse_image2(x), y))\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "\n",
    "    if augmentation:\n",
    "        dataset = dataset.map(\n",
    "            lambda x, y: (data_augmentation(x, training=True), y),\n",
    "            num_parallel_calls=AUTOTUNE,\n",
    "        )\n",
    "    dataset = dataset.repeat().prefetch(buffer_size=AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = prepare_dataset(train, augmentation = True)\n",
    "ds_valid = prepare_dataset(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_test_image(img_name):\n",
    "    img = tf.io.read_file(img_name)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img = tf.image.resize(\n",
    "        img,\n",
    "        IMAGE_SIZE,\n",
    "    )\n",
    "    img = tf.image.convert_image_dtype(img, tf.uint8)\n",
    "    return img\n",
    "\n",
    "\n",
    "def predict_new(path, model):\n",
    "    img = parse_test_image(path)\n",
    "    img = tf.expand_dims(img,axis = 0)\n",
    "    pred = model.predict(img)\n",
    "    return pred_to_labels(pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Quadro RTX 5000, compute capability 7.5\n"
     ]
    }
   ],
   "source": [
    "policy = keras.mixed_precision.experimental.Policy('mixed_float16')\n",
    "keras.mixed_precision.experimental.set_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 5:\n",
    "        return 0.01\n",
    "    elif 5 <= epoch <10:\n",
    "        return 0.001\n",
    "    elif 10 <= epoch <50:\n",
    "        return 0.0005\n",
    "    else:\n",
    "        return 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\", patience=15, restore_best_weights=True, verbose=0, mode='min',\n",
    "    ),\n",
    "    keras.callbacks.LearningRateScheduler(schedule = scheduler, verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = keras.Input(shape=INPUT_SHAPE)\n",
    "# base_model = keras.applications.EfficientNetB4(weights=None, include_top=False)\n",
    "# base_model.load_weights('/app/_data/models/efficientnet-b4_noisy-student_notop.h5', by_name=True, skip_mismatch = True)\n",
    "# x = base_model(inputs)\n",
    "# x = keras.layers.GlobalAveragePooling2D(name=\"avg_pool\")(x)\n",
    "# x = keras.layers.Flatten(name=\"flatten\")(x)\n",
    "# outputs = keras.layers.Dense(NUM_CLASSES, activation=\"sigmoid\")(x)\n",
    "# effnet = keras.Model(inputs=inputs, outputs=outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skf = StratifiedKFold(n_splits=5, random_state=SEED, shuffle=True)\n",
    "# X = labels[\"image\"]\n",
    "# y = labels[feature_columns]\n",
    "# for i, (train_index, valid_index) in enumerate(skf.split(labels[\"image\"], labels['labels'])):\n",
    "#     train, valid = labels.loc[train_index], labels.loc[valid_index]\n",
    "#     model_name = 'eff4_ns_kf_' + str(i+1) + '.h5'\n",
    "#     ds_train = prepare_dataset(train, augmentation = True)\n",
    "#     ds_valid = prepare_dataset(valid)\n",
    "#     model = effnet\n",
    "#     model.compile(\n",
    "#     loss=\"binary_crossentropy\",\n",
    "#     optimizer=Adam(),\n",
    "#     metrics=['acc',\n",
    "#         keras.metrics.Recall(),\n",
    "#         keras.metrics.Precision(),\n",
    "#         tfa.metrics.F1Score(num_classes=NUM_CLASSES, average=\"micro\"),\n",
    "#     ],\n",
    "# )\n",
    "#     history = model.fit(\n",
    "#     ds_train,\n",
    "#     validation_data=ds_valid,\n",
    "#     epochs=100,\n",
    "#     steps_per_epoch=(train.shape[0]*0.8)//BATCH_SIZE, \n",
    "#     validation_steps= (valid.shape[0]*0.2)//BATCH_SIZE,\n",
    "#     verbose=1,\n",
    "#     use_multiprocessing=True,\n",
    "#     callbacks = callbacks\n",
    "# )\n",
    "#     model.save(\"/app/_data/models/\"+model_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curves(model, loss=False):\n",
    "    df = pd.DataFrame(model.history)\n",
    "    if loss:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.title(\"loss\")\n",
    "        plt.plot(df.iloc[:, 0], label=\"loss\")\n",
    "        plt.plot(df.iloc[:, 5], label=\"val_loss\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.figure(figsize=(12, 20))\n",
    "        plt.subplot(4, 1, 1)\n",
    "        plt.title(\"accuracy\")\n",
    "        plt.plot(df.iloc[:, 1], label=\"accuracy\")\n",
    "        plt.plot(df.iloc[:, 6], label=\"val_accuracy\")\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(4, 1, 2)\n",
    "        plt.title(\"recall\")\n",
    "        plt.plot(df.iloc[:, 2], label=\"recall\")\n",
    "        plt.plot(df.iloc[:, 7], label=\"val_recall\")\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(4, 1, 3)\n",
    "        plt.title(\"precision\")\n",
    "        plt.plot(df.iloc[:, 3], label=\"precision\")\n",
    "        plt.plot(df.iloc[:, 8], label=\"val_precision\")\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(4, 1, 4)\n",
    "        plt.title(\"f1\")\n",
    "        plt.plot(df.iloc[:, 4], label=\"f1\")\n",
    "        plt.plot(df.iloc[:, 9], label=\"val_f1\")\n",
    "        plt.legend()\n",
    "        plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_curves(history,loss=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predictions for all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.models.load_model('/app/_data/models/eff4_ns_kf_1.h5')\n",
    "\n",
    "# def parse_all(file_path):\n",
    "#     img = tf.io.read_file(PATH+'380/'+file_path)\n",
    "#     img = tf.image.decode_jpeg(img, channels=3)\n",
    "#     return img\n",
    "\n",
    "# def predict_new(path, model):\n",
    "#     img = parse_all(path)\n",
    "#     img = tf.expand_dims(img,axis = 0)\n",
    "#     pred = model.predict(img)\n",
    "#     return pred_to_labels(pred[0])\n",
    "\n",
    "# df_sub = pd.DataFrame(columns=['image','labels'])\n",
    "# for img_name in os.listdir(PATH+'380/'):\n",
    "#     pred = predict_new(img_name, model)\n",
    "#     df_sub = df_sub.append( {'image': img_name, 'labels': pred}, ignore_index = True )\n",
    "# print(df_sub.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sub = df_sub.merge(labels[['image', 'labels']], on='image', how='left', suffixes=('_pred', '_true'))\n",
    "# df_sub.to_csv('/app/sandbox/wrong_predictions/prediction_raw_8_5.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_weights = []\n",
    "# for mod_path in [MODEL_PATH1,MODEL_PATH2,MODEL_PATH3,MODEL_PATH4,MODEL_PATH5]:\n",
    "#     model = keras.models.load_model(mod_path)\n",
    "#     all_weights.append(model.get_weights())\n",
    "# all_weights_mean = np.mean(np.array(all_weights), axis = 0)\n",
    "# w1 = np.array(all_weights[2])\n",
    "# w1[-10:] = all_weights_mean[-10:]\n",
    "# model.set_weights(w1)\n",
    "# model.evaluate(ds_valid, steps = (valid.shape[0]*0.2)//BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
