{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /app/kaggle.json'\n"
     ]
    }
   ],
   "source": [
    "import kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /app/kaggle.json'\n",
      "Data package template written to: /app/_data/models/final/Eff4Flatt/dataset-metadata.json\n"
     ]
    }
   ],
   "source": [
    "! kaggle datasets init -p /app/_data/models/final/Eff4Flatt/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /app/kaggle.json'\n",
      "Starting upload for file eff4_Flatt_2.h5\n",
      "100%|█████████████████████████████████████████| 218M/218M [05:48<00:00, 656kB/s]\n",
      "Upload successful: eff4_Flatt_2.h5 (218MB)\n",
      "Starting upload for file eff4_Flatt_4.h5\n",
      "100%|█████████████████████████████████████████| 218M/218M [05:40<00:00, 672kB/s]\n",
      "Upload successful: eff4_Flatt_4.h5 (218MB)\n",
      "Starting upload for file eff4_Flatt_5.h5\n",
      "100%|█████████████████████████████████████████| 218M/218M [06:09<00:00, 618kB/s]\n",
      "Upload successful: eff4_Flatt_5.h5 (218MB)\n",
      "Starting upload for file eff4_Flatt_1.h5\n",
      "100%|█████████████████████████████████████████| 218M/218M [05:38<00:00, 676kB/s]\n",
      "Upload successful: eff4_Flatt_1.h5 (218MB)\n",
      "Starting upload for file eff4_Flatt_3.h5\n",
      "100%|█████████████████████████████████████████| 218M/218M [05:43<00:00, 665kB/s]\n",
      "Upload successful: eff4_Flatt_3.h5 (218MB)\n",
      "Skipping folder: .ipynb_checkpoints; use '--dir-mode' to upload folders\n",
      "Your private Dataset is being created. Please check progress at https://www.kaggle.com/nataliayurasova/Eff4Flatt\n"
     ]
    }
   ],
   "source": [
    "! kaggle datasets create -p /app/_data/models/final/Eff4Flatt/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: albumentations in /usr/local/lib/python3.8/dist-packages (0.5.2)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.8/dist-packages (from albumentations) (0.18.1)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from albumentations) (5.3.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from albumentations) (1.4.1)\n",
      "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.8/dist-packages (from albumentations) (4.5.1.48)\n",
      "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.8/dist-packages (from albumentations) (1.17.3)\n",
      "Requirement already satisfied: imgaug>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from albumentations) (0.4.0)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from imgaug>=0.4.0->albumentations) (8.2.0)\n",
      "Requirement already satisfied: Shapely in /usr/local/lib/python3.8/dist-packages (from imgaug>=0.4.0->albumentations) (1.7.1)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (from imgaug>=0.4.0->albumentations) (4.5.1.48)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from imgaug>=0.4.0->albumentations) (3.4.1)\n",
      "Requirement already satisfied: imageio in /usr/local/lib/python3.8/dist-packages (from imgaug>=0.4.0->albumentations) (2.9.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from imgaug>=0.4.0->albumentations) (1.15.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.16.1->albumentations) (2021.4.8)\n",
      "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.16.1->albumentations) (2.5.1)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.16.1->albumentations) (1.1.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations) (1.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations) (2.8.1)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.8/dist-packages (from networkx>=2.0->scikit-image>=0.16.1->albumentations) (4.4.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install albumentations\n",
    "import albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import (\n",
    "    StratifiedKFold,\n",
    "    StratifiedShuffleSplit,\n",
    "    train_test_split,\n",
    ")\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB4, EfficientNetB7\n",
    "from tensorflow.keras.layers import (\n",
    "    AveragePooling2D,\n",
    "    AvgPool2D,\n",
    "    Conv2D,\n",
    "    Dense,\n",
    "    Flatten,\n",
    "    GlobalAveragePooling2D,\n",
    "    MaxPooling2D,\n",
    ")\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tqdm import notebook, tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/app/_data/\"\n",
    "BATCH_SIZE = 56\n",
    "SEED = 42\n",
    "IMAGE_SIZE = 380\n",
    "NUM_CLASSES = 6\n",
    "TRAIN_IMG_PATH = \"/app/_data/380_npy/\"\n",
    "TEST_IMG_PATH = \"/app/_data/test_images/\"\n",
    "feature_columns = [\n",
    "    \"complex\",\n",
    "    \"frog_eye_leaf_spot\",\n",
    "    \"healthy\",\n",
    "    \"powdery_mildew\",\n",
    "    \"rust\",\n",
    "    \"scab\",\n",
    "]\n",
    "wrong = ['ead085dfac287263.jpg', '95276ccd226ad933.jpg',\"da8770e819d2696d.jpg\", 'cd3a1d64e6806eb5.jpg', 'ccec54723ff91860.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = pd.read_csv(\"/app/_data/df_csv/labels_21_20.csv\", index_col=[0])\n",
    "df_labels[\"image\"] = df_labels[\"image\"].str.replace(\".jpg\", \".npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = df_labels.sample(frac=1, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20227, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = labels_21_20.copy()\n",
    "# sss = StratifiedShuffleSplit(n_splits=1, test_size=0.07, random_state=SEED)\n",
    "\n",
    "# for train_index, valid_index in sss.split(df[\"image\"], df[\"labels\"]):\n",
    "#     train, valid = df.loc[train_index], df.loc[valid_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 380*380\n",
    "transform = albumentations.Compose(\n",
    "    [\n",
    "        albumentations.CLAHE(p=0.1, clip_limit=(1, 2), tile_grid_size=(8, 8)),\n",
    "        albumentations.OneOf(\n",
    "            [\n",
    "                albumentations.MotionBlur((3, 3)),\n",
    "                albumentations.MedianBlur(blur_limit=3),\n",
    "                albumentations.GaussianBlur(blur_limit=(3, 3), sigma_limit=0),\n",
    "                albumentations.Blur(blur_limit=(3, 3)),\n",
    "            ],\n",
    "            p=0.2,\n",
    "        ),\n",
    "        albumentations.OneOf(\n",
    "            [\n",
    "                albumentations.GaussNoise(var_limit=[10, 50], mean=1),\n",
    "                albumentations.ISONoise(intensity=(0.1, 1), color_shift=(0.01, 0.05)),\n",
    "                albumentations.ImageCompression(\n",
    "                    quality_lower=70, quality_upper=100, compression_type=1\n",
    "                ),\n",
    "                albumentations.MultiplicativeNoise(\n",
    "                    multiplier=(0.95, 1.05), per_channel=True, elementwise=True\n",
    "                ),\n",
    "                albumentations.Downscale(\n",
    "                    scale_min=0.6, scale_max=0.99, interpolation=4\n",
    "                ),\n",
    "            ],\n",
    "            p=0.5,\n",
    "        ),\n",
    "        albumentations.OneOf(\n",
    "            [\n",
    "                albumentations.HueSaturationValue(\n",
    "                    hue_shift_limit=(-7, 7),\n",
    "                    sat_shift_limit=(-10, 10),\n",
    "                    val_shift_limit=(-10, 10),\n",
    "                ),\n",
    "                albumentations.RandomBrightnessContrast(\n",
    "                    brightness_limit=0.15,\n",
    "                    contrast_limit=0.2,\n",
    "                    brightness_by_max=True,\n",
    "                ),\n",
    "            ],\n",
    "            p=0.5,\n",
    "        ),\n",
    "        albumentations.OneOf(\n",
    "            [\n",
    "                albumentations.OpticalDistortion(\n",
    "                    distort_limit=0.05,\n",
    "                    shift_limit=0.05,\n",
    "                    border_mode=2,\n",
    "                ),\n",
    "                albumentations.ElasticTransform(\n",
    "                    alpha=2.0,\n",
    "                    sigma=50.0,\n",
    "                    alpha_affine=10.0,\n",
    "                    interpolation=0,\n",
    "                    border_mode=2,\n",
    "                ),\n",
    "                albumentations.GridDistortion(\n",
    "                    num_steps=5, distort_limit=0.3, interpolation=0, border_mode=2\n",
    "                ),\n",
    "            ],\n",
    "            p=0.5,\n",
    "        ),\n",
    "        albumentations.OneOf(\n",
    "            [\n",
    "                albumentations.HorizontalFlip(),\n",
    "                albumentations.VerticalFlip(),\n",
    "            ],\n",
    "            p=0.5,\n",
    "        ),\n",
    "        albumentations.OneOf(\n",
    "            [\n",
    "                albumentations.Rotate(\n",
    "                    limit=(-180, 180), interpolation=0, border_mode=2\n",
    "                ),\n",
    "                albumentations.ShiftScaleRotate(\n",
    "                    shift_limit=0.05,\n",
    "                    scale_limit=0.05,\n",
    "                    rotate_limit=180,\n",
    "                    interpolation=0,\n",
    "                    border_mode=2,\n",
    "                ),\n",
    "            ],\n",
    "            p=0.5,\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(keras.utils.Sequence):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        images_src_dir,\n",
    "        batch_size,\n",
    "        target_image_size,\n",
    "        shuffle=False,\n",
    "        augment=True,\n",
    "        crop=False,\n",
    "        resize=False,\n",
    "        normalize=False,\n",
    "    ):\n",
    "        self.shuffle = shuffle\n",
    "        self.batch_size = BATCH_SIZE\n",
    "        self.df = df\n",
    "        self.images_dir = images_src_dir\n",
    "        self.target_image_size = (IMAGE_SIZE, IMAGE_SIZE)\n",
    "        self.augment = augment\n",
    "        self.crop = crop\n",
    "        self.resize = resize\n",
    "        self.normalize = normalize\n",
    "        # create label index map\n",
    "        self.labels = self._read_labels()\n",
    "        self.n_samples = self.df.shape[0]\n",
    "        self.n_batches = self.n_samples // self.batch_size\n",
    "        # shuffle data, also repeated after each epoch if needed\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.labels)\n",
    "\n",
    "    def _read_labels(self):\n",
    "        \"\"\"\n",
    "        Returns list images mapping to 1-hot label\n",
    "        \"\"\"\n",
    "\n",
    "        # label indexes\n",
    "        label_ixs = self.df[feature_columns].values\n",
    "        image_ixs = self.df[\"image\"].values\n",
    "        labels = []\n",
    "\n",
    "        for i in range(len(image_ixs)):\n",
    "            labels.append([image_ixs[i], label_ixs[i]])\n",
    "        return labels\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Length in batches\n",
    "        \"\"\"\n",
    "        return self.n_batches\n",
    "\n",
    "    def __getitem__(self, b_ix):\n",
    "        \"\"\"\n",
    "        Produce batch, by batch index\n",
    "        \"\"\"\n",
    "\n",
    "        assert b_ix < self.n_batches\n",
    "\n",
    "        b_X = np.zeros(\n",
    "            (self.batch_size, self.target_image_size[0], self.target_image_size[1], 3),\n",
    "            dtype=np.uint8,\n",
    "        )\n",
    "\n",
    "        b_Y = np.zeros(\n",
    "            (self.batch_size, self.df[feature_columns].shape[1]),\n",
    "            dtype=np.uint8,\n",
    "        )\n",
    "\n",
    "        for i in range(self.batch_size):\n",
    "            b_X[i], b_Y[i] = self.get_one(\n",
    "                i + self.batch_size * b_ix,\n",
    "            )\n",
    "\n",
    "        return (b_X, b_Y)\n",
    "\n",
    "    def get_one(self, one_ix):\n",
    "        \"\"\"\n",
    "        Get single item by absolute index\n",
    "        \"\"\"\n",
    "        id = self.labels[one_ix][0]\n",
    "        src_file = self.images_dir + id\n",
    "\n",
    "        # read file\n",
    "        x = np.load(src_file)\n",
    "        if self.crop:\n",
    "            coord = self.df[self.df[\"image\"] == id][\n",
    "                [\"x_min\", \"y_min\", \"x_max\", \"y_max\"]\n",
    "            ].values[0]\n",
    "            orig_hight = x.shape[0]\n",
    "            orig_width = x.shape[1]\n",
    "            x_min = coord[0]\n",
    "            y_min = coord[1]\n",
    "            x_max = coord[2]\n",
    "            y_max = coord[3]\n",
    "            x = x[\n",
    "                np.int(y_min * orig_hight) : np.int(y_max * orig_hight),\n",
    "                np.int(x_min * orig_width) : np.int(x_max * orig_width),\n",
    "            ]\n",
    "\n",
    "        y = self.labels[one_ix][1]\n",
    "\n",
    "        # augment\n",
    "        if self.augment:\n",
    "            x = self._augment_image(x)\n",
    "\n",
    "        # normalize (sample-wise)\n",
    "        if self.normalize:\n",
    "            x = x.astype(np.float32)\n",
    "            x = x - np.mean(x, axis=(0, 1))\n",
    "            x = x / np.std(x, axis=(0, 1))\n",
    "        return x.astype(np.uint8), y\n",
    "\n",
    "    def _augment_image(self, x):\n",
    "        \"\"\"\n",
    "        Randomply augment image\n",
    "        \"\"\"\n",
    "\n",
    "        x = transform(image=x)[\"image\"]\n",
    "        return x\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3090, compute capability 8.6\n"
     ]
    }
   ],
   "source": [
    "policy = keras.mixed_precision.experimental.Policy(\"mixed_float16\")\n",
    "keras.mixed_precision.experimental.set_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    inputs = keras.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "    base_model = keras.applications.EfficientNetB4(weights=None, include_top=False)\n",
    "    base_model.load_weights(\n",
    "        \"/app/_data/models/efficientnet-b4_noisy-student_notop.h5\",\n",
    "        by_name=True,\n",
    "        skip_mismatch=True,\n",
    "    )\n",
    "    x = base_model(inputs)\n",
    "#     x = keras.layers.GlobalAveragePooling2D(name=\"avg_pool\")(x)\n",
    "    x = keras.layers.Flatten(name=\"flatten\")(x)\n",
    "    outputs = keras.layers.Dense(NUM_CLASSES, activation=\"sigmoid\")(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=Adam(lr=0.0005),\n",
    "        metrics=[\n",
    "            \"acc\",\n",
    "            keras.metrics.Recall(),\n",
    "            keras.metrics.Precision(),\n",
    "            tfa.metrics.F1Score(num_classes=NUM_CLASSES, average=\"weighted\"),\n",
    "        ],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 380, 380, 3)]     0         \n",
      "_________________________________________________________________\n",
      "efficientnetb4 (Functional)  (None, None, None, 1792)  17673823  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 216832)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 1300998   \n",
      "=================================================================\n",
      "Total params: 18,974,821\n",
      "Trainable params: 18,849,614\n",
      "Non-trainable params: 125,207\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100\n",
      "  1/288 [..............................] - ETA: 0s - loss: 0.0532 - acc: 0.9464 - recall_1: 0.9344 - precision_1: 0.9344 - f1_score: 0.9369WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0834 - acc: 0.9116 - recall_1: 0.8954 - precision_1: 0.9192 - f1_score: 0.9001\n",
      "Epoch 00005: val_f1_score improved from -inf to 0.90221, saving model to /app/_data/models/final/Eff4Flatt/eff4_Flatt_1.h5\n",
      "288/288 [==============================] - 167s 579ms/step - loss: 0.0834 - acc: 0.9116 - recall_1: 0.8954 - precision_1: 0.9192 - f1_score: 0.9001 - val_loss: 0.0762 - val_acc: 0.9144 - val_recall_1: 0.9089 - val_precision_1: 0.9218 - val_f1_score: 0.9022\n",
      "Epoch 6/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0744 - acc: 0.9186 - recall_1: 0.9057 - precision_1: 0.9254 - f1_score: 0.9062\n",
      "Epoch 00006: val_f1_score improved from 0.90221 to 0.90551, saving model to /app/_data/models/final/Eff4Flatt/eff4_Flatt_1.h5\n",
      "288/288 [==============================] - 151s 525ms/step - loss: 0.0744 - acc: 0.9186 - recall_1: 0.9057 - precision_1: 0.9254 - f1_score: 0.9062 - val_loss: 0.0810 - val_acc: 0.9241 - val_recall_1: 0.9001 - val_precision_1: 0.9299 - val_f1_score: 0.9055\n",
      "Epoch 7/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0772 - acc: 0.9182 - recall_1: 0.9070 - precision_1: 0.9262 - f1_score: 0.9069\n",
      "Epoch 00007: val_f1_score improved from 0.90551 to 0.90726, saving model to /app/_data/models/final/Eff4Flatt/eff4_Flatt_1.h5\n",
      "288/288 [==============================] - 150s 521ms/step - loss: 0.0772 - acc: 0.9182 - recall_1: 0.9070 - precision_1: 0.9262 - f1_score: 0.9069 - val_loss: 0.0766 - val_acc: 0.9249 - val_recall_1: 0.9137 - val_precision_1: 0.9252 - val_f1_score: 0.9073\n",
      "Epoch 8/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0749 - acc: 0.9218 - recall_1: 0.9092 - precision_1: 0.9267 - f1_score: 0.9104\n",
      "Epoch 00008: val_f1_score improved from 0.90726 to 0.91250, saving model to /app/_data/models/final/Eff4Flatt/eff4_Flatt_1.h5\n",
      "288/288 [==============================] - 144s 501ms/step - loss: 0.0749 - acc: 0.9218 - recall_1: 0.9092 - precision_1: 0.9267 - f1_score: 0.9104 - val_loss: 0.0780 - val_acc: 0.9261 - val_recall_1: 0.9208 - val_precision_1: 0.9274 - val_f1_score: 0.9125\n",
      "Epoch 9/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0696 - acc: 0.9260 - recall_1: 0.9157 - precision_1: 0.9320 - f1_score: 0.9143\n",
      "Epoch 00009: val_f1_score did not improve from 0.91250\n",
      "288/288 [==============================] - 148s 512ms/step - loss: 0.0696 - acc: 0.9260 - recall_1: 0.9157 - precision_1: 0.9320 - f1_score: 0.9143 - val_loss: 0.0810 - val_acc: 0.9261 - val_recall_1: 0.9072 - val_precision_1: 0.9319 - val_f1_score: 0.9099\n",
      "Epoch 10/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0693 - acc: 0.9224 - recall_1: 0.9141 - precision_1: 0.9311 - f1_score: 0.9115\n",
      "Epoch 00010: val_f1_score did not improve from 0.91250\n",
      "288/288 [==============================] - 147s 511ms/step - loss: 0.0693 - acc: 0.9224 - recall_1: 0.9141 - precision_1: 0.9311 - f1_score: 0.9115 - val_loss: 0.0820 - val_acc: 0.9174 - val_recall_1: 0.9013 - val_precision_1: 0.9293 - val_f1_score: 0.9074\n",
      "Epoch 11/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0726 - acc: 0.9228 - recall_1: 0.9134 - precision_1: 0.9307 - f1_score: 0.9132\n",
      "Epoch 00011: val_f1_score did not improve from 0.91250\n",
      "288/288 [==============================] - 143s 497ms/step - loss: 0.0726 - acc: 0.9228 - recall_1: 0.9134 - precision_1: 0.9307 - f1_score: 0.9132 - val_loss: 0.1084 - val_acc: 0.9201 - val_recall_1: 0.8792 - val_precision_1: 0.9218 - val_f1_score: 0.8984\n",
      "Epoch 12/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0755 - acc: 0.9190 - recall_1: 0.9095 - precision_1: 0.9267 - f1_score: 0.9089\n",
      "Epoch 00012: val_f1_score improved from 0.91250 to 0.91286, saving model to /app/_data/models/final/Eff4Flatt/eff4_Flatt_1.h5\n",
      "288/288 [==============================] - 146s 507ms/step - loss: 0.0755 - acc: 0.9190 - recall_1: 0.9095 - precision_1: 0.9267 - f1_score: 0.9089 - val_loss: 0.0739 - val_acc: 0.9199 - val_recall_1: 0.9280 - val_precision_1: 0.9224 - val_f1_score: 0.9129\n",
      "Epoch 13/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0649 - acc: 0.9292 - recall_1: 0.9213 - precision_1: 0.9380 - f1_score: 0.9194\n",
      "Epoch 00013: val_f1_score did not improve from 0.91286\n",
      "288/288 [==============================] - 145s 502ms/step - loss: 0.0649 - acc: 0.9292 - recall_1: 0.9213 - precision_1: 0.9380 - f1_score: 0.9194 - val_loss: 0.1050 - val_acc: 0.9189 - val_recall_1: 0.8875 - val_precision_1: 0.9192 - val_f1_score: 0.8997\n",
      "Epoch 14/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0687 - acc: 0.9284 - recall_1: 0.9206 - precision_1: 0.9383 - f1_score: 0.9188\n",
      "Epoch 00014: val_f1_score did not improve from 0.91286\n",
      "288/288 [==============================] - 144s 501ms/step - loss: 0.0687 - acc: 0.9284 - recall_1: 0.9206 - precision_1: 0.9383 - f1_score: 0.9188 - val_loss: 0.1223 - val_acc: 0.9229 - val_recall_1: 0.8911 - val_precision_1: 0.9265 - val_f1_score: 0.9029\n",
      "Epoch 15/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0681 - acc: 0.9264 - recall_1: 0.9197 - precision_1: 0.9367 - f1_score: 0.9176\n",
      "Epoch 00015: val_f1_score did not improve from 0.91286\n",
      "288/288 [==============================] - 146s 508ms/step - loss: 0.0681 - acc: 0.9264 - recall_1: 0.9197 - precision_1: 0.9367 - f1_score: 0.9176 - val_loss: 0.0967 - val_acc: 0.9187 - val_recall_1: 0.9096 - val_precision_1: 0.9303 - val_f1_score: 0.9065\n",
      "Epoch 16/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0905 - acc: 0.9137 - recall_1: 0.9035 - precision_1: 0.9182 - f1_score: 0.9042\n",
      "Epoch 00016: val_f1_score did not improve from 0.91286\n",
      "288/288 [==============================] - 145s 504ms/step - loss: 0.0905 - acc: 0.9137 - recall_1: 0.9035 - precision_1: 0.9182 - f1_score: 0.9042 - val_loss: 1.4917 - val_acc: 0.5667 - val_recall_1: 0.5869 - val_precision_1: 0.5906 - val_f1_score: 0.5458\n",
      "Epoch 17/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.1486 - acc: 0.8759 - recall_1: 0.8571 - precision_1: 0.8831 - f1_score: 0.8672\n",
      "Epoch 00017: val_f1_score did not improve from 0.91286\n",
      "288/288 [==============================] - 141s 489ms/step - loss: 0.1486 - acc: 0.8759 - recall_1: 0.8571 - precision_1: 0.8831 - f1_score: 0.8672 - val_loss: 0.0940 - val_acc: 0.9050 - val_recall_1: 0.9128 - val_precision_1: 0.9145 - val_f1_score: 0.9042\n",
      "Epoch 18/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0734 - acc: 0.9190 - recall_1: 0.9112 - precision_1: 0.9278 - f1_score: 0.9101\n",
      "Epoch 00018: val_f1_score improved from 0.91286 to 0.91380, saving model to /app/_data/models/final/Eff4Flatt/eff4_Flatt_1.h5\n",
      "288/288 [==============================] - 146s 508ms/step - loss: 0.0734 - acc: 0.9190 - recall_1: 0.9112 - precision_1: 0.9278 - f1_score: 0.9101 - val_loss: 0.0765 - val_acc: 0.9313 - val_recall_1: 0.9160 - val_precision_1: 0.9349 - val_f1_score: 0.9138\n",
      "Epoch 19/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0643 - acc: 0.9293 - recall_1: 0.9245 - precision_1: 0.9384 - f1_score: 0.9192\n",
      "Epoch 00019: val_f1_score did not improve from 0.91380\n",
      "288/288 [==============================] - 141s 490ms/step - loss: 0.0643 - acc: 0.9293 - recall_1: 0.9245 - precision_1: 0.9384 - f1_score: 0.9192 - val_loss: 0.0954 - val_acc: 0.9177 - val_recall_1: 0.8983 - val_precision_1: 0.9223 - val_f1_score: 0.9022\n",
      "Epoch 20/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0574 - acc: 0.9332 - recall_1: 0.9309 - precision_1: 0.9422 - f1_score: 0.9239\n",
      "Epoch 00020: val_f1_score did not improve from 0.91380\n",
      "288/288 [==============================] - 142s 494ms/step - loss: 0.0574 - acc: 0.9332 - recall_1: 0.9309 - precision_1: 0.9422 - f1_score: 0.9239 - val_loss: 0.0814 - val_acc: 0.9325 - val_recall_1: 0.9052 - val_precision_1: 0.9248 - val_f1_score: 0.9114\n",
      "Epoch 21/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0553 - acc: 0.9343 - recall_1: 0.9351 - precision_1: 0.9461 - f1_score: 0.9267\n",
      "Epoch 00021: val_f1_score improved from 0.91380 to 0.91611, saving model to /app/_data/models/final/Eff4Flatt/eff4_Flatt_1.h5\n",
      "288/288 [==============================] - 145s 502ms/step - loss: 0.0553 - acc: 0.9343 - recall_1: 0.9351 - precision_1: 0.9461 - f1_score: 0.9267 - val_loss: 0.0866 - val_acc: 0.9239 - val_recall_1: 0.9192 - val_precision_1: 0.9299 - val_f1_score: 0.9161\n",
      "Epoch 22/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0522 - acc: 0.9364 - recall_1: 0.9376 - precision_1: 0.9472 - f1_score: 0.9290\n",
      "Epoch 00022: val_f1_score did not improve from 0.91611\n",
      "288/288 [==============================] - 142s 493ms/step - loss: 0.0522 - acc: 0.9364 - recall_1: 0.9376 - precision_1: 0.9472 - f1_score: 0.9290 - val_loss: 0.0886 - val_acc: 0.9271 - val_recall_1: 0.9390 - val_precision_1: 0.9115 - val_f1_score: 0.9139\n",
      "Epoch 23/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0506 - acc: 0.9376 - recall_1: 0.9410 - precision_1: 0.9507 - f1_score: 0.9292\n",
      "Epoch 00023: val_f1_score did not improve from 0.91611\n",
      "288/288 [==============================] - 145s 504ms/step - loss: 0.0506 - acc: 0.9376 - recall_1: 0.9410 - precision_1: 0.9507 - f1_score: 0.9292 - val_loss: 0.0966 - val_acc: 0.9221 - val_recall_1: 0.9158 - val_precision_1: 0.9232 - val_f1_score: 0.9068\n",
      "Epoch 24/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0502 - acc: 0.9415 - recall_1: 0.9420 - precision_1: 0.9513 - f1_score: 0.9310\n",
      "Epoch 00024: val_f1_score did not improve from 0.91611\n",
      "288/288 [==============================] - 142s 494ms/step - loss: 0.0502 - acc: 0.9415 - recall_1: 0.9420 - precision_1: 0.9513 - f1_score: 0.9310 - val_loss: 0.1167 - val_acc: 0.9196 - val_recall_1: 0.8863 - val_precision_1: 0.9275 - val_f1_score: 0.8988\n",
      "Epoch 25/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0475 - acc: 0.9384 - recall_1: 0.9435 - precision_1: 0.9540 - f1_score: 0.9324\n",
      "Epoch 00025: val_f1_score did not improve from 0.91611\n",
      "288/288 [==============================] - 145s 503ms/step - loss: 0.0475 - acc: 0.9384 - recall_1: 0.9435 - precision_1: 0.9540 - f1_score: 0.9324 - val_loss: 0.0961 - val_acc: 0.9139 - val_recall_1: 0.9245 - val_precision_1: 0.9121 - val_f1_score: 0.9064\n",
      "Epoch 26/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0478 - acc: 0.9407 - recall_1: 0.9461 - precision_1: 0.9539 - f1_score: 0.9325\n",
      "Epoch 00026: val_f1_score did not improve from 0.91611\n",
      "288/288 [==============================] - 143s 495ms/step - loss: 0.0478 - acc: 0.9407 - recall_1: 0.9461 - precision_1: 0.9539 - f1_score: 0.9325 - val_loss: 0.1059 - val_acc: 0.9127 - val_recall_1: 0.9049 - val_precision_1: 0.9191 - val_f1_score: 0.8968\n",
      "Epoch 27/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0509 - acc: 0.9413 - recall_1: 0.9443 - precision_1: 0.9528 - f1_score: 0.9337\n",
      "Epoch 00027: val_f1_score did not improve from 0.91611\n",
      "288/288 [==============================] - 146s 505ms/step - loss: 0.0509 - acc: 0.9413 - recall_1: 0.9443 - precision_1: 0.9528 - f1_score: 0.9337 - val_loss: 0.1460 - val_acc: 0.9107 - val_recall_1: 0.9206 - val_precision_1: 0.9056 - val_f1_score: 0.9029\n",
      "Epoch 28/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0508 - acc: 0.9404 - recall_1: 0.9432 - precision_1: 0.9529 - f1_score: 0.9319\n",
      "Epoch 00028: val_f1_score did not improve from 0.91611\n",
      "288/288 [==============================] - 144s 501ms/step - loss: 0.0508 - acc: 0.9404 - recall_1: 0.9432 - precision_1: 0.9529 - f1_score: 0.9319 - val_loss: 0.1022 - val_acc: 0.9092 - val_recall_1: 0.9257 - val_precision_1: 0.8978 - val_f1_score: 0.9049\n",
      "Epoch 29/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0426 - acc: 0.9456 - recall_1: 0.9522 - precision_1: 0.9598 - f1_score: 0.9382\n",
      "Epoch 00029: val_f1_score did not improve from 0.91611\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0004500000213738531.\n",
      "288/288 [==============================] - 145s 502ms/step - loss: 0.0426 - acc: 0.9456 - recall_1: 0.9522 - precision_1: 0.9598 - f1_score: 0.9382 - val_loss: 0.2016 - val_acc: 0.8718 - val_recall_1: 0.8833 - val_precision_1: 0.8825 - val_f1_score: 0.8702\n",
      "Epoch 30/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0636 - acc: 0.9289 - recall_1: 0.9344 - precision_1: 0.9452 - f1_score: 0.9247\n",
      "Epoch 00030: val_f1_score did not improve from 0.91611\n",
      "288/288 [==============================] - 145s 504ms/step - loss: 0.0636 - acc: 0.9289 - recall_1: 0.9344 - precision_1: 0.9452 - f1_score: 0.9247 - val_loss: 0.1937 - val_acc: 0.9095 - val_recall_1: 0.9068 - val_precision_1: 0.9080 - val_f1_score: 0.8933\n",
      "Epoch 31/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0507 - acc: 0.9395 - recall_1: 0.9455 - precision_1: 0.9549 - f1_score: 0.9318\n",
      "Epoch 00031: val_f1_score did not improve from 0.91611\n",
      "288/288 [==============================] - 142s 494ms/step - loss: 0.0507 - acc: 0.9395 - recall_1: 0.9455 - precision_1: 0.9549 - f1_score: 0.9318 - val_loss: 0.1039 - val_acc: 0.9164 - val_recall_1: 0.9167 - val_precision_1: 0.9252 - val_f1_score: 0.9056\n",
      "Epoch 32/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0576 - acc: 0.9407 - recall_1: 0.9447 - precision_1: 0.9536 - f1_score: 0.9333Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00032: val_f1_score did not improve from 0.91611\n",
      "288/288 [==============================] - 147s 512ms/step - loss: 0.0576 - acc: 0.9407 - recall_1: 0.9447 - precision_1: 0.9536 - f1_score: 0.9333 - val_loss: 0.1716 - val_acc: 0.9038 - val_recall_1: 0.9236 - val_precision_1: 0.8912 - val_f1_score: 0.8965\n",
      "Epoch 00032: early stopping\n",
      "Epoch 1/100\n",
      "  2/288 [..............................] - ETA: 8:17 - loss: 1.0461 - acc: 0.2589 - recall: 0.2459 - precision: 0.1796 - f1_score: 0.2617WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.3836s vs `on_train_batch_end` time: 3.0965s). Check your callbacks.\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.2649 - acc: 0.7873 - recall: 0.7500 - precision: 0.7791 - f1_score: 0.7743\n",
      "Epoch 00001: val_f1_score improved from -inf to 0.74884, saving model to /app/_data/models/final/Eff4Flatt/eff4_Flatt_2.h5\n",
      "288/288 [==============================] - 154s 535ms/step - loss: 0.2649 - acc: 0.7873 - recall: 0.7500 - precision: 0.7791 - f1_score: 0.7743 - val_loss: 0.4426 - val_acc: 0.7629 - val_recall: 0.7425 - val_precision: 0.7598 - val_f1_score: 0.7488\n",
      "Epoch 2/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.1539 - acc: 0.8667 - recall: 0.8412 - precision: 0.8652 - f1_score: 0.8540\n",
      "Epoch 00002: val_f1_score improved from 0.74884 to 0.87201, saving model to /app/_data/models/final/Eff4Flatt/eff4_Flatt_2.h5\n",
      "288/288 [==============================] - 145s 503ms/step - loss: 0.1539 - acc: 0.8667 - recall: 0.8412 - precision: 0.8652 - f1_score: 0.8540 - val_loss: 0.1308 - val_acc: 0.8891 - val_recall: 0.8741 - val_precision: 0.8833 - val_f1_score: 0.8720\n",
      "Epoch 3/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.1292 - acc: 0.8881 - recall: 0.8609 - precision: 0.8830 - f1_score: 0.8758\n",
      "Epoch 00003: val_f1_score improved from 0.87201 to 0.88730, saving model to /app/_data/models/final/Eff4Flatt/eff4_Flatt_2.h5\n",
      "288/288 [==============================] - 146s 506ms/step - loss: 0.1292 - acc: 0.8881 - recall: 0.8609 - precision: 0.8830 - f1_score: 0.8758 - val_loss: 0.1091 - val_acc: 0.9010 - val_recall: 0.8868 - val_precision: 0.8975 - val_f1_score: 0.8873\n",
      "Epoch 4/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.1225 - acc: 0.8904 - recall: 0.8673 - precision: 0.8903 - f1_score: 0.8787\n",
      "Epoch 00004: val_f1_score did not improve from 0.88730\n",
      "288/288 [==============================] - 141s 490ms/step - loss: 0.1225 - acc: 0.8904 - recall: 0.8673 - precision: 0.8903 - f1_score: 0.8787 - val_loss: 0.1104 - val_acc: 0.8963 - val_recall: 0.8833 - val_precision: 0.8777 - val_f1_score: 0.8785\n",
      "Epoch 5/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.1063 - acc: 0.8986 - recall: 0.8795 - precision: 0.9008 - f1_score: 0.8881\n",
      "Epoch 00005: val_f1_score did not improve from 0.88730\n",
      "288/288 [==============================] - 143s 495ms/step - loss: 0.1063 - acc: 0.8986 - recall: 0.8795 - precision: 0.9008 - f1_score: 0.8881 - val_loss: 0.1094 - val_acc: 0.8991 - val_recall: 0.9303 - val_precision: 0.8438 - val_f1_score: 0.8857\n",
      "Epoch 6/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0957 - acc: 0.9075 - recall: 0.8909 - precision: 0.9111 - f1_score: 0.8973\n",
      "Epoch 00006: val_f1_score improved from 0.88730 to 0.89696, saving model to /app/_data/models/final/Eff4Flatt/eff4_Flatt_2.h5\n",
      "288/288 [==============================] - 145s 504ms/step - loss: 0.0957 - acc: 0.9075 - recall: 0.8909 - precision: 0.9111 - f1_score: 0.8973 - val_loss: 0.1006 - val_acc: 0.9030 - val_recall: 0.8759 - val_precision: 0.9315 - val_f1_score: 0.8970\n",
      "Epoch 7/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.1012 - acc: 0.9050 - recall: 0.8871 - precision: 0.9102 - f1_score: 0.8949\n",
      "Epoch 00007: val_f1_score did not improve from 0.89696\n",
      "288/288 [==============================] - 149s 518ms/step - loss: 0.1012 - acc: 0.9050 - recall: 0.8871 - precision: 0.9102 - f1_score: 0.8949 - val_loss: 0.1302 - val_acc: 0.8690 - val_recall: 0.8638 - val_precision: 0.9070 - val_f1_score: 0.8599\n",
      "Epoch 8/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0992 - acc: 0.9035 - recall: 0.8897 - precision: 0.9087 - f1_score: 0.8937\n",
      "Epoch 00008: val_f1_score did not improve from 0.89696\n",
      "288/288 [==============================] - 144s 502ms/step - loss: 0.0992 - acc: 0.9035 - recall: 0.8897 - precision: 0.9087 - f1_score: 0.8937 - val_loss: 0.0964 - val_acc: 0.8988 - val_recall: 0.8776 - val_precision: 0.9131 - val_f1_score: 0.8831\n",
      "Epoch 9/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.1114 - acc: 0.8974 - recall: 0.8780 - precision: 0.9008 - f1_score: 0.8872\n",
      "Epoch 00009: val_f1_score did not improve from 0.89696\n",
      "288/288 [==============================] - 141s 488ms/step - loss: 0.1114 - acc: 0.8974 - recall: 0.8780 - precision: 0.9008 - f1_score: 0.8872 - val_loss: 0.1287 - val_acc: 0.8631 - val_recall: 0.8352 - val_precision: 0.9222 - val_f1_score: 0.8620\n",
      "Epoch 10/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0902 - acc: 0.9080 - recall: 0.8934 - precision: 0.9151 - f1_score: 0.8982\n",
      "Epoch 00010: val_f1_score did not improve from 0.89696\n",
      "288/288 [==============================] - 140s 486ms/step - loss: 0.0902 - acc: 0.9080 - recall: 0.8934 - precision: 0.9151 - f1_score: 0.8982 - val_loss: 0.1036 - val_acc: 0.8924 - val_recall: 0.8987 - val_precision: 0.9081 - val_f1_score: 0.8898\n",
      "Epoch 11/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0907 - acc: 0.9087 - recall: 0.8959 - precision: 0.9163 - f1_score: 0.8987\n",
      "Epoch 00011: val_f1_score did not improve from 0.89696\n",
      "288/288 [==============================] - 146s 507ms/step - loss: 0.0907 - acc: 0.9087 - recall: 0.8959 - precision: 0.9163 - f1_score: 0.8987 - val_loss: 0.1155 - val_acc: 0.8849 - val_recall: 0.9010 - val_precision: 0.8849 - val_f1_score: 0.8840\n",
      "Epoch 12/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0882 - acc: 0.9094 - recall: 0.8992 - precision: 0.9172 - f1_score: 0.8997\n",
      "Epoch 00012: val_f1_score did not improve from 0.89696\n",
      "288/288 [==============================] - 143s 498ms/step - loss: 0.0882 - acc: 0.9094 - recall: 0.8992 - precision: 0.9172 - f1_score: 0.8997 - val_loss: 0.1248 - val_acc: 0.8725 - val_recall: 0.8603 - val_precision: 0.9180 - val_f1_score: 0.8707\n",
      "Epoch 13/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0839 - acc: 0.9125 - recall: 0.9016 - precision: 0.9214 - f1_score: 0.9035\n",
      "Epoch 00013: val_f1_score did not improve from 0.89696\n",
      "288/288 [==============================] - 144s 499ms/step - loss: 0.0839 - acc: 0.9125 - recall: 0.9016 - precision: 0.9214 - f1_score: 0.9035 - val_loss: 0.0970 - val_acc: 0.9000 - val_recall: 0.8875 - val_precision: 0.9310 - val_f1_score: 0.8929\n",
      "Epoch 14/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0958 - acc: 0.9115 - recall: 0.8973 - precision: 0.9166 - f1_score: 0.9019\n",
      "Epoch 00014: val_f1_score did not improve from 0.89696\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0004500000213738531.\n",
      "288/288 [==============================] - 141s 491ms/step - loss: 0.0958 - acc: 0.9115 - recall: 0.8973 - precision: 0.9166 - f1_score: 0.9019 - val_loss: 0.2305 - val_acc: 0.8279 - val_recall: 0.8759 - val_precision: 0.8238 - val_f1_score: 0.8278\n",
      "Epoch 15/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.1181 - acc: 0.8911 - recall: 0.8750 - precision: 0.8994 - f1_score: 0.8818\n",
      "Epoch 00015: val_f1_score did not improve from 0.89696\n",
      "288/288 [==============================] - 147s 509ms/step - loss: 0.1181 - acc: 0.8911 - recall: 0.8750 - precision: 0.8994 - f1_score: 0.8818 - val_loss: 0.1097 - val_acc: 0.8946 - val_recall: 0.9169 - val_precision: 0.8941 - val_f1_score: 0.8878\n",
      "Epoch 16/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0946 - acc: 0.9088 - recall: 0.8960 - precision: 0.9158 - f1_score: 0.8996\n",
      "Epoch 00016: val_f1_score did not improve from 0.89696\n",
      "288/288 [==============================] - 142s 493ms/step - loss: 0.0946 - acc: 0.9088 - recall: 0.8960 - precision: 0.9158 - f1_score: 0.8996 - val_loss: 0.1494 - val_acc: 0.8869 - val_recall: 0.8488 - val_precision: 0.8908 - val_f1_score: 0.8676\n",
      "Epoch 17/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0997 - acc: 0.9066 - recall: 0.8931 - precision: 0.9116 - f1_score: 0.8984Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00017: val_f1_score did not improve from 0.89696\n",
      "288/288 [==============================] - 142s 493ms/step - loss: 0.0997 - acc: 0.9066 - recall: 0.8931 - precision: 0.9116 - f1_score: 0.8984 - val_loss: 0.1027 - val_acc: 0.8998 - val_recall: 0.8941 - val_precision: 0.8937 - val_f1_score: 0.8867\n",
      "Epoch 00017: early stopping\n",
      "Epoch 1/100\n",
      "  2/288 [..............................] - ETA: 8:12 - loss: 1.2122 - acc: 0.1964 - recall: 0.2734 - precision: 0.1768 - f1_score: 0.2312WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4551s vs `on_train_batch_end` time: 2.9720s). Check your callbacks.\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.2376 - acc: 0.7917 - recall: 0.7580 - precision: 0.7911 - f1_score: 0.7812\n",
      "Epoch 00001: val_f1_score improved from -inf to 0.83737, saving model to /app/_data/models/final/Eff4Flatt/eff4_Flatt_3.h5\n",
      "288/288 [==============================] - 152s 526ms/step - loss: 0.2376 - acc: 0.7917 - recall: 0.7580 - precision: 0.7911 - f1_score: 0.7812 - val_loss: 0.1711 - val_acc: 0.8467 - val_recall: 0.8130 - val_precision: 0.8574 - val_f1_score: 0.8374\n",
      "Epoch 2/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.1395 - acc: 0.8727 - recall: 0.8458 - precision: 0.8740 - f1_score: 0.8609\n",
      "Epoch 00002: val_f1_score improved from 0.83737 to 0.88217, saving model to /app/_data/models/final/Eff4Flatt/eff4_Flatt_3.h5\n",
      "288/288 [==============================] - 145s 502ms/step - loss: 0.1395 - acc: 0.8727 - recall: 0.8458 - precision: 0.8740 - f1_score: 0.8609 - val_loss: 0.1165 - val_acc: 0.8904 - val_recall: 0.8967 - val_precision: 0.8774 - val_f1_score: 0.8822\n",
      "Epoch 3/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.1164 - acc: 0.8890 - recall: 0.8692 - precision: 0.8922 - f1_score: 0.8776\n",
      "Epoch 00003: val_f1_score did not improve from 0.88217\n",
      "288/288 [==============================] - 146s 507ms/step - loss: 0.1164 - acc: 0.8890 - recall: 0.8692 - precision: 0.8922 - f1_score: 0.8776 - val_loss: 0.1187 - val_acc: 0.8899 - val_recall: 0.8775 - val_precision: 0.8905 - val_f1_score: 0.8789\n",
      "Epoch 4/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.1059 - acc: 0.8930 - recall: 0.8744 - precision: 0.8977 - f1_score: 0.8817\n",
      "Epoch 00004: val_f1_score did not improve from 0.88217\n",
      "288/288 [==============================] - 137s 475ms/step - loss: 0.1059 - acc: 0.8930 - recall: 0.8744 - precision: 0.8977 - f1_score: 0.8817 - val_loss: 0.1242 - val_acc: 0.8738 - val_recall: 0.8835 - val_precision: 0.8774 - val_f1_score: 0.8744\n",
      "Epoch 5/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0922 - acc: 0.9036 - recall: 0.8881 - precision: 0.9116 - f1_score: 0.8928\n",
      "Epoch 00005: val_f1_score improved from 0.88217 to 0.88317, saving model to /app/_data/models/final/Eff4Flatt/eff4_Flatt_3.h5\n",
      "288/288 [==============================] - 145s 504ms/step - loss: 0.0922 - acc: 0.9036 - recall: 0.8881 - precision: 0.9116 - f1_score: 0.8928 - val_loss: 0.1057 - val_acc: 0.9003 - val_recall: 0.9041 - val_precision: 0.8781 - val_f1_score: 0.8832\n",
      "Epoch 6/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0920 - acc: 0.9074 - recall: 0.8918 - precision: 0.9098 - f1_score: 0.8968\n",
      "Epoch 00006: val_f1_score improved from 0.88317 to 0.89690, saving model to /app/_data/models/final/Eff4Flatt/eff4_Flatt_3.h5\n",
      "288/288 [==============================] - 145s 502ms/step - loss: 0.0920 - acc: 0.9074 - recall: 0.8918 - precision: 0.9098 - f1_score: 0.8968 - val_loss: 0.1062 - val_acc: 0.9127 - val_recall: 0.9002 - val_precision: 0.9197 - val_f1_score: 0.8969\n",
      "Epoch 7/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0835 - acc: 0.9108 - recall: 0.8969 - precision: 0.9189 - f1_score: 0.9004\n",
      "Epoch 00007: val_f1_score improved from 0.89690 to 0.90175, saving model to /app/_data/models/final/Eff4Flatt/eff4_Flatt_3.h5\n",
      "288/288 [==============================] - 148s 515ms/step - loss: 0.0835 - acc: 0.9108 - recall: 0.8969 - precision: 0.9189 - f1_score: 0.9004 - val_loss: 0.0942 - val_acc: 0.9179 - val_recall: 0.9295 - val_precision: 0.8774 - val_f1_score: 0.9017\n",
      "Epoch 8/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0823 - acc: 0.9151 - recall: 0.9033 - precision: 0.9197 - f1_score: 0.9055\n",
      "Epoch 00008: val_f1_score did not improve from 0.90175\n",
      "288/288 [==============================] - 146s 507ms/step - loss: 0.0823 - acc: 0.9151 - recall: 0.9033 - precision: 0.9197 - f1_score: 0.9055 - val_loss: 0.1206 - val_acc: 0.8879 - val_recall: 0.8831 - val_precision: 0.8948 - val_f1_score: 0.8694\n",
      "Epoch 9/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0853 - acc: 0.9128 - recall: 0.9030 - precision: 0.9201 - f1_score: 0.9020\n",
      "Epoch 00009: val_f1_score did not improve from 0.90175\n",
      "288/288 [==============================] - 146s 506ms/step - loss: 0.0853 - acc: 0.9128 - recall: 0.9030 - precision: 0.9201 - f1_score: 0.9020 - val_loss: 0.1015 - val_acc: 0.9112 - val_recall: 0.8960 - val_precision: 0.9109 - val_f1_score: 0.8959\n",
      "Epoch 10/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0747 - acc: 0.9200 - recall: 0.9089 - precision: 0.9274 - f1_score: 0.9104\n",
      "Epoch 00010: val_f1_score improved from 0.90175 to 0.90267, saving model to /app/_data/models/final/Eff4Flatt/eff4_Flatt_3.h5\n",
      "288/288 [==============================] - 143s 497ms/step - loss: 0.0747 - acc: 0.9200 - recall: 0.9089 - precision: 0.9274 - f1_score: 0.9104 - val_loss: 0.1035 - val_acc: 0.9216 - val_recall: 0.8856 - val_precision: 0.9267 - val_f1_score: 0.9027\n",
      "Epoch 11/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0744 - acc: 0.9202 - recall: 0.9133 - precision: 0.9302 - f1_score: 0.9123\n",
      "Epoch 00011: val_f1_score did not improve from 0.90267\n",
      "288/288 [==============================] - 143s 496ms/step - loss: 0.0744 - acc: 0.9202 - recall: 0.9133 - precision: 0.9302 - f1_score: 0.9123 - val_loss: 0.1134 - val_acc: 0.9020 - val_recall: 0.9161 - val_precision: 0.8697 - val_f1_score: 0.8819\n",
      "Epoch 12/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0737 - acc: 0.9200 - recall: 0.9153 - precision: 0.9279 - f1_score: 0.9112\n",
      "Epoch 00012: val_f1_score did not improve from 0.90267\n",
      "288/288 [==============================] - 143s 497ms/step - loss: 0.0737 - acc: 0.9200 - recall: 0.9153 - precision: 0.9279 - f1_score: 0.9112 - val_loss: 0.1283 - val_acc: 0.8812 - val_recall: 0.8782 - val_precision: 0.8879 - val_f1_score: 0.8682\n",
      "Epoch 13/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0701 - acc: 0.9231 - recall: 0.9199 - precision: 0.9341 - f1_score: 0.9165\n",
      "Epoch 00013: val_f1_score did not improve from 0.90267\n",
      "288/288 [==============================] - 139s 483ms/step - loss: 0.0701 - acc: 0.9231 - recall: 0.9199 - precision: 0.9341 - f1_score: 0.9165 - val_loss: 0.1370 - val_acc: 0.8782 - val_recall: 0.8662 - val_precision: 0.8850 - val_f1_score: 0.8706\n",
      "Epoch 14/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0674 - acc: 0.9261 - recall: 0.9208 - precision: 0.9362 - f1_score: 0.9180\n",
      "Epoch 00014: val_f1_score did not improve from 0.90267\n",
      "288/288 [==============================] - 142s 494ms/step - loss: 0.0674 - acc: 0.9261 - recall: 0.9208 - precision: 0.9362 - f1_score: 0.9180 - val_loss: 0.1074 - val_acc: 0.9080 - val_recall: 0.9085 - val_precision: 0.9068 - val_f1_score: 0.8964\n",
      "Epoch 15/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0593 - acc: 0.9294 - recall: 0.9298 - precision: 0.9417 - f1_score: 0.9232\n",
      "Epoch 00015: val_f1_score did not improve from 0.90267\n",
      "288/288 [==============================] - 143s 495ms/step - loss: 0.0593 - acc: 0.9294 - recall: 0.9298 - precision: 0.9417 - f1_score: 0.9232 - val_loss: 0.1157 - val_acc: 0.9023 - val_recall: 0.9129 - val_precision: 0.8975 - val_f1_score: 0.8910\n",
      "Epoch 16/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0571 - acc: 0.9324 - recall: 0.9339 - precision: 0.9463 - f1_score: 0.9255\n",
      "Epoch 00016: val_f1_score did not improve from 0.90267\n",
      "288/288 [==============================] - 141s 491ms/step - loss: 0.0571 - acc: 0.9324 - recall: 0.9339 - precision: 0.9463 - f1_score: 0.9255 - val_loss: 0.1087 - val_acc: 0.9110 - val_recall: 0.8969 - val_precision: 0.9098 - val_f1_score: 0.8959\n",
      "Epoch 17/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0614 - acc: 0.9310 - recall: 0.9302 - precision: 0.9434 - f1_score: 0.9240\n",
      "Epoch 00017: val_f1_score did not improve from 0.90267\n",
      "288/288 [==============================] - 146s 507ms/step - loss: 0.0614 - acc: 0.9310 - recall: 0.9302 - precision: 0.9434 - f1_score: 0.9240 - val_loss: 0.1409 - val_acc: 0.8792 - val_recall: 0.9089 - val_precision: 0.8290 - val_f1_score: 0.8706\n",
      "Epoch 18/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.1254 - acc: 0.8962 - recall: 0.8821 - precision: 0.9022 - f1_score: 0.8876\n",
      "Epoch 00018: val_f1_score did not improve from 0.90267\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0004500000213738531.\n",
      "288/288 [==============================] - 141s 489ms/step - loss: 0.1254 - acc: 0.8962 - recall: 0.8821 - precision: 0.9022 - f1_score: 0.8876 - val_loss: 0.1101 - val_acc: 0.9112 - val_recall: 0.9032 - val_precision: 0.9174 - val_f1_score: 0.9001\n",
      "Epoch 19/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0720 - acc: 0.9221 - recall: 0.9193 - precision: 0.9339 - f1_score: 0.9141\n",
      "Epoch 00019: val_f1_score did not improve from 0.90267\n",
      "288/288 [==============================] - 142s 492ms/step - loss: 0.0720 - acc: 0.9221 - recall: 0.9193 - precision: 0.9339 - f1_score: 0.9141 - val_loss: 0.0891 - val_acc: 0.9033 - val_recall: 0.9247 - val_precision: 0.8975 - val_f1_score: 0.8983\n",
      "Epoch 20/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0553 - acc: 0.9332 - recall: 0.9360 - precision: 0.9471 - f1_score: 0.9265\n",
      "Epoch 00020: val_f1_score improved from 0.90267 to 0.90652, saving model to /app/_data/models/final/Eff4Flatt/eff4_Flatt_3.h5\n",
      "288/288 [==============================] - 143s 497ms/step - loss: 0.0553 - acc: 0.9332 - recall: 0.9360 - precision: 0.9471 - f1_score: 0.9265 - val_loss: 0.0949 - val_acc: 0.9239 - val_recall: 0.9223 - val_precision: 0.9085 - val_f1_score: 0.9065\n",
      "Epoch 21/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0500 - acc: 0.9369 - recall: 0.9415 - precision: 0.9507 - f1_score: 0.9301\n",
      "Epoch 00021: val_f1_score did not improve from 0.90652\n",
      "288/288 [==============================] - 145s 504ms/step - loss: 0.0500 - acc: 0.9369 - recall: 0.9415 - precision: 0.9507 - f1_score: 0.9301 - val_loss: 0.0965 - val_acc: 0.9169 - val_recall: 0.9436 - val_precision: 0.8851 - val_f1_score: 0.9018\n",
      "Epoch 22/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0455 - acc: 0.9404 - recall: 0.9450 - precision: 0.9537 - f1_score: 0.9333\n",
      "Epoch 00022: val_f1_score did not improve from 0.90652\n",
      "288/288 [==============================] - 142s 493ms/step - loss: 0.0455 - acc: 0.9404 - recall: 0.9450 - precision: 0.9537 - f1_score: 0.9333 - val_loss: 0.0983 - val_acc: 0.9137 - val_recall: 0.9184 - val_precision: 0.9119 - val_f1_score: 0.9047\n",
      "Epoch 23/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0488 - acc: 0.9372 - recall: 0.9430 - precision: 0.9525 - f1_score: 0.9313\n",
      "Epoch 00023: val_f1_score did not improve from 0.90652\n",
      "288/288 [==============================] - 144s 499ms/step - loss: 0.0488 - acc: 0.9372 - recall: 0.9430 - precision: 0.9525 - f1_score: 0.9313 - val_loss: 0.1062 - val_acc: 0.9134 - val_recall: 0.9173 - val_precision: 0.9145 - val_f1_score: 0.9028\n",
      "Epoch 24/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0451 - acc: 0.9407 - recall: 0.9472 - precision: 0.9570 - f1_score: 0.9350\n",
      "Epoch 00024: val_f1_score did not improve from 0.90652\n",
      "288/288 [==============================] - 138s 481ms/step - loss: 0.0451 - acc: 0.9407 - recall: 0.9472 - precision: 0.9570 - f1_score: 0.9350 - val_loss: 0.1060 - val_acc: 0.9110 - val_recall: 0.9119 - val_precision: 0.9053 - val_f1_score: 0.8983\n",
      "Epoch 25/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0384 - acc: 0.9481 - recall: 0.9556 - precision: 0.9619 - f1_score: 0.9400\n",
      "Epoch 00025: val_f1_score did not improve from 0.90652\n",
      "288/288 [==============================] - 145s 504ms/step - loss: 0.0384 - acc: 0.9481 - recall: 0.9556 - precision: 0.9619 - f1_score: 0.9400 - val_loss: 0.1088 - val_acc: 0.9246 - val_recall: 0.8965 - val_precision: 0.9316 - val_f1_score: 0.9063\n",
      "Epoch 26/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0384 - acc: 0.9486 - recall: 0.9545 - precision: 0.9634 - f1_score: 0.9417\n",
      "Epoch 00026: val_f1_score did not improve from 0.90652\n",
      "288/288 [==============================] - 146s 508ms/step - loss: 0.0384 - acc: 0.9486 - recall: 0.9545 - precision: 0.9634 - f1_score: 0.9417 - val_loss: 0.1331 - val_acc: 0.8938 - val_recall: 0.9267 - val_precision: 0.8833 - val_f1_score: 0.8918\n",
      "Epoch 27/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0397 - acc: 0.9482 - recall: 0.9556 - precision: 0.9613 - f1_score: 0.9416\n",
      "Epoch 00027: val_f1_score did not improve from 0.90652\n",
      "288/288 [==============================] - 140s 485ms/step - loss: 0.0397 - acc: 0.9482 - recall: 0.9556 - precision: 0.9613 - f1_score: 0.9416 - val_loss: 0.1646 - val_acc: 0.9033 - val_recall: 0.8727 - val_precision: 0.9181 - val_f1_score: 0.8881\n",
      "Epoch 28/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0449 - acc: 0.9441 - recall: 0.9518 - precision: 0.9588 - f1_score: 0.9377\n",
      "Epoch 00028: val_f1_score did not improve from 0.90652\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0004050000192364678.\n",
      "288/288 [==============================] - 143s 497ms/step - loss: 0.0449 - acc: 0.9441 - recall: 0.9518 - precision: 0.9588 - f1_score: 0.9377 - val_loss: 0.1424 - val_acc: 0.9015 - val_recall: 0.8835 - val_precision: 0.9025 - val_f1_score: 0.8872\n",
      "Epoch 29/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0344 - acc: 0.9507 - recall: 0.9620 - precision: 0.9669 - f1_score: 0.9444\n",
      "Epoch 00029: val_f1_score improved from 0.90652 to 0.91131, saving model to /app/_data/models/final/Eff4Flatt/eff4_Flatt_3.h5\n",
      "288/288 [==============================] - 145s 503ms/step - loss: 0.0344 - acc: 0.9507 - recall: 0.9620 - precision: 0.9669 - f1_score: 0.9444 - val_loss: 0.1230 - val_acc: 0.9226 - val_recall: 0.9323 - val_precision: 0.9051 - val_f1_score: 0.9113\n",
      "Epoch 30/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0317 - acc: 0.9518 - recall: 0.9643 - precision: 0.9688 - f1_score: 0.9474\n",
      "Epoch 00030: val_f1_score did not improve from 0.91131\n",
      "288/288 [==============================] - 137s 476ms/step - loss: 0.0317 - acc: 0.9518 - recall: 0.9643 - precision: 0.9688 - f1_score: 0.9474 - val_loss: 0.1205 - val_acc: 0.9216 - val_recall: 0.9119 - val_precision: 0.9265 - val_f1_score: 0.9083\n",
      "Epoch 31/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0286 - acc: 0.9550 - recall: 0.9664 - precision: 0.9711 - f1_score: 0.9484\n",
      "Epoch 00031: val_f1_score did not improve from 0.91131\n",
      "288/288 [==============================] - 141s 490ms/step - loss: 0.0286 - acc: 0.9550 - recall: 0.9664 - precision: 0.9711 - f1_score: 0.9484 - val_loss: 0.1290 - val_acc: 0.9152 - val_recall: 0.9154 - val_precision: 0.9125 - val_f1_score: 0.9048\n",
      "Epoch 32/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0479 - acc: 0.9466 - recall: 0.9545 - precision: 0.9594 - f1_score: 0.9393\n",
      "Epoch 00032: val_f1_score did not improve from 0.91131\n",
      "288/288 [==============================] - 140s 487ms/step - loss: 0.0479 - acc: 0.9466 - recall: 0.9545 - precision: 0.9594 - f1_score: 0.9393 - val_loss: 0.1983 - val_acc: 0.8760 - val_recall: 0.9237 - val_precision: 0.8250 - val_f1_score: 0.8634\n",
      "Epoch 33/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0516 - acc: 0.9398 - recall: 0.9456 - precision: 0.9548 - f1_score: 0.9339\n",
      "Epoch 00033: val_f1_score did not improve from 0.91131\n",
      "288/288 [==============================] - 143s 496ms/step - loss: 0.0516 - acc: 0.9398 - recall: 0.9456 - precision: 0.9548 - f1_score: 0.9339 - val_loss: 0.1195 - val_acc: 0.9107 - val_recall: 0.9198 - val_precision: 0.9137 - val_f1_score: 0.9045\n",
      "Epoch 34/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0293 - acc: 0.9521 - recall: 0.9671 - precision: 0.9697 - f1_score: 0.9480\n",
      "Epoch 00034: val_f1_score did not improve from 0.91131\n",
      "288/288 [==============================] - 143s 495ms/step - loss: 0.0293 - acc: 0.9521 - recall: 0.9671 - precision: 0.9697 - f1_score: 0.9480 - val_loss: 0.1153 - val_acc: 0.9194 - val_recall: 0.9173 - val_precision: 0.9143 - val_f1_score: 0.9078\n",
      "Epoch 35/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0261 - acc: 0.9541 - recall: 0.9708 - precision: 0.9749 - f1_score: 0.9487\n",
      "Epoch 00035: val_f1_score did not improve from 0.91131\n",
      "288/288 [==============================] - 145s 502ms/step - loss: 0.0261 - acc: 0.9541 - recall: 0.9708 - precision: 0.9749 - f1_score: 0.9487 - val_loss: 0.1171 - val_acc: 0.9072 - val_recall: 0.9066 - val_precision: 0.9228 - val_f1_score: 0.9023\n",
      "Epoch 36/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0253 - acc: 0.9527 - recall: 0.9721 - precision: 0.9758 - f1_score: 0.9513\n",
      "Epoch 00036: val_f1_score did not improve from 0.91131\n",
      "288/288 [==============================] - 144s 501ms/step - loss: 0.0253 - acc: 0.9527 - recall: 0.9721 - precision: 0.9758 - f1_score: 0.9513 - val_loss: 0.1366 - val_acc: 0.9127 - val_recall: 0.9226 - val_precision: 0.9067 - val_f1_score: 0.9060\n",
      "Epoch 37/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0246 - acc: 0.9563 - recall: 0.9742 - precision: 0.9774 - f1_score: 0.9541\n",
      "Epoch 00037: val_f1_score did not improve from 0.91131\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0003645000251708552.\n",
      "288/288 [==============================] - 141s 490ms/step - loss: 0.0246 - acc: 0.9563 - recall: 0.9742 - precision: 0.9774 - f1_score: 0.9541 - val_loss: 0.1280 - val_acc: 0.9204 - val_recall: 0.9221 - val_precision: 0.9112 - val_f1_score: 0.9059\n",
      "Epoch 38/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0218 - acc: 0.9576 - recall: 0.9761 - precision: 0.9791 - f1_score: 0.9548\n",
      "Epoch 00038: val_f1_score did not improve from 0.91131\n",
      "288/288 [==============================] - 143s 497ms/step - loss: 0.0218 - acc: 0.9576 - recall: 0.9761 - precision: 0.9791 - f1_score: 0.9548 - val_loss: 0.1574 - val_acc: 0.9132 - val_recall: 0.9200 - val_precision: 0.9116 - val_f1_score: 0.9027\n",
      "Epoch 39/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0213 - acc: 0.9565 - recall: 0.9762 - precision: 0.9798 - f1_score: 0.9535\n",
      "Epoch 00039: val_f1_score improved from 0.91131 to 0.91139, saving model to /app/_data/models/final/Eff4Flatt/eff4_Flatt_3.h5\n",
      "288/288 [==============================] - 146s 505ms/step - loss: 0.0213 - acc: 0.9565 - recall: 0.9762 - precision: 0.9798 - f1_score: 0.9535 - val_loss: 0.1314 - val_acc: 0.9219 - val_recall: 0.9163 - val_precision: 0.9299 - val_f1_score: 0.9114\n",
      "Epoch 40/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0217 - acc: 0.9616 - recall: 0.9784 - precision: 0.9799 - f1_score: 0.9575\n",
      "Epoch 00040: val_f1_score did not improve from 0.91139\n",
      "288/288 [==============================] - 145s 503ms/step - loss: 0.0217 - acc: 0.9616 - recall: 0.9784 - precision: 0.9799 - f1_score: 0.9575 - val_loss: 0.1800 - val_acc: 0.9090 - val_recall: 0.9006 - val_precision: 0.9154 - val_f1_score: 0.8959\n",
      "Epoch 41/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0287 - acc: 0.9561 - recall: 0.9709 - precision: 0.9746 - f1_score: 0.9514\n",
      "Epoch 00041: val_f1_score did not improve from 0.91139\n",
      "288/288 [==============================] - 146s 505ms/step - loss: 0.0287 - acc: 0.9561 - recall: 0.9709 - precision: 0.9746 - f1_score: 0.9514 - val_loss: 0.1528 - val_acc: 0.9100 - val_recall: 0.9189 - val_precision: 0.9034 - val_f1_score: 0.8998\n",
      "Epoch 42/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0196 - acc: 0.9598 - recall: 0.9795 - precision: 0.9810 - f1_score: 0.9564\n",
      "Epoch 00042: val_f1_score did not improve from 0.91139\n",
      "288/288 [==============================] - 144s 501ms/step - loss: 0.0196 - acc: 0.9598 - recall: 0.9795 - precision: 0.9810 - f1_score: 0.9564 - val_loss: 0.1499 - val_acc: 0.9154 - val_recall: 0.9191 - val_precision: 0.9132 - val_f1_score: 0.9077\n",
      "Epoch 43/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0183 - acc: 0.9598 - recall: 0.9794 - precision: 0.9833 - f1_score: 0.9590\n",
      "Epoch 00043: val_f1_score did not improve from 0.91139\n",
      "288/288 [==============================] - 146s 508ms/step - loss: 0.0183 - acc: 0.9598 - recall: 0.9794 - precision: 0.9833 - f1_score: 0.9590 - val_loss: 0.1477 - val_acc: 0.9206 - val_recall: 0.9029 - val_precision: 0.9256 - val_f1_score: 0.9080\n",
      "Epoch 44/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0198 - acc: 0.9617 - recall: 0.9789 - precision: 0.9815 - f1_score: 0.9583\n",
      "Epoch 00044: val_f1_score did not improve from 0.91139\n",
      "288/288 [==============================] - 142s 493ms/step - loss: 0.0198 - acc: 0.9617 - recall: 0.9789 - precision: 0.9815 - f1_score: 0.9583 - val_loss: 0.1476 - val_acc: 0.9144 - val_recall: 0.9198 - val_precision: 0.9045 - val_f1_score: 0.9014\n",
      "Epoch 45/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0180 - acc: 0.9639 - recall: 0.9807 - precision: 0.9814 - f1_score: 0.9593\n",
      "Epoch 00045: val_f1_score did not improve from 0.91139\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.0003280500357504934.\n",
      "288/288 [==============================] - 143s 496ms/step - loss: 0.0180 - acc: 0.9639 - recall: 0.9807 - precision: 0.9814 - f1_score: 0.9593 - val_loss: 0.1545 - val_acc: 0.9147 - val_recall: 0.9078 - val_precision: 0.9216 - val_f1_score: 0.9054\n",
      "Epoch 46/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0194 - acc: 0.9611 - recall: 0.9807 - precision: 0.9822 - f1_score: 0.9589\n",
      "Epoch 00046: val_f1_score did not improve from 0.91139\n",
      "288/288 [==============================] - 140s 486ms/step - loss: 0.0194 - acc: 0.9611 - recall: 0.9807 - precision: 0.9822 - f1_score: 0.9589 - val_loss: 0.1880 - val_acc: 0.9102 - val_recall: 0.9189 - val_precision: 0.9012 - val_f1_score: 0.9016\n",
      "Epoch 47/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0149 - acc: 0.9627 - recall: 0.9846 - precision: 0.9857 - f1_score: 0.9609\n",
      "Epoch 00047: val_f1_score did not improve from 0.91139\n",
      "288/288 [==============================] - 146s 507ms/step - loss: 0.0149 - acc: 0.9627 - recall: 0.9846 - precision: 0.9857 - f1_score: 0.9609 - val_loss: 0.1664 - val_acc: 0.9110 - val_recall: 0.9087 - val_precision: 0.9087 - val_f1_score: 0.8984\n",
      "Epoch 48/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0272 - acc: 0.9548 - recall: 0.9734 - precision: 0.9760 - f1_score: 0.9546\n",
      "Epoch 00048: val_f1_score did not improve from 0.91139\n",
      "288/288 [==============================] - 143s 497ms/step - loss: 0.0272 - acc: 0.9548 - recall: 0.9734 - precision: 0.9760 - f1_score: 0.9546 - val_loss: 0.1646 - val_acc: 0.9132 - val_recall: 0.9094 - val_precision: 0.9081 - val_f1_score: 0.9003\n",
      "Epoch 49/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0177 - acc: 0.9627 - recall: 0.9815 - precision: 0.9843 - f1_score: 0.9599\n",
      "Epoch 00049: val_f1_score did not improve from 0.91139\n",
      "288/288 [==============================] - 143s 495ms/step - loss: 0.0177 - acc: 0.9627 - recall: 0.9815 - precision: 0.9843 - f1_score: 0.9599 - val_loss: 0.1559 - val_acc: 0.9085 - val_recall: 0.9193 - val_precision: 0.9025 - val_f1_score: 0.9038\n",
      "Epoch 50/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0137 - acc: 0.9663 - recall: 0.9850 - precision: 0.9869 - f1_score: 0.9651Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00050: val_f1_score did not improve from 0.91139\n",
      "288/288 [==============================] - 144s 500ms/step - loss: 0.0137 - acc: 0.9663 - recall: 0.9850 - precision: 0.9869 - f1_score: 0.9651 - val_loss: 0.1709 - val_acc: 0.9206 - val_recall: 0.9198 - val_precision: 0.9154 - val_f1_score: 0.9110\n",
      "Epoch 00050: early stopping\n",
      "Epoch 1/100\n",
      "  2/288 [..............................] - ETA: 6:02 - loss: 1.2185 - acc: 0.2500 - recall: 0.2645 - precision: 0.2092 - f1_score: 0.2743WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.3821s vs `on_train_batch_end` time: 2.1506s). Check your callbacks.\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.2432 - acc: 0.7909 - recall: 0.7556 - precision: 0.7932 - f1_score: 0.7808\n",
      "Epoch 00001: val_f1_score improved from -inf to 0.86888, saving model to /app/_data/models/final/Eff4Flatt/eff4_Flatt_4.h5\n",
      "288/288 [==============================] - 151s 523ms/step - loss: 0.2432 - acc: 0.7909 - recall: 0.7556 - precision: 0.7932 - f1_score: 0.7808 - val_loss: 0.1509 - val_acc: 0.8805 - val_recall: 0.8601 - val_precision: 0.8893 - val_f1_score: 0.8689\n",
      "Epoch 2/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.1471 - acc: 0.8669 - recall: 0.8428 - precision: 0.8674 - f1_score: 0.8556\n",
      "Epoch 00002: val_f1_score improved from 0.86888 to 0.88746, saving model to /app/_data/models/final/Eff4Flatt/eff4_Flatt_4.h5\n",
      "288/288 [==============================] - 143s 496ms/step - loss: 0.1471 - acc: 0.8669 - recall: 0.8428 - precision: 0.8674 - f1_score: 0.8556 - val_loss: 0.1186 - val_acc: 0.9045 - val_recall: 0.8733 - val_precision: 0.8948 - val_f1_score: 0.8875\n",
      "Epoch 3/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.1166 - acc: 0.8833 - recall: 0.8651 - precision: 0.8885 - f1_score: 0.8731\n",
      "Epoch 00003: val_f1_score did not improve from 0.88746\n",
      "288/288 [==============================] - 144s 500ms/step - loss: 0.1166 - acc: 0.8833 - recall: 0.8651 - precision: 0.8885 - f1_score: 0.8731 - val_loss: 0.1150 - val_acc: 0.8936 - val_recall: 0.8950 - val_precision: 0.8780 - val_f1_score: 0.8862\n",
      "Epoch 4/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.1045 - acc: 0.8963 - recall: 0.8761 - precision: 0.9006 - f1_score: 0.8855\n",
      "Epoch 00004: val_f1_score improved from 0.88746 to 0.90488, saving model to /app/_data/models/final/Eff4Flatt/eff4_Flatt_4.h5\n",
      "288/288 [==============================] - 145s 505ms/step - loss: 0.1045 - acc: 0.8963 - recall: 0.8761 - precision: 0.9006 - f1_score: 0.8855 - val_loss: 0.0927 - val_acc: 0.9236 - val_recall: 0.9073 - val_precision: 0.9136 - val_f1_score: 0.9049\n",
      "Epoch 5/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0940 - acc: 0.9002 - recall: 0.8888 - precision: 0.9095 - f1_score: 0.8914\n",
      "Epoch 00005: val_f1_score did not improve from 0.90488\n",
      "288/288 [==============================] - 140s 488ms/step - loss: 0.0940 - acc: 0.9002 - recall: 0.8888 - precision: 0.9095 - f1_score: 0.8914 - val_loss: 0.1116 - val_acc: 0.8658 - val_recall: 0.8812 - val_precision: 0.8946 - val_f1_score: 0.8635\n",
      "Epoch 6/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0881 - acc: 0.9086 - recall: 0.8938 - precision: 0.9145 - f1_score: 0.8980\n",
      "Epoch 00006: val_f1_score did not improve from 0.90488\n",
      "288/288 [==============================] - 142s 494ms/step - loss: 0.0881 - acc: 0.9086 - recall: 0.8938 - precision: 0.9145 - f1_score: 0.8980 - val_loss: 0.0997 - val_acc: 0.9174 - val_recall: 0.9186 - val_precision: 0.8894 - val_f1_score: 0.9011\n",
      "Epoch 7/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0882 - acc: 0.9074 - recall: 0.8954 - precision: 0.9158 - f1_score: 0.8979\n",
      "Epoch 00007: val_f1_score did not improve from 0.90488\n",
      "288/288 [==============================] - 140s 487ms/step - loss: 0.0882 - acc: 0.9074 - recall: 0.8954 - precision: 0.9158 - f1_score: 0.8979 - val_loss: 0.1733 - val_acc: 0.8790 - val_recall: 0.8682 - val_precision: 0.8733 - val_f1_score: 0.8675\n",
      "Epoch 8/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0830 - acc: 0.9124 - recall: 0.9017 - precision: 0.9199 - f1_score: 0.9034\n",
      "Epoch 00008: val_f1_score did not improve from 0.90488\n",
      "288/288 [==============================] - 139s 484ms/step - loss: 0.0830 - acc: 0.9124 - recall: 0.9017 - precision: 0.9199 - f1_score: 0.9034 - val_loss: 0.0895 - val_acc: 0.9144 - val_recall: 0.9020 - val_precision: 0.9024 - val_f1_score: 0.8981\n",
      "Epoch 9/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0782 - acc: 0.9164 - recall: 0.9062 - precision: 0.9243 - f1_score: 0.9075\n",
      "Epoch 00009: val_f1_score did not improve from 0.90488\n",
      "288/288 [==============================] - 145s 502ms/step - loss: 0.0782 - acc: 0.9164 - recall: 0.9062 - precision: 0.9243 - f1_score: 0.9075 - val_loss: 0.1048 - val_acc: 0.8951 - val_recall: 0.9061 - val_precision: 0.8995 - val_f1_score: 0.8925\n",
      "Epoch 10/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0869 - acc: 0.9069 - recall: 0.8989 - precision: 0.9156 - f1_score: 0.8983\n",
      "Epoch 00010: val_f1_score did not improve from 0.90488\n",
      "288/288 [==============================] - 145s 504ms/step - loss: 0.0869 - acc: 0.9069 - recall: 0.8989 - precision: 0.9156 - f1_score: 0.8983 - val_loss: 0.1384 - val_acc: 0.9008 - val_recall: 0.8740 - val_precision: 0.9204 - val_f1_score: 0.8929\n",
      "Epoch 11/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0739 - acc: 0.9185 - recall: 0.9104 - precision: 0.9271 - f1_score: 0.9092\n",
      "Epoch 00011: val_f1_score did not improve from 0.90488\n",
      "288/288 [==============================] - 143s 496ms/step - loss: 0.0739 - acc: 0.9185 - recall: 0.9104 - precision: 0.9271 - f1_score: 0.9092 - val_loss: 0.0972 - val_acc: 0.9070 - val_recall: 0.9265 - val_precision: 0.9055 - val_f1_score: 0.9032\n",
      "Epoch 12/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0672 - acc: 0.9237 - recall: 0.9198 - precision: 0.9315 - f1_score: 0.9153\n",
      "Epoch 00012: val_f1_score improved from 0.90488 to 0.90878, saving model to /app/_data/models/final/Eff4Flatt/eff4_Flatt_4.h5\n",
      "288/288 [==============================] - 141s 489ms/step - loss: 0.0672 - acc: 0.9237 - recall: 0.9198 - precision: 0.9315 - f1_score: 0.9153 - val_loss: 0.0889 - val_acc: 0.9229 - val_recall: 0.9036 - val_precision: 0.9272 - val_f1_score: 0.9088\n",
      "Epoch 13/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0625 - acc: 0.9268 - recall: 0.9235 - precision: 0.9376 - f1_score: 0.9182\n",
      "Epoch 00013: val_f1_score improved from 0.90878 to 0.91358, saving model to /app/_data/models/final/Eff4Flatt/eff4_Flatt_4.h5\n",
      "288/288 [==============================] - 144s 498ms/step - loss: 0.0625 - acc: 0.9268 - recall: 0.9235 - precision: 0.9376 - f1_score: 0.9182 - val_loss: 0.0858 - val_acc: 0.9288 - val_recall: 0.9276 - val_precision: 0.9147 - val_f1_score: 0.9136\n",
      "Epoch 14/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0741 - acc: 0.9182 - recall: 0.9149 - precision: 0.9266 - f1_score: 0.9113\n",
      "Epoch 00014: val_f1_score did not improve from 0.91358\n",
      "288/288 [==============================] - 141s 490ms/step - loss: 0.0741 - acc: 0.9182 - recall: 0.9149 - precision: 0.9266 - f1_score: 0.9113 - val_loss: 0.1699 - val_acc: 0.8872 - val_recall: 0.8738 - val_precision: 0.8748 - val_f1_score: 0.8731\n",
      "Epoch 15/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0777 - acc: 0.9180 - recall: 0.9107 - precision: 0.9279 - f1_score: 0.9096\n",
      "Epoch 00015: val_f1_score did not improve from 0.91358\n",
      "288/288 [==============================] - 138s 479ms/step - loss: 0.0777 - acc: 0.9180 - recall: 0.9107 - precision: 0.9279 - f1_score: 0.9096 - val_loss: 0.0972 - val_acc: 0.9152 - val_recall: 0.8987 - val_precision: 0.9146 - val_f1_score: 0.8998\n",
      "Epoch 16/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0612 - acc: 0.9293 - recall: 0.9262 - precision: 0.9391 - f1_score: 0.9204\n",
      "Epoch 00016: val_f1_score did not improve from 0.91358\n",
      "288/288 [==============================] - 140s 485ms/step - loss: 0.0612 - acc: 0.9293 - recall: 0.9262 - precision: 0.9391 - f1_score: 0.9204 - val_loss: 0.1000 - val_acc: 0.9132 - val_recall: 0.8839 - val_precision: 0.9384 - val_f1_score: 0.9051\n",
      "Epoch 17/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0670 - acc: 0.9257 - recall: 0.9270 - precision: 0.9371 - f1_score: 0.9192\n",
      "Epoch 00017: val_f1_score did not improve from 0.91358\n",
      "288/288 [==============================] - 142s 494ms/step - loss: 0.0670 - acc: 0.9257 - recall: 0.9270 - precision: 0.9371 - f1_score: 0.9192 - val_loss: 0.1369 - val_acc: 0.8896 - val_recall: 0.9422 - val_precision: 0.8522 - val_f1_score: 0.8842\n",
      "Epoch 18/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0753 - acc: 0.9227 - recall: 0.9170 - precision: 0.9323 - f1_score: 0.9135\n",
      "Epoch 00018: val_f1_score did not improve from 0.91358\n",
      "288/288 [==============================] - 143s 495ms/step - loss: 0.0753 - acc: 0.9227 - recall: 0.9170 - precision: 0.9323 - f1_score: 0.9135 - val_loss: 0.0998 - val_acc: 0.9244 - val_recall: 0.9105 - val_precision: 0.9167 - val_f1_score: 0.9069\n",
      "Epoch 19/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0676 - acc: 0.9229 - recall: 0.9222 - precision: 0.9359 - f1_score: 0.9169\n",
      "Epoch 00019: val_f1_score did not improve from 0.91358\n",
      "288/288 [==============================] - 141s 490ms/step - loss: 0.0676 - acc: 0.9229 - recall: 0.9222 - precision: 0.9359 - f1_score: 0.9169 - val_loss: 0.1062 - val_acc: 0.9169 - val_recall: 0.9075 - val_precision: 0.9192 - val_f1_score: 0.9034\n",
      "Epoch 20/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0952 - acc: 0.9105 - recall: 0.9044 - precision: 0.9179 - f1_score: 0.9038\n",
      "Epoch 00020: val_f1_score did not improve from 0.91358\n",
      "288/288 [==============================] - 143s 496ms/step - loss: 0.0952 - acc: 0.9105 - recall: 0.9044 - precision: 0.9179 - f1_score: 0.9038 - val_loss: 0.1525 - val_acc: 0.9033 - val_recall: 0.9133 - val_precision: 0.8784 - val_f1_score: 0.8925\n",
      "Epoch 21/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0746 - acc: 0.9204 - recall: 0.9185 - precision: 0.9303 - f1_score: 0.9137\n",
      "Epoch 00021: val_f1_score did not improve from 0.91358\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0004500000213738531.\n",
      "288/288 [==============================] - 141s 490ms/step - loss: 0.0746 - acc: 0.9204 - recall: 0.9185 - precision: 0.9303 - f1_score: 0.9137 - val_loss: 0.1458 - val_acc: 0.8762 - val_recall: 0.8862 - val_precision: 0.8840 - val_f1_score: 0.8649\n",
      "Epoch 22/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0550 - acc: 0.9325 - recall: 0.9342 - precision: 0.9459 - f1_score: 0.9264\n",
      "Epoch 00022: val_f1_score did not improve from 0.91358\n",
      "288/288 [==============================] - 141s 491ms/step - loss: 0.0550 - acc: 0.9325 - recall: 0.9342 - precision: 0.9459 - f1_score: 0.9264 - val_loss: 0.1038 - val_acc: 0.9157 - val_recall: 0.9110 - val_precision: 0.9208 - val_f1_score: 0.9035\n",
      "Epoch 23/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0434 - acc: 0.9438 - recall: 0.9489 - precision: 0.9579 - f1_score: 0.9361\n",
      "Epoch 00023: val_f1_score did not improve from 0.91358\n",
      "288/288 [==============================] - 141s 490ms/step - loss: 0.0434 - acc: 0.9438 - recall: 0.9489 - precision: 0.9579 - f1_score: 0.9361 - val_loss: 0.0997 - val_acc: 0.9229 - val_recall: 0.9170 - val_precision: 0.9217 - val_f1_score: 0.9092\n",
      "Epoch 24/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0415 - acc: 0.9435 - recall: 0.9519 - precision: 0.9602 - f1_score: 0.9372\n",
      "Epoch 00024: val_f1_score improved from 0.91358 to 0.91479, saving model to /app/_data/models/final/Eff4Flatt/eff4_Flatt_4.h5\n",
      "288/288 [==============================] - 146s 508ms/step - loss: 0.0415 - acc: 0.9435 - recall: 0.9519 - precision: 0.9602 - f1_score: 0.9372 - val_loss: 0.1017 - val_acc: 0.9273 - val_recall: 0.9154 - val_precision: 0.9322 - val_f1_score: 0.9148\n",
      "Epoch 25/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0401 - acc: 0.9420 - recall: 0.9529 - precision: 0.9604 - f1_score: 0.9365\n",
      "Epoch 00025: val_f1_score did not improve from 0.91479\n",
      "288/288 [==============================] - 143s 497ms/step - loss: 0.0401 - acc: 0.9420 - recall: 0.9529 - precision: 0.9604 - f1_score: 0.9365 - val_loss: 0.1425 - val_acc: 0.9139 - val_recall: 0.9054 - val_precision: 0.9061 - val_f1_score: 0.8961\n",
      "Epoch 26/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0424 - acc: 0.9453 - recall: 0.9527 - precision: 0.9592 - f1_score: 0.9396\n",
      "Epoch 00026: val_f1_score did not improve from 0.91479\n",
      "288/288 [==============================] - 140s 487ms/step - loss: 0.0424 - acc: 0.9453 - recall: 0.9527 - precision: 0.9592 - f1_score: 0.9396 - val_loss: 0.1085 - val_acc: 0.9142 - val_recall: 0.9225 - val_precision: 0.8989 - val_f1_score: 0.9014\n",
      "Epoch 27/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0402 - acc: 0.9461 - recall: 0.9536 - precision: 0.9612 - f1_score: 0.9404\n",
      "Epoch 00027: val_f1_score did not improve from 0.91479\n",
      "288/288 [==============================] - 143s 497ms/step - loss: 0.0402 - acc: 0.9461 - recall: 0.9536 - precision: 0.9612 - f1_score: 0.9404 - val_loss: 0.1489 - val_acc: 0.8983 - val_recall: 0.9161 - val_precision: 0.8639 - val_f1_score: 0.8872\n",
      "Epoch 28/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0388 - acc: 0.9434 - recall: 0.9563 - precision: 0.9611 - f1_score: 0.9402\n",
      "Epoch 00028: val_f1_score did not improve from 0.91479\n",
      "288/288 [==============================] - 144s 499ms/step - loss: 0.0388 - acc: 0.9434 - recall: 0.9563 - precision: 0.9611 - f1_score: 0.9402 - val_loss: 0.1408 - val_acc: 0.9077 - val_recall: 0.9142 - val_precision: 0.9056 - val_f1_score: 0.8957\n",
      "Epoch 29/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0384 - acc: 0.9457 - recall: 0.9579 - precision: 0.9645 - f1_score: 0.9416\n",
      "Epoch 00029: val_f1_score did not improve from 0.91479\n",
      "288/288 [==============================] - 142s 491ms/step - loss: 0.0384 - acc: 0.9457 - recall: 0.9579 - precision: 0.9645 - f1_score: 0.9416 - val_loss: 0.1730 - val_acc: 0.9127 - val_recall: 0.8645 - val_precision: 0.9315 - val_f1_score: 0.8951\n",
      "Epoch 30/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0460 - acc: 0.9394 - recall: 0.9531 - precision: 0.9596 - f1_score: 0.9370\n",
      "Epoch 00030: val_f1_score did not improve from 0.91479\n",
      "288/288 [==============================] - 142s 493ms/step - loss: 0.0460 - acc: 0.9394 - recall: 0.9531 - precision: 0.9596 - f1_score: 0.9370 - val_loss: 0.1279 - val_acc: 0.9241 - val_recall: 0.9140 - val_precision: 0.9271 - val_f1_score: 0.9103\n",
      "Epoch 31/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0371 - acc: 0.9498 - recall: 0.9608 - precision: 0.9655 - f1_score: 0.9438\n",
      "Epoch 00031: val_f1_score did not improve from 0.91479\n",
      "288/288 [==============================] - 141s 490ms/step - loss: 0.0371 - acc: 0.9498 - recall: 0.9608 - precision: 0.9655 - f1_score: 0.9438 - val_loss: 0.1545 - val_acc: 0.9125 - val_recall: 0.8911 - val_precision: 0.9200 - val_f1_score: 0.8992\n",
      "Epoch 32/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0546 - acc: 0.9455 - recall: 0.9556 - precision: 0.9598 - f1_score: 0.9399\n",
      "Epoch 00032: val_f1_score did not improve from 0.91479\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0004050000192364678.\n",
      "288/288 [==============================] - 139s 481ms/step - loss: 0.0546 - acc: 0.9455 - recall: 0.9556 - precision: 0.9598 - f1_score: 0.9399 - val_loss: 0.4281 - val_acc: 0.8708 - val_recall: 0.8467 - val_precision: 0.9112 - val_f1_score: 0.8668\n",
      "Epoch 33/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0437 - acc: 0.9446 - recall: 0.9519 - precision: 0.9608 - f1_score: 0.9373\n",
      "Epoch 00033: val_f1_score did not improve from 0.91479\n",
      "288/288 [==============================] - 142s 494ms/step - loss: 0.0437 - acc: 0.9446 - recall: 0.9519 - precision: 0.9608 - f1_score: 0.9373 - val_loss: 0.1236 - val_acc: 0.9283 - val_recall: 0.9047 - val_precision: 0.9229 - val_f1_score: 0.9096\n",
      "Epoch 34/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0312 - acc: 0.9513 - recall: 0.9651 - precision: 0.9703 - f1_score: 0.9463\n",
      "Epoch 00034: val_f1_score improved from 0.91479 to 0.91616, saving model to /app/_data/models/final/Eff4Flatt/eff4_Flatt_4.h5\n",
      "288/288 [==============================] - 147s 511ms/step - loss: 0.0312 - acc: 0.9513 - recall: 0.9651 - precision: 0.9703 - f1_score: 0.9463 - val_loss: 0.1287 - val_acc: 0.9308 - val_recall: 0.9163 - val_precision: 0.9294 - val_f1_score: 0.9162\n",
      "Epoch 35/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0277 - acc: 0.9532 - recall: 0.9693 - precision: 0.9736 - f1_score: 0.9499\n",
      "Epoch 00035: val_f1_score did not improve from 0.91616\n",
      "288/288 [==============================] - 142s 493ms/step - loss: 0.0277 - acc: 0.9532 - recall: 0.9693 - precision: 0.9736 - f1_score: 0.9499 - val_loss: 0.1233 - val_acc: 0.9209 - val_recall: 0.9339 - val_precision: 0.9026 - val_f1_score: 0.9097\n",
      "Epoch 36/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0248 - acc: 0.9547 - recall: 0.9714 - precision: 0.9761 - f1_score: 0.9510\n",
      "Epoch 00036: val_f1_score did not improve from 0.91616\n",
      "288/288 [==============================] - 144s 502ms/step - loss: 0.0248 - acc: 0.9547 - recall: 0.9714 - precision: 0.9761 - f1_score: 0.9510 - val_loss: 0.1302 - val_acc: 0.9196 - val_recall: 0.9232 - val_precision: 0.9141 - val_f1_score: 0.9082\n",
      "Epoch 37/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0230 - acc: 0.9591 - recall: 0.9743 - precision: 0.9783 - f1_score: 0.9544\n",
      "Epoch 00037: val_f1_score did not improve from 0.91616\n",
      "288/288 [==============================] - 146s 506ms/step - loss: 0.0230 - acc: 0.9591 - recall: 0.9743 - precision: 0.9783 - f1_score: 0.9544 - val_loss: 0.1583 - val_acc: 0.9216 - val_recall: 0.9161 - val_precision: 0.9129 - val_f1_score: 0.9063\n",
      "Epoch 38/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0241 - acc: 0.9581 - recall: 0.9742 - precision: 0.9770 - f1_score: 0.9547\n",
      "Epoch 00038: val_f1_score did not improve from 0.91616\n",
      "288/288 [==============================] - 142s 491ms/step - loss: 0.0241 - acc: 0.9581 - recall: 0.9742 - precision: 0.9770 - f1_score: 0.9547 - val_loss: 0.1306 - val_acc: 0.9219 - val_recall: 0.9163 - val_precision: 0.9180 - val_f1_score: 0.9112\n",
      "Epoch 39/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0235 - acc: 0.9545 - recall: 0.9736 - precision: 0.9769 - f1_score: 0.9521\n",
      "Epoch 00039: val_f1_score did not improve from 0.91616\n",
      "288/288 [==============================] - 140s 485ms/step - loss: 0.0235 - acc: 0.9545 - recall: 0.9736 - precision: 0.9769 - f1_score: 0.9521 - val_loss: 0.1267 - val_acc: 0.9244 - val_recall: 0.9182 - val_precision: 0.9220 - val_f1_score: 0.9109\n",
      "Epoch 40/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0250 - acc: 0.9574 - recall: 0.9727 - precision: 0.9765 - f1_score: 0.9541\n",
      "Epoch 00040: val_f1_score did not improve from 0.91616\n",
      "288/288 [==============================] - 142s 494ms/step - loss: 0.0250 - acc: 0.9574 - recall: 0.9727 - precision: 0.9765 - f1_score: 0.9541 - val_loss: 0.1595 - val_acc: 0.9067 - val_recall: 0.8987 - val_precision: 0.8830 - val_f1_score: 0.8889\n",
      "Epoch 41/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.1197 - acc: 0.9112 - recall: 0.9134 - precision: 0.9235 - f1_score: 0.9064\n",
      "Epoch 00041: val_f1_score did not improve from 0.91616\n",
      "288/288 [==============================] - 142s 492ms/step - loss: 0.1197 - acc: 0.9112 - recall: 0.9134 - precision: 0.9235 - f1_score: 0.9064 - val_loss: 0.1490 - val_acc: 0.9048 - val_recall: 0.9075 - val_precision: 0.8810 - val_f1_score: 0.8879\n",
      "Epoch 42/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0421 - acc: 0.9398 - recall: 0.9545 - precision: 0.9623 - f1_score: 0.9371\n",
      "Epoch 00042: val_f1_score did not improve from 0.91616\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.0003645000251708552.\n",
      "288/288 [==============================] - 142s 494ms/step - loss: 0.0421 - acc: 0.9398 - recall: 0.9545 - precision: 0.9623 - f1_score: 0.9371 - val_loss: 0.1292 - val_acc: 0.9182 - val_recall: 0.9071 - val_precision: 0.9145 - val_f1_score: 0.9009\n",
      "Epoch 43/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0299 - acc: 0.9529 - recall: 0.9692 - precision: 0.9731 - f1_score: 0.9486\n",
      "Epoch 00043: val_f1_score did not improve from 0.91616\n",
      "288/288 [==============================] - 144s 500ms/step - loss: 0.0299 - acc: 0.9529 - recall: 0.9692 - precision: 0.9731 - f1_score: 0.9486 - val_loss: 0.1217 - val_acc: 0.9251 - val_recall: 0.9195 - val_precision: 0.9270 - val_f1_score: 0.9123\n",
      "Epoch 44/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0213 - acc: 0.9552 - recall: 0.9765 - precision: 0.9790 - f1_score: 0.9543\n",
      "Epoch 00044: val_f1_score did not improve from 0.91616\n",
      "288/288 [==============================] - 138s 480ms/step - loss: 0.0213 - acc: 0.9552 - recall: 0.9765 - precision: 0.9790 - f1_score: 0.9543 - val_loss: 0.1248 - val_acc: 0.9214 - val_recall: 0.9147 - val_precision: 0.9243 - val_f1_score: 0.9103\n",
      "Epoch 45/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0192 - acc: 0.9603 - recall: 0.9788 - precision: 0.9815 - f1_score: 0.9570Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00045: val_f1_score did not improve from 0.91616\n",
      "288/288 [==============================] - 143s 497ms/step - loss: 0.0192 - acc: 0.9603 - recall: 0.9788 - precision: 0.9815 - f1_score: 0.9570 - val_loss: 0.1285 - val_acc: 0.9246 - val_recall: 0.9193 - val_precision: 0.9153 - val_f1_score: 0.9088\n",
      "Epoch 00045: early stopping\n",
      "Epoch 1/100\n",
      "  2/288 [..............................] - ETA: 8:41 - loss: 1.1594 - acc: 0.2232 - recall: 0.3333 - precision: 0.1896 - f1_score: 0.2489WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.3994s vs `on_train_batch_end` time: 3.2456s). Check your callbacks.\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.2501 - acc: 0.7896 - recall: 0.7550 - precision: 0.7841 - f1_score: 0.7815\n",
      "Epoch 00001: val_f1_score improved from -inf to 0.83156, saving model to /app/_data/models/final/Eff4Flatt/eff4_Flatt_5.h5\n",
      "288/288 [==============================] - 155s 539ms/step - loss: 0.2501 - acc: 0.7896 - recall: 0.7550 - precision: 0.7841 - f1_score: 0.7815 - val_loss: 0.1962 - val_acc: 0.8418 - val_recall: 0.8397 - val_precision: 0.8713 - val_f1_score: 0.8316\n",
      "Epoch 2/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.1482 - acc: 0.8674 - recall: 0.8440 - precision: 0.8706 - f1_score: 0.8577\n",
      "Epoch 00002: val_f1_score improved from 0.83156 to 0.88768, saving model to /app/_data/models/final/Eff4Flatt/eff4_Flatt_5.h5\n",
      "288/288 [==============================] - 145s 502ms/step - loss: 0.1482 - acc: 0.8674 - recall: 0.8440 - precision: 0.8706 - f1_score: 0.8577 - val_loss: 0.1268 - val_acc: 0.9100 - val_recall: 0.8438 - val_precision: 0.9328 - val_f1_score: 0.8877\n",
      "Epoch 3/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.1200 - acc: 0.8849 - recall: 0.8649 - precision: 0.8917 - f1_score: 0.8742\n",
      "Epoch 00003: val_f1_score did not improve from 0.88768\n",
      "288/288 [==============================] - 141s 488ms/step - loss: 0.1200 - acc: 0.8849 - recall: 0.8649 - precision: 0.8917 - f1_score: 0.8742 - val_loss: 0.1249 - val_acc: 0.8921 - val_recall: 0.8677 - val_precision: 0.8999 - val_f1_score: 0.8767\n",
      "Epoch 4/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.1005 - acc: 0.9002 - recall: 0.8829 - precision: 0.9066 - f1_score: 0.8907\n",
      "Epoch 00004: val_f1_score did not improve from 0.88768\n",
      "288/288 [==============================] - 139s 482ms/step - loss: 0.1005 - acc: 0.9002 - recall: 0.8829 - precision: 0.9066 - f1_score: 0.8907 - val_loss: 0.1096 - val_acc: 0.8886 - val_recall: 0.8858 - val_precision: 0.9070 - val_f1_score: 0.8842\n",
      "Epoch 5/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0944 - acc: 0.9040 - recall: 0.8888 - precision: 0.9113 - f1_score: 0.8940\n",
      "Epoch 00005: val_f1_score improved from 0.88768 to 0.89154, saving model to /app/_data/models/final/Eff4Flatt/eff4_Flatt_5.h5\n",
      "288/288 [==============================] - 148s 515ms/step - loss: 0.0944 - acc: 0.9040 - recall: 0.8888 - precision: 0.9113 - f1_score: 0.8940 - val_loss: 0.1067 - val_acc: 0.9085 - val_recall: 0.8964 - val_precision: 0.8925 - val_f1_score: 0.8915\n",
      "Epoch 6/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0901 - acc: 0.9070 - recall: 0.8930 - precision: 0.9126 - f1_score: 0.8957\n",
      "Epoch 00006: val_f1_score improved from 0.89154 to 0.89677, saving model to /app/_data/models/final/Eff4Flatt/eff4_Flatt_5.h5\n",
      "288/288 [==============================] - 140s 487ms/step - loss: 0.0901 - acc: 0.9070 - recall: 0.8930 - precision: 0.9126 - f1_score: 0.8957 - val_loss: 0.0907 - val_acc: 0.9147 - val_recall: 0.8975 - val_precision: 0.9171 - val_f1_score: 0.8968\n",
      "Epoch 7/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0867 - acc: 0.9139 - recall: 0.8998 - precision: 0.9186 - f1_score: 0.9038\n",
      "Epoch 00007: val_f1_score improved from 0.89677 to 0.89878, saving model to /app/_data/models/final/Eff4Flatt/eff4_Flatt_5.h5\n",
      "288/288 [==============================] - 142s 493ms/step - loss: 0.0867 - acc: 0.9139 - recall: 0.8998 - precision: 0.9186 - f1_score: 0.9038 - val_loss: 0.0833 - val_acc: 0.9055 - val_recall: 0.9062 - val_precision: 0.9212 - val_f1_score: 0.8988\n",
      "Epoch 8/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0831 - acc: 0.9151 - recall: 0.9015 - precision: 0.9215 - f1_score: 0.9055\n",
      "Epoch 00008: val_f1_score did not improve from 0.89878\n",
      "288/288 [==============================] - 144s 499ms/step - loss: 0.0831 - acc: 0.9151 - recall: 0.9015 - precision: 0.9215 - f1_score: 0.9055 - val_loss: 0.0874 - val_acc: 0.9110 - val_recall: 0.8833 - val_precision: 0.9311 - val_f1_score: 0.8973\n",
      "Epoch 9/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0778 - acc: 0.9160 - recall: 0.9078 - precision: 0.9238 - f1_score: 0.9078\n",
      "Epoch 00009: val_f1_score improved from 0.89878 to 0.89964, saving model to /app/_data/models/final/Eff4Flatt/eff4_Flatt_5.h5\n",
      "288/288 [==============================] - 147s 512ms/step - loss: 0.0778 - acc: 0.9160 - recall: 0.9078 - precision: 0.9238 - f1_score: 0.9078 - val_loss: 0.0854 - val_acc: 0.9154 - val_recall: 0.9083 - val_precision: 0.9093 - val_f1_score: 0.8996\n",
      "Epoch 10/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0783 - acc: 0.9170 - recall: 0.9094 - precision: 0.9252 - f1_score: 0.9085\n",
      "Epoch 00010: val_f1_score improved from 0.89964 to 0.90438, saving model to /app/_data/models/final/Eff4Flatt/eff4_Flatt_5.h5\n",
      "288/288 [==============================] - 144s 498ms/step - loss: 0.0783 - acc: 0.9170 - recall: 0.9094 - precision: 0.9252 - f1_score: 0.9085 - val_loss: 0.0826 - val_acc: 0.9214 - val_recall: 0.9074 - val_precision: 0.9293 - val_f1_score: 0.9044\n",
      "Epoch 11/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0727 - acc: 0.9213 - recall: 0.9152 - precision: 0.9302 - f1_score: 0.9123\n",
      "Epoch 00011: val_f1_score did not improve from 0.90438\n",
      "288/288 [==============================] - 144s 499ms/step - loss: 0.0727 - acc: 0.9213 - recall: 0.9152 - precision: 0.9302 - f1_score: 0.9123 - val_loss: 0.1131 - val_acc: 0.8996 - val_recall: 0.8828 - val_precision: 0.9257 - val_f1_score: 0.8930\n",
      "Epoch 12/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0773 - acc: 0.9200 - recall: 0.9106 - precision: 0.9282 - f1_score: 0.9108\n",
      "Epoch 00012: val_f1_score did not improve from 0.90438\n",
      "288/288 [==============================] - 140s 488ms/step - loss: 0.0773 - acc: 0.9200 - recall: 0.9106 - precision: 0.9282 - f1_score: 0.9108 - val_loss: 0.0945 - val_acc: 0.9062 - val_recall: 0.8966 - val_precision: 0.9144 - val_f1_score: 0.8893\n",
      "Epoch 13/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0653 - acc: 0.9271 - recall: 0.9266 - precision: 0.9371 - f1_score: 0.9199\n",
      "Epoch 00013: val_f1_score did not improve from 0.90438\n",
      "288/288 [==============================] - 147s 509ms/step - loss: 0.0653 - acc: 0.9271 - recall: 0.9266 - precision: 0.9371 - f1_score: 0.9199 - val_loss: 0.1265 - val_acc: 0.8777 - val_recall: 0.9012 - val_precision: 0.8776 - val_f1_score: 0.8728\n",
      "Epoch 14/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0707 - acc: 0.9218 - recall: 0.9187 - precision: 0.9316 - f1_score: 0.9144\n",
      "Epoch 00014: val_f1_score did not improve from 0.90438\n",
      "288/288 [==============================] - 141s 488ms/step - loss: 0.0707 - acc: 0.9218 - recall: 0.9187 - precision: 0.9316 - f1_score: 0.9144 - val_loss: 0.1130 - val_acc: 0.9050 - val_recall: 0.8888 - val_precision: 0.9014 - val_f1_score: 0.8877\n",
      "Epoch 15/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0869 - acc: 0.9092 - recall: 0.9025 - precision: 0.9206 - f1_score: 0.9032\n",
      "Epoch 00015: val_f1_score did not improve from 0.90438\n",
      "288/288 [==============================] - 143s 495ms/step - loss: 0.0869 - acc: 0.9092 - recall: 0.9025 - precision: 0.9206 - f1_score: 0.9032 - val_loss: 0.1018 - val_acc: 0.8996 - val_recall: 0.8810 - val_precision: 0.9198 - val_f1_score: 0.8922\n",
      "Epoch 16/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0658 - acc: 0.9252 - recall: 0.9224 - precision: 0.9374 - f1_score: 0.9179\n",
      "Epoch 00016: val_f1_score improved from 0.90438 to 0.90604, saving model to /app/_data/models/final/Eff4Flatt/eff4_Flatt_5.h5\n",
      "288/288 [==============================] - 146s 506ms/step - loss: 0.0658 - acc: 0.9252 - recall: 0.9224 - precision: 0.9374 - f1_score: 0.9179 - val_loss: 0.0893 - val_acc: 0.9179 - val_recall: 0.9200 - val_precision: 0.9154 - val_f1_score: 0.9060\n",
      "Epoch 17/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0603 - acc: 0.9304 - recall: 0.9301 - precision: 0.9422 - f1_score: 0.9235\n",
      "Epoch 00017: val_f1_score did not improve from 0.90604\n",
      "288/288 [==============================] - 146s 508ms/step - loss: 0.0603 - acc: 0.9304 - recall: 0.9301 - precision: 0.9422 - f1_score: 0.9235 - val_loss: 0.0894 - val_acc: 0.9204 - val_recall: 0.8966 - val_precision: 0.9228 - val_f1_score: 0.9021\n",
      "Epoch 18/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0560 - acc: 0.9330 - recall: 0.9352 - precision: 0.9458 - f1_score: 0.9264\n",
      "Epoch 00018: val_f1_score did not improve from 0.90604\n",
      "288/288 [==============================] - 140s 486ms/step - loss: 0.0560 - acc: 0.9330 - recall: 0.9352 - precision: 0.9458 - f1_score: 0.9264 - val_loss: 0.1271 - val_acc: 0.8819 - val_recall: 0.8762 - val_precision: 0.8951 - val_f1_score: 0.8710\n",
      "Epoch 19/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0763 - acc: 0.9176 - recall: 0.9108 - precision: 0.9286 - f1_score: 0.9094\n",
      "Epoch 00019: val_f1_score did not improve from 0.90604\n",
      "288/288 [==============================] - 146s 505ms/step - loss: 0.0763 - acc: 0.9176 - recall: 0.9108 - precision: 0.9286 - f1_score: 0.9094 - val_loss: 0.1200 - val_acc: 0.8884 - val_recall: 0.9211 - val_precision: 0.8856 - val_f1_score: 0.8850\n",
      "Epoch 20/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0646 - acc: 0.9275 - recall: 0.9269 - precision: 0.9386 - f1_score: 0.9207\n",
      "Epoch 00020: val_f1_score did not improve from 0.90604\n",
      "288/288 [==============================] - 146s 506ms/step - loss: 0.0646 - acc: 0.9275 - recall: 0.9269 - precision: 0.9386 - f1_score: 0.9207 - val_loss: 0.1061 - val_acc: 0.9157 - val_recall: 0.9083 - val_precision: 0.9182 - val_f1_score: 0.9058\n",
      "Epoch 21/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0599 - acc: 0.9312 - recall: 0.9354 - precision: 0.9451 - f1_score: 0.9262\n",
      "Epoch 00021: val_f1_score did not improve from 0.90604\n",
      "288/288 [==============================] - 143s 498ms/step - loss: 0.0599 - acc: 0.9312 - recall: 0.9354 - precision: 0.9451 - f1_score: 0.9262 - val_loss: 0.1329 - val_acc: 0.9085 - val_recall: 0.9133 - val_precision: 0.8943 - val_f1_score: 0.8960\n",
      "Epoch 22/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0740 - acc: 0.9263 - recall: 0.9259 - precision: 0.9383 - f1_score: 0.9207\n",
      "Epoch 00022: val_f1_score did not improve from 0.90604\n",
      "288/288 [==============================] - 145s 505ms/step - loss: 0.0740 - acc: 0.9263 - recall: 0.9259 - precision: 0.9383 - f1_score: 0.9207 - val_loss: 0.1169 - val_acc: 0.9137 - val_recall: 0.8780 - val_precision: 0.9364 - val_f1_score: 0.9006\n",
      "Epoch 23/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0548 - acc: 0.9360 - recall: 0.9365 - precision: 0.9488 - f1_score: 0.9286\n",
      "Epoch 00023: val_f1_score did not improve from 0.90604\n",
      "288/288 [==============================] - 140s 486ms/step - loss: 0.0548 - acc: 0.9360 - recall: 0.9365 - precision: 0.9488 - f1_score: 0.9286 - val_loss: 0.1062 - val_acc: 0.9139 - val_recall: 0.9257 - val_precision: 0.9045 - val_f1_score: 0.9049\n",
      "Epoch 24/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0485 - acc: 0.9416 - recall: 0.9453 - precision: 0.9535 - f1_score: 0.9342\n",
      "Epoch 00024: val_f1_score improved from 0.90604 to 0.91064, saving model to /app/_data/models/final/Eff4Flatt/eff4_Flatt_5.h5\n",
      "288/288 [==============================] - 146s 506ms/step - loss: 0.0485 - acc: 0.9416 - recall: 0.9453 - precision: 0.9535 - f1_score: 0.9342 - val_loss: 0.0943 - val_acc: 0.9194 - val_recall: 0.9094 - val_precision: 0.9354 - val_f1_score: 0.9106\n",
      "Epoch 25/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0447 - acc: 0.9443 - recall: 0.9502 - precision: 0.9569 - f1_score: 0.9369\n",
      "Epoch 00025: val_f1_score did not improve from 0.91064\n",
      "288/288 [==============================] - 140s 485ms/step - loss: 0.0447 - acc: 0.9443 - recall: 0.9502 - precision: 0.9569 - f1_score: 0.9369 - val_loss: 0.1039 - val_acc: 0.9253 - val_recall: 0.8872 - val_precision: 0.9425 - val_f1_score: 0.9069\n",
      "Epoch 26/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0457 - acc: 0.9426 - recall: 0.9504 - precision: 0.9574 - f1_score: 0.9368\n",
      "Epoch 00026: val_f1_score did not improve from 0.91064\n",
      "288/288 [==============================] - 144s 499ms/step - loss: 0.0457 - acc: 0.9426 - recall: 0.9504 - precision: 0.9574 - f1_score: 0.9368 - val_loss: 0.1220 - val_acc: 0.9008 - val_recall: 0.8796 - val_precision: 0.9192 - val_f1_score: 0.8898\n",
      "Epoch 27/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0938 - acc: 0.9161 - recall: 0.9105 - precision: 0.9234 - f1_score: 0.9099\n",
      "Epoch 00027: val_f1_score did not improve from 0.91064\n",
      "288/288 [==============================] - 144s 501ms/step - loss: 0.0938 - acc: 0.9161 - recall: 0.9105 - precision: 0.9234 - f1_score: 0.9099 - val_loss: 0.1058 - val_acc: 0.9206 - val_recall: 0.9071 - val_precision: 0.9117 - val_f1_score: 0.9028\n",
      "Epoch 28/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0648 - acc: 0.9324 - recall: 0.9341 - precision: 0.9443 - f1_score: 0.9244\n",
      "Epoch 00028: val_f1_score did not improve from 0.91064\n",
      "288/288 [==============================] - 143s 498ms/step - loss: 0.0648 - acc: 0.9324 - recall: 0.9341 - precision: 0.9443 - f1_score: 0.9244 - val_loss: 0.0936 - val_acc: 0.9152 - val_recall: 0.9115 - val_precision: 0.9125 - val_f1_score: 0.9027\n",
      "Epoch 29/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0413 - acc: 0.9468 - recall: 0.9532 - precision: 0.9601 - f1_score: 0.9403\n",
      "Epoch 00029: val_f1_score did not improve from 0.91064\n",
      "288/288 [==============================] - 142s 492ms/step - loss: 0.0413 - acc: 0.9468 - recall: 0.9532 - precision: 0.9601 - f1_score: 0.9403 - val_loss: 0.1147 - val_acc: 0.9102 - val_recall: 0.9080 - val_precision: 0.9160 - val_f1_score: 0.8965\n",
      "Epoch 30/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0354 - acc: 0.9491 - recall: 0.9592 - precision: 0.9666 - f1_score: 0.9428\n",
      "Epoch 00030: val_f1_score did not improve from 0.91064\n",
      "288/288 [==============================] - 141s 491ms/step - loss: 0.0354 - acc: 0.9491 - recall: 0.9592 - precision: 0.9666 - f1_score: 0.9428 - val_loss: 0.1023 - val_acc: 0.9226 - val_recall: 0.9259 - val_precision: 0.9184 - val_f1_score: 0.9093\n",
      "Epoch 31/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0321 - acc: 0.9538 - recall: 0.9626 - precision: 0.9691 - f1_score: 0.9470\n",
      "Epoch 00031: val_f1_score did not improve from 0.91064\n",
      "288/288 [==============================] - 145s 503ms/step - loss: 0.0321 - acc: 0.9538 - recall: 0.9626 - precision: 0.9691 - f1_score: 0.9470 - val_loss: 0.1087 - val_acc: 0.9184 - val_recall: 0.9083 - val_precision: 0.9160 - val_f1_score: 0.9023\n",
      "Epoch 32/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0293 - acc: 0.9554 - recall: 0.9674 - precision: 0.9713 - f1_score: 0.9499\n",
      "Epoch 00032: val_f1_score did not improve from 0.91064\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0004500000213738531.\n",
      "288/288 [==============================] - 142s 493ms/step - loss: 0.0293 - acc: 0.9554 - recall: 0.9674 - precision: 0.9713 - f1_score: 0.9499 - val_loss: 0.1184 - val_acc: 0.9169 - val_recall: 0.9131 - val_precision: 0.9201 - val_f1_score: 0.9082\n",
      "Epoch 33/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0264 - acc: 0.9552 - recall: 0.9706 - precision: 0.9742 - f1_score: 0.9505\n",
      "Epoch 00033: val_f1_score did not improve from 0.91064\n",
      "288/288 [==============================] - 147s 510ms/step - loss: 0.0264 - acc: 0.9552 - recall: 0.9706 - precision: 0.9742 - f1_score: 0.9505 - val_loss: 0.1261 - val_acc: 0.9082 - val_recall: 0.9278 - val_precision: 0.9011 - val_f1_score: 0.9008\n",
      "Epoch 34/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0309 - acc: 0.9528 - recall: 0.9674 - precision: 0.9704 - f1_score: 0.9486\n",
      "Epoch 00034: val_f1_score did not improve from 0.91064\n",
      "288/288 [==============================] - 140s 487ms/step - loss: 0.0309 - acc: 0.9528 - recall: 0.9674 - precision: 0.9704 - f1_score: 0.9486 - val_loss: 0.1239 - val_acc: 0.9196 - val_recall: 0.9170 - val_precision: 0.9274 - val_f1_score: 0.9067\n",
      "Epoch 35/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0261 - acc: 0.9584 - recall: 0.9717 - precision: 0.9764 - f1_score: 0.9530Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00035: val_f1_score did not improve from 0.91064\n",
      "288/288 [==============================] - 146s 507ms/step - loss: 0.0261 - acc: 0.9584 - recall: 0.9717 - precision: 0.9764 - f1_score: 0.9530 - val_loss: 0.1277 - val_acc: 0.9149 - val_recall: 0.9158 - val_precision: 0.9135 - val_f1_score: 0.9018\n",
      "Epoch 00035: early stopping\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=SEED, shuffle=True)\n",
    "\n",
    "for i, (train_index, valid_index) in enumerate(\n",
    "    skf.split(df_labels[\"image\"], df_labels[\"labels\"])\n",
    "):\n",
    "        train, valid = df_labels.loc[train_index], df_labels.loc[valid_index]\n",
    "        model_name = \"eff4_Flatt_\" + str(i + 1) + \".h5\"\n",
    "        log_dir = 'logs_Flatt_'+str(i + 1)+'/'\n",
    "        callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor=\"val_f1_score\",\n",
    "                patience=11,\n",
    "                restore_best_weights=True,\n",
    "                verbose=1,\n",
    "                mode=\"max\",\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                \"/app/_data/models/final/Eff4Flatt/\" + model_name,\n",
    "                monitor=\"val_f1_score\",\n",
    "                verbose=1,\n",
    "                save_best_only=True,\n",
    "                save_weights_only=False,\n",
    "                mode=\"max\",\n",
    "                save_freq=\"epoch\",\n",
    "            ),\n",
    "            keras.callbacks.ReduceLROnPlateau(\n",
    "                monitor=\"val_f1_score\",\n",
    "                factor=0.9,\n",
    "                patience=8,\n",
    "                verbose=1,\n",
    "                mode=\"max\",\n",
    "                min_delta=1e-4,\n",
    "                min_lr=0.00000001,\n",
    "            ),\n",
    "            keras.callbacks.TensorBoard(\n",
    "                log_dir=\"/app/.tensorboard/\"+log_dir, histogram_freq=0\n",
    "            ),\n",
    "            keras.callbacks.experimental.BackupAndRestore(\n",
    "        '/app/_data/models/final/Eff4Flatt/backup/'\n",
    "    )\n",
    "        ]\n",
    "\n",
    "        gen_train = Generator(\n",
    "            df=train,\n",
    "            images_src_dir=TRAIN_IMG_PATH,\n",
    "            target_image_size=IMAGE_SIZE,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=True,\n",
    "            augment=True,\n",
    "            crop=False,\n",
    "            resize=False,\n",
    "        )\n",
    "        gen_valid = Generator(\n",
    "            df=valid,\n",
    "            images_src_dir=TRAIN_IMG_PATH,\n",
    "            target_image_size=IMAGE_SIZE,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=False,\n",
    "            augment=False,\n",
    "            crop=False,\n",
    "            resize=False,\n",
    "        )\n",
    "        model = get_model()\n",
    "        history = model.fit(\n",
    "            gen_train,\n",
    "            validation_data=gen_valid,\n",
    "            epochs=100,\n",
    "            steps_per_epoch=train.shape[0]//BATCH_SIZE,\n",
    "            validation_steps=valid.shape[0]//BATCH_SIZE,\n",
    "            verbose=1,\n",
    "            workers = 25,\n",
    "            callbacks=callbacks,\n",
    "        )\n",
    "        tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices(\"GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_all(file_path):\n",
    "    img = tf.io.read_file(TRAIN_IMG_PATH + file_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    return img\n",
    "\n",
    "\n",
    "def predict_new(path, model):\n",
    "    img = parse_all(path)\n",
    "    img = tf.expand_dims(img, axis=0)\n",
    "    pred = model.predict(img)\n",
    "    return pred_to_labels(pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  image                   labels\n",
      "0  bfc6d90f402f4c34.jpg  frog_eye_leaf_spot scab\n",
      "1  9eb93fe282326266.jpg           powdery_mildew\n",
      "2  f4cb3a8f41b413e4.jpg       frog_eye_leaf_spot\n",
      "3  98322eab16bef2c1.jpg                     rust\n",
      "4  dad5d6250cae80b7.jpg                  complex\n"
     ]
    }
   ],
   "source": [
    "df_sub = pd.DataFrame(columns=[\"image\", \"labels\"])\n",
    "for img_name in os.listdir(TRAIN_IMG_PATH):\n",
    "    pred = predict_new(img_name, model)\n",
    "\n",
    "    df_sub = df_sub.append({\"image\": img_name, \"labels\": pred}, ignore_index=True)\n",
    "\n",
    "print(df_sub.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = df_sub.merge(\n",
    "    labels_21_20[[\"image\", \"labels\"]],\n",
    "    on=\"image\",\n",
    "    how=\"left\",\n",
    "    suffixes=(\"_pred\", \"_true\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.to_csv(\"/app/sandbox/wrong_predictions/eff4/eff4_ns_cropped_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "complex                    22\n",
       "scab                       10\n",
       "rust                        7\n",
       "frog_eye_leaf_spot          5\n",
       "scab frog_eye_leaf_spot     1\n",
       "rust frog_eye_leaf_spot     1\n",
       "powdery_mildew complex      1\n",
       "powdery_mildew              1\n",
       "healthy                     1\n",
       "Name: labels_true, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub[df_sub[\"labels_pred\"] == \"\"][\"labels_true\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scab frog_eye_leaf_spot            682\n",
       "complex                            438\n",
       "scab frog_eye_leaf_spot complex    200\n",
       "frog_eye_leaf_spot complex         165\n",
       "scab                               124\n",
       "rust frog_eye_leaf_spot            118\n",
       "rust complex                        91\n",
       "powdery_mildew complex              87\n",
       "rust                                74\n",
       "frog_eye_leaf_spot                  71\n",
       "healthy                             19\n",
       "powdery_mildew                       7\n",
       "Name: labels_true, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub[df_sub[\"labels_pred\"] != df_sub[\"labels_true\"]][\"labels_true\"].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
