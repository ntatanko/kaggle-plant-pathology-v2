{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## resizing and saving images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def resize_im(\n",
    "#     image_name, new_folder_name=\"small_nearest\", size=(224, 224), resample=Image.NEAREST\n",
    "# ):\n",
    "#     image = Image.open(PATH + \"train_images/\" + image_name)\n",
    "#     image = image.resize(size, resample=resample)\n",
    "#     if not os.path.isdir(PATH + new_folder_name + \"/\"):\n",
    "#         os.mkdir(PATH + new_folder_name + \"/\")\n",
    "#     image.save(PATH  + new_folder_name + \"/\" + image_name)\n",
    "# labels['image'].apply(resize_im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## weights for multilabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels[\"multi_label\"] = labels[\"labels\"].astype(\"category\").cat.codes\n",
    "# dict_weights = (\n",
    "#     1\n",
    "#     / labels[\"multi_label\"].value_counts()\n",
    "#     / np.sum(1 / labels[\"multi_label\"].value_counts())\n",
    "# ).to_dict()\n",
    "# def weight_fill(x):\n",
    "#     return dict_weights[x]\n",
    "# labels[\"weights\"] = labels[\"multi_label\"].apply(weight_fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MyImageDataGenerator(ImageDataGenerator):\n",
    "#     def __init__(self, std_normalization=True):\n",
    "#         self.std_normalization = std_normalization\n",
    "\n",
    "#     if self.std_normalization:\n",
    "#         x = x.astype(np.float32)\n",
    "#         x = x - np.mean(x, axis=(0, 1))\n",
    "#         x = x / np.std(x, axis=(0, 1))\n",
    "\n",
    "#     else:\n",
    "#         warnings.warn(\"Ничего не получилось\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from PIL import Image, ImageStat\n",
    "\n",
    "# image_folder = os.path.join(PATH, \"small_nearest\")\n",
    "# image_files = labels['image'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean pix for each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicate_files_3 = pd.DataFrame()\n",
    "# for file in tqdm(image_files):\n",
    "#     image = Image.open(os.path.join(image_folder, file))\n",
    "#     pix_mean = ImageStat.Stat(image).mean\n",
    "#     duplicate_files_3.loc[file, 'pix_mean1'] = pix_mean[0]\n",
    "#     duplicate_files_3.loc[file, 'pix_mean2'] = pix_mean[1]\n",
    "#     duplicate_files_3.loc[file, 'pix_mean3'] = pix_mean[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicate_files = duplicate_files.reset_index(drop=False)\n",
    "# duplicate_files.columns = ['image', 'pix_mean1', 'pix_mean2', 'pix_mean3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### np.round or without"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicates_array = np.round(duplicate_files[['pix_mean1', 'pix_mean2', 'pix_mean3']].values)\n",
    "# duplicates_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_duplicates = []\n",
    "# for i in tqdm(range(len(duplicates_array))):\n",
    "#     for j in range(len(duplicates_array)):\n",
    "#         val1 = duplicates_array[i]\n",
    "#         val2 = duplicates_array[j]\n",
    "#         if i != j:\n",
    "#             if all(val1 == val2):\n",
    "#                 list_duplicates.append([duplicate_files.loc[i, 'image'], duplicate_files.loc[j, 'image']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_duplicates = pd.DataFrame(list_duplicates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for im1, im2 in df_duplicates.values:\n",
    "#     plt.figure(figsize=(10,3))\n",
    "#     plt.subplot(1,2,1)\n",
    "#     plt.title(labels[labels['image'] == im1]['labels'].tolist())\n",
    "#     plt.imshow(Image.open(image_folder+'/'+im1))\n",
    "#     plt.subplot(1,2,2)\n",
    "#     plt.title(labels[labels['image'] == im2]['labels'].tolist())\n",
    "#     plt.imshow(Image.open(image_folder+'/'+im2))\n",
    "#     plt.show();\n",
    "# plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## duplicates via hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import imagehash\n",
    "# funcs = [\n",
    "#         imagehash.average_hash,\n",
    "#         imagehash.phash,\n",
    "#         imagehash.dhash,\n",
    "#         imagehash.whash,\n",
    "#     ]\n",
    "\n",
    "# image_ids = []\n",
    "# hashes = []\n",
    "\n",
    "# for img_id in tqdm(labels['image']):\n",
    "#     image = Image.open(image_folder+'/'+img_id)\n",
    "#     image_ids.append(img_id)\n",
    "#     hashes.append(np.array([f(image).hash for f in funcs]).reshape(256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hashes_all = np.array(hashes)\n",
    "# hashes_all = torch.Tensor(hashes_all.astype(int))\n",
    "\n",
    "# %time sims = np.array([(hashes_all[i] == hashes_all).sum(dim=1).numpy()/256 for i in range(hashes_all.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices1 = np.where(sims > 0.9)\n",
    "# indices2 = np.where(indices1[0] != indices1[1])\n",
    "# image_ids1 = [image_ids[i] for i in indices1[0][indices2]]\n",
    "# image_ids2 = [image_ids[i] for i in indices1[1][indices2]]\n",
    "\n",
    "# dups = [list(sorted([image_ids1,image_ids2])) for image_ids1, image_ids2 in zip(image_ids1, image_ids2)]\n",
    "# print('found %d duplicates' % len(dups))\n",
    "# for row in dups:\n",
    "#     print(','.join(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
