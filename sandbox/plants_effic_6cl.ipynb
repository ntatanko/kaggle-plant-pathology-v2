{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import warnings\n",
    "\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(action='once')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "# plots\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from PIL import Image\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    f1_score,\n",
    "    plot_confusion_matrix,\n",
    "    precision_recall_curve,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "# from tensorflow.keras.applications.resnet import ResNet50\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB7\n",
    "from tensorflow.keras.layers import (\n",
    "    AveragePooling2D,\n",
    "    AvgPool2D,\n",
    "    Conv2D,\n",
    "    Dense,\n",
    "    Flatten,\n",
    "    GlobalAveragePooling2D,\n",
    "    MaxPooling2D,\n",
    ")\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tqdm import notebook, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "PATH = \"/app/_data/\"\n",
    "BATCH_SIZE = 16\n",
    "SEED1 = 1488\n",
    "IMAGE_SIZE = (600, 600)\n",
    "NUM_CLASSES = 6\n",
    "INPUT_SHAPE = (600, 600, 3)\n",
    "IMG_PATH = '/app/_data/train_images/'\n",
    "SEED2 = 42\n",
    "MODEL_PATH = '/app/_data/models/effnet7_2_6cl_frozen_40ep_42.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(PATH+'train_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(PATH + \"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.join(labels[\"labels\"].str.get_dummies(sep=\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>labels</th>\n",
       "      <th>complex</th>\n",
       "      <th>frog_eye_leaf_spot</th>\n",
       "      <th>healthy</th>\n",
       "      <th>powdery_mildew</th>\n",
       "      <th>rust</th>\n",
       "      <th>scab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>800113bb65efe69e.jpg</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  image   labels  complex  frog_eye_leaf_spot  healthy  \\\n",
       "0  800113bb65efe69e.jpg  healthy        0                   0        1   \n",
       "\n",
       "   powdery_mildew  rust  scab  \n",
       "0               0     0     0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['complex', 'frog_eye_leaf_spot', 'healthy', 'powdery_mildew', 'rust', 'scab']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns = labels.columns[2:].tolist()\n",
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, valid_df = train_test_split(\n",
    "    labels, train_size=0.8, random_state=SEED1, stratify=labels[\"labels\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# train_df[train_df[\"powdery_mildew\"] == 1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in feature_columns:\n",
    "#     print(col, train_df[train_df[col] == 1][col].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# powdery_mildew = (\n",
    "#     train_df[train_df[\"powdery_mildew\"] == 1]\n",
    "#     .sample(\n",
    "#         n=(3000 - train_df[train_df[\"powdery_mildew\"] == 1].shape[0]),\n",
    "#         replace=True,\n",
    "#         random_state=SEED,\n",
    "#     )\n",
    "# )\n",
    "# rust = (\n",
    "#     train_df[train_df[\"rust\"] == 1]\n",
    "#     .sample(\n",
    "#         n=(3000 - train_df[train_df[\"rust\"] == 1].shape[0]),\n",
    "#         replace=True,\n",
    "#         random_state=SEED,\n",
    "#     )\n",
    "# )\n",
    "# complex_df = (\n",
    "#     train_df[train_df[\"complex\"] == 1]\n",
    "#     .sample(\n",
    "#         n=(3000 - train_df[train_df[\"complex\"] == 1].shape[0]),\n",
    "#         replace=True,\n",
    "#         random_state=SEED,\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df_new = pd.concat(\n",
    "#     [\n",
    "#         train_df,\n",
    "#         powdery_mildew,\n",
    "#         rust,\n",
    "#         complex_df,\n",
    "#     ],axis=0,ignore_index=True, \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df_new.shape\n",
    "# train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14800 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    validation_split=0.2\n",
    ")\n",
    "train = train_datagen.flow_from_dataframe(\n",
    "    dataframe=labels,\n",
    "    directory=IMG_PATH,\n",
    "    x_col=\"image\",\n",
    "    y_col=feature_columns,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"raw\",\n",
    "    subset=\"training\",\n",
    "    seed=SEED2,\n",
    "    interpolation=\"bicubic\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14800 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train2=ImageDataGenerator().flow_from_dataframe(\n",
    "    dataframe=train_df ,\n",
    "    directory=IMG_PATH,\n",
    "    x_col=\"image\",\n",
    "    y_col=feature_columns,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"raw\",\n",
    "    seed=SEED1,\n",
    "    interpolation=\"bicubic\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3700 validated image filenames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras_preprocessing/image/dataframe_iterator.py:219: UserWarning: `classes` will be ignored given the class_mode=\"raw\"\n",
      "  warnings.warn('`classes` will be ignored given the class_mode=\"{}\"'\n"
     ]
    }
   ],
   "source": [
    "valid_datagen = ImageDataGenerator(\n",
    "    validation_split=0.2,\n",
    "\n",
    ")\n",
    "valid = valid_datagen.flow_from_dataframe(\n",
    "    dataframe=labels,\n",
    "    directory=IMG_PATH,\n",
    "    x_col=\"image\",\n",
    "    y_col=feature_columns,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"raw\",\n",
    "    subset=\"validation\",\n",
    "    seed=SEED2,\n",
    "    classes=feature_columns,\n",
    "    interpolation=\"bicubic\",\n",
    "    shuffle=True,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3700 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "valid2=ImageDataGenerator().flow_from_dataframe(\n",
    "    dataframe=valid_df ,\n",
    "    directory=IMG_PATH,\n",
    "    x_col=\"image\",\n",
    "    y_col=feature_columns,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"raw\",\n",
    "    seed=SEED2,\n",
    "    interpolation=\"bicubic\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "test = test_datagen.flow_from_dataframe(\n",
    "    dataframe=sample_submission,\n",
    "    directory=PATH + \"test_images/\",\n",
    "    x_col=\"image\",\n",
    "    y_col=None,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=None,\n",
    "    seed=SEED2,\n",
    "    shuffle=False,\n",
    "    interpolation=\"bicubic\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curves(model, loss=False):\n",
    "    df = pd.DataFrame(model.history)\n",
    "    if loss:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.title(\"loss\")\n",
    "        plt.plot(df.iloc[:, 0], label=\"loss\")\n",
    "        plt.plot(df.iloc[:, 5], label=\"val_loss\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.figure(figsize=(12, 20))\n",
    "        plt.subplot(4, 1, 1)\n",
    "        plt.title(\"accuracy\")\n",
    "        plt.plot(df.iloc[:, 1], label=\"accuracy\")\n",
    "        plt.plot(df.iloc[:, 6], label=\"val_accuracy\")\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(4, 1, 2)\n",
    "        plt.title(\"recall\")\n",
    "        plt.plot(df.iloc[:, 2], label=\"recall\")\n",
    "        plt.plot(df.iloc[:, 7], label=\"val_recall\")\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(4, 1, 3)\n",
    "        plt.title(\"precision\")\n",
    "        plt.plot(df.iloc[:, 3], label=\"precision\")\n",
    "        plt.plot(df.iloc[:, 8], label=\"val_precision\")\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(4, 1, 4)\n",
    "        plt.title(\"f1\")\n",
    "        plt.plot(df.iloc[:, 4], label=\"f1\")\n",
    "        plt.plot(df.iloc[:, 9], label=\"val_f1\")\n",
    "        plt.legend()\n",
    "        plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "        keras.layers.experimental.preprocessing.RandomHeight(0.1),\n",
    "        keras.layers.experimental.preprocessing.RandomWidth(0.1),\n",
    "        keras.layers.experimental.preprocessing.RandomRotation(0.15),\n",
    "        keras.layers.experimental.preprocessing.RandomZoom(0.25, 0.25),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features, target = next(train)\n",
    "# plt.figure(figsize=(15,15))\n",
    "# for i in range(9):\n",
    "#     ax = plt.subplot(3, 3, i + 1)\n",
    "#     aug_img = data_augmentation(tf.expand_dims(features[0], axis=0))\n",
    "#     plt.imshow(aug_img[0].numpy().astype(\"uint8\"))\n",
    "#     plt.title(i)\n",
    "#     plt.axis(\"off\")\n",
    "# plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Quadro RTX 5000, compute capability 7.5\n"
     ]
    }
   ],
   "source": [
    "# tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "policy = keras.mixed_precision.experimental.Policy('mixed_float16')\n",
    "keras.mixed_precision.experimental.set_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scheduler(epoch, lr):\n",
    "#     if epoch < 5:\n",
    "#         return lr\n",
    "#     elif 5 <= epoch < 20:\n",
    "#         return 0.0005\n",
    "#     else:\n",
    "#         return 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks=[\n",
    "        keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "            patience=10, restore_best_weights=True, verbose=1),\n",
    "#         keras.callbacks.LearningRateScheduler(schedule = scheduler, verbose=1)\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = keras.layers.Input(shape=INPUT_SHAPE)\n",
    "# x = data_augmentation(inputs)\n",
    "# model = keras.applications.EfficientNetB7(weights=\"imagenet\", include_top=False,  input_tensor=x)\n",
    "# model.trainable = False\n",
    "\n",
    "# x = keras.layers.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n",
    "# x = keras.layers.Flatten(name=\"flatten\")(x)\n",
    "# outputs = keras.layers.Dense(NUM_CLASSES, activation=\"sigmoid\")(x)\n",
    "# model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = keras.Input(shape=INPUT_SHAPE)\n",
    "# x = data_augmentation(inputs)\n",
    "# x = keras.applications.EfficientNetB7(weights=\"imagenet\", include_top=False)(x)\n",
    "# x = keras.layers.GlobalAveragePooling2D(name=\"avg_pool\")(x)\n",
    "# x = keras.layers.Flatten(name=\"flatten\")(x)\n",
    "# outputs = keras.layers.Dense(NUM_CLASSES, activation=\"sigmoid\")(x)\n",
    "# model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(\n",
    "#     loss=\"binary_crossentropy\",\n",
    "#     optimizer=Adam(lr=0.0005),\n",
    "#     metrics=['acc',\n",
    "#         keras.metrics.Recall(),\n",
    "#         keras.metrics.Precision(),\n",
    "#         tfa.metrics.F1Score(num_classes=NUM_CLASSES, average=\"micro\"),\n",
    "#     ],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(\n",
    "#     train,\n",
    "#     validation_data=valid,\n",
    "#     epochs=20,\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     verbose=1,\n",
    "#     use_multiprocessing=True,\n",
    "#     callbacks = callbacks\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history_effnet7_2_6cl_frozen_40epseed_42 = pd.DataFrame(history.history)\n",
    "# history_effnet7_2_6cl_frozen_40epseed_42.to_csv(\"history_effnet7_2_6cl_frozen_40epseed_42.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"/app/_data/models/effnet7_2_6cl_frozen_40ep_42.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# shutil.make_archive('base_model_0001_nearest', 'zip','/app/_data/models/base_model_0001/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = keras.models.load_model(\"/app/_data/models/effnet7_2_6cl_frozen_40ep_42.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_curves(history, loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_curves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "711"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1040"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model2.trainable_weights)\n",
    "len(model2.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "924/925 [============================>.] - ETA: 3s - loss: 0.1667 - acc: 0.8347 - recall: 0.7563 - precision: 0.8626 - f1_score: 0.8302WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "925/925 [==============================] - ETA: 0s - loss: 0.1666 - acc: 0.8349 - recall: 0.7565 - precision: 0.8627 - f1_score: 0.8304WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "925/925 [==============================] - 3573s 4s/step - loss: 0.1666 - acc: 0.8349 - recall: 0.7565 - precision: 0.8627 - f1_score: 0.8304 - val_loss: 0.1639 - val_acc: 0.8370 - val_recall: 0.7787 - val_precision: 0.8532 - val_f1_score: 0.8260\n",
      "Epoch 2/20\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "924/925 [============================>.] - ETA: 3s - loss: 0.1665 - acc: 0.8355 - recall: 0.7552 - precision: 0.8625 - f1_score: 0.8318WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "925/925 [==============================] - ETA: 0s - loss: 0.1665 - acc: 0.8355 - recall: 0.7553 - precision: 0.8625 - f1_score: 0.8319WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "925/925 [==============================] - 3547s 4s/step - loss: 0.1665 - acc: 0.8355 - recall: 0.7553 - precision: 0.8625 - f1_score: 0.8319 - val_loss: 0.1627 - val_acc: 0.8392 - val_recall: 0.8036 - val_precision: 0.8456 - val_f1_score: 0.8311\n",
      "Epoch 3/20\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "924/925 [============================>.] - ETA: 3s - loss: 0.1676 - acc: 0.8331 - recall: 0.7536 - precision: 0.8584 - f1_score: 0.8298WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "925/925 [==============================] - ETA: 0s - loss: 0.1676 - acc: 0.8330 - recall: 0.7536 - precision: 0.8584 - f1_score: 0.8297WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "925/925 [==============================] - 3552s 4s/step - loss: 0.1676 - acc: 0.8330 - recall: 0.7536 - precision: 0.8584 - f1_score: 0.8297 - val_loss: 0.1697 - val_acc: 0.8303 - val_recall: 0.7712 - val_precision: 0.8475 - val_f1_score: 0.8196\n",
      "Epoch 4/20\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "924/925 [============================>.] - ETA: 3s - loss: 0.1669 - acc: 0.8331 - recall: 0.7565 - precision: 0.8634 - f1_score: 0.8294WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "925/925 [==============================] - ETA: 0s - loss: 0.1669 - acc: 0.8332 - recall: 0.7567 - precision: 0.8635 - f1_score: 0.8295WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "925/925 [==============================] - 3580s 4s/step - loss: 0.1669 - acc: 0.8332 - recall: 0.7567 - precision: 0.8635 - f1_score: 0.8295 - val_loss: 0.1594 - val_acc: 0.8454 - val_recall: 0.7919 - val_precision: 0.8548 - val_f1_score: 0.8342\n",
      "Epoch 5/20\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "924/925 [============================>.] - ETA: 3s - loss: 0.1673 - acc: 0.8327 - recall: 0.7578 - precision: 0.8617 - f1_score: 0.8287WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "925/925 [==============================] - ETA: 0s - loss: 0.1672 - acc: 0.8326 - recall: 0.7578 - precision: 0.8616 - f1_score: 0.8287WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "925/925 [==============================] - 3539s 4s/step - loss: 0.1672 - acc: 0.8326 - recall: 0.7578 - precision: 0.8616 - f1_score: 0.8287 - val_loss: 0.1599 - val_acc: 0.8368 - val_recall: 0.7932 - val_precision: 0.8525 - val_f1_score: 0.8306\n",
      "Epoch 6/20\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "924/925 [============================>.] - ETA: 3s - loss: 0.1670 - acc: 0.8335 - recall: 0.7547 - precision: 0.8638 - f1_score: 0.8296WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "925/925 [==============================] - ETA: 0s - loss: 0.1670 - acc: 0.8335 - recall: 0.7547 - precision: 0.8639 - f1_score: 0.8296WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "925/925 [==============================] - 3534s 4s/step - loss: 0.1670 - acc: 0.8335 - recall: 0.7547 - precision: 0.8639 - f1_score: 0.8296 - val_loss: 0.1665 - val_acc: 0.8211 - val_recall: 0.7817 - val_precision: 0.8470 - val_f1_score: 0.8202\n",
      "Epoch 7/20\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "924/925 [============================>.] - ETA: 3s - loss: 0.1666 - acc: 0.8312 - recall: 0.7578 - precision: 0.8630 - f1_score: 0.8280WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "925/925 [==============================] - ETA: 0s - loss: 0.1666 - acc: 0.8312 - recall: 0.7578 - precision: 0.8630 - f1_score: 0.8280WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "925/925 [==============================] - 3577s 4s/step - loss: 0.1666 - acc: 0.8312 - recall: 0.7578 - precision: 0.8630 - f1_score: 0.8280 - val_loss: 0.1605 - val_acc: 0.8416 - val_recall: 0.7784 - val_precision: 0.8588 - val_f1_score: 0.8308\n",
      "Epoch 8/20\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "924/925 [============================>.] - ETA: 3s - loss: 0.1659 - acc: 0.8340 - recall: 0.7610 - precision: 0.8635 - f1_score: 0.8289WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "925/925 [==============================] - ETA: 0s - loss: 0.1658 - acc: 0.8341 - recall: 0.7611 - precision: 0.8636 - f1_score: 0.8290WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "925/925 [==============================] - 3594s 4s/step - loss: 0.1658 - acc: 0.8341 - recall: 0.7611 - precision: 0.8636 - f1_score: 0.8290 - val_loss: 0.1597 - val_acc: 0.8332 - val_recall: 0.7929 - val_precision: 0.8538 - val_f1_score: 0.8294\n",
      "Epoch 9/20\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "924/925 [============================>.] - ETA: 3s - loss: 0.1658 - acc: 0.8363 - recall: 0.7603 - precision: 0.8646 - f1_score: 0.8321WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "925/925 [==============================] - ETA: 0s - loss: 0.1657 - acc: 0.8364 - recall: 0.7605 - precision: 0.8646 - f1_score: 0.8322WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "925/925 [==============================] - 3535s 4s/step - loss: 0.1657 - acc: 0.8364 - recall: 0.7605 - precision: 0.8646 - f1_score: 0.8322 - val_loss: 0.1614 - val_acc: 0.8368 - val_recall: 0.8079 - val_precision: 0.8443 - val_f1_score: 0.8302\n",
      "Epoch 10/20\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "924/925 [============================>.] - ETA: 3s - loss: 0.1646 - acc: 0.8375 - recall: 0.7645 - precision: 0.8664 - f1_score: 0.8325WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "925/925 [==============================] - ETA: 0s - loss: 0.1646 - acc: 0.8376 - recall: 0.7643 - precision: 0.8665 - f1_score: 0.8325WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "925/925 [==============================] - 3542s 4s/step - loss: 0.1646 - acc: 0.8376 - recall: 0.7643 - precision: 0.8665 - f1_score: 0.8325 - val_loss: 0.1635 - val_acc: 0.8386 - val_recall: 0.7964 - val_precision: 0.8456 - val_f1_score: 0.8277\n",
      "Epoch 11/20\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "924/925 [============================>.] - ETA: 3s - loss: 0.1666 - acc: 0.8341 - recall: 0.7554 - precision: 0.8603 - f1_score: 0.8289WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "925/925 [==============================] - ETA: 0s - loss: 0.1666 - acc: 0.8342 - recall: 0.7554 - precision: 0.8602 - f1_score: 0.8290WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "925/925 [==============================] - 3545s 4s/step - loss: 0.1666 - acc: 0.8342 - recall: 0.7554 - precision: 0.8602 - f1_score: 0.8290 - val_loss: 0.1606 - val_acc: 0.8368 - val_recall: 0.7757 - val_precision: 0.8627 - val_f1_score: 0.8275\n",
      "Epoch 12/20\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "924/925 [============================>.] - ETA: 3s - loss: 0.1640 - acc: 0.8352 - recall: 0.7636 - precision: 0.8662 - f1_score: 0.8307WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "925/925 [==============================] - ETA: 0s - loss: 0.1640 - acc: 0.8351 - recall: 0.7635 - precision: 0.8663 - f1_score: 0.8307WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "925/925 [==============================] - 3551s 4s/step - loss: 0.1640 - acc: 0.8351 - recall: 0.7635 - precision: 0.8663 - f1_score: 0.8307 - val_loss: 0.1603 - val_acc: 0.8362 - val_recall: 0.8041 - val_precision: 0.8428 - val_f1_score: 0.8304\n",
      "Epoch 13/20\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "924/925 [============================>.] - ETA: 3s - loss: 0.1647 - acc: 0.8379 - recall: 0.7638 - precision: 0.8641 - f1_score: 0.8326WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "925/925 [==============================] - ETA: 0s - loss: 0.1648 - acc: 0.8378 - recall: 0.7636 - precision: 0.8641 - f1_score: 0.8326WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "925/925 [==============================] - 3563s 4s/step - loss: 0.1648 - acc: 0.8378 - recall: 0.7636 - precision: 0.8641 - f1_score: 0.8326 - val_loss: 0.1711 - val_acc: 0.8286 - val_recall: 0.7562 - val_precision: 0.8528 - val_f1_score: 0.8183\n",
      "Epoch 14/20\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "924/925 [============================>.] - ETA: 3s - loss: 0.1647 - acc: 0.8341 - recall: 0.7577 - precision: 0.8637 - f1_score: 0.8300WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "925/925 [==============================] - ETA: 0s - loss: 0.1647 - acc: 0.8341 - recall: 0.7577 - precision: 0.8636 - f1_score: 0.8300WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "925/925 [==============================] - 3548s 4s/step - loss: 0.1647 - acc: 0.8341 - recall: 0.7577 - precision: 0.8636 - f1_score: 0.8300 - val_loss: 0.1651 - val_acc: 0.8362 - val_recall: 0.7705 - val_precision: 0.8580 - val_f1_score: 0.8256\n",
      "Epoch 00014: early stopping\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(\n",
    "    train2,\n",
    "    validation_data=valid2,\n",
    "    epochs=20,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    verbose=1,\n",
    "    use_multiprocessing=True,\n",
    "    callbacks = callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save(\"/app/_data/models/effnet7_2_6cl_from_frozezen_20ep.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(model,feature_columns, rescale=True):\n",
    "    if rescale:\n",
    "        dg = ImageDataGenerator(rescale = 1. /255)\n",
    "    else:\n",
    "        dg = ImageDataGenerator()\n",
    "    all_img = dg.flow_from_dataframe(\n",
    "    dataframe=labels,\n",
    "    directory=IMG_PATH,\n",
    "    x_col=\"image\",\n",
    "    y_col=feature_columns,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"raw\",\n",
    "    interpolation = 'bicubic',\n",
    "    shuffle=False,\n",
    ")\n",
    "    prediction_all = model.predict(all_img)\n",
    "    prediction = pd.DataFrame(prediction_all, columns=feature_columns).join(pd.DataFrame(all_img._targets, columns=feature_columns), rsuffix='_true', lsuffix = '_pred')\n",
    "    prediction.index = all_img.filenames\n",
    "    return prediction_all,prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18500 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "prediction_all,prediction = get_prediction(model2, rescale=False, feature_columns = feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_all.to_csv('/app/sandbox/wrong_predictions/prediction_raw_5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
