{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lib.train_utils import get_training_arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "from lib.train_utils import create_tensorboard_run_dir, save_trained_model\n",
    "from tensorflow import keras\n",
    "\n",
    "from src.config import config\n",
    "import argparse\n",
    "# from lib.train_utils import get_training_arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_arguments(\n",
    "    description=\"resnet50\",\n",
    "    RUN=\"A\",\n",
    "    LR_START=5e-6,\n",
    "    VAL_SPLIT=0.2,\n",
    "    BATCH_SIZE=64,\n",
    "    TOTAL_EPOCHS=50,\n",
    "    EARLY_STOP_PATIENCE=10,\n",
    "):\n",
    "\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=description,\n",
    "        formatter_class=argparse.ArgumentDefaultsHelpFormatter,\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\"-f\", \"--run\", type=str, default=RUN)\n",
    "    parser.add_argument(\"--max_items\", type=int, default=None)\n",
    "    parser.add_argument(\"--epochs\", type=int, default=TOTAL_EPOCHS)\n",
    "    parser.add_argument( \"--batch\", type=int, default=BATCH_SIZE)\n",
    "    parser.add_argument(  \"--lr_start\", type=float, default=LR_START)\n",
    "    parser.add_argument( \"--val_split\", type=float, default=VAL_SPLIT)\n",
    "    parser.add_argument( \"--early_stop_patience\", type=int, default=EARLY_STOP_PATIENCE)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # display arguments\n",
    "#     print(f\"* Arguments:\\n{pformat(vars(args))}\")\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read cli arguments\n",
    "args = get_training_arguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tensorboard log dir\n",
    "tb_log_dir = create_tensorboard_run_dir(args.run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load training data\n",
    "# train_X, train_Y, val_X, val_Y = bert_load_training_data(\n",
    "#     max_items=args.max_items, shuffle=True, val_split=args.val_split\n",
    "# )\n",
    "\n",
    "# # prepare model\n",
    "\n",
    "# model = bert_build_model(\n",
    "#     bert_model_dir=config[\"DATA_DIR\"] + \"/bert\", max_seq_len=config[\"MAX_SEQ_LENGTH\"]\n",
    "# )\n",
    "\n",
    "# model.compile(\n",
    "#     optimizer=keras.optimizers.Adam(learning_rate=args.lr_start),\n",
    "#     loss=keras.losses.BinaryCrossentropy(),\n",
    "#     metrics=[\n",
    "#         keras.metrics.AUC(\n",
    "#             multi_label=True,\n",
    "#         )\n",
    "#     ],\n",
    "# )\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "# # fit\n",
    "\n",
    "# model.fit(\n",
    "#     x=train_X,\n",
    "#     y=train_Y,\n",
    "#     shuffle=True,\n",
    "#     epochs=args.epochs,\n",
    "#     batch_size=args.batch,\n",
    "#     validation_data=(val_X, val_Y),\n",
    "#     steps_per_epoch=args.samples_per_epoch // args.batch,\n",
    "#     callbacks=[\n",
    "#         keras.callbacks.EarlyStopping(\n",
    "#             patience=args.early_stop_patience, restore_best_weights=True, verbose=1\n",
    "#         ),\n",
    "#         keras.callbacks.TensorBoard(log_dir=tb_log_dir),\n",
    "#     ],\n",
    "# )\n",
    "\n",
    "# # save trained model\n",
    "# save_trained_model(model=model, run=args.run, info=vars(args))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
