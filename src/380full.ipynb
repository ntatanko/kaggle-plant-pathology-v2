{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /app/kaggle.json'\n"
     ]
    }
   ],
   "source": [
    "import kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /app/kaggle.json'\n",
      "Data package template written to: /app/_data/models/final/eff4_full/dataset-metadata.json\n"
     ]
    }
   ],
   "source": [
    "# ! kaggle datasets init -p /app/_data/models/final/eff4_full/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /app/kaggle.json'\n",
      "Starting upload for file eff4_full_2.h5\n",
      "100%|█████████████████████████████████████████| 203M/203M [05:19<00:00, 666kB/s]\n",
      "Upload successful: eff4_full_2.h5 (203MB)\n",
      "Starting upload for file eff4_full_1.h5\n",
      "100%|█████████████████████████████████████████| 203M/203M [05:23<00:00, 658kB/s]\n",
      "Upload successful: eff4_full_1.h5 (203MB)\n",
      "Starting upload for file eff4_full_5.h5\n",
      "100%|█████████████████████████████████████████| 203M/203M [05:16<00:00, 672kB/s]\n",
      "Upload successful: eff4_full_5.h5 (203MB)\n",
      "Starting upload for file eff4_full_4.h5\n",
      "100%|█████████████████████████████████████████| 203M/203M [05:17<00:00, 671kB/s]\n",
      "Upload successful: eff4_full_4.h5 (203MB)\n",
      "Starting upload for file eff4_full_3.h5\n",
      "100%|█████████████████████████████████████████| 203M/203M [05:18<00:00, 669kB/s]\n",
      "Upload successful: eff4_full_3.h5 (203MB)\n",
      "Skipping folder: .ipynb_checkpoints; use '--dir-mode' to upload folders\n",
      "Your private Dataset is being created. Please check progress at https://www.kaggle.com/nataliayurasova/Eff4Full\n"
     ]
    }
   ],
   "source": [
    "# ! kaggle datasets create -p /app/_data/models/final/eff4_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.891\n",
    "MODEL_BB_PATH= '../input/model-bb-1/bond_box_999_200.h5'\n",
    "MODEL_PATH = '../input/0865fulltrain/'\n",
    "IMAGE_SIZE = (380, 380)\n",
    "DF_PART = '../input/df-kf-plant/df_kf.csv'\n",
    "PATH = \"/kaggle/input/plant-pathology-2021-fgvc8/\"\n",
    "TRAIN_IMG_PATH = PATH+'train_images/'\n",
    "TEST_IMG_PATH = PATH+'test_images/'\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES=6\n",
    "SEED = 1488\n",
    "- replace ''-'scab'\n",
    "https://www.kaggle.com/nataliayurasova/plant-pathology0891/edit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: albumentations in /usr/local/lib/python3.8/dist-packages (0.5.2)\n",
      "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.8/dist-packages (from albumentations) (1.17.3)\n",
      "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.8/dist-packages (from albumentations) (4.5.1.48)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.8/dist-packages (from albumentations) (0.18.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from albumentations) (1.4.1)\n",
      "Requirement already satisfied: imgaug>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from albumentations) (0.4.0)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from albumentations) (5.3.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from imgaug>=0.4.0->albumentations) (3.3.4)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (from imgaug>=0.4.0->albumentations) (4.5.1.48)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from imgaug>=0.4.0->albumentations) (1.15.0)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from imgaug>=0.4.0->albumentations) (8.1.2)\n",
      "Requirement already satisfied: Shapely in /usr/local/lib/python3.8/dist-packages (from imgaug>=0.4.0->albumentations) (1.7.1)\n",
      "Requirement already satisfied: imageio in /usr/local/lib/python3.8/dist-packages (from imgaug>=0.4.0->albumentations) (2.9.0)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.16.1->albumentations) (1.1.1)\n",
      "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.16.1->albumentations) (2.5.1)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.16.1->albumentations) (2021.4.8)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations) (0.10.0)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.8/dist-packages (from networkx>=2.0->scikit-image>=0.16.1->albumentations) (4.4.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install albumentations\n",
    "import albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import (\n",
    "    StratifiedKFold,\n",
    "    StratifiedShuffleSplit,\n",
    "    train_test_split,\n",
    ")\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB4, EfficientNetB7\n",
    "from tensorflow.keras.layers import (\n",
    "    AveragePooling2D,\n",
    "    AvgPool2D,\n",
    "    Conv2D,\n",
    "    Dense,\n",
    "    Flatten,\n",
    "    GlobalAveragePooling2D,\n",
    "    MaxPooling2D,\n",
    ")\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tqdm import notebook, tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/app/_data/\"\n",
    "BATCH_SIZE = 56\n",
    "SEED = 42\n",
    "IMAGE_SIZE = 380\n",
    "NUM_CLASSES = 6\n",
    "TRAIN_IMG_PATH = \"/app/_data/380_full_npy/\"\n",
    "TEST_IMG_PATH = \"/app/_data/test_images/\"\n",
    "feature_columns = [\n",
    "    \"complex\",\n",
    "    \"frog_eye_leaf_spot\",\n",
    "    \"healthy\",\n",
    "    \"powdery_mildew\",\n",
    "    \"rust\",\n",
    "    \"scab\",\n",
    "]\n",
    "wrong = ['ead085dfac287263.jpg', '95276ccd226ad933.jpg',\"da8770e819d2696d.jpg\", 'cd3a1d64e6806eb5.jpg', 'ccec54723ff91860.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f8228796cfdae848.npy'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(TRAIN_IMG_PATH)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(380, 380, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.load(TRAIN_IMG_PATH+os.listdir(TRAIN_IMG_PATH)[0])\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = pd.read_csv(\"../_data/df_csv/labels_21_20.csv\", index_col=[0])\n",
    "df_labels = df_labels.query('image not in @wrong').reset_index(drop=True)\n",
    "df_labels[\"image\"] = df_labels[\"image\"].str.replace(\".jpg\", \".npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = df_labels.sample(frac=1, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20225, 8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complex</th>\n",
       "      <th>frog_eye_leaf_spot</th>\n",
       "      <th>healthy</th>\n",
       "      <th>powdery_mildew</th>\n",
       "      <th>rust</th>\n",
       "      <th>scab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20225.000000</td>\n",
       "      <td>20225.000000</td>\n",
       "      <td>20225.000000</td>\n",
       "      <td>20225.000000</td>\n",
       "      <td>20225.000000</td>\n",
       "      <td>20225.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.104821</td>\n",
       "      <td>0.214487</td>\n",
       "      <td>0.253103</td>\n",
       "      <td>0.062645</td>\n",
       "      <td>0.130680</td>\n",
       "      <td>0.310556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.306330</td>\n",
       "      <td>0.410476</td>\n",
       "      <td>0.434800</td>\n",
       "      <td>0.242330</td>\n",
       "      <td>0.337058</td>\n",
       "      <td>0.462733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            complex  frog_eye_leaf_spot       healthy  powdery_mildew  \\\n",
       "count  20225.000000        20225.000000  20225.000000    20225.000000   \n",
       "mean       0.104821            0.214487      0.253103        0.062645   \n",
       "std        0.306330            0.410476      0.434800        0.242330   \n",
       "min        0.000000            0.000000      0.000000        0.000000   \n",
       "25%        0.000000            0.000000      0.000000        0.000000   \n",
       "50%        0.000000            0.000000      0.000000        0.000000   \n",
       "75%        0.000000            0.000000      1.000000        0.000000   \n",
       "max        1.000000            1.000000      1.000000        1.000000   \n",
       "\n",
       "               rust          scab  \n",
       "count  20225.000000  20225.000000  \n",
       "mean       0.130680      0.310556  \n",
       "std        0.337058      0.462733  \n",
       "min        0.000000      0.000000  \n",
       "25%        0.000000      0.000000  \n",
       "50%        0.000000      0.000000  \n",
       "75%        0.000000      1.000000  \n",
       "max        1.000000      1.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels[feature_columns].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 380*380\n",
    "transform = albumentations.Compose(\n",
    "    [\n",
    "        albumentations.CLAHE(p=0.1, clip_limit=(1, 2), tile_grid_size=(8, 8)),\n",
    "        albumentations.OneOf(\n",
    "            [\n",
    "                albumentations.MotionBlur((3, 3)),\n",
    "                albumentations.MedianBlur(blur_limit=3),\n",
    "                albumentations.GaussianBlur(blur_limit=(3, 3), sigma_limit=0),\n",
    "                albumentations.Blur(blur_limit=(3, 3)),\n",
    "            ],\n",
    "            p=0.2,\n",
    "        ),\n",
    "        albumentations.OneOf(\n",
    "            [\n",
    "                albumentations.GaussNoise(var_limit=[10, 50], mean=1),\n",
    "                albumentations.ISONoise(intensity=(0.1, 1), color_shift=(0.01, 0.05)),\n",
    "                albumentations.ImageCompression(\n",
    "                    quality_lower=70, quality_upper=100, compression_type=1\n",
    "                ),\n",
    "                albumentations.MultiplicativeNoise(\n",
    "                    multiplier=(0.95, 1.05), per_channel=True, elementwise=True\n",
    "                ),\n",
    "                albumentations.Downscale(\n",
    "                    scale_min=0.6, scale_max=0.99, interpolation=4\n",
    "                ),\n",
    "            ],\n",
    "            p=0.5,\n",
    "        ),\n",
    "        albumentations.OneOf(\n",
    "            [\n",
    "                albumentations.HueSaturationValue(\n",
    "                    hue_shift_limit=(-7, 7),\n",
    "                    sat_shift_limit=(-10, 10),\n",
    "                    val_shift_limit=(-10, 10),\n",
    "                ),\n",
    "                albumentations.RandomBrightnessContrast(\n",
    "                    brightness_limit=0.15,\n",
    "                    contrast_limit=0.2,\n",
    "                    brightness_by_max=True,\n",
    "                ),\n",
    "            ],\n",
    "            p=0.5,\n",
    "        ),\n",
    "        albumentations.OneOf(\n",
    "            [\n",
    "                albumentations.OpticalDistortion(\n",
    "                    distort_limit=0.05,\n",
    "                    shift_limit=0.05,\n",
    "                    border_mode=2,\n",
    "                ),\n",
    "                albumentations.ElasticTransform(\n",
    "                    alpha=2.0,\n",
    "                    sigma=50.0,\n",
    "                    alpha_affine=10.0,\n",
    "                    interpolation=0,\n",
    "                    border_mode=2,\n",
    "                ),\n",
    "                albumentations.GridDistortion(\n",
    "                    num_steps=5, distort_limit=0.3, interpolation=0, border_mode=2\n",
    "                ),\n",
    "            ],\n",
    "            p=0.5,\n",
    "        ),\n",
    "        albumentations.OneOf(\n",
    "            [\n",
    "                albumentations.HorizontalFlip(),\n",
    "                albumentations.VerticalFlip(),\n",
    "            ],\n",
    "            p=0.5,\n",
    "        ),\n",
    "        albumentations.OneOf(\n",
    "            [\n",
    "                albumentations.Rotate(\n",
    "                    limit=(-180, 180), interpolation=0, border_mode=2\n",
    "                ),\n",
    "                albumentations.ShiftScaleRotate(\n",
    "                    shift_limit=0.05,\n",
    "                    scale_limit=0.05,\n",
    "                    rotate_limit=180,\n",
    "                    interpolation=0,\n",
    "                    border_mode=2,\n",
    "                ),\n",
    "            ],\n",
    "            p=0.5,\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(keras.utils.Sequence):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        images_src_dir,\n",
    "        batch_size,\n",
    "        target_image_size,\n",
    "        shuffle=False,\n",
    "        augment=True,\n",
    "        crop=False,\n",
    "        resize=False,\n",
    "        normalize=False,\n",
    "    ):\n",
    "        self.shuffle = shuffle\n",
    "        self.batch_size = BATCH_SIZE\n",
    "        self.df = df\n",
    "        self.images_dir = images_src_dir\n",
    "        self.target_image_size = (IMAGE_SIZE, IMAGE_SIZE)\n",
    "        self.augment = augment\n",
    "        self.crop = crop\n",
    "        self.resize = resize\n",
    "        self.normalize = normalize\n",
    "        # create label index map\n",
    "        self.labels = self._read_labels()\n",
    "        self.n_samples = self.df.shape[0]\n",
    "        self.n_batches = self.n_samples // self.batch_size\n",
    "        # shuffle data, also repeated after each epoch if needed\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.labels)\n",
    "\n",
    "    def _read_labels(self):\n",
    "        \"\"\"\n",
    "        Returns list images mapping to 1-hot label\n",
    "        \"\"\"\n",
    "\n",
    "        # label indexes\n",
    "        label_ixs = self.df[feature_columns].values\n",
    "        image_ixs = self.df[\"image\"].values\n",
    "        labels = []\n",
    "\n",
    "        for i in range(len(image_ixs)):\n",
    "            labels.append([image_ixs[i], label_ixs[i]])\n",
    "        return labels\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Length in batches\n",
    "        \"\"\"\n",
    "        return self.n_batches\n",
    "\n",
    "    def __getitem__(self, b_ix):\n",
    "        \"\"\"\n",
    "        Produce batch, by batch index\n",
    "        \"\"\"\n",
    "\n",
    "        assert b_ix < self.n_batches\n",
    "\n",
    "        b_X = np.zeros(\n",
    "            (self.batch_size, self.target_image_size[0], self.target_image_size[1], 3),\n",
    "            dtype=np.uint8,\n",
    "        )\n",
    "\n",
    "        b_Y = np.zeros(\n",
    "            (self.batch_size, self.df[feature_columns].shape[1]),\n",
    "            dtype=np.uint8,\n",
    "        )\n",
    "\n",
    "        for i in range(self.batch_size):\n",
    "            b_X[i], b_Y[i] = self.get_one(\n",
    "                i + self.batch_size * b_ix,\n",
    "            )\n",
    "\n",
    "        return (b_X, b_Y)\n",
    "\n",
    "    def get_one(self, one_ix):\n",
    "        \"\"\"\n",
    "        Get single item by absolute index\n",
    "        \"\"\"\n",
    "        id = self.labels[one_ix][0]\n",
    "        src_file = self.images_dir + id\n",
    "\n",
    "        # read file\n",
    "        x = np.load(src_file)\n",
    "        if self.crop:\n",
    "            coord = self.df[self.df[\"image\"] == id][\n",
    "                [\"x_min\", \"y_min\", \"x_max\", \"y_max\"]\n",
    "            ].values[0]\n",
    "            orig_hight = x.shape[0]\n",
    "            orig_width = x.shape[1]\n",
    "            x_min = coord[0]\n",
    "            y_min = coord[1]\n",
    "            x_max = coord[2]\n",
    "            y_max = coord[3]\n",
    "            x = x[\n",
    "                np.int(y_min * orig_hight) : np.int(y_max * orig_hight),\n",
    "                np.int(x_min * orig_width) : np.int(x_max * orig_width),\n",
    "            ]\n",
    "\n",
    "        y = self.labels[one_ix][1]\n",
    "\n",
    "        # augment\n",
    "        if self.augment:\n",
    "            x = self._augment_image(x)\n",
    "\n",
    "        # normalize (sample-wise)\n",
    "        if self.normalize:\n",
    "            x = x.astype(np.float32)\n",
    "            x = x - np.mean(x, axis=(0, 1))\n",
    "            x = x / np.std(x, axis=(0, 1))\n",
    "        return x.astype(np.uint8), y\n",
    "\n",
    "    def _augment_image(self, x):\n",
    "        \"\"\"\n",
    "        Randomply augment image\n",
    "        \"\"\"\n",
    "\n",
    "        x = transform(image=x)[\"image\"]\n",
    "        return x\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3090, compute capability 8.6\n"
     ]
    }
   ],
   "source": [
    "policy = keras.mixed_precision.experimental.Policy(\"mixed_float16\")\n",
    "keras.mixed_precision.experimental.set_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    inputs = keras.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "    base_model = keras.applications.EfficientNetB4(weights=None, include_top=False)\n",
    "    base_model.load_weights(\n",
    "        \"/app/_data/models/efficientnet-b4_noisy-student_notop.h5\",\n",
    "        by_name=True,\n",
    "        skip_mismatch=True,\n",
    "    )\n",
    "    x = base_model(inputs)\n",
    "    x = keras.layers.GlobalAveragePooling2D(name=\"avg_pool\")(x)\n",
    "    x = keras.layers.Flatten(name=\"flatten\")(x)\n",
    "    outputs = keras.layers.Dense(NUM_CLASSES, activation=\"sigmoid\")(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=Adam(lr=0.0005),\n",
    "        metrics=[\n",
    "            \"acc\",\n",
    "            keras.metrics.Recall(),\n",
    "            keras.metrics.Precision(),\n",
    "            tfa.metrics.F1Score(num_classes=NUM_CLASSES, average=\"weighted\"),\n",
    "        ],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  1/288 [..............................] - ETA: 0s - loss: 0.6763 - acc: 0.1964 - recall: 0.4483 - precision: 0.2047 - f1_score: 0.2092WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.1518 - acc: 0.8321 - recall: 0.7917 - precision: 0.8580 - f1_score: 0.8208\n",
      "Epoch 00001: val_f1_score improved from -inf to 0.83931, saving model to /app/_data/models/final/eff4_full/eff4_full_1.h5\n",
      "288/288 [==============================] - 204s 708ms/step - loss: 0.1518 - acc: 0.8321 - recall: 0.7917 - precision: 0.8580 - f1_score: 0.8208 - val_loss: 0.1608 - val_acc: 0.8549 - val_recall: 0.8021 - val_precision: 0.8935 - val_f1_score: 0.8393\n",
      "Epoch 2/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.1000 - acc: 0.8924 - recall: 0.8717 - precision: 0.9018 - f1_score: 0.8789\n",
      "Epoch 00002: val_f1_score improved from 0.83931 to 0.90329, saving model to /app/_data/models/final/eff4_full/eff4_full_1.h5\n",
      "288/288 [==============================] - 281s 977ms/step - loss: 0.1000 - acc: 0.8924 - recall: 0.8717 - precision: 0.9018 - f1_score: 0.8789 - val_loss: 0.0915 - val_acc: 0.9127 - val_recall: 0.8871 - val_precision: 0.9357 - val_f1_score: 0.9033\n",
      "Epoch 3/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0890 - acc: 0.9014 - recall: 0.8880 - precision: 0.9122 - f1_score: 0.8904\n",
      "Epoch 00003: val_f1_score did not improve from 0.90329\n",
      "288/288 [==============================] - 312s 1s/step - loss: 0.0890 - acc: 0.9014 - recall: 0.8880 - precision: 0.9122 - f1_score: 0.8904 - val_loss: 0.0919 - val_acc: 0.8765 - val_recall: 0.8762 - val_precision: 0.9064 - val_f1_score: 0.8791\n",
      "Epoch 4/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0794 - acc: 0.9134 - recall: 0.9010 - precision: 0.9204 - f1_score: 0.9010\n",
      "Epoch 00004: val_f1_score did not improve from 0.90329\n",
      "288/288 [==============================] - 302s 1s/step - loss: 0.0794 - acc: 0.9134 - recall: 0.9010 - precision: 0.9204 - f1_score: 0.9010 - val_loss: 0.0891 - val_acc: 0.8872 - val_recall: 0.8868 - val_precision: 0.9082 - val_f1_score: 0.8760\n",
      "Epoch 5/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0751 - acc: 0.9178 - recall: 0.9046 - precision: 0.9258 - f1_score: 0.9057\n",
      "Epoch 00005: val_f1_score did not improve from 0.90329\n",
      "288/288 [==============================] - 278s 964ms/step - loss: 0.0751 - acc: 0.9178 - recall: 0.9046 - precision: 0.9258 - f1_score: 0.9057 - val_loss: 0.0837 - val_acc: 0.9120 - val_recall: 0.9120 - val_precision: 0.9137 - val_f1_score: 0.9004\n",
      "Epoch 6/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0696 - acc: 0.9209 - recall: 0.9116 - precision: 0.9283 - f1_score: 0.9094\n",
      "Epoch 00006: val_f1_score improved from 0.90329 to 0.90595, saving model to /app/_data/models/final/eff4_full/eff4_full_1.h5\n",
      "288/288 [==============================] - 290s 1s/step - loss: 0.0696 - acc: 0.9209 - recall: 0.9116 - precision: 0.9283 - f1_score: 0.9094 - val_loss: 0.0805 - val_acc: 0.9209 - val_recall: 0.8963 - val_precision: 0.9260 - val_f1_score: 0.9060\n",
      "Epoch 7/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0653 - acc: 0.9274 - recall: 0.9199 - precision: 0.9344 - f1_score: 0.9155\n",
      "Epoch 00007: val_f1_score did not improve from 0.90595\n",
      "288/288 [==============================] - 289s 1s/step - loss: 0.0653 - acc: 0.9274 - recall: 0.9199 - precision: 0.9344 - f1_score: 0.9155 - val_loss: 0.0897 - val_acc: 0.9062 - val_recall: 0.8898 - val_precision: 0.9111 - val_f1_score: 0.8927\n",
      "Epoch 8/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0605 - acc: 0.9293 - recall: 0.9248 - precision: 0.9369 - f1_score: 0.9174\n",
      "Epoch 00008: val_f1_score did not improve from 0.90595\n",
      "288/288 [==============================] - 286s 993ms/step - loss: 0.0605 - acc: 0.9293 - recall: 0.9248 - precision: 0.9369 - f1_score: 0.9174 - val_loss: 0.0841 - val_acc: 0.9134 - val_recall: 0.9046 - val_precision: 0.9169 - val_f1_score: 0.9018\n",
      "Epoch 9/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0590 - acc: 0.9333 - recall: 0.9276 - precision: 0.9394 - f1_score: 0.9203\n",
      "Epoch 00009: val_f1_score did not improve from 0.90595\n",
      "288/288 [==============================] - 282s 979ms/step - loss: 0.0590 - acc: 0.9333 - recall: 0.9276 - precision: 0.9394 - f1_score: 0.9203 - val_loss: 0.0831 - val_acc: 0.9196 - val_recall: 0.8880 - val_precision: 0.9308 - val_f1_score: 0.9054\n",
      "Epoch 10/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0551 - acc: 0.9332 - recall: 0.9310 - precision: 0.9438 - f1_score: 0.9227\n",
      "Epoch 00010: val_f1_score improved from 0.90595 to 0.90857, saving model to /app/_data/models/final/eff4_full/eff4_full_1.h5\n",
      "288/288 [==============================] - 287s 997ms/step - loss: 0.0551 - acc: 0.9332 - recall: 0.9310 - precision: 0.9438 - f1_score: 0.9227 - val_loss: 0.0804 - val_acc: 0.9182 - val_recall: 0.9150 - val_precision: 0.9255 - val_f1_score: 0.9086\n",
      "Epoch 11/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0527 - acc: 0.9353 - recall: 0.9364 - precision: 0.9457 - f1_score: 0.9253\n",
      "Epoch 00011: val_f1_score did not improve from 0.90857\n",
      "288/288 [==============================] - 284s 986ms/step - loss: 0.0527 - acc: 0.9353 - recall: 0.9364 - precision: 0.9457 - f1_score: 0.9253 - val_loss: 0.0987 - val_acc: 0.9028 - val_recall: 0.8885 - val_precision: 0.9164 - val_f1_score: 0.8925\n",
      "Epoch 12/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0487 - acc: 0.9387 - recall: 0.9404 - precision: 0.9490 - f1_score: 0.9275\n",
      "Epoch 00012: val_f1_score did not improve from 0.90857\n",
      "288/288 [==============================] - 298s 1s/step - loss: 0.0487 - acc: 0.9387 - recall: 0.9404 - precision: 0.9490 - f1_score: 0.9275 - val_loss: 0.0807 - val_acc: 0.9209 - val_recall: 0.9141 - val_precision: 0.9135 - val_f1_score: 0.9081\n",
      "Epoch 13/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0457 - acc: 0.9420 - recall: 0.9445 - precision: 0.9553 - f1_score: 0.9327\n",
      "Epoch 00013: val_f1_score did not improve from 0.90857\n",
      "288/288 [==============================] - 283s 982ms/step - loss: 0.0457 - acc: 0.9420 - recall: 0.9445 - precision: 0.9553 - f1_score: 0.9327 - val_loss: 0.1537 - val_acc: 0.9035 - val_recall: 0.9180 - val_precision: 0.8831 - val_f1_score: 0.8934\n",
      "Epoch 14/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0439 - acc: 0.9417 - recall: 0.9467 - precision: 0.9538 - f1_score: 0.9314\n",
      "Epoch 00014: val_f1_score did not improve from 0.90857\n",
      "288/288 [==============================] - 274s 950ms/step - loss: 0.0439 - acc: 0.9417 - recall: 0.9467 - precision: 0.9538 - f1_score: 0.9314 - val_loss: 0.0990 - val_acc: 0.9028 - val_recall: 0.8979 - val_precision: 0.9270 - val_f1_score: 0.8992\n",
      "Epoch 15/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0436 - acc: 0.9457 - recall: 0.9492 - precision: 0.9588 - f1_score: 0.9353\n",
      "Epoch 00015: val_f1_score did not improve from 0.90857\n",
      "288/288 [==============================] - 285s 988ms/step - loss: 0.0436 - acc: 0.9457 - recall: 0.9492 - precision: 0.9588 - f1_score: 0.9353 - val_loss: 0.0939 - val_acc: 0.9110 - val_recall: 0.9201 - val_precision: 0.9201 - val_f1_score: 0.9053\n",
      "Epoch 16/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0370 - acc: 0.9477 - recall: 0.9542 - precision: 0.9629 - f1_score: 0.9391\n",
      "Epoch 00016: val_f1_score did not improve from 0.90857\n",
      "288/288 [==============================] - 275s 953ms/step - loss: 0.0370 - acc: 0.9477 - recall: 0.9542 - precision: 0.9629 - f1_score: 0.9391 - val_loss: 0.1069 - val_acc: 0.8978 - val_recall: 0.8857 - val_precision: 0.9166 - val_f1_score: 0.8916\n",
      "Epoch 17/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0368 - acc: 0.9487 - recall: 0.9575 - precision: 0.9634 - f1_score: 0.9407\n",
      "Epoch 00017: val_f1_score did not improve from 0.90857\n",
      "288/288 [==============================] - 286s 992ms/step - loss: 0.0368 - acc: 0.9487 - recall: 0.9575 - precision: 0.9634 - f1_score: 0.9407 - val_loss: 0.0874 - val_acc: 0.9196 - val_recall: 0.9125 - val_precision: 0.9270 - val_f1_score: 0.9080\n",
      "Epoch 18/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0370 - acc: 0.9482 - recall: 0.9570 - precision: 0.9628 - f1_score: 0.9388\n",
      "Epoch 00018: val_f1_score did not improve from 0.90857\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0004500000213738531.\n",
      "288/288 [==============================] - 280s 972ms/step - loss: 0.0370 - acc: 0.9482 - recall: 0.9570 - precision: 0.9628 - f1_score: 0.9388 - val_loss: 0.1005 - val_acc: 0.9194 - val_recall: 0.9090 - val_precision: 0.9158 - val_f1_score: 0.9058\n",
      "Epoch 19/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0303 - acc: 0.9539 - recall: 0.9642 - precision: 0.9677 - f1_score: 0.9448\n",
      "Epoch 00019: val_f1_score improved from 0.90857 to 0.91203, saving model to /app/_data/models/final/eff4_full/eff4_full_1.h5\n",
      "288/288 [==============================] - 287s 998ms/step - loss: 0.0303 - acc: 0.9539 - recall: 0.9642 - precision: 0.9677 - f1_score: 0.9448 - val_loss: 0.0910 - val_acc: 0.9229 - val_recall: 0.9192 - val_precision: 0.9207 - val_f1_score: 0.9120\n",
      "Epoch 20/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0281 - acc: 0.9550 - recall: 0.9671 - precision: 0.9727 - f1_score: 0.9468\n",
      "Epoch 00020: val_f1_score did not improve from 0.91203\n",
      "288/288 [==============================] - 268s 930ms/step - loss: 0.0281 - acc: 0.9550 - recall: 0.9671 - precision: 0.9727 - f1_score: 0.9468 - val_loss: 0.1042 - val_acc: 0.9048 - val_recall: 0.9113 - val_precision: 0.9183 - val_f1_score: 0.9013\n",
      "Epoch 21/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0285 - acc: 0.9570 - recall: 0.9664 - precision: 0.9711 - f1_score: 0.9483\n",
      "Epoch 00021: val_f1_score did not improve from 0.91203\n",
      "288/288 [==============================] - 270s 936ms/step - loss: 0.0285 - acc: 0.9570 - recall: 0.9664 - precision: 0.9711 - f1_score: 0.9483 - val_loss: 0.0958 - val_acc: 0.9221 - val_recall: 0.9333 - val_precision: 0.9024 - val_f1_score: 0.9097\n",
      "Epoch 22/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0256 - acc: 0.9581 - recall: 0.9700 - precision: 0.9751 - f1_score: 0.9496\n",
      "Epoch 00022: val_f1_score improved from 0.91203 to 0.91363, saving model to /app/_data/models/final/eff4_full/eff4_full_1.h5\n",
      "288/288 [==============================] - 280s 971ms/step - loss: 0.0256 - acc: 0.9581 - recall: 0.9700 - precision: 0.9751 - f1_score: 0.9496 - val_loss: 0.0978 - val_acc: 0.9214 - val_recall: 0.9256 - val_precision: 0.9227 - val_f1_score: 0.9136\n",
      "Epoch 23/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0249 - acc: 0.9549 - recall: 0.9706 - precision: 0.9748 - f1_score: 0.9492\n",
      "Epoch 00023: val_f1_score did not improve from 0.91363\n",
      "288/288 [==============================] - 279s 967ms/step - loss: 0.0249 - acc: 0.9549 - recall: 0.9706 - precision: 0.9748 - f1_score: 0.9492 - val_loss: 0.1035 - val_acc: 0.9201 - val_recall: 0.9256 - val_precision: 0.9184 - val_f1_score: 0.9093\n",
      "Epoch 24/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0236 - acc: 0.9585 - recall: 0.9723 - precision: 0.9761 - f1_score: 0.9517\n",
      "Epoch 00024: val_f1_score improved from 0.91363 to 0.91867, saving model to /app/_data/models/final/eff4_full/eff4_full_1.h5\n",
      "288/288 [==============================] - 279s 969ms/step - loss: 0.0236 - acc: 0.9585 - recall: 0.9723 - precision: 0.9761 - f1_score: 0.9517 - val_loss: 0.0992 - val_acc: 0.9306 - val_recall: 0.9242 - val_precision: 0.9303 - val_f1_score: 0.9187\n",
      "Epoch 25/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0228 - acc: 0.9586 - recall: 0.9751 - precision: 0.9768 - f1_score: 0.9522\n",
      "Epoch 00025: val_f1_score did not improve from 0.91867\n",
      "288/288 [==============================] - 270s 936ms/step - loss: 0.0228 - acc: 0.9586 - recall: 0.9751 - precision: 0.9768 - f1_score: 0.9522 - val_loss: 0.1095 - val_acc: 0.9236 - val_recall: 0.9210 - val_precision: 0.9187 - val_f1_score: 0.9115\n",
      "Epoch 26/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0231 - acc: 0.9598 - recall: 0.9746 - precision: 0.9780 - f1_score: 0.9512\n",
      "Epoch 00026: val_f1_score did not improve from 0.91867\n",
      "288/288 [==============================] - 290s 1s/step - loss: 0.0231 - acc: 0.9598 - recall: 0.9746 - precision: 0.9780 - f1_score: 0.9512 - val_loss: 0.1125 - val_acc: 0.9167 - val_recall: 0.9162 - val_precision: 0.9174 - val_f1_score: 0.9082\n",
      "Epoch 27/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0199 - acc: 0.9577 - recall: 0.9766 - precision: 0.9801 - f1_score: 0.9535\n",
      "Epoch 00027: val_f1_score did not improve from 0.91867\n",
      "288/288 [==============================] - 289s 1s/step - loss: 0.0199 - acc: 0.9577 - recall: 0.9766 - precision: 0.9801 - f1_score: 0.9535 - val_loss: 0.1033 - val_acc: 0.9182 - val_recall: 0.9148 - val_precision: 0.9302 - val_f1_score: 0.9123\n",
      "Epoch 28/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0203 - acc: 0.9582 - recall: 0.9773 - precision: 0.9805 - f1_score: 0.9535\n",
      "Epoch 00028: val_f1_score did not improve from 0.91867\n",
      "288/288 [==============================] - 300s 1s/step - loss: 0.0203 - acc: 0.9582 - recall: 0.9773 - precision: 0.9805 - f1_score: 0.9535 - val_loss: 0.1032 - val_acc: 0.9241 - val_recall: 0.9321 - val_precision: 0.9127 - val_f1_score: 0.9160\n",
      "Epoch 29/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0178 - acc: 0.9625 - recall: 0.9789 - precision: 0.9820 - f1_score: 0.9555\n",
      "Epoch 00029: val_f1_score did not improve from 0.91867\n",
      "288/288 [==============================] - 295s 1s/step - loss: 0.0178 - acc: 0.9625 - recall: 0.9789 - precision: 0.9820 - f1_score: 0.9555 - val_loss: 0.1161 - val_acc: 0.9209 - val_recall: 0.9206 - val_precision: 0.9265 - val_f1_score: 0.9135\n",
      "Epoch 30/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0199 - acc: 0.9624 - recall: 0.9764 - precision: 0.9803 - f1_score: 0.9538\n",
      "Epoch 00030: val_f1_score did not improve from 0.91867\n",
      "288/288 [==============================] - 278s 965ms/step - loss: 0.0199 - acc: 0.9624 - recall: 0.9764 - precision: 0.9803 - f1_score: 0.9538 - val_loss: 0.1189 - val_acc: 0.9221 - val_recall: 0.9238 - val_precision: 0.9153 - val_f1_score: 0.9139\n",
      "Epoch 31/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0200 - acc: 0.9596 - recall: 0.9780 - precision: 0.9812 - f1_score: 0.9547\n",
      "Epoch 00031: val_f1_score did not improve from 0.91867\n",
      "288/288 [==============================] - 291s 1s/step - loss: 0.0200 - acc: 0.9596 - recall: 0.9780 - precision: 0.9812 - f1_score: 0.9547 - val_loss: 0.1010 - val_acc: 0.9241 - val_recall: 0.9199 - val_precision: 0.9239 - val_f1_score: 0.9114\n",
      "Epoch 32/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0176 - acc: 0.9645 - recall: 0.9803 - precision: 0.9830 - f1_score: 0.9565\n",
      "Epoch 00032: val_f1_score did not improve from 0.91867\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0004050000192364678.\n",
      "288/288 [==============================] - 292s 1s/step - loss: 0.0176 - acc: 0.9645 - recall: 0.9803 - precision: 0.9830 - f1_score: 0.9565 - val_loss: 0.0984 - val_acc: 0.9224 - val_recall: 0.9208 - val_precision: 0.9242 - val_f1_score: 0.9153\n",
      "Epoch 33/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0161 - acc: 0.9598 - recall: 0.9827 - precision: 0.9836 - f1_score: 0.9560\n",
      "Epoch 00033: val_f1_score did not improve from 0.91867\n",
      "288/288 [==============================] - 289s 1s/step - loss: 0.0161 - acc: 0.9598 - recall: 0.9827 - precision: 0.9836 - f1_score: 0.9560 - val_loss: 0.1071 - val_acc: 0.9189 - val_recall: 0.9127 - val_precision: 0.9347 - val_f1_score: 0.9133\n",
      "Epoch 34/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0138 - acc: 0.9640 - recall: 0.9851 - precision: 0.9866 - f1_score: 0.9605\n",
      "Epoch 00034: val_f1_score did not improve from 0.91867\n",
      "288/288 [==============================] - 314s 1s/step - loss: 0.0138 - acc: 0.9640 - recall: 0.9851 - precision: 0.9866 - f1_score: 0.9605 - val_loss: 0.1224 - val_acc: 0.9164 - val_recall: 0.9162 - val_precision: 0.9105 - val_f1_score: 0.9079\n",
      "Epoch 35/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0134 - acc: 0.9639 - recall: 0.9854 - precision: 0.9863 - f1_score: 0.9616Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00035: val_f1_score did not improve from 0.91867\n",
      "288/288 [==============================] - 293s 1s/step - loss: 0.0134 - acc: 0.9639 - recall: 0.9854 - precision: 0.9863 - f1_score: 0.9616 - val_loss: 0.1198 - val_acc: 0.9204 - val_recall: 0.9314 - val_precision: 0.9061 - val_f1_score: 0.9100\n",
      "Epoch 00035: early stopping\n",
      "Epoch 1/100\n",
      "  2/288 [..............................] - ETA: 6:48 - loss: 0.6709 - acc: 0.1964 - recall: 0.4880 - precision: 0.2311 - f1_score: 0.2107WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.3928s vs `on_train_batch_end` time: 2.4617s). Check your callbacks.\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.1515 - acc: 0.8337 - recall: 0.7968 - precision: 0.8561 - f1_score: 0.8220\n",
      "Epoch 00001: val_f1_score improved from -inf to 0.86051, saving model to /app/_data/models/final/eff4_full/eff4_full_2.h5\n",
      "288/288 [==============================] - 283s 982ms/step - loss: 0.1515 - acc: 0.8337 - recall: 0.7968 - precision: 0.8561 - f1_score: 0.8220 - val_loss: 0.1228 - val_acc: 0.8832 - val_recall: 0.8274 - val_precision: 0.8947 - val_f1_score: 0.8605\n",
      "Epoch 2/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.1003 - acc: 0.8917 - recall: 0.8701 - precision: 0.9018 - f1_score: 0.8787\n",
      "Epoch 00002: val_f1_score improved from 0.86051 to 0.90340, saving model to /app/_data/models/final/eff4_full/eff4_full_2.h5\n",
      "288/288 [==============================] - 296s 1s/step - loss: 0.1003 - acc: 0.8917 - recall: 0.8701 - precision: 0.9018 - f1_score: 0.8787 - val_loss: 0.0851 - val_acc: 0.9216 - val_recall: 0.8985 - val_precision: 0.9192 - val_f1_score: 0.9034\n",
      "Epoch 3/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0883 - acc: 0.9052 - recall: 0.8880 - precision: 0.9139 - f1_score: 0.8924\n",
      "Epoch 00003: val_f1_score did not improve from 0.90340\n",
      "288/288 [==============================] - 294s 1s/step - loss: 0.0883 - acc: 0.9052 - recall: 0.8880 - precision: 0.9139 - f1_score: 0.8924 - val_loss: 0.0921 - val_acc: 0.9025 - val_recall: 0.8680 - val_precision: 0.9284 - val_f1_score: 0.8877\n",
      "Epoch 4/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0810 - acc: 0.9107 - recall: 0.8979 - precision: 0.9188 - f1_score: 0.8987\n",
      "Epoch 00004: val_f1_score did not improve from 0.90340\n",
      "288/288 [==============================] - 298s 1s/step - loss: 0.0810 - acc: 0.9107 - recall: 0.8979 - precision: 0.9188 - f1_score: 0.8987 - val_loss: 0.0812 - val_acc: 0.9050 - val_recall: 0.8955 - val_precision: 0.9240 - val_f1_score: 0.8899\n",
      "Epoch 5/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0751 - acc: 0.9141 - recall: 0.9070 - precision: 0.9241 - f1_score: 0.9038\n",
      "Epoch 00005: val_f1_score did not improve from 0.90340\n",
      "288/288 [==============================] - 295s 1s/step - loss: 0.0751 - acc: 0.9141 - recall: 0.9070 - precision: 0.9241 - f1_score: 0.9038 - val_loss: 0.0780 - val_acc: 0.9077 - val_recall: 0.8982 - val_precision: 0.9171 - val_f1_score: 0.8922\n",
      "Epoch 6/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0709 - acc: 0.9221 - recall: 0.9134 - precision: 0.9282 - f1_score: 0.9099\n",
      "Epoch 00006: val_f1_score improved from 0.90340 to 0.90622, saving model to /app/_data/models/final/eff4_full/eff4_full_2.h5\n",
      "288/288 [==============================] - 297s 1s/step - loss: 0.0709 - acc: 0.9221 - recall: 0.9134 - precision: 0.9282 - f1_score: 0.9099 - val_loss: 0.0763 - val_acc: 0.9221 - val_recall: 0.9141 - val_precision: 0.9165 - val_f1_score: 0.9062\n",
      "Epoch 7/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0648 - acc: 0.9234 - recall: 0.9180 - precision: 0.9319 - f1_score: 0.9130\n",
      "Epoch 00007: val_f1_score did not improve from 0.90622\n",
      "288/288 [==============================] - 290s 1s/step - loss: 0.0648 - acc: 0.9234 - recall: 0.9180 - precision: 0.9319 - f1_score: 0.9130 - val_loss: 0.0766 - val_acc: 0.9127 - val_recall: 0.9005 - val_precision: 0.9308 - val_f1_score: 0.9023\n",
      "Epoch 8/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0633 - acc: 0.9255 - recall: 0.9229 - precision: 0.9336 - f1_score: 0.9144\n",
      "Epoch 00008: val_f1_score did not improve from 0.90622\n",
      "288/288 [==============================] - 307s 1s/step - loss: 0.0633 - acc: 0.9255 - recall: 0.9229 - precision: 0.9336 - f1_score: 0.9144 - val_loss: 0.0992 - val_acc: 0.9221 - val_recall: 0.8878 - val_precision: 0.9308 - val_f1_score: 0.9039\n",
      "Epoch 9/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0606 - acc: 0.9284 - recall: 0.9256 - precision: 0.9352 - f1_score: 0.9173\n",
      "Epoch 00009: val_f1_score did not improve from 0.90622\n",
      "288/288 [==============================] - 302s 1s/step - loss: 0.0606 - acc: 0.9284 - recall: 0.9256 - precision: 0.9352 - f1_score: 0.9173 - val_loss: 0.0783 - val_acc: 0.9174 - val_recall: 0.9056 - val_precision: 0.9233 - val_f1_score: 0.9032\n",
      "Epoch 10/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0568 - acc: 0.9343 - recall: 0.9315 - precision: 0.9443 - f1_score: 0.9226\n",
      "Epoch 00010: val_f1_score improved from 0.90622 to 0.90824, saving model to /app/_data/models/final/eff4_full/eff4_full_2.h5\n",
      "288/288 [==============================] - 302s 1s/step - loss: 0.0568 - acc: 0.9343 - recall: 0.9315 - precision: 0.9443 - f1_score: 0.9226 - val_loss: 0.0793 - val_acc: 0.9241 - val_recall: 0.9234 - val_precision: 0.9151 - val_f1_score: 0.9082\n",
      "Epoch 11/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0506 - acc: 0.9394 - recall: 0.9379 - precision: 0.9469 - f1_score: 0.9278\n",
      "Epoch 00011: val_f1_score did not improve from 0.90824\n",
      "288/288 [==============================] - 302s 1s/step - loss: 0.0506 - acc: 0.9394 - recall: 0.9379 - precision: 0.9469 - f1_score: 0.9278 - val_loss: 0.0886 - val_acc: 0.9048 - val_recall: 0.9128 - val_precision: 0.9098 - val_f1_score: 0.8997\n",
      "Epoch 12/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0519 - acc: 0.9375 - recall: 0.9387 - precision: 0.9460 - f1_score: 0.9257\n",
      "Epoch 00012: val_f1_score did not improve from 0.90824\n",
      "288/288 [==============================] - 298s 1s/step - loss: 0.0519 - acc: 0.9375 - recall: 0.9387 - precision: 0.9460 - f1_score: 0.9257 - val_loss: 0.0861 - val_acc: 0.9144 - val_recall: 0.9058 - val_precision: 0.9227 - val_f1_score: 0.9006\n",
      "Epoch 13/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0448 - acc: 0.9430 - recall: 0.9458 - precision: 0.9537 - f1_score: 0.9322\n",
      "Epoch 00013: val_f1_score improved from 0.90824 to 0.90862, saving model to /app/_data/models/final/eff4_full/eff4_full_2.h5\n",
      "288/288 [==============================] - 307s 1s/step - loss: 0.0448 - acc: 0.9430 - recall: 0.9458 - precision: 0.9537 - f1_score: 0.9322 - val_loss: 0.0738 - val_acc: 0.9204 - val_recall: 0.9227 - val_precision: 0.9182 - val_f1_score: 0.9086\n",
      "Epoch 14/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0465 - acc: 0.9391 - recall: 0.9433 - precision: 0.9505 - f1_score: 0.9304\n",
      "Epoch 00014: val_f1_score improved from 0.90862 to 0.90904, saving model to /app/_data/models/final/eff4_full/eff4_full_2.h5\n",
      "288/288 [==============================] - 296s 1s/step - loss: 0.0465 - acc: 0.9391 - recall: 0.9433 - precision: 0.9505 - f1_score: 0.9304 - val_loss: 0.0839 - val_acc: 0.9239 - val_recall: 0.8978 - val_precision: 0.9396 - val_f1_score: 0.9090\n",
      "Epoch 15/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0437 - acc: 0.9435 - recall: 0.9482 - precision: 0.9566 - f1_score: 0.9338\n",
      "Epoch 00015: val_f1_score improved from 0.90904 to 0.91302, saving model to /app/_data/models/final/eff4_full/eff4_full_2.h5\n",
      "288/288 [==============================] - 299s 1s/step - loss: 0.0437 - acc: 0.9435 - recall: 0.9482 - precision: 0.9566 - f1_score: 0.9338 - val_loss: 0.0943 - val_acc: 0.9261 - val_recall: 0.9070 - val_precision: 0.9353 - val_f1_score: 0.9130\n",
      "Epoch 16/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0386 - acc: 0.9441 - recall: 0.9540 - precision: 0.9616 - f1_score: 0.9383\n",
      "Epoch 00016: val_f1_score did not improve from 0.91302\n",
      "288/288 [==============================] - 295s 1s/step - loss: 0.0386 - acc: 0.9441 - recall: 0.9540 - precision: 0.9616 - f1_score: 0.9383 - val_loss: 0.0808 - val_acc: 0.9283 - val_recall: 0.9252 - val_precision: 0.9172 - val_f1_score: 0.9125\n",
      "Epoch 17/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0383 - acc: 0.9433 - recall: 0.9555 - precision: 0.9609 - f1_score: 0.9382\n",
      "Epoch 00017: val_f1_score did not improve from 0.91302\n",
      "288/288 [==============================] - 294s 1s/step - loss: 0.0383 - acc: 0.9433 - recall: 0.9555 - precision: 0.9609 - f1_score: 0.9382 - val_loss: 0.0784 - val_acc: 0.9206 - val_recall: 0.9123 - val_precision: 0.9330 - val_f1_score: 0.9106\n",
      "Epoch 18/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0377 - acc: 0.9452 - recall: 0.9562 - precision: 0.9627 - f1_score: 0.9395\n",
      "Epoch 00018: val_f1_score did not improve from 0.91302\n",
      "288/288 [==============================] - 270s 936ms/step - loss: 0.0377 - acc: 0.9452 - recall: 0.9562 - precision: 0.9627 - f1_score: 0.9395 - val_loss: 0.0779 - val_acc: 0.9127 - val_recall: 0.9238 - val_precision: 0.9185 - val_f1_score: 0.9099\n",
      "Epoch 19/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0333 - acc: 0.9491 - recall: 0.9610 - precision: 0.9673 - f1_score: 0.9423\n",
      "Epoch 00019: val_f1_score did not improve from 0.91302\n",
      "288/288 [==============================] - 285s 991ms/step - loss: 0.0333 - acc: 0.9491 - recall: 0.9610 - precision: 0.9673 - f1_score: 0.9423 - val_loss: 0.1215 - val_acc: 0.9137 - val_recall: 0.8929 - val_precision: 0.9234 - val_f1_score: 0.8979\n",
      "Epoch 20/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0351 - acc: 0.9486 - recall: 0.9606 - precision: 0.9651 - f1_score: 0.9403\n",
      "Epoch 00020: val_f1_score did not improve from 0.91302\n",
      "288/288 [==============================] - 284s 985ms/step - loss: 0.0351 - acc: 0.9486 - recall: 0.9606 - precision: 0.9651 - f1_score: 0.9403 - val_loss: 0.1099 - val_acc: 0.9013 - val_recall: 0.9054 - val_precision: 0.9073 - val_f1_score: 0.8936\n",
      "Epoch 21/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0293 - acc: 0.9528 - recall: 0.9671 - precision: 0.9708 - f1_score: 0.9466\n",
      "Epoch 00021: val_f1_score did not improve from 0.91302\n",
      "288/288 [==============================] - 299s 1s/step - loss: 0.0293 - acc: 0.9528 - recall: 0.9671 - precision: 0.9708 - f1_score: 0.9466 - val_loss: 0.0901 - val_acc: 0.9211 - val_recall: 0.9238 - val_precision: 0.9164 - val_f1_score: 0.9049\n",
      "Epoch 22/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0284 - acc: 0.9565 - recall: 0.9667 - precision: 0.9708 - f1_score: 0.9471\n",
      "Epoch 00022: val_f1_score did not improve from 0.91302\n",
      "288/288 [==============================] - 301s 1s/step - loss: 0.0284 - acc: 0.9565 - recall: 0.9667 - precision: 0.9708 - f1_score: 0.9471 - val_loss: 0.1156 - val_acc: 0.9117 - val_recall: 0.9038 - val_precision: 0.9105 - val_f1_score: 0.8951\n",
      "Epoch 23/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0293 - acc: 0.9508 - recall: 0.9669 - precision: 0.9711 - f1_score: 0.9458\n",
      "Epoch 00023: val_f1_score did not improve from 0.91302\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0004500000213738531.\n",
      "288/288 [==============================] - 293s 1s/step - loss: 0.0293 - acc: 0.9508 - recall: 0.9669 - precision: 0.9711 - f1_score: 0.9458 - val_loss: 0.0978 - val_acc: 0.9157 - val_recall: 0.9139 - val_precision: 0.9129 - val_f1_score: 0.9003\n",
      "Epoch 24/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0249 - acc: 0.9526 - recall: 0.9741 - precision: 0.9750 - f1_score: 0.9500\n",
      "Epoch 00024: val_f1_score did not improve from 0.91302\n",
      "288/288 [==============================] - 290s 1s/step - loss: 0.0249 - acc: 0.9526 - recall: 0.9741 - precision: 0.9750 - f1_score: 0.9500 - val_loss: 0.0930 - val_acc: 0.9224 - val_recall: 0.9160 - val_precision: 0.9187 - val_f1_score: 0.9083\n",
      "Epoch 25/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0234 - acc: 0.9530 - recall: 0.9742 - precision: 0.9767 - f1_score: 0.9506\n",
      "Epoch 00025: val_f1_score improved from 0.91302 to 0.91349, saving model to /app/_data/models/final/eff4_full/eff4_full_2.h5\n",
      "288/288 [==============================] - 292s 1s/step - loss: 0.0234 - acc: 0.9530 - recall: 0.9742 - precision: 0.9767 - f1_score: 0.9506 - val_loss: 0.1010 - val_acc: 0.9246 - val_recall: 0.9091 - val_precision: 0.9381 - val_f1_score: 0.9135\n",
      "Epoch 26/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0217 - acc: 0.9575 - recall: 0.9755 - precision: 0.9802 - f1_score: 0.9546\n",
      "Epoch 00026: val_f1_score did not improve from 0.91349\n",
      "288/288 [==============================] - 306s 1s/step - loss: 0.0217 - acc: 0.9575 - recall: 0.9755 - precision: 0.9802 - f1_score: 0.9546 - val_loss: 0.1065 - val_acc: 0.9261 - val_recall: 0.9031 - val_precision: 0.9357 - val_f1_score: 0.9126\n",
      "Epoch 27/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0219 - acc: 0.9597 - recall: 0.9739 - precision: 0.9777 - f1_score: 0.9515\n",
      "Epoch 00027: val_f1_score did not improve from 0.91349\n",
      "288/288 [==============================] - 303s 1s/step - loss: 0.0219 - acc: 0.9597 - recall: 0.9739 - precision: 0.9777 - f1_score: 0.9515 - val_loss: 0.0942 - val_acc: 0.9221 - val_recall: 0.9257 - val_precision: 0.9116 - val_f1_score: 0.9105\n",
      "Epoch 28/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0220 - acc: 0.9570 - recall: 0.9744 - precision: 0.9791 - f1_score: 0.9512\n",
      "Epoch 00028: val_f1_score did not improve from 0.91349\n",
      "288/288 [==============================] - 293s 1s/step - loss: 0.0220 - acc: 0.9570 - recall: 0.9744 - precision: 0.9791 - f1_score: 0.9512 - val_loss: 0.1029 - val_acc: 0.9206 - val_recall: 0.9093 - val_precision: 0.9343 - val_f1_score: 0.9112\n",
      "Epoch 29/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0210 - acc: 0.9598 - recall: 0.9764 - precision: 0.9797 - f1_score: 0.9526\n",
      "Epoch 00029: val_f1_score did not improve from 0.91349\n",
      "288/288 [==============================] - 303s 1s/step - loss: 0.0210 - acc: 0.9598 - recall: 0.9764 - precision: 0.9797 - f1_score: 0.9526 - val_loss: 0.1174 - val_acc: 0.9246 - val_recall: 0.9081 - val_precision: 0.9265 - val_f1_score: 0.9095\n",
      "Epoch 30/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0177 - acc: 0.9590 - recall: 0.9798 - precision: 0.9818 - f1_score: 0.9554\n",
      "Epoch 00030: val_f1_score did not improve from 0.91349\n",
      "288/288 [==============================] - 298s 1s/step - loss: 0.0177 - acc: 0.9590 - recall: 0.9798 - precision: 0.9818 - f1_score: 0.9554 - val_loss: 0.1000 - val_acc: 0.9167 - val_recall: 0.9211 - val_precision: 0.9213 - val_f1_score: 0.9101\n",
      "Epoch 31/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0185 - acc: 0.9614 - recall: 0.9800 - precision: 0.9820 - f1_score: 0.9568\n",
      "Epoch 00031: val_f1_score did not improve from 0.91349\n",
      "288/288 [==============================] - 288s 999ms/step - loss: 0.0185 - acc: 0.9614 - recall: 0.9800 - precision: 0.9820 - f1_score: 0.9568 - val_loss: 0.1016 - val_acc: 0.9276 - val_recall: 0.9195 - val_precision: 0.9231 - val_f1_score: 0.9119\n",
      "Epoch 32/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0191 - acc: 0.9612 - recall: 0.9787 - precision: 0.9804 - f1_score: 0.9549\n",
      "Epoch 00032: val_f1_score did not improve from 0.91349\n",
      "288/288 [==============================] - 295s 1s/step - loss: 0.0191 - acc: 0.9612 - recall: 0.9787 - precision: 0.9804 - f1_score: 0.9549 - val_loss: 0.1176 - val_acc: 0.9115 - val_recall: 0.9049 - val_precision: 0.9263 - val_f1_score: 0.9031\n",
      "Epoch 33/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0163 - acc: 0.9621 - recall: 0.9819 - precision: 0.9834 - f1_score: 0.9579\n",
      "Epoch 00033: val_f1_score did not improve from 0.91349\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.0004050000192364678.\n",
      "288/288 [==============================] - 303s 1s/step - loss: 0.0163 - acc: 0.9621 - recall: 0.9819 - precision: 0.9834 - f1_score: 0.9579 - val_loss: 0.1197 - val_acc: 0.9142 - val_recall: 0.9116 - val_precision: 0.9192 - val_f1_score: 0.9071\n",
      "Epoch 34/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0129 - acc: 0.9673 - recall: 0.9858 - precision: 0.9855 - f1_score: 0.9610\n",
      "Epoch 00034: val_f1_score did not improve from 0.91349\n",
      "288/288 [==============================] - 312s 1s/step - loss: 0.0129 - acc: 0.9673 - recall: 0.9858 - precision: 0.9855 - f1_score: 0.9610 - val_loss: 0.1275 - val_acc: 0.9164 - val_recall: 0.9192 - val_precision: 0.9192 - val_f1_score: 0.9092\n",
      "Epoch 35/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0139 - acc: 0.9654 - recall: 0.9847 - precision: 0.9876 - f1_score: 0.9621\n",
      "Epoch 00035: val_f1_score did not improve from 0.91349\n",
      "288/288 [==============================] - 300s 1s/step - loss: 0.0139 - acc: 0.9654 - recall: 0.9847 - precision: 0.9876 - f1_score: 0.9621 - val_loss: 0.1429 - val_acc: 0.9043 - val_recall: 0.9061 - val_precision: 0.9107 - val_f1_score: 0.8909\n",
      "Epoch 36/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0147 - acc: 0.9656 - recall: 0.9839 - precision: 0.9846 - f1_score: 0.9595Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00036: val_f1_score did not improve from 0.91349\n",
      "288/288 [==============================] - 312s 1s/step - loss: 0.0147 - acc: 0.9656 - recall: 0.9839 - precision: 0.9846 - f1_score: 0.9595 - val_loss: 0.1141 - val_acc: 0.9062 - val_recall: 0.9146 - val_precision: 0.9001 - val_f1_score: 0.8967\n",
      "Epoch 00036: early stopping\n",
      "Epoch 1/100\n",
      "  2/288 [..............................] - ETA: 7:03 - loss: 0.6665 - acc: 0.2321 - recall: 0.4538 - precision: 0.2169 - f1_score: 0.2259WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4749s vs `on_train_batch_end` time: 2.4848s). Check your callbacks.\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.1487 - acc: 0.8401 - recall: 0.8018 - precision: 0.8614 - f1_score: 0.8286\n",
      "Epoch 00001: val_f1_score improved from -inf to 0.82069, saving model to /app/_data/models/final/eff4_full/eff4_full_3.h5\n",
      "288/288 [==============================] - 271s 940ms/step - loss: 0.1487 - acc: 0.8401 - recall: 0.8018 - precision: 0.8614 - f1_score: 0.8286 - val_loss: 0.1557 - val_acc: 0.8415 - val_recall: 0.8365 - val_precision: 0.8496 - val_f1_score: 0.8207\n",
      "Epoch 2/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0986 - acc: 0.8934 - recall: 0.8715 - precision: 0.9047 - f1_score: 0.8815\n",
      "Epoch 00002: val_f1_score improved from 0.82069 to 0.88182, saving model to /app/_data/models/final/eff4_full/eff4_full_3.h5\n",
      "288/288 [==============================] - 306s 1s/step - loss: 0.0986 - acc: 0.8934 - recall: 0.8715 - precision: 0.9047 - f1_score: 0.8815 - val_loss: 0.1114 - val_acc: 0.8899 - val_recall: 0.8634 - val_precision: 0.9191 - val_f1_score: 0.8818\n",
      "Epoch 3/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0868 - acc: 0.9057 - recall: 0.8906 - precision: 0.9151 - f1_score: 0.8946\n",
      "Epoch 00003: val_f1_score improved from 0.88182 to 0.88660, saving model to /app/_data/models/final/eff4_full/eff4_full_3.h5\n",
      "288/288 [==============================] - 289s 1s/step - loss: 0.0868 - acc: 0.9057 - recall: 0.8906 - precision: 0.9151 - f1_score: 0.8946 - val_loss: 0.0912 - val_acc: 0.9100 - val_recall: 0.8774 - val_precision: 0.9018 - val_f1_score: 0.8866\n",
      "Epoch 4/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0796 - acc: 0.9121 - recall: 0.8995 - precision: 0.9202 - f1_score: 0.9007\n",
      "Epoch 00004: val_f1_score did not improve from 0.88660\n",
      "288/288 [==============================] - 286s 992ms/step - loss: 0.0796 - acc: 0.9121 - recall: 0.8995 - precision: 0.9202 - f1_score: 0.9007 - val_loss: 0.0947 - val_acc: 0.8966 - val_recall: 0.8887 - val_precision: 0.9036 - val_f1_score: 0.8814\n",
      "Epoch 5/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0728 - acc: 0.9182 - recall: 0.9076 - precision: 0.9278 - f1_score: 0.9080\n",
      "Epoch 00005: val_f1_score did not improve from 0.88660\n",
      "288/288 [==============================] - 295s 1s/step - loss: 0.0728 - acc: 0.9182 - recall: 0.9076 - precision: 0.9278 - f1_score: 0.9080 - val_loss: 0.0958 - val_acc: 0.8879 - val_recall: 0.9128 - val_precision: 0.8847 - val_f1_score: 0.8853\n",
      "Epoch 6/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0688 - acc: 0.9212 - recall: 0.9131 - precision: 0.9304 - f1_score: 0.9107\n",
      "Epoch 00006: val_f1_score did not improve from 0.88660\n",
      "288/288 [==============================] - 298s 1s/step - loss: 0.0688 - acc: 0.9212 - recall: 0.9131 - precision: 0.9304 - f1_score: 0.9107 - val_loss: 0.0904 - val_acc: 0.8862 - val_recall: 0.8838 - val_precision: 0.9097 - val_f1_score: 0.8758\n",
      "Epoch 7/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0637 - acc: 0.9257 - recall: 0.9191 - precision: 0.9340 - f1_score: 0.9151\n",
      "Epoch 00007: val_f1_score improved from 0.88660 to 0.89542, saving model to /app/_data/models/final/eff4_full/eff4_full_3.h5\n",
      "288/288 [==============================] - 298s 1s/step - loss: 0.0637 - acc: 0.9257 - recall: 0.9191 - precision: 0.9340 - f1_score: 0.9151 - val_loss: 0.0990 - val_acc: 0.9112 - val_recall: 0.8802 - val_precision: 0.9299 - val_f1_score: 0.8954\n",
      "Epoch 8/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0622 - acc: 0.9271 - recall: 0.9207 - precision: 0.9350 - f1_score: 0.9158\n",
      "Epoch 00008: val_f1_score did not improve from 0.89542\n",
      "288/288 [==============================] - 299s 1s/step - loss: 0.0622 - acc: 0.9271 - recall: 0.9207 - precision: 0.9350 - f1_score: 0.9158 - val_loss: 0.0869 - val_acc: 0.9132 - val_recall: 0.8985 - val_precision: 0.9212 - val_f1_score: 0.8943\n",
      "Epoch 9/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0592 - acc: 0.9311 - recall: 0.9267 - precision: 0.9382 - f1_score: 0.9200\n",
      "Epoch 00009: val_f1_score did not improve from 0.89542\n",
      "288/288 [==============================] - 290s 1s/step - loss: 0.0592 - acc: 0.9311 - recall: 0.9267 - precision: 0.9382 - f1_score: 0.9200 - val_loss: 0.0976 - val_acc: 0.9020 - val_recall: 0.8744 - val_precision: 0.9174 - val_f1_score: 0.8856\n",
      "Epoch 10/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0550 - acc: 0.9359 - recall: 0.9323 - precision: 0.9458 - f1_score: 0.9255\n",
      "Epoch 00010: val_f1_score improved from 0.89542 to 0.90337, saving model to /app/_data/models/final/eff4_full/eff4_full_3.h5\n",
      "288/288 [==============================] - 297s 1s/step - loss: 0.0550 - acc: 0.9359 - recall: 0.9323 - precision: 0.9458 - f1_score: 0.9255 - val_loss: 0.0864 - val_acc: 0.9167 - val_recall: 0.9020 - val_precision: 0.9286 - val_f1_score: 0.9034\n",
      "Epoch 11/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0534 - acc: 0.9357 - recall: 0.9332 - precision: 0.9458 - f1_score: 0.9252\n",
      "Epoch 00011: val_f1_score did not improve from 0.90337\n",
      "288/288 [==============================] - 290s 1s/step - loss: 0.0534 - acc: 0.9357 - recall: 0.9332 - precision: 0.9458 - f1_score: 0.9252 - val_loss: 0.0889 - val_acc: 0.9110 - val_recall: 0.9130 - val_precision: 0.9107 - val_f1_score: 0.9002\n",
      "Epoch 12/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0487 - acc: 0.9404 - recall: 0.9406 - precision: 0.9512 - f1_score: 0.9310\n",
      "Epoch 00012: val_f1_score improved from 0.90337 to 0.90717, saving model to /app/_data/models/final/eff4_full/eff4_full_3.h5\n",
      "288/288 [==============================] - 286s 992ms/step - loss: 0.0487 - acc: 0.9404 - recall: 0.9406 - precision: 0.9512 - f1_score: 0.9310 - val_loss: 0.0810 - val_acc: 0.9194 - val_recall: 0.9157 - val_precision: 0.9223 - val_f1_score: 0.9072\n",
      "Epoch 13/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0491 - acc: 0.9381 - recall: 0.9400 - precision: 0.9500 - f1_score: 0.9288\n",
      "Epoch 00013: val_f1_score did not improve from 0.90717\n",
      "288/288 [==============================] - 292s 1s/step - loss: 0.0491 - acc: 0.9381 - recall: 0.9400 - precision: 0.9500 - f1_score: 0.9288 - val_loss: 0.0988 - val_acc: 0.9125 - val_recall: 0.9162 - val_precision: 0.9099 - val_f1_score: 0.8999\n",
      "Epoch 14/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0451 - acc: 0.9428 - recall: 0.9466 - precision: 0.9549 - f1_score: 0.9329\n",
      "Epoch 00014: val_f1_score did not improve from 0.90717\n",
      "288/288 [==============================] - 283s 982ms/step - loss: 0.0451 - acc: 0.9428 - recall: 0.9466 - precision: 0.9549 - f1_score: 0.9329 - val_loss: 0.0865 - val_acc: 0.9085 - val_recall: 0.9027 - val_precision: 0.9265 - val_f1_score: 0.9018\n",
      "Epoch 15/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0413 - acc: 0.9426 - recall: 0.9509 - precision: 0.9579 - f1_score: 0.9362\n",
      "Epoch 00015: val_f1_score did not improve from 0.90717\n",
      "288/288 [==============================] - 286s 994ms/step - loss: 0.0413 - acc: 0.9426 - recall: 0.9509 - precision: 0.9579 - f1_score: 0.9362 - val_loss: 0.1007 - val_acc: 0.9152 - val_recall: 0.8981 - val_precision: 0.9233 - val_f1_score: 0.8964\n",
      "Epoch 16/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0391 - acc: 0.9455 - recall: 0.9522 - precision: 0.9584 - f1_score: 0.9373\n",
      "Epoch 00016: val_f1_score did not improve from 0.90717\n",
      "288/288 [==============================] - 315s 1s/step - loss: 0.0391 - acc: 0.9455 - recall: 0.9522 - precision: 0.9584 - f1_score: 0.9373 - val_loss: 0.1030 - val_acc: 0.9191 - val_recall: 0.8861 - val_precision: 0.9246 - val_f1_score: 0.8968\n",
      "Epoch 17/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0396 - acc: 0.9454 - recall: 0.9546 - precision: 0.9604 - f1_score: 0.9387\n",
      "Epoch 00017: val_f1_score did not improve from 0.90717\n",
      "288/288 [==============================] - 300s 1s/step - loss: 0.0396 - acc: 0.9454 - recall: 0.9546 - precision: 0.9604 - f1_score: 0.9387 - val_loss: 0.0996 - val_acc: 0.9028 - val_recall: 0.9043 - val_precision: 0.9141 - val_f1_score: 0.8966\n",
      "Epoch 18/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0351 - acc: 0.9490 - recall: 0.9589 - precision: 0.9640 - f1_score: 0.9423\n",
      "Epoch 00018: val_f1_score did not improve from 0.90717\n",
      "288/288 [==============================] - 279s 968ms/step - loss: 0.0351 - acc: 0.9490 - recall: 0.9589 - precision: 0.9640 - f1_score: 0.9423 - val_loss: 0.1199 - val_acc: 0.9062 - val_recall: 0.8753 - val_precision: 0.9172 - val_f1_score: 0.8893\n",
      "Epoch 19/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0353 - acc: 0.9520 - recall: 0.9572 - precision: 0.9643 - f1_score: 0.9423\n",
      "Epoch 00019: val_f1_score improved from 0.90717 to 0.90769, saving model to /app/_data/models/final/eff4_full/eff4_full_3.h5\n",
      "288/288 [==============================] - 299s 1s/step - loss: 0.0353 - acc: 0.9520 - recall: 0.9572 - precision: 0.9643 - f1_score: 0.9423 - val_loss: 0.0947 - val_acc: 0.9244 - val_recall: 0.9206 - val_precision: 0.9159 - val_f1_score: 0.9077\n",
      "Epoch 20/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0328 - acc: 0.9511 - recall: 0.9614 - precision: 0.9683 - f1_score: 0.9441\n",
      "Epoch 00020: val_f1_score did not improve from 0.90769\n",
      "288/288 [==============================] - 299s 1s/step - loss: 0.0328 - acc: 0.9511 - recall: 0.9614 - precision: 0.9683 - f1_score: 0.9441 - val_loss: 0.1162 - val_acc: 0.9117 - val_recall: 0.9215 - val_precision: 0.9081 - val_f1_score: 0.8968\n",
      "Epoch 21/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0345 - acc: 0.9514 - recall: 0.9617 - precision: 0.9658 - f1_score: 0.9424\n",
      "Epoch 00021: val_f1_score did not improve from 0.90769\n",
      "288/288 [==============================] - 281s 977ms/step - loss: 0.0345 - acc: 0.9514 - recall: 0.9617 - precision: 0.9658 - f1_score: 0.9424 - val_loss: 0.1034 - val_acc: 0.9149 - val_recall: 0.9102 - val_precision: 0.9227 - val_f1_score: 0.9048\n",
      "Epoch 22/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0283 - acc: 0.9518 - recall: 0.9670 - precision: 0.9720 - f1_score: 0.9472\n",
      "Epoch 00022: val_f1_score did not improve from 0.90769\n",
      "288/288 [==============================] - 286s 993ms/step - loss: 0.0283 - acc: 0.9518 - recall: 0.9670 - precision: 0.9720 - f1_score: 0.9472 - val_loss: 0.1062 - val_acc: 0.9077 - val_recall: 0.9073 - val_precision: 0.9266 - val_f1_score: 0.9018\n",
      "Epoch 23/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0290 - acc: 0.9523 - recall: 0.9660 - precision: 0.9709 - f1_score: 0.9471\n",
      "Epoch 00023: val_f1_score did not improve from 0.90769\n",
      "288/288 [==============================] - 296s 1s/step - loss: 0.0290 - acc: 0.9523 - recall: 0.9660 - precision: 0.9709 - f1_score: 0.9471 - val_loss: 0.1125 - val_acc: 0.9137 - val_recall: 0.9096 - val_precision: 0.9123 - val_f1_score: 0.8982\n",
      "Epoch 24/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0283 - acc: 0.9528 - recall: 0.9687 - precision: 0.9710 - f1_score: 0.9469\n",
      "Epoch 00024: val_f1_score did not improve from 0.90769\n",
      "288/288 [==============================] - 296s 1s/step - loss: 0.0283 - acc: 0.9528 - recall: 0.9687 - precision: 0.9710 - f1_score: 0.9469 - val_loss: 0.1161 - val_acc: 0.9122 - val_recall: 0.8965 - val_precision: 0.9251 - val_f1_score: 0.9025\n",
      "Epoch 25/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0253 - acc: 0.9516 - recall: 0.9713 - precision: 0.9739 - f1_score: 0.9495\n",
      "Epoch 00025: val_f1_score did not improve from 0.90769\n",
      "288/288 [==============================] - 308s 1s/step - loss: 0.0253 - acc: 0.9516 - recall: 0.9713 - precision: 0.9739 - f1_score: 0.9495 - val_loss: 0.1282 - val_acc: 0.9003 - val_recall: 0.9020 - val_precision: 0.9103 - val_f1_score: 0.8919\n",
      "Epoch 26/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0253 - acc: 0.9542 - recall: 0.9719 - precision: 0.9756 - f1_score: 0.9496\n",
      "Epoch 00026: val_f1_score did not improve from 0.90769\n",
      "288/288 [==============================] - 286s 994ms/step - loss: 0.0253 - acc: 0.9542 - recall: 0.9719 - precision: 0.9756 - f1_score: 0.9496 - val_loss: 0.1364 - val_acc: 0.8958 - val_recall: 0.9116 - val_precision: 0.8848 - val_f1_score: 0.8831\n",
      "Epoch 27/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0255 - acc: 0.9549 - recall: 0.9711 - precision: 0.9749 - f1_score: 0.9498\n",
      "Epoch 00027: val_f1_score improved from 0.90769 to 0.90903, saving model to /app/_data/models/final/eff4_full/eff4_full_3.h5\n",
      "288/288 [==============================] - 297s 1s/step - loss: 0.0255 - acc: 0.9549 - recall: 0.9711 - precision: 0.9749 - f1_score: 0.9498 - val_loss: 0.1018 - val_acc: 0.9142 - val_recall: 0.9265 - val_precision: 0.9181 - val_f1_score: 0.9090\n",
      "Epoch 28/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0225 - acc: 0.9560 - recall: 0.9733 - precision: 0.9767 - f1_score: 0.9509\n",
      "Epoch 00028: val_f1_score did not improve from 0.90903\n",
      "288/288 [==============================] - 276s 958ms/step - loss: 0.0225 - acc: 0.9560 - recall: 0.9733 - precision: 0.9767 - f1_score: 0.9509 - val_loss: 0.1157 - val_acc: 0.9211 - val_recall: 0.9052 - val_precision: 0.9232 - val_f1_score: 0.9071\n",
      "Epoch 29/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0202 - acc: 0.9593 - recall: 0.9786 - precision: 0.9792 - f1_score: 0.9552\n",
      "Epoch 00029: val_f1_score did not improve from 0.90903\n",
      "288/288 [==============================] - 295s 1s/step - loss: 0.0202 - acc: 0.9593 - recall: 0.9786 - precision: 0.9792 - f1_score: 0.9552 - val_loss: 0.1059 - val_acc: 0.9167 - val_recall: 0.9006 - val_precision: 0.9312 - val_f1_score: 0.9055\n",
      "Epoch 30/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0202 - acc: 0.9603 - recall: 0.9768 - precision: 0.9795 - f1_score: 0.9549\n",
      "Epoch 00030: val_f1_score improved from 0.90903 to 0.91059, saving model to /app/_data/models/final/eff4_full/eff4_full_3.h5\n",
      "288/288 [==============================] - 291s 1s/step - loss: 0.0202 - acc: 0.9603 - recall: 0.9768 - precision: 0.9795 - f1_score: 0.9549 - val_loss: 0.1109 - val_acc: 0.9244 - val_recall: 0.9213 - val_precision: 0.9266 - val_f1_score: 0.9106\n",
      "Epoch 31/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0224 - acc: 0.9577 - recall: 0.9754 - precision: 0.9772 - f1_score: 0.9535\n",
      "Epoch 00031: val_f1_score improved from 0.91059 to 0.91126, saving model to /app/_data/models/final/eff4_full/eff4_full_3.h5\n",
      "288/288 [==============================] - 318s 1s/step - loss: 0.0224 - acc: 0.9577 - recall: 0.9754 - precision: 0.9772 - f1_score: 0.9535 - val_loss: 0.1177 - val_acc: 0.9162 - val_recall: 0.9116 - val_precision: 0.9293 - val_f1_score: 0.9113\n",
      "Epoch 32/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0210 - acc: 0.9580 - recall: 0.9762 - precision: 0.9777 - f1_score: 0.9533\n",
      "Epoch 00032: val_f1_score did not improve from 0.91126\n",
      "288/288 [==============================] - 309s 1s/step - loss: 0.0210 - acc: 0.9580 - recall: 0.9762 - precision: 0.9777 - f1_score: 0.9533 - val_loss: 0.1155 - val_acc: 0.9199 - val_recall: 0.9139 - val_precision: 0.9217 - val_f1_score: 0.9056\n",
      "Epoch 33/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0199 - acc: 0.9564 - recall: 0.9782 - precision: 0.9812 - f1_score: 0.9556\n",
      "Epoch 00033: val_f1_score did not improve from 0.91126\n",
      "288/288 [==============================] - 290s 1s/step - loss: 0.0199 - acc: 0.9564 - recall: 0.9782 - precision: 0.9812 - f1_score: 0.9556 - val_loss: 0.1137 - val_acc: 0.9142 - val_recall: 0.9174 - val_precision: 0.9229 - val_f1_score: 0.9091\n",
      "Epoch 34/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0174 - acc: 0.9627 - recall: 0.9800 - precision: 0.9825 - f1_score: 0.9580\n",
      "Epoch 00034: val_f1_score did not improve from 0.91126\n",
      "288/288 [==============================] - 304s 1s/step - loss: 0.0174 - acc: 0.9627 - recall: 0.9800 - precision: 0.9825 - f1_score: 0.9580 - val_loss: 0.1429 - val_acc: 0.9157 - val_recall: 0.8949 - val_precision: 0.9206 - val_f1_score: 0.9011\n",
      "Epoch 35/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0173 - acc: 0.9610 - recall: 0.9805 - precision: 0.9821 - f1_score: 0.9570\n",
      "Epoch 00035: val_f1_score did not improve from 0.91126\n",
      "288/288 [==============================] - 303s 1s/step - loss: 0.0173 - acc: 0.9610 - recall: 0.9805 - precision: 0.9821 - f1_score: 0.9570 - val_loss: 0.1301 - val_acc: 0.9147 - val_recall: 0.9132 - val_precision: 0.9243 - val_f1_score: 0.9079\n",
      "Epoch 36/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0178 - acc: 0.9589 - recall: 0.9800 - precision: 0.9817 - f1_score: 0.9562\n",
      "Epoch 00036: val_f1_score did not improve from 0.91126\n",
      "288/288 [==============================] - 290s 1s/step - loss: 0.0178 - acc: 0.9589 - recall: 0.9800 - precision: 0.9817 - f1_score: 0.9562 - val_loss: 0.1257 - val_acc: 0.9142 - val_recall: 0.8939 - val_precision: 0.9294 - val_f1_score: 0.9018\n",
      "Epoch 37/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0165 - acc: 0.9593 - recall: 0.9819 - precision: 0.9836 - f1_score: 0.9577\n",
      "Epoch 00037: val_f1_score did not improve from 0.91126\n",
      "288/288 [==============================] - 307s 1s/step - loss: 0.0165 - acc: 0.9593 - recall: 0.9819 - precision: 0.9836 - f1_score: 0.9577 - val_loss: 0.1099 - val_acc: 0.9229 - val_recall: 0.9146 - val_precision: 0.9278 - val_f1_score: 0.9105\n",
      "Epoch 38/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0160 - acc: 0.9629 - recall: 0.9830 - precision: 0.9845 - f1_score: 0.9581\n",
      "Epoch 00038: val_f1_score did not improve from 0.91126\n",
      "288/288 [==============================] - 314s 1s/step - loss: 0.0160 - acc: 0.9629 - recall: 0.9830 - precision: 0.9845 - f1_score: 0.9581 - val_loss: 0.1327 - val_acc: 0.9204 - val_recall: 0.9180 - val_precision: 0.9204 - val_f1_score: 0.9032\n",
      "Epoch 39/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0145 - acc: 0.9647 - recall: 0.9842 - precision: 0.9850 - f1_score: 0.9598\n",
      "Epoch 00039: val_f1_score did not improve from 0.91126\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.0004500000213738531.\n",
      "288/288 [==============================] - 295s 1s/step - loss: 0.0145 - acc: 0.9647 - recall: 0.9842 - precision: 0.9850 - f1_score: 0.9598 - val_loss: 0.1289 - val_acc: 0.9239 - val_recall: 0.9238 - val_precision: 0.9187 - val_f1_score: 0.9105\n",
      "Epoch 40/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0136 - acc: 0.9656 - recall: 0.9856 - precision: 0.9866 - f1_score: 0.9623\n",
      "Epoch 00040: val_f1_score did not improve from 0.91126\n",
      "288/288 [==============================] - 302s 1s/step - loss: 0.0136 - acc: 0.9656 - recall: 0.9856 - precision: 0.9866 - f1_score: 0.9623 - val_loss: 0.1274 - val_acc: 0.9209 - val_recall: 0.9125 - val_precision: 0.9298 - val_f1_score: 0.9096\n",
      "Epoch 41/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0118 - acc: 0.9696 - recall: 0.9869 - precision: 0.9880 - f1_score: 0.9661\n",
      "Epoch 00041: val_f1_score improved from 0.91126 to 0.91191, saving model to /app/_data/models/final/eff4_full/eff4_full_3.h5\n",
      "288/288 [==============================] - 308s 1s/step - loss: 0.0118 - acc: 0.9696 - recall: 0.9869 - precision: 0.9880 - f1_score: 0.9661 - val_loss: 0.1278 - val_acc: 0.9263 - val_recall: 0.9180 - val_precision: 0.9216 - val_f1_score: 0.9119\n",
      "Epoch 42/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0131 - acc: 0.9668 - recall: 0.9854 - precision: 0.9863 - f1_score: 0.9622\n",
      "Epoch 00042: val_f1_score did not improve from 0.91191\n",
      "288/288 [==============================] - 317s 1s/step - loss: 0.0131 - acc: 0.9668 - recall: 0.9854 - precision: 0.9863 - f1_score: 0.9622 - val_loss: 0.1304 - val_acc: 0.9179 - val_recall: 0.9222 - val_precision: 0.9127 - val_f1_score: 0.9077\n",
      "Epoch 43/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0119 - acc: 0.9627 - recall: 0.9876 - precision: 0.9882 - f1_score: 0.9640\n",
      "Epoch 00043: val_f1_score did not improve from 0.91191\n",
      "288/288 [==============================] - 297s 1s/step - loss: 0.0119 - acc: 0.9627 - recall: 0.9876 - precision: 0.9882 - f1_score: 0.9640 - val_loss: 0.1386 - val_acc: 0.9211 - val_recall: 0.9144 - val_precision: 0.9317 - val_f1_score: 0.9118\n",
      "Epoch 44/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0127 - acc: 0.9633 - recall: 0.9865 - precision: 0.9876 - f1_score: 0.9626\n",
      "Epoch 00044: val_f1_score did not improve from 0.91191\n",
      "288/288 [==============================] - 296s 1s/step - loss: 0.0127 - acc: 0.9633 - recall: 0.9865 - precision: 0.9876 - f1_score: 0.9626 - val_loss: 0.1349 - val_acc: 0.9172 - val_recall: 0.9130 - val_precision: 0.9234 - val_f1_score: 0.9065\n",
      "Epoch 45/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0136 - acc: 0.9645 - recall: 0.9859 - precision: 0.9874 - f1_score: 0.9638\n",
      "Epoch 00045: val_f1_score did not improve from 0.91191\n",
      "288/288 [==============================] - 295s 1s/step - loss: 0.0136 - acc: 0.9645 - recall: 0.9859 - precision: 0.9874 - f1_score: 0.9638 - val_loss: 0.1285 - val_acc: 0.9199 - val_recall: 0.9082 - val_precision: 0.9302 - val_f1_score: 0.9098\n",
      "Epoch 46/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0114 - acc: 0.9661 - recall: 0.9878 - precision: 0.9875 - f1_score: 0.9646\n",
      "Epoch 00046: val_f1_score did not improve from 0.91191\n",
      "288/288 [==============================] - 283s 984ms/step - loss: 0.0114 - acc: 0.9661 - recall: 0.9878 - precision: 0.9875 - f1_score: 0.9646 - val_loss: 0.1297 - val_acc: 0.9191 - val_recall: 0.9190 - val_precision: 0.9230 - val_f1_score: 0.9099\n",
      "Epoch 47/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0114 - acc: 0.9676 - recall: 0.9873 - precision: 0.9886 - f1_score: 0.9655\n",
      "Epoch 00047: val_f1_score did not improve from 0.91191\n",
      "288/288 [==============================] - 289s 1s/step - loss: 0.0114 - acc: 0.9676 - recall: 0.9873 - precision: 0.9886 - f1_score: 0.9655 - val_loss: 0.1229 - val_acc: 0.9244 - val_recall: 0.9132 - val_precision: 0.9303 - val_f1_score: 0.9110\n",
      "Epoch 48/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0100 - acc: 0.9703 - recall: 0.9901 - precision: 0.9904 - f1_score: 0.9682\n",
      "Epoch 00048: val_f1_score did not improve from 0.91191\n",
      "288/288 [==============================] - 283s 982ms/step - loss: 0.0100 - acc: 0.9703 - recall: 0.9901 - precision: 0.9904 - f1_score: 0.9682 - val_loss: 0.1422 - val_acc: 0.9154 - val_recall: 0.9121 - val_precision: 0.9117 - val_f1_score: 0.9015\n",
      "Epoch 49/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0102 - acc: 0.9699 - recall: 0.9896 - precision: 0.9899 - f1_score: 0.9676\n",
      "Epoch 00049: val_f1_score did not improve from 0.91191\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.0004050000192364678.\n",
      "288/288 [==============================] - 294s 1s/step - loss: 0.0102 - acc: 0.9699 - recall: 0.9896 - precision: 0.9899 - f1_score: 0.9676 - val_loss: 0.1391 - val_acc: 0.8884 - val_recall: 0.8714 - val_precision: 0.9077 - val_f1_score: 0.8774\n",
      "Epoch 50/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0113 - acc: 0.9670 - recall: 0.9886 - precision: 0.9888 - f1_score: 0.9676\n",
      "Epoch 00050: val_f1_score did not improve from 0.91191\n",
      "288/288 [==============================] - 299s 1s/step - loss: 0.0113 - acc: 0.9670 - recall: 0.9886 - precision: 0.9888 - f1_score: 0.9676 - val_loss: 0.1419 - val_acc: 0.9219 - val_recall: 0.9082 - val_precision: 0.9224 - val_f1_score: 0.9085\n",
      "Epoch 51/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0097 - acc: 0.9665 - recall: 0.9894 - precision: 0.9907 - f1_score: 0.9671\n",
      "Epoch 00051: val_f1_score improved from 0.91191 to 0.91214, saving model to /app/_data/models/final/eff4_full/eff4_full_3.h5\n",
      "288/288 [==============================] - 294s 1s/step - loss: 0.0097 - acc: 0.9665 - recall: 0.9894 - precision: 0.9907 - f1_score: 0.9671 - val_loss: 0.1320 - val_acc: 0.9229 - val_recall: 0.9148 - val_precision: 0.9240 - val_f1_score: 0.9121\n",
      "Epoch 52/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0086 - acc: 0.9733 - recall: 0.9909 - precision: 0.9921 - f1_score: 0.9708\n",
      "Epoch 00052: val_f1_score did not improve from 0.91214\n",
      "288/288 [==============================] - 296s 1s/step - loss: 0.0086 - acc: 0.9733 - recall: 0.9909 - precision: 0.9921 - f1_score: 0.9708 - val_loss: 0.1440 - val_acc: 0.9154 - val_recall: 0.9178 - val_precision: 0.9117 - val_f1_score: 0.9065\n",
      "Epoch 53/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0104 - acc: 0.9721 - recall: 0.9891 - precision: 0.9896 - f1_score: 0.9671\n",
      "Epoch 00053: val_f1_score did not improve from 0.91214\n",
      "288/288 [==============================] - 279s 969ms/step - loss: 0.0104 - acc: 0.9721 - recall: 0.9891 - precision: 0.9896 - f1_score: 0.9671 - val_loss: 0.1470 - val_acc: 0.9122 - val_recall: 0.9089 - val_precision: 0.9205 - val_f1_score: 0.9000\n",
      "Epoch 54/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0102 - acc: 0.9698 - recall: 0.9889 - precision: 0.9896 - f1_score: 0.9685\n",
      "Epoch 00054: val_f1_score improved from 0.91214 to 0.91286, saving model to /app/_data/models/final/eff4_full/eff4_full_3.h5\n",
      "288/288 [==============================] - 300s 1s/step - loss: 0.0102 - acc: 0.9698 - recall: 0.9889 - precision: 0.9896 - f1_score: 0.9685 - val_loss: 0.1258 - val_acc: 0.9204 - val_recall: 0.9286 - val_precision: 0.9197 - val_f1_score: 0.9129\n",
      "Epoch 55/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0074 - acc: 0.9751 - recall: 0.9927 - precision: 0.9926 - f1_score: 0.9734\n",
      "Epoch 00055: val_f1_score did not improve from 0.91286\n",
      "288/288 [==============================] - 270s 938ms/step - loss: 0.0074 - acc: 0.9751 - recall: 0.9927 - precision: 0.9926 - f1_score: 0.9734 - val_loss: 0.1351 - val_acc: 0.9261 - val_recall: 0.9073 - val_precision: 0.9338 - val_f1_score: 0.9120\n",
      "Epoch 56/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0087 - acc: 0.9694 - recall: 0.9905 - precision: 0.9913 - f1_score: 0.9719\n",
      "Epoch 00056: val_f1_score did not improve from 0.91286\n",
      "288/288 [==============================] - 286s 993ms/step - loss: 0.0087 - acc: 0.9694 - recall: 0.9905 - precision: 0.9913 - f1_score: 0.9719 - val_loss: 0.1518 - val_acc: 0.9172 - val_recall: 0.9222 - val_precision: 0.9142 - val_f1_score: 0.9109\n",
      "Epoch 57/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0090 - acc: 0.9697 - recall: 0.9903 - precision: 0.9912 - f1_score: 0.9695\n",
      "Epoch 00057: val_f1_score did not improve from 0.91286\n",
      "288/288 [==============================] - 285s 990ms/step - loss: 0.0090 - acc: 0.9697 - recall: 0.9903 - precision: 0.9912 - f1_score: 0.9695 - val_loss: 0.1430 - val_acc: 0.9199 - val_recall: 0.9139 - val_precision: 0.9317 - val_f1_score: 0.9101\n",
      "Epoch 58/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0079 - acc: 0.9705 - recall: 0.9909 - precision: 0.9917 - f1_score: 0.9715\n",
      "Epoch 00058: val_f1_score improved from 0.91286 to 0.91388, saving model to /app/_data/models/final/eff4_full/eff4_full_3.h5\n",
      "288/288 [==============================] - 287s 998ms/step - loss: 0.0079 - acc: 0.9705 - recall: 0.9909 - precision: 0.9917 - f1_score: 0.9715 - val_loss: 0.1381 - val_acc: 0.9209 - val_recall: 0.9190 - val_precision: 0.9215 - val_f1_score: 0.9139\n",
      "Epoch 59/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0087 - acc: 0.9708 - recall: 0.9907 - precision: 0.9916 - f1_score: 0.9712\n",
      "Epoch 00059: val_f1_score did not improve from 0.91388\n",
      "288/288 [==============================] - 284s 986ms/step - loss: 0.0087 - acc: 0.9708 - recall: 0.9907 - precision: 0.9916 - f1_score: 0.9712 - val_loss: 0.1242 - val_acc: 0.9278 - val_recall: 0.9190 - val_precision: 0.9258 - val_f1_score: 0.9135\n",
      "Epoch 60/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0078 - acc: 0.9730 - recall: 0.9914 - precision: 0.9926 - f1_score: 0.9720\n",
      "Epoch 00060: val_f1_score did not improve from 0.91388\n",
      "288/288 [==============================] - 274s 952ms/step - loss: 0.0078 - acc: 0.9730 - recall: 0.9914 - precision: 0.9926 - f1_score: 0.9720 - val_loss: 0.1475 - val_acc: 0.9187 - val_recall: 0.9066 - val_precision: 0.9216 - val_f1_score: 0.9054\n",
      "Epoch 61/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0070 - acc: 0.9750 - recall: 0.9922 - precision: 0.9928 - f1_score: 0.9748\n",
      "Epoch 00061: val_f1_score did not improve from 0.91388\n",
      "288/288 [==============================] - 280s 971ms/step - loss: 0.0070 - acc: 0.9750 - recall: 0.9922 - precision: 0.9928 - f1_score: 0.9748 - val_loss: 0.1475 - val_acc: 0.9234 - val_recall: 0.9146 - val_precision: 0.9188 - val_f1_score: 0.9099\n",
      "Epoch 62/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0080 - acc: 0.9683 - recall: 0.9910 - precision: 0.9915 - f1_score: 0.9720\n",
      "Epoch 00062: val_f1_score did not improve from 0.91388\n",
      "288/288 [==============================] - 296s 1s/step - loss: 0.0080 - acc: 0.9683 - recall: 0.9910 - precision: 0.9915 - f1_score: 0.9720 - val_loss: 0.1538 - val_acc: 0.9174 - val_recall: 0.9079 - val_precision: 0.9176 - val_f1_score: 0.9058\n",
      "Epoch 63/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0088 - acc: 0.9697 - recall: 0.9901 - precision: 0.9907 - f1_score: 0.9703\n",
      "Epoch 00063: val_f1_score did not improve from 0.91388\n",
      "288/288 [==============================] - 290s 1s/step - loss: 0.0088 - acc: 0.9697 - recall: 0.9901 - precision: 0.9907 - f1_score: 0.9703 - val_loss: 0.1526 - val_acc: 0.9266 - val_recall: 0.9217 - val_precision: 0.9173 - val_f1_score: 0.9127\n",
      "Epoch 64/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0092 - acc: 0.9749 - recall: 0.9903 - precision: 0.9909 - f1_score: 0.9706\n",
      "Epoch 00064: val_f1_score did not improve from 0.91388\n",
      "288/288 [==============================] - 296s 1s/step - loss: 0.0092 - acc: 0.9749 - recall: 0.9903 - precision: 0.9909 - f1_score: 0.9706 - val_loss: 0.1480 - val_acc: 0.9142 - val_recall: 0.9100 - val_precision: 0.9214 - val_f1_score: 0.9053\n",
      "Epoch 65/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0077 - acc: 0.9739 - recall: 0.9920 - precision: 0.9929 - f1_score: 0.9743\n",
      "Epoch 00065: val_f1_score did not improve from 0.91388\n",
      "288/288 [==============================] - 299s 1s/step - loss: 0.0077 - acc: 0.9739 - recall: 0.9920 - precision: 0.9929 - f1_score: 0.9743 - val_loss: 0.1570 - val_acc: 0.9105 - val_recall: 0.9066 - val_precision: 0.9209 - val_f1_score: 0.9014\n",
      "Epoch 66/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0074 - acc: 0.9719 - recall: 0.9924 - precision: 0.9926 - f1_score: 0.9736\n",
      "Epoch 00066: val_f1_score did not improve from 0.91388\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 0.0003645000251708552.\n",
      "288/288 [==============================] - 311s 1s/step - loss: 0.0074 - acc: 0.9719 - recall: 0.9924 - precision: 0.9926 - f1_score: 0.9736 - val_loss: 0.1519 - val_acc: 0.9072 - val_recall: 0.9141 - val_precision: 0.9108 - val_f1_score: 0.8996\n",
      "Epoch 67/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0076 - acc: 0.9736 - recall: 0.9927 - precision: 0.9923 - f1_score: 0.9734\n",
      "Epoch 00067: val_f1_score did not improve from 0.91388\n",
      "288/288 [==============================] - 285s 988ms/step - loss: 0.0076 - acc: 0.9736 - recall: 0.9927 - precision: 0.9923 - f1_score: 0.9734 - val_loss: 0.1538 - val_acc: 0.9172 - val_recall: 0.9128 - val_precision: 0.9208 - val_f1_score: 0.9072\n",
      "Epoch 68/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0066 - acc: 0.9781 - recall: 0.9921 - precision: 0.9930 - f1_score: 0.9747\n",
      "Epoch 00068: val_f1_score did not improve from 0.91388\n",
      "288/288 [==============================] - 315s 1s/step - loss: 0.0066 - acc: 0.9781 - recall: 0.9921 - precision: 0.9930 - f1_score: 0.9747 - val_loss: 0.1363 - val_acc: 0.9196 - val_recall: 0.9164 - val_precision: 0.9286 - val_f1_score: 0.9109\n",
      "Epoch 69/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0071 - acc: 0.9768 - recall: 0.9923 - precision: 0.9928 - f1_score: 0.9731Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00069: val_f1_score did not improve from 0.91388\n",
      "288/288 [==============================] - 306s 1s/step - loss: 0.0071 - acc: 0.9768 - recall: 0.9923 - precision: 0.9928 - f1_score: 0.9731 - val_loss: 0.1536 - val_acc: 0.9234 - val_recall: 0.9190 - val_precision: 0.9185 - val_f1_score: 0.9126\n",
      "Epoch 00069: early stopping\n",
      "Epoch 1/100\n",
      "  2/288 [..............................] - ETA: 6:45 - loss: 0.6748 - acc: 0.1964 - recall: 0.4407 - precision: 0.1962 - f1_score: 0.2385WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.3921s vs `on_train_batch_end` time: 2.4459s). Check your callbacks.\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.1530 - acc: 0.8330 - recall: 0.7866 - precision: 0.8561 - f1_score: 0.8199\n",
      "Epoch 00001: val_f1_score improved from -inf to 0.82303, saving model to /app/_data/models/final/eff4_full/eff4_full_4.h5\n",
      "288/288 [==============================] - 293s 1s/step - loss: 0.1530 - acc: 0.8330 - recall: 0.7866 - precision: 0.8561 - f1_score: 0.8199 - val_loss: 0.1679 - val_acc: 0.8410 - val_recall: 0.8237 - val_precision: 0.8479 - val_f1_score: 0.8230\n",
      "Epoch 2/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.1002 - acc: 0.8950 - recall: 0.8706 - precision: 0.9035 - f1_score: 0.8799\n",
      "Epoch 00002: val_f1_score improved from 0.82303 to 0.85220, saving model to /app/_data/models/final/eff4_full/eff4_full_4.h5\n",
      "288/288 [==============================] - 321s 1s/step - loss: 0.1002 - acc: 0.8950 - recall: 0.8706 - precision: 0.9035 - f1_score: 0.8799 - val_loss: 0.1225 - val_acc: 0.8698 - val_recall: 0.8414 - val_precision: 0.8643 - val_f1_score: 0.8522\n",
      "Epoch 3/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0877 - acc: 0.9031 - recall: 0.8866 - precision: 0.9101 - f1_score: 0.8909\n",
      "Epoch 00003: val_f1_score improved from 0.85220 to 0.88850, saving model to /app/_data/models/final/eff4_full/eff4_full_4.h5\n",
      "288/288 [==============================] - 292s 1s/step - loss: 0.0877 - acc: 0.9031 - recall: 0.8866 - precision: 0.9101 - f1_score: 0.8909 - val_loss: 0.0955 - val_acc: 0.9015 - val_recall: 0.8942 - val_precision: 0.9112 - val_f1_score: 0.8885\n",
      "Epoch 4/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0782 - acc: 0.9156 - recall: 0.8995 - precision: 0.9217 - f1_score: 0.9008\n",
      "Epoch 00004: val_f1_score did not improve from 0.88850\n",
      "288/288 [==============================] - 294s 1s/step - loss: 0.0782 - acc: 0.9156 - recall: 0.8995 - precision: 0.9217 - f1_score: 0.9008 - val_loss: 0.1168 - val_acc: 0.8725 - val_recall: 0.8638 - val_precision: 0.8856 - val_f1_score: 0.8688\n",
      "Epoch 5/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0777 - acc: 0.9148 - recall: 0.9026 - precision: 0.9246 - f1_score: 0.9029\n",
      "Epoch 00005: val_f1_score did not improve from 0.88850\n",
      "288/288 [==============================] - 293s 1s/step - loss: 0.0777 - acc: 0.9148 - recall: 0.9026 - precision: 0.9246 - f1_score: 0.9029 - val_loss: 0.1003 - val_acc: 0.8812 - val_recall: 0.8582 - val_precision: 0.9150 - val_f1_score: 0.8787\n",
      "Epoch 6/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0706 - acc: 0.9228 - recall: 0.9119 - precision: 0.9269 - f1_score: 0.9101\n",
      "Epoch 00006: val_f1_score improved from 0.88850 to 0.90051, saving model to /app/_data/models/final/eff4_full/eff4_full_4.h5\n",
      "288/288 [==============================] - 301s 1s/step - loss: 0.0706 - acc: 0.9228 - recall: 0.9119 - precision: 0.9269 - f1_score: 0.9101 - val_loss: 0.0831 - val_acc: 0.9023 - val_recall: 0.8988 - val_precision: 0.9275 - val_f1_score: 0.9005\n",
      "Epoch 7/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0659 - acc: 0.9251 - recall: 0.9188 - precision: 0.9331 - f1_score: 0.9135\n",
      "Epoch 00007: val_f1_score did not improve from 0.90051\n",
      "288/288 [==============================] - 313s 1s/step - loss: 0.0659 - acc: 0.9251 - recall: 0.9188 - precision: 0.9331 - f1_score: 0.9135 - val_loss: 0.0861 - val_acc: 0.9172 - val_recall: 0.9085 - val_precision: 0.9165 - val_f1_score: 0.8998\n",
      "Epoch 8/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0633 - acc: 0.9262 - recall: 0.9218 - precision: 0.9359 - f1_score: 0.9158\n",
      "Epoch 00008: val_f1_score improved from 0.90051 to 0.90176, saving model to /app/_data/models/final/eff4_full/eff4_full_4.h5\n",
      "288/288 [==============================] - 297s 1s/step - loss: 0.0633 - acc: 0.9262 - recall: 0.9218 - precision: 0.9359 - f1_score: 0.9158 - val_loss: 0.0842 - val_acc: 0.9045 - val_recall: 0.9046 - val_precision: 0.9242 - val_f1_score: 0.9018\n",
      "Epoch 9/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0585 - acc: 0.9320 - recall: 0.9278 - precision: 0.9412 - f1_score: 0.9217\n",
      "Epoch 00009: val_f1_score improved from 0.90176 to 0.90314, saving model to /app/_data/models/final/eff4_full/eff4_full_4.h5\n",
      "288/288 [==============================] - 301s 1s/step - loss: 0.0585 - acc: 0.9320 - recall: 0.9278 - precision: 0.9412 - f1_score: 0.9217 - val_loss: 0.0810 - val_acc: 0.9164 - val_recall: 0.8965 - val_precision: 0.9235 - val_f1_score: 0.9031\n",
      "Epoch 10/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0558 - acc: 0.9332 - recall: 0.9313 - precision: 0.9431 - f1_score: 0.9232\n",
      "Epoch 00010: val_f1_score did not improve from 0.90314\n",
      "288/288 [==============================] - 306s 1s/step - loss: 0.0558 - acc: 0.9332 - recall: 0.9313 - precision: 0.9431 - f1_score: 0.9232 - val_loss: 0.0922 - val_acc: 0.9125 - val_recall: 0.9043 - val_precision: 0.9187 - val_f1_score: 0.8984\n",
      "Epoch 11/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0542 - acc: 0.9315 - recall: 0.9340 - precision: 0.9455 - f1_score: 0.9238\n",
      "Epoch 00011: val_f1_score improved from 0.90314 to 0.90489, saving model to /app/_data/models/final/eff4_full/eff4_full_4.h5\n",
      "288/288 [==============================] - 313s 1s/step - loss: 0.0542 - acc: 0.9315 - recall: 0.9340 - precision: 0.9455 - f1_score: 0.9238 - val_loss: 0.0825 - val_acc: 0.9162 - val_recall: 0.9207 - val_precision: 0.9182 - val_f1_score: 0.9049\n",
      "Epoch 12/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0506 - acc: 0.9384 - recall: 0.9377 - precision: 0.9491 - f1_score: 0.9293\n",
      "Epoch 00012: val_f1_score improved from 0.90489 to 0.91048, saving model to /app/_data/models/final/eff4_full/eff4_full_4.h5\n",
      "288/288 [==============================] - 308s 1s/step - loss: 0.0506 - acc: 0.9384 - recall: 0.9377 - precision: 0.9491 - f1_score: 0.9293 - val_loss: 0.0786 - val_acc: 0.9234 - val_recall: 0.9249 - val_precision: 0.9172 - val_f1_score: 0.9105\n",
      "Epoch 13/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0491 - acc: 0.9399 - recall: 0.9383 - precision: 0.9501 - f1_score: 0.9296\n",
      "Epoch 00013: val_f1_score did not improve from 0.91048\n",
      "288/288 [==============================] - 296s 1s/step - loss: 0.0491 - acc: 0.9399 - recall: 0.9383 - precision: 0.9501 - f1_score: 0.9296 - val_loss: 0.1018 - val_acc: 0.8993 - val_recall: 0.9200 - val_precision: 0.8837 - val_f1_score: 0.8906\n",
      "Epoch 14/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0450 - acc: 0.9412 - recall: 0.9468 - precision: 0.9543 - f1_score: 0.9325\n",
      "Epoch 00014: val_f1_score did not improve from 0.91048\n",
      "288/288 [==============================] - 323s 1s/step - loss: 0.0450 - acc: 0.9412 - recall: 0.9468 - precision: 0.9543 - f1_score: 0.9325 - val_loss: 0.0990 - val_acc: 0.9129 - val_recall: 0.9112 - val_precision: 0.9096 - val_f1_score: 0.8986\n",
      "Epoch 15/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0416 - acc: 0.9440 - recall: 0.9488 - precision: 0.9571 - f1_score: 0.9353\n",
      "Epoch 00015: val_f1_score did not improve from 0.91048\n",
      "288/288 [==============================] - 321s 1s/step - loss: 0.0416 - acc: 0.9440 - recall: 0.9488 - precision: 0.9571 - f1_score: 0.9353 - val_loss: 0.1164 - val_acc: 0.9048 - val_recall: 0.9055 - val_precision: 0.9061 - val_f1_score: 0.8931\n",
      "Epoch 16/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0430 - acc: 0.9422 - recall: 0.9494 - precision: 0.9564 - f1_score: 0.9333\n",
      "Epoch 00016: val_f1_score did not improve from 0.91048\n",
      "288/288 [==============================] - 329s 1s/step - loss: 0.0430 - acc: 0.9422 - recall: 0.9494 - precision: 0.9564 - f1_score: 0.9333 - val_loss: 0.1136 - val_acc: 0.9035 - val_recall: 0.9214 - val_precision: 0.9008 - val_f1_score: 0.8978\n",
      "Epoch 17/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0381 - acc: 0.9465 - recall: 0.9548 - precision: 0.9625 - f1_score: 0.9388\n",
      "Epoch 00017: val_f1_score did not improve from 0.91048\n",
      "288/288 [==============================] - 307s 1s/step - loss: 0.0381 - acc: 0.9465 - recall: 0.9548 - precision: 0.9625 - f1_score: 0.9388 - val_loss: 0.0903 - val_acc: 0.9226 - val_recall: 0.9043 - val_precision: 0.9268 - val_f1_score: 0.9094\n",
      "Epoch 18/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0362 - acc: 0.9461 - recall: 0.9569 - precision: 0.9641 - f1_score: 0.9401\n",
      "Epoch 00018: val_f1_score did not improve from 0.91048\n",
      "288/288 [==============================] - 307s 1s/step - loss: 0.0362 - acc: 0.9461 - recall: 0.9569 - precision: 0.9641 - f1_score: 0.9401 - val_loss: 0.1191 - val_acc: 0.8943 - val_recall: 0.8891 - val_precision: 0.9103 - val_f1_score: 0.8891\n",
      "Epoch 19/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0354 - acc: 0.9477 - recall: 0.9584 - precision: 0.9639 - f1_score: 0.9407\n",
      "Epoch 00019: val_f1_score did not improve from 0.91048\n",
      "288/288 [==============================] - 337s 1s/step - loss: 0.0354 - acc: 0.9477 - recall: 0.9584 - precision: 0.9639 - f1_score: 0.9407 - val_loss: 0.0940 - val_acc: 0.9191 - val_recall: 0.9046 - val_precision: 0.9310 - val_f1_score: 0.9073\n",
      "Epoch 20/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0322 - acc: 0.9510 - recall: 0.9624 - precision: 0.9679 - f1_score: 0.9457\n",
      "Epoch 00020: val_f1_score did not improve from 0.91048\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0004500000213738531.\n",
      "288/288 [==============================] - 331s 1s/step - loss: 0.0322 - acc: 0.9510 - recall: 0.9624 - precision: 0.9679 - f1_score: 0.9457 - val_loss: 0.0975 - val_acc: 0.9085 - val_recall: 0.9050 - val_precision: 0.9220 - val_f1_score: 0.8995\n",
      "Epoch 21/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0272 - acc: 0.9529 - recall: 0.9705 - precision: 0.9721 - f1_score: 0.9468\n",
      "Epoch 00021: val_f1_score did not improve from 0.91048\n",
      "288/288 [==============================] - 327s 1s/step - loss: 0.0272 - acc: 0.9529 - recall: 0.9705 - precision: 0.9721 - f1_score: 0.9468 - val_loss: 0.0913 - val_acc: 0.9169 - val_recall: 0.9267 - val_precision: 0.9189 - val_f1_score: 0.9082\n",
      "Epoch 22/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0277 - acc: 0.9548 - recall: 0.9677 - precision: 0.9726 - f1_score: 0.9469\n",
      "Epoch 00022: val_f1_score did not improve from 0.91048\n",
      "288/288 [==============================] - 327s 1s/step - loss: 0.0277 - acc: 0.9548 - recall: 0.9677 - precision: 0.9726 - f1_score: 0.9469 - val_loss: 0.1019 - val_acc: 0.9164 - val_recall: 0.9101 - val_precision: 0.9261 - val_f1_score: 0.9055\n",
      "Epoch 23/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0271 - acc: 0.9528 - recall: 0.9689 - precision: 0.9710 - f1_score: 0.9470\n",
      "Epoch 00023: val_f1_score improved from 0.91048 to 0.91143, saving model to /app/_data/models/final/eff4_full/eff4_full_4.h5\n",
      "288/288 [==============================] - 329s 1s/step - loss: 0.0271 - acc: 0.9528 - recall: 0.9689 - precision: 0.9710 - f1_score: 0.9470 - val_loss: 0.0951 - val_acc: 0.9271 - val_recall: 0.9166 - val_precision: 0.9234 - val_f1_score: 0.9114\n",
      "Epoch 24/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0262 - acc: 0.9564 - recall: 0.9702 - precision: 0.9739 - f1_score: 0.9492\n",
      "Epoch 00024: val_f1_score did not improve from 0.91143\n",
      "288/288 [==============================] - 324s 1s/step - loss: 0.0262 - acc: 0.9564 - recall: 0.9702 - precision: 0.9739 - f1_score: 0.9492 - val_loss: 0.0927 - val_acc: 0.9229 - val_recall: 0.9246 - val_precision: 0.9225 - val_f1_score: 0.9103\n",
      "Epoch 25/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0220 - acc: 0.9583 - recall: 0.9754 - precision: 0.9784 - f1_score: 0.9510\n",
      "Epoch 00025: val_f1_score improved from 0.91143 to 0.91182, saving model to /app/_data/models/final/eff4_full/eff4_full_4.h5\n",
      "288/288 [==============================] - 343s 1s/step - loss: 0.0220 - acc: 0.9583 - recall: 0.9754 - precision: 0.9784 - f1_score: 0.9510 - val_loss: 0.1019 - val_acc: 0.9177 - val_recall: 0.9172 - val_precision: 0.9325 - val_f1_score: 0.9118\n",
      "Epoch 26/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0220 - acc: 0.9585 - recall: 0.9742 - precision: 0.9775 - f1_score: 0.9530\n",
      "Epoch 00026: val_f1_score did not improve from 0.91182\n",
      "288/288 [==============================] - 326s 1s/step - loss: 0.0220 - acc: 0.9585 - recall: 0.9742 - precision: 0.9775 - f1_score: 0.9530 - val_loss: 0.1153 - val_acc: 0.9100 - val_recall: 0.9258 - val_precision: 0.8940 - val_f1_score: 0.9029\n",
      "Epoch 27/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0219 - acc: 0.9590 - recall: 0.9749 - precision: 0.9785 - f1_score: 0.9515\n",
      "Epoch 00027: val_f1_score improved from 0.91182 to 0.91353, saving model to /app/_data/models/final/eff4_full/eff4_full_4.h5\n",
      "288/288 [==============================] - 350s 1s/step - loss: 0.0219 - acc: 0.9590 - recall: 0.9749 - precision: 0.9785 - f1_score: 0.9515 - val_loss: 0.1198 - val_acc: 0.9298 - val_recall: 0.9315 - val_precision: 0.9108 - val_f1_score: 0.9135\n",
      "Epoch 28/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0204 - acc: 0.9591 - recall: 0.9771 - precision: 0.9787 - f1_score: 0.9531\n",
      "Epoch 00028: val_f1_score did not improve from 0.91353\n",
      "288/288 [==============================] - 348s 1s/step - loss: 0.0204 - acc: 0.9591 - recall: 0.9771 - precision: 0.9787 - f1_score: 0.9531 - val_loss: 0.1184 - val_acc: 0.9162 - val_recall: 0.9018 - val_precision: 0.9266 - val_f1_score: 0.9054\n",
      "Epoch 29/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0207 - acc: 0.9596 - recall: 0.9777 - precision: 0.9793 - f1_score: 0.9534\n",
      "Epoch 00029: val_f1_score did not improve from 0.91353\n",
      "288/288 [==============================] - 322s 1s/step - loss: 0.0207 - acc: 0.9596 - recall: 0.9777 - precision: 0.9793 - f1_score: 0.9534 - val_loss: 0.1118 - val_acc: 0.9246 - val_recall: 0.9094 - val_precision: 0.9271 - val_f1_score: 0.9090\n",
      "Epoch 30/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0200 - acc: 0.9601 - recall: 0.9772 - precision: 0.9790 - f1_score: 0.9540\n",
      "Epoch 00030: val_f1_score did not improve from 0.91353\n",
      "288/288 [==============================] - 314s 1s/step - loss: 0.0200 - acc: 0.9601 - recall: 0.9772 - precision: 0.9790 - f1_score: 0.9540 - val_loss: 0.1253 - val_acc: 0.9191 - val_recall: 0.9078 - val_precision: 0.9321 - val_f1_score: 0.9097\n",
      "Epoch 31/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0189 - acc: 0.9593 - recall: 0.9788 - precision: 0.9806 - f1_score: 0.9544\n",
      "Epoch 00031: val_f1_score improved from 0.91353 to 0.91483, saving model to /app/_data/models/final/eff4_full/eff4_full_4.h5\n",
      "288/288 [==============================] - 299s 1s/step - loss: 0.0189 - acc: 0.9593 - recall: 0.9788 - precision: 0.9806 - f1_score: 0.9544 - val_loss: 0.1194 - val_acc: 0.9273 - val_recall: 0.9239 - val_precision: 0.9280 - val_f1_score: 0.9148\n",
      "Epoch 32/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0193 - acc: 0.9602 - recall: 0.9789 - precision: 0.9807 - f1_score: 0.9550\n",
      "Epoch 00032: val_f1_score did not improve from 0.91483\n",
      "288/288 [==============================] - 289s 1s/step - loss: 0.0193 - acc: 0.9602 - recall: 0.9789 - precision: 0.9807 - f1_score: 0.9550 - val_loss: 0.1140 - val_acc: 0.9092 - val_recall: 0.9041 - val_precision: 0.9248 - val_f1_score: 0.9041\n",
      "Epoch 33/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0186 - acc: 0.9549 - recall: 0.9800 - precision: 0.9811 - f1_score: 0.9557\n",
      "Epoch 00033: val_f1_score did not improve from 0.91483\n",
      "288/288 [==============================] - 311s 1s/step - loss: 0.0186 - acc: 0.9549 - recall: 0.9800 - precision: 0.9811 - f1_score: 0.9557 - val_loss: 0.1339 - val_acc: 0.9179 - val_recall: 0.9129 - val_precision: 0.9188 - val_f1_score: 0.9073\n",
      "Epoch 34/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0179 - acc: 0.9616 - recall: 0.9813 - precision: 0.9827 - f1_score: 0.9572\n",
      "Epoch 00034: val_f1_score did not improve from 0.91483\n",
      "288/288 [==============================] - 314s 1s/step - loss: 0.0179 - acc: 0.9616 - recall: 0.9813 - precision: 0.9827 - f1_score: 0.9572 - val_loss: 0.1175 - val_acc: 0.9139 - val_recall: 0.9304 - val_precision: 0.9123 - val_f1_score: 0.9066\n",
      "Epoch 35/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0150 - acc: 0.9642 - recall: 0.9833 - precision: 0.9847 - f1_score: 0.9586\n",
      "Epoch 00035: val_f1_score did not improve from 0.91483\n",
      "288/288 [==============================] - 286s 993ms/step - loss: 0.0150 - acc: 0.9642 - recall: 0.9833 - precision: 0.9847 - f1_score: 0.9586 - val_loss: 0.1335 - val_acc: 0.9125 - val_recall: 0.9000 - val_precision: 0.9113 - val_f1_score: 0.8979\n",
      "Epoch 36/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0161 - acc: 0.9621 - recall: 0.9824 - precision: 0.9838 - f1_score: 0.9593\n",
      "Epoch 00036: val_f1_score did not improve from 0.91483\n",
      "288/288 [==============================] - 303s 1s/step - loss: 0.0161 - acc: 0.9621 - recall: 0.9824 - precision: 0.9838 - f1_score: 0.9593 - val_loss: 0.1220 - val_acc: 0.9159 - val_recall: 0.9057 - val_precision: 0.9284 - val_f1_score: 0.9055\n",
      "Epoch 37/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0153 - acc: 0.9629 - recall: 0.9831 - precision: 0.9850 - f1_score: 0.9595\n",
      "Epoch 00037: val_f1_score did not improve from 0.91483\n",
      "288/288 [==============================] - 302s 1s/step - loss: 0.0153 - acc: 0.9629 - recall: 0.9831 - precision: 0.9850 - f1_score: 0.9595 - val_loss: 0.1181 - val_acc: 0.9206 - val_recall: 0.9129 - val_precision: 0.9209 - val_f1_score: 0.9109\n",
      "Epoch 38/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0154 - acc: 0.9644 - recall: 0.9832 - precision: 0.9854 - f1_score: 0.9592\n",
      "Epoch 00038: val_f1_score did not improve from 0.91483\n",
      "288/288 [==============================] - 296s 1s/step - loss: 0.0154 - acc: 0.9644 - recall: 0.9832 - precision: 0.9854 - f1_score: 0.9592 - val_loss: 0.1236 - val_acc: 0.9087 - val_recall: 0.9163 - val_precision: 0.9182 - val_f1_score: 0.9055\n",
      "Epoch 39/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0153 - acc: 0.9577 - recall: 0.9843 - precision: 0.9856 - f1_score: 0.9594\n",
      "Epoch 00039: val_f1_score did not improve from 0.91483\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.0004050000192364678.\n",
      "288/288 [==============================] - 301s 1s/step - loss: 0.0153 - acc: 0.9577 - recall: 0.9843 - precision: 0.9856 - f1_score: 0.9594 - val_loss: 0.1307 - val_acc: 0.9204 - val_recall: 0.9032 - val_precision: 0.9349 - val_f1_score: 0.9113\n",
      "Epoch 40/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0123 - acc: 0.9652 - recall: 0.9871 - precision: 0.9884 - f1_score: 0.9634\n",
      "Epoch 00040: val_f1_score did not improve from 0.91483\n",
      "288/288 [==============================] - 302s 1s/step - loss: 0.0123 - acc: 0.9652 - recall: 0.9871 - precision: 0.9884 - f1_score: 0.9634 - val_loss: 0.1276 - val_acc: 0.9221 - val_recall: 0.9202 - val_precision: 0.9286 - val_f1_score: 0.9142\n",
      "Epoch 41/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0140 - acc: 0.9625 - recall: 0.9855 - precision: 0.9868 - f1_score: 0.9626\n",
      "Epoch 00041: val_f1_score did not improve from 0.91483\n",
      "288/288 [==============================] - 304s 1s/step - loss: 0.0140 - acc: 0.9625 - recall: 0.9855 - precision: 0.9868 - f1_score: 0.9626 - val_loss: 0.1180 - val_acc: 0.9122 - val_recall: 0.9202 - val_precision: 0.9192 - val_f1_score: 0.9087\n",
      "Epoch 42/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0127 - acc: 0.9665 - recall: 0.9855 - precision: 0.9873 - f1_score: 0.9647Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00042: val_f1_score did not improve from 0.91483\n",
      "288/288 [==============================] - 287s 997ms/step - loss: 0.0127 - acc: 0.9665 - recall: 0.9855 - precision: 0.9873 - f1_score: 0.9647 - val_loss: 0.1301 - val_acc: 0.9102 - val_recall: 0.9179 - val_precision: 0.8997 - val_f1_score: 0.9070\n",
      "Epoch 00042: early stopping\n",
      "Epoch 1/100\n",
      "  2/288 [..............................] - ETA: 6:26 - loss: 0.6677 - acc: 0.1250 - recall: 0.3136 - precision: 0.1630 - f1_score: 0.1318WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.3876s vs `on_train_batch_end` time: 2.3116s). Check your callbacks.\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.1516 - acc: 0.8366 - recall: 0.7950 - precision: 0.8591 - f1_score: 0.8245\n",
      "Epoch 00001: val_f1_score improved from -inf to 0.83356, saving model to /app/_data/models/final/eff4_full/eff4_full_5.h5\n",
      "288/288 [==============================] - 287s 997ms/step - loss: 0.1516 - acc: 0.8366 - recall: 0.7950 - precision: 0.8591 - f1_score: 0.8245 - val_loss: 0.1424 - val_acc: 0.8514 - val_recall: 0.8060 - val_precision: 0.8716 - val_f1_score: 0.8336\n",
      "Epoch 2/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0993 - acc: 0.8930 - recall: 0.8722 - precision: 0.9021 - f1_score: 0.8806\n",
      "Epoch 00002: val_f1_score improved from 0.83356 to 0.88556, saving model to /app/_data/models/final/eff4_full/eff4_full_5.h5\n",
      "288/288 [==============================] - 315s 1s/step - loss: 0.0993 - acc: 0.8930 - recall: 0.8722 - precision: 0.9021 - f1_score: 0.8806 - val_loss: 0.1030 - val_acc: 0.9070 - val_recall: 0.8580 - val_precision: 0.9223 - val_f1_score: 0.8856\n",
      "Epoch 3/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0872 - acc: 0.9036 - recall: 0.8896 - precision: 0.9150 - f1_score: 0.8923\n",
      "Epoch 00003: val_f1_score improved from 0.88556 to 0.89919, saving model to /app/_data/models/final/eff4_full/eff4_full_5.h5\n",
      "288/288 [==============================] - 293s 1s/step - loss: 0.0872 - acc: 0.9036 - recall: 0.8896 - precision: 0.9150 - f1_score: 0.8923 - val_loss: 0.0821 - val_acc: 0.9184 - val_recall: 0.8856 - val_precision: 0.9322 - val_f1_score: 0.8992\n",
      "Epoch 4/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0819 - acc: 0.9092 - recall: 0.8937 - precision: 0.9166 - f1_score: 0.8972\n",
      "Epoch 00004: val_f1_score improved from 0.89919 to 0.90506, saving model to /app/_data/models/final/eff4_full/eff4_full_5.h5\n",
      "288/288 [==============================] - 310s 1s/step - loss: 0.0819 - acc: 0.9092 - recall: 0.8937 - precision: 0.9166 - f1_score: 0.8972 - val_loss: 0.0742 - val_acc: 0.9256 - val_recall: 0.8958 - val_precision: 0.9331 - val_f1_score: 0.9051\n",
      "Epoch 5/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0745 - acc: 0.9163 - recall: 0.9054 - precision: 0.9221 - f1_score: 0.9044\n",
      "Epoch 00005: val_f1_score improved from 0.90506 to 0.90966, saving model to /app/_data/models/final/eff4_full/eff4_full_5.h5\n",
      "288/288 [==============================] - 283s 984ms/step - loss: 0.0745 - acc: 0.9163 - recall: 0.9054 - precision: 0.9221 - f1_score: 0.9044 - val_loss: 0.0791 - val_acc: 0.9306 - val_recall: 0.8971 - val_precision: 0.9319 - val_f1_score: 0.9097\n",
      "Epoch 6/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0701 - acc: 0.9229 - recall: 0.9105 - precision: 0.9295 - f1_score: 0.9102\n",
      "Epoch 00006: val_f1_score did not improve from 0.90966\n",
      "288/288 [==============================] - 218s 758ms/step - loss: 0.0701 - acc: 0.9229 - recall: 0.9105 - precision: 0.9295 - f1_score: 0.9102 - val_loss: 0.0902 - val_acc: 0.8983 - val_recall: 0.8935 - val_precision: 0.9180 - val_f1_score: 0.8916\n",
      "Epoch 7/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0676 - acc: 0.9242 - recall: 0.9159 - precision: 0.9308 - f1_score: 0.9126\n",
      "Epoch 00007: val_f1_score did not improve from 0.90966\n",
      "288/288 [==============================] - 172s 597ms/step - loss: 0.0676 - acc: 0.9242 - recall: 0.9159 - precision: 0.9308 - f1_score: 0.9126 - val_loss: 0.0951 - val_acc: 0.9122 - val_recall: 0.8836 - val_precision: 0.9242 - val_f1_score: 0.8964\n",
      "Epoch 8/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0630 - acc: 0.9297 - recall: 0.9220 - precision: 0.9372 - f1_score: 0.9179\n",
      "Epoch 00008: val_f1_score did not improve from 0.90966\n",
      "288/288 [==============================] - 152s 527ms/step - loss: 0.0630 - acc: 0.9297 - recall: 0.9220 - precision: 0.9372 - f1_score: 0.9179 - val_loss: 0.0755 - val_acc: 0.9251 - val_recall: 0.9162 - val_precision: 0.9222 - val_f1_score: 0.9045\n",
      "Epoch 9/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0596 - acc: 0.9310 - recall: 0.9262 - precision: 0.9392 - f1_score: 0.9202\n",
      "Epoch 00009: val_f1_score did not improve from 0.90966\n",
      "288/288 [==============================] - 150s 521ms/step - loss: 0.0596 - acc: 0.9310 - recall: 0.9262 - precision: 0.9392 - f1_score: 0.9202 - val_loss: 0.0857 - val_acc: 0.9261 - val_recall: 0.8976 - val_precision: 0.9248 - val_f1_score: 0.9048\n",
      "Epoch 10/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0556 - acc: 0.9316 - recall: 0.9317 - precision: 0.9422 - f1_score: 0.9227\n",
      "Epoch 00010: val_f1_score did not improve from 0.90966\n",
      "288/288 [==============================] - 144s 501ms/step - loss: 0.0556 - acc: 0.9316 - recall: 0.9317 - precision: 0.9422 - f1_score: 0.9227 - val_loss: 0.0834 - val_acc: 0.9132 - val_recall: 0.9248 - val_precision: 0.9013 - val_f1_score: 0.8969\n",
      "Epoch 11/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0531 - acc: 0.9360 - recall: 0.9353 - precision: 0.9464 - f1_score: 0.9260\n",
      "Epoch 00011: val_f1_score did not improve from 0.90966\n",
      "288/288 [==============================] - 146s 508ms/step - loss: 0.0531 - acc: 0.9360 - recall: 0.9353 - precision: 0.9464 - f1_score: 0.9260 - val_loss: 0.0774 - val_acc: 0.9301 - val_recall: 0.9073 - val_precision: 0.9368 - val_f1_score: 0.9091\n",
      "Epoch 12/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0524 - acc: 0.9362 - recall: 0.9370 - precision: 0.9459 - f1_score: 0.9262\n",
      "Epoch 00012: val_f1_score did not improve from 0.90966\n",
      "288/288 [==============================] - 143s 495ms/step - loss: 0.0524 - acc: 0.9362 - recall: 0.9370 - precision: 0.9459 - f1_score: 0.9262 - val_loss: 0.0791 - val_acc: 0.9187 - val_recall: 0.9144 - val_precision: 0.9263 - val_f1_score: 0.9074\n",
      "Epoch 13/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0484 - acc: 0.9387 - recall: 0.9405 - precision: 0.9511 - f1_score: 0.9296\n",
      "Epoch 00013: val_f1_score did not improve from 0.90966\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0004500000213738531.\n",
      "288/288 [==============================] - 144s 499ms/step - loss: 0.0484 - acc: 0.9387 - recall: 0.9405 - precision: 0.9511 - f1_score: 0.9296 - val_loss: 0.0890 - val_acc: 0.9239 - val_recall: 0.9008 - val_precision: 0.9335 - val_f1_score: 0.9055\n",
      "Epoch 14/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0427 - acc: 0.9434 - recall: 0.9487 - precision: 0.9543 - f1_score: 0.9332\n",
      "Epoch 00014: val_f1_score improved from 0.90966 to 0.91407, saving model to /app/_data/models/final/eff4_full/eff4_full_5.h5\n",
      "288/288 [==============================] - 144s 500ms/step - loss: 0.0427 - acc: 0.9434 - recall: 0.9487 - precision: 0.9543 - f1_score: 0.9332 - val_loss: 0.0744 - val_acc: 0.9291 - val_recall: 0.9188 - val_precision: 0.9323 - val_f1_score: 0.9141\n",
      "Epoch 15/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0403 - acc: 0.9453 - recall: 0.9507 - precision: 0.9593 - f1_score: 0.9374\n",
      "Epoch 00015: val_f1_score did not improve from 0.91407\n",
      "288/288 [==============================] - 138s 481ms/step - loss: 0.0403 - acc: 0.9453 - recall: 0.9507 - precision: 0.9593 - f1_score: 0.9374 - val_loss: 0.1238 - val_acc: 0.8966 - val_recall: 0.8930 - val_precision: 0.9151 - val_f1_score: 0.8920\n",
      "Epoch 16/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0395 - acc: 0.9457 - recall: 0.9541 - precision: 0.9603 - f1_score: 0.9385\n",
      "Epoch 00016: val_f1_score did not improve from 0.91407\n",
      "288/288 [==============================] - 145s 503ms/step - loss: 0.0395 - acc: 0.9457 - recall: 0.9541 - precision: 0.9603 - f1_score: 0.9385 - val_loss: 0.1171 - val_acc: 0.9033 - val_recall: 0.8879 - val_precision: 0.9188 - val_f1_score: 0.8895\n",
      "Epoch 17/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0371 - acc: 0.9449 - recall: 0.9546 - precision: 0.9622 - f1_score: 0.9385\n",
      "Epoch 00017: val_f1_score did not improve from 0.91407\n",
      "288/288 [==============================] - 139s 482ms/step - loss: 0.0371 - acc: 0.9449 - recall: 0.9546 - precision: 0.9622 - f1_score: 0.9385 - val_loss: 0.0862 - val_acc: 0.9191 - val_recall: 0.9084 - val_precision: 0.9272 - val_f1_score: 0.9067\n",
      "Epoch 18/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0330 - acc: 0.9521 - recall: 0.9601 - precision: 0.9676 - f1_score: 0.9433\n",
      "Epoch 00018: val_f1_score did not improve from 0.91407\n",
      "288/288 [==============================] - 144s 501ms/step - loss: 0.0330 - acc: 0.9521 - recall: 0.9601 - precision: 0.9676 - f1_score: 0.9433 - val_loss: 0.0960 - val_acc: 0.9164 - val_recall: 0.9139 - val_precision: 0.9306 - val_f1_score: 0.9079\n",
      "Epoch 19/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0326 - acc: 0.9521 - recall: 0.9616 - precision: 0.9686 - f1_score: 0.9443\n",
      "Epoch 00019: val_f1_score did not improve from 0.91407\n",
      "288/288 [==============================] - 146s 505ms/step - loss: 0.0326 - acc: 0.9521 - recall: 0.9616 - precision: 0.9686 - f1_score: 0.9443 - val_loss: 0.0948 - val_acc: 0.9293 - val_recall: 0.9066 - val_precision: 0.9368 - val_f1_score: 0.9134\n",
      "Epoch 20/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0321 - acc: 0.9510 - recall: 0.9631 - precision: 0.9664 - f1_score: 0.9437\n",
      "Epoch 00020: val_f1_score did not improve from 0.91407\n",
      "288/288 [==============================] - 146s 508ms/step - loss: 0.0321 - acc: 0.9510 - recall: 0.9631 - precision: 0.9664 - f1_score: 0.9437 - val_loss: 0.0986 - val_acc: 0.9204 - val_recall: 0.9024 - val_precision: 0.9233 - val_f1_score: 0.9028\n",
      "Epoch 21/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0309 - acc: 0.9549 - recall: 0.9636 - precision: 0.9688 - f1_score: 0.9451\n",
      "Epoch 00021: val_f1_score did not improve from 0.91407\n",
      "288/288 [==============================] - 141s 491ms/step - loss: 0.0309 - acc: 0.9549 - recall: 0.9636 - precision: 0.9688 - f1_score: 0.9451 - val_loss: 0.0796 - val_acc: 0.9224 - val_recall: 0.9390 - val_precision: 0.9085 - val_f1_score: 0.9114\n",
      "Epoch 22/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0276 - acc: 0.9583 - recall: 0.9673 - precision: 0.9716 - f1_score: 0.9479\n",
      "Epoch 00022: val_f1_score did not improve from 0.91407\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0004050000192364678.\n",
      "288/288 [==============================] - 145s 502ms/step - loss: 0.0276 - acc: 0.9583 - recall: 0.9673 - precision: 0.9716 - f1_score: 0.9479 - val_loss: 0.0872 - val_acc: 0.9201 - val_recall: 0.9241 - val_precision: 0.9236 - val_f1_score: 0.9075\n",
      "Epoch 23/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0251 - acc: 0.9553 - recall: 0.9713 - precision: 0.9745 - f1_score: 0.9495\n",
      "Epoch 00023: val_f1_score improved from 0.91407 to 0.91443, saving model to /app/_data/models/final/eff4_full/eff4_full_5.h5\n",
      "288/288 [==============================] - 146s 507ms/step - loss: 0.0251 - acc: 0.9553 - recall: 0.9713 - precision: 0.9745 - f1_score: 0.9495 - val_loss: 0.0972 - val_acc: 0.9256 - val_recall: 0.9165 - val_precision: 0.9317 - val_f1_score: 0.9144\n",
      "Epoch 24/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0220 - acc: 0.9598 - recall: 0.9739 - precision: 0.9785 - f1_score: 0.9525\n",
      "Epoch 00024: val_f1_score improved from 0.91443 to 0.91772, saving model to /app/_data/models/final/eff4_full/eff4_full_5.h5\n",
      "288/288 [==============================] - 147s 510ms/step - loss: 0.0220 - acc: 0.9598 - recall: 0.9739 - precision: 0.9785 - f1_score: 0.9525 - val_loss: 0.0968 - val_acc: 0.9345 - val_recall: 0.9275 - val_precision: 0.9312 - val_f1_score: 0.9177\n",
      "Epoch 25/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0204 - acc: 0.9598 - recall: 0.9781 - precision: 0.9799 - f1_score: 0.9547\n",
      "Epoch 00025: val_f1_score did not improve from 0.91772\n",
      "288/288 [==============================] - 142s 493ms/step - loss: 0.0204 - acc: 0.9598 - recall: 0.9781 - precision: 0.9799 - f1_score: 0.9547 - val_loss: 0.0954 - val_acc: 0.9194 - val_recall: 0.9137 - val_precision: 0.9315 - val_f1_score: 0.9114\n",
      "Epoch 26/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0208 - acc: 0.9558 - recall: 0.9761 - precision: 0.9797 - f1_score: 0.9530\n",
      "Epoch 00026: val_f1_score did not improve from 0.91772\n",
      "288/288 [==============================] - 142s 495ms/step - loss: 0.0208 - acc: 0.9558 - recall: 0.9761 - precision: 0.9797 - f1_score: 0.9530 - val_loss: 0.1058 - val_acc: 0.9311 - val_recall: 0.9243 - val_precision: 0.9138 - val_f1_score: 0.9142\n",
      "Epoch 27/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0207 - acc: 0.9573 - recall: 0.9770 - precision: 0.9803 - f1_score: 0.9543\n",
      "Epoch 00027: val_f1_score improved from 0.91772 to 0.91809, saving model to /app/_data/models/final/eff4_full/eff4_full_5.h5\n",
      "288/288 [==============================] - 149s 517ms/step - loss: 0.0207 - acc: 0.9573 - recall: 0.9770 - precision: 0.9803 - f1_score: 0.9543 - val_loss: 0.0878 - val_acc: 0.9244 - val_recall: 0.9231 - val_precision: 0.9332 - val_f1_score: 0.9181\n",
      "Epoch 28/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0192 - acc: 0.9615 - recall: 0.9790 - precision: 0.9811 - f1_score: 0.9575\n",
      "Epoch 00028: val_f1_score did not improve from 0.91809\n",
      "288/288 [==============================] - 146s 508ms/step - loss: 0.0192 - acc: 0.9615 - recall: 0.9790 - precision: 0.9811 - f1_score: 0.9575 - val_loss: 0.0995 - val_acc: 0.9343 - val_recall: 0.9172 - val_precision: 0.9350 - val_f1_score: 0.9162\n",
      "Epoch 29/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0188 - acc: 0.9610 - recall: 0.9784 - precision: 0.9822 - f1_score: 0.9555\n",
      "Epoch 00029: val_f1_score did not improve from 0.91809\n",
      "288/288 [==============================] - 147s 509ms/step - loss: 0.0188 - acc: 0.9610 - recall: 0.9784 - precision: 0.9822 - f1_score: 0.9555 - val_loss: 0.1068 - val_acc: 0.9221 - val_recall: 0.9257 - val_precision: 0.9250 - val_f1_score: 0.9112\n",
      "Epoch 30/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0179 - acc: 0.9603 - recall: 0.9806 - precision: 0.9824 - f1_score: 0.9561\n",
      "Epoch 00030: val_f1_score did not improve from 0.91809\n",
      "288/288 [==============================] - 147s 510ms/step - loss: 0.0179 - acc: 0.9603 - recall: 0.9806 - precision: 0.9824 - f1_score: 0.9561 - val_loss: 0.1014 - val_acc: 0.9288 - val_recall: 0.9252 - val_precision: 0.9329 - val_f1_score: 0.9168\n",
      "Epoch 31/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0174 - acc: 0.9629 - recall: 0.9806 - precision: 0.9824 - f1_score: 0.9582\n",
      "Epoch 00031: val_f1_score did not improve from 0.91809\n",
      "288/288 [==============================] - 146s 507ms/step - loss: 0.0174 - acc: 0.9629 - recall: 0.9806 - precision: 0.9824 - f1_score: 0.9582 - val_loss: 0.1069 - val_acc: 0.9246 - val_recall: 0.9169 - val_precision: 0.9304 - val_f1_score: 0.9111\n",
      "Epoch 32/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0161 - acc: 0.9614 - recall: 0.9814 - precision: 0.9855 - f1_score: 0.9588\n",
      "Epoch 00032: val_f1_score did not improve from 0.91809\n",
      "288/288 [==============================] - 148s 513ms/step - loss: 0.0161 - acc: 0.9614 - recall: 0.9814 - precision: 0.9855 - f1_score: 0.9588 - val_loss: 0.1068 - val_acc: 0.9204 - val_recall: 0.9204 - val_precision: 0.9337 - val_f1_score: 0.9129\n",
      "Epoch 33/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0143 - acc: 0.9621 - recall: 0.9833 - precision: 0.9860 - f1_score: 0.9611\n",
      "Epoch 00033: val_f1_score did not improve from 0.91809\n",
      "288/288 [==============================] - 147s 511ms/step - loss: 0.0143 - acc: 0.9621 - recall: 0.9833 - precision: 0.9860 - f1_score: 0.9611 - val_loss: 0.1190 - val_acc: 0.9306 - val_recall: 0.9317 - val_precision: 0.9257 - val_f1_score: 0.9177\n",
      "Epoch 34/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0178 - acc: 0.9631 - recall: 0.9794 - precision: 0.9828 - f1_score: 0.9583\n",
      "Epoch 00034: val_f1_score did not improve from 0.91809\n",
      "288/288 [==============================] - 150s 522ms/step - loss: 0.0178 - acc: 0.9631 - recall: 0.9794 - precision: 0.9828 - f1_score: 0.9583 - val_loss: 0.1120 - val_acc: 0.9234 - val_recall: 0.9158 - val_precision: 0.9256 - val_f1_score: 0.9081\n",
      "Epoch 35/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0143 - acc: 0.9667 - recall: 0.9838 - precision: 0.9860 - f1_score: 0.9609\n",
      "Epoch 00035: val_f1_score did not improve from 0.91809\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.0003645000251708552.\n",
      "288/288 [==============================] - 151s 526ms/step - loss: 0.0143 - acc: 0.9667 - recall: 0.9838 - precision: 0.9860 - f1_score: 0.9609 - val_loss: 0.1197 - val_acc: 0.9273 - val_recall: 0.8960 - val_precision: 0.9338 - val_f1_score: 0.9079\n",
      "Epoch 36/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0126 - acc: 0.9639 - recall: 0.9866 - precision: 0.9875 - f1_score: 0.9620\n",
      "Epoch 00036: val_f1_score did not improve from 0.91809\n",
      "288/288 [==============================] - 148s 513ms/step - loss: 0.0126 - acc: 0.9639 - recall: 0.9866 - precision: 0.9875 - f1_score: 0.9620 - val_loss: 0.1134 - val_acc: 0.9167 - val_recall: 0.9188 - val_precision: 0.9200 - val_f1_score: 0.9068\n",
      "Epoch 37/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0114 - acc: 0.9669 - recall: 0.9873 - precision: 0.9889 - f1_score: 0.9658\n",
      "Epoch 00037: val_f1_score improved from 0.91809 to 0.91839, saving model to /app/_data/models/final/eff4_full/eff4_full_5.h5\n",
      "288/288 [==============================] - 152s 528ms/step - loss: 0.0114 - acc: 0.9669 - recall: 0.9873 - precision: 0.9889 - f1_score: 0.9658 - val_loss: 0.1148 - val_acc: 0.9283 - val_recall: 0.9199 - val_precision: 0.9376 - val_f1_score: 0.9184\n",
      "Epoch 38/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0118 - acc: 0.9671 - recall: 0.9876 - precision: 0.9887 - f1_score: 0.9655\n",
      "Epoch 00038: val_f1_score did not improve from 0.91839\n",
      "288/288 [==============================] - 142s 493ms/step - loss: 0.0118 - acc: 0.9671 - recall: 0.9876 - precision: 0.9887 - f1_score: 0.9655 - val_loss: 0.1150 - val_acc: 0.9291 - val_recall: 0.9167 - val_precision: 0.9348 - val_f1_score: 0.9152\n",
      "Epoch 39/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0128 - acc: 0.9656 - recall: 0.9865 - precision: 0.9866 - f1_score: 0.9628\n",
      "Epoch 00039: val_f1_score did not improve from 0.91839\n",
      "288/288 [==============================] - 150s 520ms/step - loss: 0.0128 - acc: 0.9656 - recall: 0.9865 - precision: 0.9866 - f1_score: 0.9628 - val_loss: 0.1052 - val_acc: 0.9231 - val_recall: 0.9257 - val_precision: 0.9208 - val_f1_score: 0.9102\n",
      "Epoch 40/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0124 - acc: 0.9654 - recall: 0.9874 - precision: 0.9870 - f1_score: 0.9630\n",
      "Epoch 00040: val_f1_score did not improve from 0.91839\n",
      "288/288 [==============================] - 152s 526ms/step - loss: 0.0124 - acc: 0.9654 - recall: 0.9874 - precision: 0.9870 - f1_score: 0.9630 - val_loss: 0.1162 - val_acc: 0.9201 - val_recall: 0.9259 - val_precision: 0.9210 - val_f1_score: 0.9114\n",
      "Epoch 41/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0105 - acc: 0.9676 - recall: 0.9884 - precision: 0.9904 - f1_score: 0.9676\n",
      "Epoch 00041: val_f1_score did not improve from 0.91839\n",
      "288/288 [==============================] - 145s 502ms/step - loss: 0.0105 - acc: 0.9676 - recall: 0.9884 - precision: 0.9904 - f1_score: 0.9676 - val_loss: 0.1167 - val_acc: 0.9301 - val_recall: 0.9199 - val_precision: 0.9350 - val_f1_score: 0.9157\n",
      "Epoch 42/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0096 - acc: 0.9695 - recall: 0.9898 - precision: 0.9909 - f1_score: 0.9676\n",
      "Epoch 00042: val_f1_score did not improve from 0.91839\n",
      "288/288 [==============================] - 147s 511ms/step - loss: 0.0096 - acc: 0.9695 - recall: 0.9898 - precision: 0.9909 - f1_score: 0.9676 - val_loss: 0.1327 - val_acc: 0.9253 - val_recall: 0.9167 - val_precision: 0.9352 - val_f1_score: 0.9151\n",
      "Epoch 43/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0093 - acc: 0.9702 - recall: 0.9897 - precision: 0.9909 - f1_score: 0.9714\n",
      "Epoch 00043: val_f1_score did not improve from 0.91839\n",
      "288/288 [==============================] - 149s 516ms/step - loss: 0.0093 - acc: 0.9702 - recall: 0.9897 - precision: 0.9909 - f1_score: 0.9714 - val_loss: 0.1176 - val_acc: 0.9239 - val_recall: 0.9261 - val_precision: 0.9278 - val_f1_score: 0.9162\n",
      "Epoch 44/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0120 - acc: 0.9660 - recall: 0.9867 - precision: 0.9891 - f1_score: 0.9645\n",
      "Epoch 00044: val_f1_score did not improve from 0.91839\n",
      "288/288 [==============================] - 149s 518ms/step - loss: 0.0120 - acc: 0.9660 - recall: 0.9867 - precision: 0.9891 - f1_score: 0.9645 - val_loss: 0.1216 - val_acc: 0.9224 - val_recall: 0.9225 - val_precision: 0.9231 - val_f1_score: 0.9121\n",
      "Epoch 45/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0108 - acc: 0.9686 - recall: 0.9885 - precision: 0.9905 - f1_score: 0.9662\n",
      "Epoch 00045: val_f1_score did not improve from 0.91839\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.0003280500357504934.\n",
      "288/288 [==============================] - 150s 520ms/step - loss: 0.0108 - acc: 0.9686 - recall: 0.9885 - precision: 0.9905 - f1_score: 0.9662 - val_loss: 0.1147 - val_acc: 0.9268 - val_recall: 0.9287 - val_precision: 0.9225 - val_f1_score: 0.9166\n",
      "Epoch 46/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0104 - acc: 0.9691 - recall: 0.9896 - precision: 0.9895 - f1_score: 0.9683\n",
      "Epoch 00046: val_f1_score did not improve from 0.91839\n",
      "288/288 [==============================] - 147s 510ms/step - loss: 0.0104 - acc: 0.9691 - recall: 0.9896 - precision: 0.9895 - f1_score: 0.9683 - val_loss: 0.1132 - val_acc: 0.9335 - val_recall: 0.9243 - val_precision: 0.9281 - val_f1_score: 0.9157\n",
      "Epoch 47/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0084 - acc: 0.9712 - recall: 0.9914 - precision: 0.9912 - f1_score: 0.9707\n",
      "Epoch 00047: val_f1_score did not improve from 0.91839\n",
      "288/288 [==============================] - 149s 516ms/step - loss: 0.0084 - acc: 0.9712 - recall: 0.9914 - precision: 0.9912 - f1_score: 0.9707 - val_loss: 0.1359 - val_acc: 0.9293 - val_recall: 0.9054 - val_precision: 0.9347 - val_f1_score: 0.9122\n",
      "Epoch 48/100\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0079 - acc: 0.9725 - recall: 0.9911 - precision: 0.9919 - f1_score: 0.9713Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00048: val_f1_score did not improve from 0.91839\n",
      "288/288 [==============================] - 150s 520ms/step - loss: 0.0079 - acc: 0.9725 - recall: 0.9911 - precision: 0.9919 - f1_score: 0.9713 - val_loss: 0.1302 - val_acc: 0.9273 - val_recall: 0.9199 - val_precision: 0.9326 - val_f1_score: 0.9158\n",
      "Epoch 00048: early stopping\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=SEED, shuffle=True)\n",
    "\n",
    "for i, (train_index, valid_index) in enumerate(\n",
    "    skf.split(df_labels[\"image\"], df_labels[\"labels\"])\n",
    "):\n",
    "        train, valid = df_labels.loc[train_index], df_labels.loc[valid_index]\n",
    "        model_name = \"eff4_full_\" + str(i + 1) + \".h5\"\n",
    "        log_dir = 'logs_eff4_full_'+str(i + 1)+'/'\n",
    "        callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor=\"val_f1_score\",\n",
    "                patience=11,\n",
    "                restore_best_weights=True,\n",
    "                verbose=1,\n",
    "                mode=\"max\",\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                \"/app/_data/models/final/eff4_full/\" + model_name,\n",
    "                monitor=\"val_f1_score\",\n",
    "                verbose=1,\n",
    "                save_best_only=True,\n",
    "                save_weights_only=False,\n",
    "                mode=\"max\",\n",
    "                save_freq=\"epoch\",\n",
    "            ),\n",
    "            keras.callbacks.ReduceLROnPlateau(\n",
    "                monitor=\"val_f1_score\",\n",
    "                factor=0.9,\n",
    "                patience=8,\n",
    "                verbose=1,\n",
    "                mode=\"max\",\n",
    "                min_delta=1e-4,\n",
    "                min_lr=0.00000001,\n",
    "            ),\n",
    "            keras.callbacks.TensorBoard(\n",
    "                log_dir=\"/app/.tensorboard/\"+log_dir, histogram_freq=0\n",
    "            ),\n",
    "            keras.callbacks.experimental.BackupAndRestore(\n",
    "        '/app/_data/models/final/eff4_full/backup/'\n",
    "    )\n",
    "        ]\n",
    "\n",
    "        gen_train = Generator(\n",
    "            df=train,\n",
    "            images_src_dir=TRAIN_IMG_PATH,\n",
    "            target_image_size=IMAGE_SIZE,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=True,\n",
    "            augment=True,\n",
    "            crop=False,\n",
    "            resize=False,\n",
    "        )\n",
    "        gen_valid = Generator(\n",
    "            df=valid,\n",
    "            images_src_dir=TRAIN_IMG_PATH,\n",
    "            target_image_size=IMAGE_SIZE,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=False,\n",
    "            augment=False,\n",
    "            crop=False,\n",
    "            resize=False,\n",
    "        )\n",
    "        model = get_model()\n",
    "        history = model.fit(\n",
    "            gen_train,\n",
    "            validation_data=gen_valid,\n",
    "            epochs=100,\n",
    "            steps_per_epoch=train.shape[0]//BATCH_SIZE,\n",
    "            validation_steps=valid.shape[0]//BATCH_SIZE,\n",
    "            verbose=1,\n",
    "            workers = 25,\n",
    "            callbacks=callbacks,\n",
    "        )\n",
    "        tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices(\"GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_all(file_path):\n",
    "    img = tf.io.read_file(TRAIN_IMG_PATH + file_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    return img\n",
    "\n",
    "\n",
    "def predict_new(path, model):\n",
    "    img = parse_all(path)\n",
    "    img = tf.expand_dims(img, axis=0)\n",
    "    pred = model.predict(img)\n",
    "    return pred_to_labels(pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = pd.DataFrame(columns=[\"image\", \"labels\"])\n",
    "for img_name in os.listdir(TRAIN_IMG_PATH):\n",
    "    pred = predict_new(img_name, model)\n",
    "\n",
    "    df_sub = df_sub.append({\"image\": img_name, \"labels\": pred}, ignore_index=True)\n",
    "\n",
    "print(df_sub.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = df_sub.merge(\n",
    "    labels_21_20[[\"image\", \"labels\"]],\n",
    "    on=\"image\",\n",
    "    how=\"left\",\n",
    "    suffixes=(\"_pred\", \"_true\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.to_csv(\"/app/sandbox/wrong_predictions/eff4/eff4_ns_cropped_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub[df_sub[\"labels_pred\"] == \"\"][\"labels_true\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scab frog_eye_leaf_spot            682\n",
       "complex                            438\n",
       "scab frog_eye_leaf_spot complex    200\n",
       "frog_eye_leaf_spot complex         165\n",
       "scab                               124\n",
       "rust frog_eye_leaf_spot            118\n",
       "rust complex                        91\n",
       "powdery_mildew complex              87\n",
       "rust                                74\n",
       "frog_eye_leaf_spot                  71\n",
       "healthy                             19\n",
       "powdery_mildew                       7\n",
       "Name: labels_true, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub[df_sub[\"labels_pred\"] != df_sub[\"labels_true\"]][\"labels_true\"].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
