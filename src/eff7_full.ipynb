{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /app/kaggle.json'\n"
     ]
    }
   ],
   "source": [
    "import kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /app/kaggle.json'\n",
      "Data package template written to: /app/_data/models/final/eff7_full/dataset-metadata.json\n"
     ]
    }
   ],
   "source": [
    "! kaggle datasets init -p /app/_data/models/final/eff7_full/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /app/kaggle.json'\n",
      "Starting upload for file eff7_full_4.h5\n",
      "100%|█████████████████████████████████████████| 734M/734M [18:14<00:00, 704kB/s]\n",
      "Upload successful: eff7_full_4.h5 (734MB)\n",
      "Starting upload for file eff7_full_1.h5\n",
      "100%|█████████████████████████████████████████| 734M/734M [19:18<00:00, 664kB/s]\n",
      "Upload successful: eff7_full_1.h5 (734MB)\n",
      "Starting upload for file eff7_full_3.h5\n",
      "100%|█████████████████████████████████████████| 734M/734M [19:03<00:00, 673kB/s]\n",
      "Upload successful: eff7_full_3.h5 (734MB)\n",
      "Starting upload for file eff7_full_2.h5\n",
      "100%|█████████████████████████████████████████| 734M/734M [19:09<00:00, 670kB/s]\n",
      "Upload successful: eff7_full_2.h5 (734MB)\n",
      "Starting upload for file eff7_full_5.h5\n",
      "100%|█████████████████████████████████████████| 734M/734M [18:56<00:00, 678kB/s]\n",
      "Upload successful: eff7_full_5.h5 (734MB)\n",
      "Skipping folder: .ipynb_checkpoints; use '--dir-mode' to upload folders\n",
      "Your private Dataset is being created. Please check progress at https://www.kaggle.com/nataliayurasova/Eff7FullImg\n"
     ]
    }
   ],
   "source": [
    "! kaggle datasets create -p /app/_data/models/final/eff7_full/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.891\n",
    "MODEL_BB_PATH= '../input/model-bb-1/bond_box_999_200.h5'\n",
    "MODEL_PATH = '../input/0865fulltrain/'\n",
    "IMAGE_SIZE = (380, 380)\n",
    "DF_PART = '../input/df-kf-plant/df_kf.csv'\n",
    "PATH = \"/kaggle/input/plant-pathology-2021-fgvc8/\"\n",
    "TRAIN_IMG_PATH = PATH+'train_images/'\n",
    "TEST_IMG_PATH = PATH+'test_images/'\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES=6\n",
    "SEED = 1488\n",
    "- replace ''-'scab'\n",
    "https://www.kaggle.com/nataliayurasova/plant-pathology0891/edit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: albumentations in /usr/local/lib/python3.8/dist-packages (0.5.2)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from albumentations) (5.3.1)\n",
      "Requirement already satisfied: imgaug>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from albumentations) (0.4.0)\n",
      "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.8/dist-packages (from albumentations) (4.5.1.48)\n",
      "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.8/dist-packages (from albumentations) (1.17.3)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from albumentations) (1.4.1)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.8/dist-packages (from albumentations) (0.18.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from imgaug>=0.4.0->albumentations) (1.15.0)\n",
      "Requirement already satisfied: imageio in /usr/local/lib/python3.8/dist-packages (from imgaug>=0.4.0->albumentations) (2.9.0)\n",
      "Requirement already satisfied: Shapely in /usr/local/lib/python3.8/dist-packages (from imgaug>=0.4.0->albumentations) (1.7.1)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from imgaug>=0.4.0->albumentations) (8.1.2)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (from imgaug>=0.4.0->albumentations) (4.5.1.48)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from imgaug>=0.4.0->albumentations) (3.3.4)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.16.1->albumentations) (1.1.1)\n",
      "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.16.1->albumentations) (2.5.1)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.16.1->albumentations) (2021.4.8)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations) (1.3.1)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.8/dist-packages (from networkx>=2.0->scikit-image>=0.16.1->albumentations) (4.4.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install albumentations\n",
    "import albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import (\n",
    "    StratifiedKFold,\n",
    "    StratifiedShuffleSplit,\n",
    "    train_test_split,\n",
    ")\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB4, EfficientNetB7\n",
    "from tensorflow.keras.layers import (\n",
    "    AveragePooling2D,\n",
    "    AvgPool2D,\n",
    "    Conv2D,\n",
    "    Dense,\n",
    "    Flatten,\n",
    "    GlobalAveragePooling2D,\n",
    "    MaxPooling2D,\n",
    ")\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tqdm import notebook, tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/app/_data/\"\n",
    "BATCH_SIZE = 8\n",
    "SEED = 42\n",
    "IMAGE_SIZE = 600\n",
    "NUM_CLASSES = 6\n",
    "TRAIN_IMG_PATH = \"/app/_data/600_full_npy/\"\n",
    "TEST_IMG_PATH = \"/app/_data/test_images/\"\n",
    "feature_columns = [\n",
    "    \"complex\",\n",
    "    \"frog_eye_leaf_spot\",\n",
    "    \"healthy\",\n",
    "    \"powdery_mildew\",\n",
    "    \"rust\",\n",
    "    \"scab\",\n",
    "]\n",
    "wrong = ['ead085dfac287263.jpg', '95276ccd226ad933.jpg',\"da8770e819d2696d.jpg\", 'cd3a1d64e6806eb5.jpg', 'ccec54723ff91860.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f8228796cfdae848.npy'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(TRAIN_IMG_PATH)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 600, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.load(TRAIN_IMG_PATH+os.listdir(TRAIN_IMG_PATH)[0])\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = pd.read_csv(\"../_data/df_csv/labels_21_20.csv\", index_col=[0])\n",
    "df_labels = df_labels.query('image not in @wrong').reset_index(drop=True)\n",
    "df_labels[\"image\"] = df_labels[\"image\"].str.replace(\".jpg\", \".npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = df_labels.sample(frac=1, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20225, 8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complex</th>\n",
       "      <th>frog_eye_leaf_spot</th>\n",
       "      <th>healthy</th>\n",
       "      <th>powdery_mildew</th>\n",
       "      <th>rust</th>\n",
       "      <th>scab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20225.000000</td>\n",
       "      <td>20225.000000</td>\n",
       "      <td>20225.000000</td>\n",
       "      <td>20225.000000</td>\n",
       "      <td>20225.000000</td>\n",
       "      <td>20225.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.104821</td>\n",
       "      <td>0.214487</td>\n",
       "      <td>0.253103</td>\n",
       "      <td>0.062645</td>\n",
       "      <td>0.130680</td>\n",
       "      <td>0.310556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.306330</td>\n",
       "      <td>0.410476</td>\n",
       "      <td>0.434800</td>\n",
       "      <td>0.242330</td>\n",
       "      <td>0.337058</td>\n",
       "      <td>0.462733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            complex  frog_eye_leaf_spot       healthy  powdery_mildew  \\\n",
       "count  20225.000000        20225.000000  20225.000000    20225.000000   \n",
       "mean       0.104821            0.214487      0.253103        0.062645   \n",
       "std        0.306330            0.410476      0.434800        0.242330   \n",
       "min        0.000000            0.000000      0.000000        0.000000   \n",
       "25%        0.000000            0.000000      0.000000        0.000000   \n",
       "50%        0.000000            0.000000      0.000000        0.000000   \n",
       "75%        0.000000            0.000000      1.000000        0.000000   \n",
       "max        1.000000            1.000000      1.000000        1.000000   \n",
       "\n",
       "               rust          scab  \n",
       "count  20225.000000  20225.000000  \n",
       "mean       0.130680      0.310556  \n",
       "std        0.337058      0.462733  \n",
       "min        0.000000      0.000000  \n",
       "25%        0.000000      0.000000  \n",
       "50%        0.000000      0.000000  \n",
       "75%        0.000000      1.000000  \n",
       "max        1.000000      1.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels[feature_columns].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 380*380\n",
    "transform = albumentations.Compose(\n",
    "    [\n",
    "        albumentations.CLAHE(p=0.1, clip_limit=(1, 2), tile_grid_size=(8, 8)),\n",
    "        albumentations.OneOf(\n",
    "            [\n",
    "                albumentations.MotionBlur((3, 3)),\n",
    "                albumentations.MedianBlur(blur_limit=3),\n",
    "                albumentations.GaussianBlur(blur_limit=(3, 3), sigma_limit=0),\n",
    "                albumentations.Blur(blur_limit=(3, 3)),\n",
    "            ],\n",
    "            p=0.2,\n",
    "        ),\n",
    "        albumentations.OneOf(\n",
    "            [\n",
    "                albumentations.GaussNoise(var_limit=[10, 50], mean=1),\n",
    "                albumentations.ISONoise(intensity=(0.1, 1), color_shift=(0.01, 0.05)),\n",
    "                albumentations.ImageCompression(\n",
    "                    quality_lower=70, quality_upper=100, compression_type=1\n",
    "                ),\n",
    "                albumentations.MultiplicativeNoise(\n",
    "                    multiplier=(0.95, 1.05), per_channel=True, elementwise=True\n",
    "                ),\n",
    "                albumentations.Downscale(\n",
    "                    scale_min=0.6, scale_max=0.99, interpolation=4\n",
    "                ),\n",
    "            ],\n",
    "            p=0.5,\n",
    "        ),\n",
    "        albumentations.OneOf(\n",
    "            [\n",
    "                albumentations.HueSaturationValue(\n",
    "                    hue_shift_limit=(-7, 7),\n",
    "                    sat_shift_limit=(-10, 10),\n",
    "                    val_shift_limit=(-10, 10),\n",
    "                ),\n",
    "                albumentations.RandomBrightnessContrast(\n",
    "                    brightness_limit=0.15,\n",
    "                    contrast_limit=0.2,\n",
    "                    brightness_by_max=True,\n",
    "                ),\n",
    "            ],\n",
    "            p=0.5,\n",
    "        ),\n",
    "        albumentations.OneOf(\n",
    "            [\n",
    "                albumentations.OpticalDistortion(\n",
    "                    distort_limit=0.05,\n",
    "                    shift_limit=0.05,\n",
    "                    border_mode=2,\n",
    "                ),\n",
    "                albumentations.ElasticTransform(\n",
    "                    alpha=2.0,\n",
    "                    sigma=50.0,\n",
    "                    alpha_affine=10.0,\n",
    "                    interpolation=0,\n",
    "                    border_mode=2,\n",
    "                ),\n",
    "                albumentations.GridDistortion(\n",
    "                    num_steps=5, distort_limit=0.3, interpolation=0, border_mode=2\n",
    "                ),\n",
    "            ],\n",
    "            p=0.5,\n",
    "        ),\n",
    "        albumentations.OneOf(\n",
    "            [\n",
    "                albumentations.HorizontalFlip(),\n",
    "                albumentations.VerticalFlip(),\n",
    "            ],\n",
    "            p=0.5,\n",
    "        ),\n",
    "        albumentations.OneOf(\n",
    "            [\n",
    "                albumentations.Rotate(\n",
    "                    limit=(-180, 180), interpolation=0, border_mode=2\n",
    "                ),\n",
    "                albumentations.ShiftScaleRotate(\n",
    "                    shift_limit=0.05,\n",
    "                    scale_limit=0.05,\n",
    "                    rotate_limit=180,\n",
    "                    interpolation=0,\n",
    "                    border_mode=2,\n",
    "                ),\n",
    "            ],\n",
    "            p=0.5,\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(keras.utils.Sequence):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        images_src_dir,\n",
    "        batch_size,\n",
    "        target_image_size,\n",
    "        shuffle=False,\n",
    "        augment=True,\n",
    "        crop=False,\n",
    "        resize=False,\n",
    "        normalize=False,\n",
    "    ):\n",
    "        self.shuffle = shuffle\n",
    "        self.batch_size = BATCH_SIZE\n",
    "        self.df = df\n",
    "        self.images_dir = images_src_dir\n",
    "        self.target_image_size = (IMAGE_SIZE, IMAGE_SIZE)\n",
    "        self.augment = augment\n",
    "        self.crop = crop\n",
    "        self.resize = resize\n",
    "        self.normalize = normalize\n",
    "        # create label index map\n",
    "        self.labels = self._read_labels()\n",
    "        self.n_samples = self.df.shape[0]\n",
    "        self.n_batches = self.n_samples // self.batch_size\n",
    "        # shuffle data, also repeated after each epoch if needed\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.labels)\n",
    "\n",
    "    def _read_labels(self):\n",
    "        \"\"\"\n",
    "        Returns list images mapping to 1-hot label\n",
    "        \"\"\"\n",
    "\n",
    "        # label indexes\n",
    "        label_ixs = self.df[feature_columns].values\n",
    "        image_ixs = self.df[\"image\"].values\n",
    "        labels = []\n",
    "\n",
    "        for i in range(len(image_ixs)):\n",
    "            labels.append([image_ixs[i], label_ixs[i]])\n",
    "        return labels\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Length in batches\n",
    "        \"\"\"\n",
    "        return self.n_batches\n",
    "\n",
    "    def __getitem__(self, b_ix):\n",
    "        \"\"\"\n",
    "        Produce batch, by batch index\n",
    "        \"\"\"\n",
    "\n",
    "        assert b_ix < self.n_batches\n",
    "\n",
    "        b_X = np.zeros(\n",
    "            (self.batch_size, self.target_image_size[0], self.target_image_size[1], 3),\n",
    "            dtype=np.uint8,\n",
    "        )\n",
    "\n",
    "        b_Y = np.zeros(\n",
    "            (self.batch_size, self.df[feature_columns].shape[1]),\n",
    "            dtype=np.uint8,\n",
    "        )\n",
    "\n",
    "        for i in range(self.batch_size):\n",
    "            b_X[i], b_Y[i] = self.get_one(\n",
    "                i + self.batch_size * b_ix,\n",
    "            )\n",
    "\n",
    "        return (b_X, b_Y)\n",
    "\n",
    "    def get_one(self, one_ix):\n",
    "        \"\"\"\n",
    "        Get single item by absolute index\n",
    "        \"\"\"\n",
    "        id = self.labels[one_ix][0]\n",
    "        src_file = self.images_dir + id\n",
    "\n",
    "        # read file\n",
    "        x = np.load(src_file)\n",
    "        if self.crop:\n",
    "            coord = self.df[self.df[\"image\"] == id][\n",
    "                [\"x_min\", \"y_min\", \"x_max\", \"y_max\"]\n",
    "            ].values[0]\n",
    "            orig_hight = x.shape[0]\n",
    "            orig_width = x.shape[1]\n",
    "            x_min = coord[0]\n",
    "            y_min = coord[1]\n",
    "            x_max = coord[2]\n",
    "            y_max = coord[3]\n",
    "            x = x[\n",
    "                np.int(y_min * orig_hight) : np.int(y_max * orig_hight),\n",
    "                np.int(x_min * orig_width) : np.int(x_max * orig_width),\n",
    "            ]\n",
    "\n",
    "        y = self.labels[one_ix][1]\n",
    "\n",
    "        # augment\n",
    "        if self.augment:\n",
    "            x = self._augment_image(x)\n",
    "\n",
    "        # normalize (sample-wise)\n",
    "        if self.normalize:\n",
    "            x = x.astype(np.float32)\n",
    "            x = x - np.mean(x, axis=(0, 1))\n",
    "            x = x / np.std(x, axis=(0, 1))\n",
    "        return x.astype(np.uint8), y\n",
    "\n",
    "    def _augment_image(self, x):\n",
    "        \"\"\"\n",
    "        Randomply augment image\n",
    "        \"\"\"\n",
    "\n",
    "        x = transform(image=x)[\"image\"]\n",
    "        return x\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3090, compute capability 8.6\n"
     ]
    }
   ],
   "source": [
    "policy = keras.mixed_precision.experimental.Policy(\"mixed_float16\")\n",
    "keras.mixed_precision.experimental.set_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    inputs = keras.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "    base_model = keras.applications.EfficientNetB7(weights=None, include_top=False)\n",
    "    base_model.load_weights(\n",
    "        \"/app/_data/models/efficientnet-b7_noisy-student_notop.h5\",\n",
    "        by_name=True,\n",
    "        skip_mismatch=True,\n",
    "    )\n",
    "    x = base_model(inputs)\n",
    "    x = keras.layers.GlobalAveragePooling2D(name=\"avg_pool\")(x)\n",
    "    x = keras.layers.Flatten(name=\"flatten\")(x)\n",
    "    outputs = keras.layers.Dense(NUM_CLASSES, activation=\"sigmoid\")(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=Adam(lr=0.0005),\n",
    "        metrics=[\n",
    "            \"acc\",\n",
    "            keras.metrics.Recall(),\n",
    "            keras.metrics.Precision(),\n",
    "            tfa.metrics.F1Score(num_classes=NUM_CLASSES, average=\"weighted\"),\n",
    "        ],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100\n",
      "   1/2696 [..............................] - ETA: 0s - loss: 0.1174 - acc: 1.0000 - recall: 0.7500 - precision: 1.0000 - f1_score: 0.7500WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "   2/2696 [..............................] - ETA: 1:28:33 - loss: 0.1021 - acc: 1.0000 - recall: 0.8000 - precision: 1.0000 - f1_score: 0.8600WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 1.3069s vs `on_train_batch_end` time: 2.6361s). Check your callbacks.\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0710 - acc: 0.9203 - recall: 0.9117 - precision: 0.9280 - f1_score: 0.9104\n",
      "Epoch 00019: val_f1_score improved from -inf to 0.89180, saving model to /app/_data/models/final/eff7_full/eff7_full_3.h5\n",
      "2696/2696 [==============================] - 1199s 445ms/step - loss: 0.0710 - acc: 0.9203 - recall: 0.9117 - precision: 0.9280 - f1_score: 0.9104 - val_loss: 0.1053 - val_acc: 0.9167 - val_recall: 0.8913 - val_precision: 0.9009 - val_f1_score: 0.8918\n",
      "Epoch 20/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0692 - acc: 0.9225 - recall: 0.9144 - precision: 0.9321 - f1_score: 0.9116\n",
      "Epoch 00020: val_f1_score improved from 0.89180 to 0.90553, saving model to /app/_data/models/final/eff7_full/eff7_full_3.h5\n",
      "2696/2696 [==============================] - 1212s 449ms/step - loss: 0.0692 - acc: 0.9225 - recall: 0.9144 - precision: 0.9321 - f1_score: 0.9116 - val_loss: 0.0757 - val_acc: 0.9184 - val_recall: 0.9116 - val_precision: 0.9293 - val_f1_score: 0.9055\n",
      "Epoch 21/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0671 - acc: 0.9207 - recall: 0.9145 - precision: 0.9315 - f1_score: 0.9107\n",
      "Epoch 00021: val_f1_score did not improve from 0.90553\n",
      "2696/2696 [==============================] - 1215s 451ms/step - loss: 0.0671 - acc: 0.9207 - recall: 0.9145 - precision: 0.9315 - f1_score: 0.9107 - val_loss: 0.0810 - val_acc: 0.9132 - val_recall: 0.9032 - val_precision: 0.9202 - val_f1_score: 0.9005\n",
      "Epoch 22/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0664 - acc: 0.9243 - recall: 0.9162 - precision: 0.9319 - f1_score: 0.9129\n",
      "Epoch 00022: val_f1_score did not improve from 0.90553\n",
      "2696/2696 [==============================] - 1212s 450ms/step - loss: 0.0664 - acc: 0.9243 - recall: 0.9162 - precision: 0.9319 - f1_score: 0.9129 - val_loss: 0.1855 - val_acc: 0.9048 - val_recall: 0.8864 - val_precision: 0.8879 - val_f1_score: 0.8829\n",
      "Epoch 23/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0656 - acc: 0.9235 - recall: 0.9180 - precision: 0.9309 - f1_score: 0.9124\n",
      "Epoch 00023: val_f1_score improved from 0.90553 to 0.90654, saving model to /app/_data/models/final/eff7_full/eff7_full_3.h5\n",
      "2696/2696 [==============================] - 1231s 457ms/step - loss: 0.0656 - acc: 0.9235 - recall: 0.9180 - precision: 0.9309 - f1_score: 0.9124 - val_loss: 0.0737 - val_acc: 0.9256 - val_recall: 0.9146 - val_precision: 0.9224 - val_f1_score: 0.9065\n",
      "Epoch 24/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0643 - acc: 0.9260 - recall: 0.9220 - precision: 0.9341 - f1_score: 0.9159\n",
      "Epoch 00024: val_f1_score did not improve from 0.90654\n",
      "2696/2696 [==============================] - 1215s 451ms/step - loss: 0.0643 - acc: 0.9260 - recall: 0.9220 - precision: 0.9341 - f1_score: 0.9159 - val_loss: 0.0831 - val_acc: 0.9008 - val_recall: 0.9352 - val_precision: 0.8829 - val_f1_score: 0.8932\n",
      "Epoch 25/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0632 - acc: 0.9247 - recall: 0.9209 - precision: 0.9326 - f1_score: 0.9151\n",
      "Epoch 00025: val_f1_score did not improve from 0.90654\n",
      "2696/2696 [==============================] - 1226s 455ms/step - loss: 0.0632 - acc: 0.9247 - recall: 0.9209 - precision: 0.9326 - f1_score: 0.9151 - val_loss: 0.0809 - val_acc: 0.9214 - val_recall: 0.9151 - val_precision: 0.9142 - val_f1_score: 0.9039\n",
      "Epoch 26/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0619 - acc: 0.9259 - recall: 0.9235 - precision: 0.9353 - f1_score: 0.9175\n",
      "Epoch 00026: val_f1_score did not improve from 0.90654\n",
      "2696/2696 [==============================] - 1214s 450ms/step - loss: 0.0619 - acc: 0.9259 - recall: 0.9235 - precision: 0.9353 - f1_score: 0.9175 - val_loss: 0.0847 - val_acc: 0.9186 - val_recall: 0.9192 - val_precision: 0.9167 - val_f1_score: 0.9033\n",
      "Epoch 27/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0599 - acc: 0.9293 - recall: 0.9246 - precision: 0.9374 - f1_score: 0.9190\n",
      "Epoch 00027: val_f1_score did not improve from 0.90654\n",
      "2696/2696 [==============================] - 1224s 454ms/step - loss: 0.0599 - acc: 0.9293 - recall: 0.9246 - precision: 0.9374 - f1_score: 0.9190 - val_loss: 0.0908 - val_acc: 0.9088 - val_recall: 0.9107 - val_precision: 0.9068 - val_f1_score: 0.8961\n",
      "Epoch 28/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0597 - acc: 0.9284 - recall: 0.9261 - precision: 0.9370 - f1_score: 0.9186\n",
      "Epoch 00028: val_f1_score did not improve from 0.90654\n",
      "2696/2696 [==============================] - 1234s 458ms/step - loss: 0.0597 - acc: 0.9284 - recall: 0.9261 - precision: 0.9370 - f1_score: 0.9186 - val_loss: 0.0766 - val_acc: 0.9231 - val_recall: 0.9251 - val_precision: 0.9128 - val_f1_score: 0.9057\n",
      "Epoch 29/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0570 - acc: 0.9305 - recall: 0.9296 - precision: 0.9421 - f1_score: 0.9223\n",
      "Epoch 00029: val_f1_score did not improve from 0.90654\n",
      "2696/2696 [==============================] - 1206s 447ms/step - loss: 0.0570 - acc: 0.9305 - recall: 0.9296 - precision: 0.9421 - f1_score: 0.9223 - val_loss: 0.0750 - val_acc: 0.9238 - val_recall: 0.9155 - val_precision: 0.9219 - val_f1_score: 0.9052\n",
      "Epoch 30/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0561 - acc: 0.9305 - recall: 0.9306 - precision: 0.9420 - f1_score: 0.9216\n",
      "Epoch 00030: val_f1_score did not improve from 0.90654\n",
      "2696/2696 [==============================] - 1211s 449ms/step - loss: 0.0561 - acc: 0.9305 - recall: 0.9306 - precision: 0.9420 - f1_score: 0.9216 - val_loss: 0.0922 - val_acc: 0.9149 - val_recall: 0.9254 - val_precision: 0.8998 - val_f1_score: 0.8965\n",
      "Epoch 31/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0572 - acc: 0.9308 - recall: 0.9281 - precision: 0.9416 - f1_score: 0.9221\n",
      "Epoch 00031: val_f1_score did not improve from 0.90654\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0004500000213738531.\n",
      "2696/2696 [==============================] - 1233s 457ms/step - loss: 0.0572 - acc: 0.9308 - recall: 0.9281 - precision: 0.9416 - f1_score: 0.9221 - val_loss: 0.0861 - val_acc: 0.9095 - val_recall: 0.9160 - val_precision: 0.9099 - val_f1_score: 0.8981\n",
      "Epoch 32/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0535 - acc: 0.9356 - recall: 0.9349 - precision: 0.9442 - f1_score: 0.9258\n",
      "Epoch 00032: val_f1_score did not improve from 0.90654\n",
      "2696/2696 [==============================] - 1218s 452ms/step - loss: 0.0535 - acc: 0.9356 - recall: 0.9349 - precision: 0.9442 - f1_score: 0.9258 - val_loss: 0.0920 - val_acc: 0.9169 - val_recall: 0.9048 - val_precision: 0.9077 - val_f1_score: 0.8969\n",
      "Epoch 33/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0511 - acc: 0.9366 - recall: 0.9362 - precision: 0.9472 - f1_score: 0.9272\n",
      "Epoch 00033: val_f1_score improved from 0.90654 to 0.90758, saving model to /app/_data/models/final/eff7_full/eff7_full_3.h5\n",
      "2696/2696 [==============================] - 1212s 450ms/step - loss: 0.0511 - acc: 0.9366 - recall: 0.9362 - precision: 0.9472 - f1_score: 0.9272 - val_loss: 0.0814 - val_acc: 0.9236 - val_recall: 0.9245 - val_precision: 0.9163 - val_f1_score: 0.9076\n",
      "Epoch 34/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0505 - acc: 0.9363 - recall: 0.9385 - precision: 0.9477 - f1_score: 0.9281\n",
      "Epoch 00034: val_f1_score did not improve from 0.90758\n",
      "2696/2696 [==============================] - 1210s 449ms/step - loss: 0.0505 - acc: 0.9363 - recall: 0.9385 - precision: 0.9477 - f1_score: 0.9281 - val_loss: 0.0903 - val_acc: 0.9177 - val_recall: 0.9242 - val_precision: 0.8995 - val_f1_score: 0.9021\n",
      "Epoch 35/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0493 - acc: 0.9364 - recall: 0.9396 - precision: 0.9470 - f1_score: 0.9286\n",
      "Epoch 00035: val_f1_score improved from 0.90758 to 0.90962, saving model to /app/_data/models/final/eff7_full/eff7_full_3.h5\n",
      "2696/2696 [==============================] - 1215s 451ms/step - loss: 0.0493 - acc: 0.9364 - recall: 0.9396 - precision: 0.9470 - f1_score: 0.9286 - val_loss: 0.0854 - val_acc: 0.9303 - val_recall: 0.9160 - val_precision: 0.9285 - val_f1_score: 0.9096\n",
      "Epoch 36/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0473 - acc: 0.9403 - recall: 0.9428 - precision: 0.9516 - f1_score: 0.9311\n",
      "Epoch 00036: val_f1_score did not improve from 0.90962\n",
      "2696/2696 [==============================] - 1217s 451ms/step - loss: 0.0473 - acc: 0.9403 - recall: 0.9428 - precision: 0.9516 - f1_score: 0.9311 - val_loss: 0.0936 - val_acc: 0.9253 - val_recall: 0.9057 - val_precision: 0.9217 - val_f1_score: 0.9051\n",
      "Epoch 37/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0466 - acc: 0.9397 - recall: 0.9427 - precision: 0.9507 - f1_score: 0.9300\n",
      "Epoch 00037: val_f1_score did not improve from 0.90962\n",
      "2696/2696 [==============================] - 1230s 456ms/step - loss: 0.0466 - acc: 0.9397 - recall: 0.9427 - precision: 0.9507 - f1_score: 0.9300 - val_loss: 0.0870 - val_acc: 0.9191 - val_recall: 0.9084 - val_precision: 0.9213 - val_f1_score: 0.9029\n",
      "Epoch 38/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0454 - acc: 0.9382 - recall: 0.9454 - precision: 0.9504 - f1_score: 0.9311\n",
      "Epoch 00038: val_f1_score did not improve from 0.90962\n",
      "2696/2696 [==============================] - 1213s 450ms/step - loss: 0.0454 - acc: 0.9382 - recall: 0.9454 - precision: 0.9504 - f1_score: 0.9311 - val_loss: 0.0909 - val_acc: 0.9149 - val_recall: 0.9130 - val_precision: 0.9208 - val_f1_score: 0.9008\n",
      "Epoch 39/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0450 - acc: 0.9407 - recall: 0.9457 - precision: 0.9530 - f1_score: 0.9331\n",
      "Epoch 00039: val_f1_score did not improve from 0.90962\n",
      "2696/2696 [==============================] - 1203s 446ms/step - loss: 0.0450 - acc: 0.9407 - recall: 0.9457 - precision: 0.9530 - f1_score: 0.9331 - val_loss: 0.0834 - val_acc: 0.9194 - val_recall: 0.9146 - val_precision: 0.9186 - val_f1_score: 0.9056\n",
      "Epoch 40/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0435 - acc: 0.9400 - recall: 0.9462 - precision: 0.9547 - f1_score: 0.9335\n",
      "Epoch 00040: val_f1_score did not improve from 0.90962\n",
      "2696/2696 [==============================] - 1209s 449ms/step - loss: 0.0435 - acc: 0.9400 - recall: 0.9462 - precision: 0.9547 - f1_score: 0.9335 - val_loss: 0.0948 - val_acc: 0.9214 - val_recall: 0.9212 - val_precision: 0.9204 - val_f1_score: 0.9080\n",
      "Epoch 41/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0433 - acc: 0.9402 - recall: 0.9469 - precision: 0.9558 - f1_score: 0.9347\n",
      "Epoch 00041: val_f1_score did not improve from 0.90962\n",
      "2696/2696 [==============================] - 1199s 445ms/step - loss: 0.0433 - acc: 0.9402 - recall: 0.9469 - precision: 0.9558 - f1_score: 0.9347 - val_loss: 0.0873 - val_acc: 0.9169 - val_recall: 0.9224 - val_precision: 0.9144 - val_f1_score: 0.9030\n",
      "Epoch 42/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0440 - acc: 0.9432 - recall: 0.9465 - precision: 0.9552 - f1_score: 0.9348\n",
      "Epoch 00042: val_f1_score did not improve from 0.90962\n",
      "2696/2696 [==============================] - 1192s 442ms/step - loss: 0.0440 - acc: 0.9432 - recall: 0.9465 - precision: 0.9552 - f1_score: 0.9348 - val_loss: 0.0959 - val_acc: 0.9097 - val_recall: 0.9137 - val_precision: 0.9143 - val_f1_score: 0.9010\n",
      "Epoch 43/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0402 - acc: 0.9468 - recall: 0.9500 - precision: 0.9594 - f1_score: 0.9377\n",
      "Epoch 00043: val_f1_score did not improve from 0.90962\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.0004050000192364678.\n",
      "2696/2696 [==============================] - 1215s 451ms/step - loss: 0.0402 - acc: 0.9468 - recall: 0.9500 - precision: 0.9594 - f1_score: 0.9377 - val_loss: 0.0878 - val_acc: 0.9090 - val_recall: 0.9185 - val_precision: 0.9020 - val_f1_score: 0.8972\n",
      "Epoch 44/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0401 - acc: 0.9448 - recall: 0.9517 - precision: 0.9590 - f1_score: 0.9364\n",
      "Epoch 00044: val_f1_score did not improve from 0.90962\n",
      "2696/2696 [==============================] - 1217s 451ms/step - loss: 0.0401 - acc: 0.9448 - recall: 0.9517 - precision: 0.9590 - f1_score: 0.9364 - val_loss: 0.0961 - val_acc: 0.9196 - val_recall: 0.9082 - val_precision: 0.9143 - val_f1_score: 0.9017\n",
      "Epoch 45/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0381 - acc: 0.9447 - recall: 0.9550 - precision: 0.9612 - f1_score: 0.9383\n",
      "Epoch 00045: val_f1_score did not improve from 0.90962\n",
      "2696/2696 [==============================] - 1224s 454ms/step - loss: 0.0381 - acc: 0.9447 - recall: 0.9550 - precision: 0.9612 - f1_score: 0.9383 - val_loss: 0.0991 - val_acc: 0.9139 - val_recall: 0.9210 - val_precision: 0.9170 - val_f1_score: 0.9026\n",
      "Epoch 46/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0360 - acc: 0.9465 - recall: 0.9592 - precision: 0.9630 - f1_score: 0.9403Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00046: val_f1_score did not improve from 0.90962\n",
      "2696/2696 [==============================] - 1228s 456ms/step - loss: 0.0360 - acc: 0.9465 - recall: 0.9592 - precision: 0.9630 - f1_score: 0.9403 - val_loss: 0.1105 - val_acc: 0.9154 - val_recall: 0.9151 - val_precision: 0.9184 - val_f1_score: 0.9052\n",
      "Epoch 00046: early stopping\n",
      "Epoch 1/100\n",
      "   2/2696 [..............................] - ETA: 1:56:15 - loss: 0.6824 - acc: 0.1667 - recall: 0.2500 - precision: 0.0968 - f1_score: 0.1556WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4373s vs `on_train_batch_end` time: 4.7408s). Check your callbacks.\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.1805 - acc: 0.8043 - recall: 0.7562 - precision: 0.8396 - f1_score: 0.7918\n",
      "Epoch 00001: val_f1_score improved from -inf to 0.88125, saving model to /app/_data/models/final/eff7_full/eff7_full_4.h5\n",
      "2696/2696 [==============================] - 1219s 452ms/step - loss: 0.1805 - acc: 0.8043 - recall: 0.7562 - precision: 0.8396 - f1_score: 0.7918 - val_loss: 0.1118 - val_acc: 0.8954 - val_recall: 0.8713 - val_precision: 0.8968 - val_f1_score: 0.8812\n",
      "Epoch 2/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.1329 - acc: 0.8546 - recall: 0.8251 - precision: 0.8754 - f1_score: 0.8422\n",
      "Epoch 00002: val_f1_score did not improve from 0.88125\n",
      "2696/2696 [==============================] - 1207s 448ms/step - loss: 0.1329 - acc: 0.8546 - recall: 0.8251 - precision: 0.8754 - f1_score: 0.8422 - val_loss: 0.1088 - val_acc: 0.8840 - val_recall: 0.8685 - val_precision: 0.8985 - val_f1_score: 0.8786\n",
      "Epoch 3/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.1165 - acc: 0.8728 - recall: 0.8513 - precision: 0.8890 - f1_score: 0.8600\n",
      "Epoch 00003: val_f1_score improved from 0.88125 to 0.88511, saving model to /app/_data/models/final/eff7_full/eff7_full_4.h5\n",
      "2696/2696 [==============================] - 1226s 455ms/step - loss: 0.1165 - acc: 0.8728 - recall: 0.8513 - precision: 0.8890 - f1_score: 0.8600 - val_loss: 0.1013 - val_acc: 0.9033 - val_recall: 0.8715 - val_precision: 0.9061 - val_f1_score: 0.8851\n",
      "Epoch 4/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.1096 - acc: 0.8831 - recall: 0.8577 - precision: 0.8933 - f1_score: 0.8700\n",
      "Epoch 00004: val_f1_score did not improve from 0.88511\n",
      "2696/2696 [==============================] - 1210s 449ms/step - loss: 0.1096 - acc: 0.8831 - recall: 0.8577 - precision: 0.8933 - f1_score: 0.8700 - val_loss: 0.4209 - val_acc: 0.8408 - val_recall: 0.8616 - val_precision: 0.7843 - val_f1_score: 0.8301\n",
      "Epoch 5/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.1045 - acc: 0.8846 - recall: 0.8647 - precision: 0.8967 - f1_score: 0.8729\n",
      "Epoch 00005: val_f1_score did not improve from 0.88511\n",
      "2696/2696 [==============================] - 1212s 449ms/step - loss: 0.1045 - acc: 0.8846 - recall: 0.8647 - precision: 0.8967 - f1_score: 0.8729 - val_loss: 0.1738 - val_acc: 0.8623 - val_recall: 0.8439 - val_precision: 0.8965 - val_f1_score: 0.8571\n",
      "Epoch 6/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0996 - acc: 0.8909 - recall: 0.8712 - precision: 0.9001 - f1_score: 0.8786\n",
      "Epoch 00006: val_f1_score improved from 0.88511 to 0.90056, saving model to /app/_data/models/final/eff7_full/eff7_full_4.h5\n",
      "2696/2696 [==============================] - 1216s 451ms/step - loss: 0.0996 - acc: 0.8909 - recall: 0.8712 - precision: 0.9001 - f1_score: 0.8786 - val_loss: 0.0859 - val_acc: 0.9132 - val_recall: 0.9046 - val_precision: 0.9102 - val_f1_score: 0.9006\n",
      "Epoch 7/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0939 - acc: 0.8960 - recall: 0.8794 - precision: 0.9073 - f1_score: 0.8842\n",
      "Epoch 00007: val_f1_score did not improve from 0.90056\n",
      "2696/2696 [==============================] - 1217s 451ms/step - loss: 0.0939 - acc: 0.8960 - recall: 0.8794 - precision: 0.9073 - f1_score: 0.8842 - val_loss: 0.1097 - val_acc: 0.8932 - val_recall: 0.8768 - val_precision: 0.9029 - val_f1_score: 0.8818\n",
      "Epoch 8/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0918 - acc: 0.9010 - recall: 0.8839 - precision: 0.9094 - f1_score: 0.8886\n",
      "Epoch 00008: val_f1_score did not improve from 0.90056\n",
      "2696/2696 [==============================] - 1219s 452ms/step - loss: 0.0918 - acc: 0.9010 - recall: 0.8839 - precision: 0.9094 - f1_score: 0.8886 - val_loss: 0.0944 - val_acc: 0.9048 - val_recall: 0.8821 - val_precision: 0.9151 - val_f1_score: 0.8930\n",
      "Epoch 9/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0872 - acc: 0.9025 - recall: 0.8889 - precision: 0.9117 - f1_score: 0.8908\n",
      "Epoch 00009: val_f1_score did not improve from 0.90056\n",
      "2696/2696 [==============================] - 1203s 446ms/step - loss: 0.0872 - acc: 0.9025 - recall: 0.8889 - precision: 0.9117 - f1_score: 0.8908 - val_loss: 0.0999 - val_acc: 0.9130 - val_recall: 0.8954 - val_precision: 0.9182 - val_f1_score: 0.8979\n",
      "Epoch 10/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0844 - acc: 0.9058 - recall: 0.8942 - precision: 0.9142 - f1_score: 0.8942\n",
      "Epoch 00010: val_f1_score did not improve from 0.90056\n",
      "2696/2696 [==============================] - 1210s 449ms/step - loss: 0.0844 - acc: 0.9058 - recall: 0.8942 - precision: 0.9142 - f1_score: 0.8942 - val_loss: 0.1204 - val_acc: 0.8971 - val_recall: 0.8623 - val_precision: 0.9023 - val_f1_score: 0.8798\n",
      "Epoch 11/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0816 - acc: 0.9107 - recall: 0.8977 - precision: 0.9180 - f1_score: 0.8989\n",
      "Epoch 00011: val_f1_score did not improve from 0.90056\n",
      "2696/2696 [==============================] - 1209s 448ms/step - loss: 0.0816 - acc: 0.9107 - recall: 0.8977 - precision: 0.9180 - f1_score: 0.8989 - val_loss: 0.1210 - val_acc: 0.8739 - val_recall: 0.8779 - val_precision: 0.8844 - val_f1_score: 0.8738\n",
      "Epoch 12/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0800 - acc: 0.9083 - recall: 0.8962 - precision: 0.9178 - f1_score: 0.8975\n",
      "Epoch 00012: val_f1_score did not improve from 0.90056\n",
      "2696/2696 [==============================] - 1201s 446ms/step - loss: 0.0800 - acc: 0.9083 - recall: 0.8962 - precision: 0.9178 - f1_score: 0.8975 - val_loss: 0.1355 - val_acc: 0.8974 - val_recall: 0.8782 - val_precision: 0.9016 - val_f1_score: 0.8835\n",
      "Epoch 13/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0788 - acc: 0.9112 - recall: 0.9016 - precision: 0.9182 - f1_score: 0.8992\n",
      "Epoch 00013: val_f1_score did not improve from 0.90056\n",
      "2696/2696 [==============================] - 1211s 449ms/step - loss: 0.0788 - acc: 0.9112 - recall: 0.9016 - precision: 0.9182 - f1_score: 0.8992 - val_loss: 0.1046 - val_acc: 0.9132 - val_recall: 0.9018 - val_precision: 0.9161 - val_f1_score: 0.8968\n",
      "Epoch 14/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0766 - acc: 0.9149 - recall: 0.9066 - precision: 0.9223 - f1_score: 0.9032\n",
      "Epoch 00014: val_f1_score improved from 0.90056 to 0.90103, saving model to /app/_data/models/final/eff7_full/eff7_full_4.h5\n",
      "2696/2696 [==============================] - 1206s 447ms/step - loss: 0.0766 - acc: 0.9149 - recall: 0.9066 - precision: 0.9223 - f1_score: 0.9032 - val_loss: 0.0842 - val_acc: 0.9174 - val_recall: 0.9007 - val_precision: 0.9133 - val_f1_score: 0.9010\n",
      "Epoch 15/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0750 - acc: 0.9158 - recall: 0.9054 - precision: 0.9232 - f1_score: 0.9031\n",
      "Epoch 00015: val_f1_score did not improve from 0.90103\n",
      "2696/2696 [==============================] - 1224s 454ms/step - loss: 0.0750 - acc: 0.9158 - recall: 0.9054 - precision: 0.9232 - f1_score: 0.9031 - val_loss: 0.1148 - val_acc: 0.8947 - val_recall: 0.8717 - val_precision: 0.8876 - val_f1_score: 0.8762\n",
      "Epoch 16/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0727 - acc: 0.9191 - recall: 0.9100 - precision: 0.9228 - f1_score: 0.9073\n",
      "Epoch 00016: val_f1_score did not improve from 0.90103\n",
      "2696/2696 [==============================] - 1221s 453ms/step - loss: 0.0727 - acc: 0.9191 - recall: 0.9100 - precision: 0.9228 - f1_score: 0.9073 - val_loss: 0.0933 - val_acc: 0.9120 - val_recall: 0.9198 - val_precision: 0.8987 - val_f1_score: 0.8946\n",
      "Epoch 17/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0728 - acc: 0.9169 - recall: 0.9087 - precision: 0.9221 - f1_score: 0.9056\n",
      "Epoch 00017: val_f1_score improved from 0.90103 to 0.90209, saving model to /app/_data/models/final/eff7_full/eff7_full_4.h5\n",
      "2696/2696 [==============================] - 1207s 448ms/step - loss: 0.0728 - acc: 0.9169 - recall: 0.9087 - precision: 0.9221 - f1_score: 0.9056 - val_loss: 0.0822 - val_acc: 0.9172 - val_recall: 0.9170 - val_precision: 0.9099 - val_f1_score: 0.9021\n",
      "Epoch 18/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0722 - acc: 0.9188 - recall: 0.9108 - precision: 0.9257 - f1_score: 0.9076\n",
      "Epoch 00018: val_f1_score did not improve from 0.90209\n",
      "2696/2696 [==============================] - 1212s 449ms/step - loss: 0.0722 - acc: 0.9188 - recall: 0.9108 - precision: 0.9257 - f1_score: 0.9076 - val_loss: 0.1177 - val_acc: 0.8986 - val_recall: 0.8885 - val_precision: 0.9058 - val_f1_score: 0.8912\n",
      "Epoch 19/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0700 - acc: 0.9187 - recall: 0.9133 - precision: 0.9279 - f1_score: 0.9086\n",
      "Epoch 00019: val_f1_score improved from 0.90209 to 0.91301, saving model to /app/_data/models/final/eff7_full/eff7_full_4.h5\n",
      "2696/2696 [==============================] - 1226s 455ms/step - loss: 0.0700 - acc: 0.9187 - recall: 0.9133 - precision: 0.9279 - f1_score: 0.9086 - val_loss: 0.0758 - val_acc: 0.9263 - val_recall: 0.9161 - val_precision: 0.9300 - val_f1_score: 0.9130\n",
      "Epoch 20/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0688 - acc: 0.9228 - recall: 0.9151 - precision: 0.9282 - f1_score: 0.9109\n",
      "Epoch 00020: val_f1_score improved from 0.91301 to 0.91332, saving model to /app/_data/models/final/eff7_full/eff7_full_4.h5\n",
      "2696/2696 [==============================] - 1220s 452ms/step - loss: 0.0688 - acc: 0.9228 - recall: 0.9151 - precision: 0.9282 - f1_score: 0.9109 - val_loss: 0.0729 - val_acc: 0.9293 - val_recall: 0.9175 - val_precision: 0.9271 - val_f1_score: 0.9133\n",
      "Epoch 21/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0674 - acc: 0.9233 - recall: 0.9175 - precision: 0.9308 - f1_score: 0.9117\n",
      "Epoch 00021: val_f1_score did not improve from 0.91332\n",
      "2696/2696 [==============================] - 1197s 444ms/step - loss: 0.0674 - acc: 0.9233 - recall: 0.9175 - precision: 0.9308 - f1_score: 0.9117 - val_loss: 0.0806 - val_acc: 0.9201 - val_recall: 0.9062 - val_precision: 0.9269 - val_f1_score: 0.9055\n",
      "Epoch 22/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0647 - acc: 0.9250 - recall: 0.9189 - precision: 0.9345 - f1_score: 0.9142\n",
      "Epoch 00022: val_f1_score did not improve from 0.91332\n",
      "2696/2696 [==============================] - 1211s 449ms/step - loss: 0.0647 - acc: 0.9250 - recall: 0.9189 - precision: 0.9345 - f1_score: 0.9142 - val_loss: 0.0827 - val_acc: 0.9130 - val_recall: 0.9101 - val_precision: 0.9226 - val_f1_score: 0.9032\n",
      "Epoch 23/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0643 - acc: 0.9252 - recall: 0.9198 - precision: 0.9322 - f1_score: 0.9151\n",
      "Epoch 00023: val_f1_score did not improve from 0.91332\n",
      "2696/2696 [==============================] - 1206s 447ms/step - loss: 0.0643 - acc: 0.9252 - recall: 0.9198 - precision: 0.9322 - f1_score: 0.9151 - val_loss: 0.0893 - val_acc: 0.9169 - val_recall: 0.9186 - val_precision: 0.9119 - val_f1_score: 0.9041\n",
      "Epoch 24/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0646 - acc: 0.9240 - recall: 0.9201 - precision: 0.9334 - f1_score: 0.9145\n",
      "Epoch 00024: val_f1_score did not improve from 0.91332\n",
      "2696/2696 [==============================] - 1211s 449ms/step - loss: 0.0646 - acc: 0.9240 - recall: 0.9201 - precision: 0.9334 - f1_score: 0.9145 - val_loss: 0.0981 - val_acc: 0.9090 - val_recall: 0.9156 - val_precision: 0.8887 - val_f1_score: 0.8964\n",
      "Epoch 25/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0613 - acc: 0.9282 - recall: 0.9263 - precision: 0.9370 - f1_score: 0.9189\n",
      "Epoch 00025: val_f1_score did not improve from 0.91332\n",
      "2696/2696 [==============================] - 1205s 447ms/step - loss: 0.0613 - acc: 0.9282 - recall: 0.9263 - precision: 0.9370 - f1_score: 0.9189 - val_loss: 0.0875 - val_acc: 0.9127 - val_recall: 0.9193 - val_precision: 0.9149 - val_f1_score: 0.9085\n",
      "Epoch 26/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0616 - acc: 0.9277 - recall: 0.9233 - precision: 0.9379 - f1_score: 0.9171\n",
      "Epoch 00026: val_f1_score did not improve from 0.91332\n",
      "2696/2696 [==============================] - 1201s 445ms/step - loss: 0.0616 - acc: 0.9277 - recall: 0.9233 - precision: 0.9379 - f1_score: 0.9171 - val_loss: 0.0893 - val_acc: 0.9182 - val_recall: 0.9287 - val_precision: 0.9077 - val_f1_score: 0.9052\n",
      "Epoch 27/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0608 - acc: 0.9274 - recall: 0.9245 - precision: 0.9356 - f1_score: 0.9180\n",
      "Epoch 00027: val_f1_score did not improve from 0.91332\n",
      "2696/2696 [==============================] - 1215s 451ms/step - loss: 0.0608 - acc: 0.9274 - recall: 0.9245 - precision: 0.9356 - f1_score: 0.9180 - val_loss: 0.0987 - val_acc: 0.9107 - val_recall: 0.9145 - val_precision: 0.9174 - val_f1_score: 0.8986\n",
      "Epoch 28/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0587 - acc: 0.9319 - recall: 0.9279 - precision: 0.9382 - f1_score: 0.9209\n",
      "Epoch 00028: val_f1_score did not improve from 0.91332\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0004500000213738531.\n",
      "2696/2696 [==============================] - 1225s 454ms/step - loss: 0.0587 - acc: 0.9319 - recall: 0.9279 - precision: 0.9382 - f1_score: 0.9209 - val_loss: 0.1000 - val_acc: 0.9105 - val_recall: 0.9078 - val_precision: 0.8977 - val_f1_score: 0.8933\n",
      "Epoch 29/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0568 - acc: 0.9326 - recall: 0.9296 - precision: 0.9412 - f1_score: 0.9223\n",
      "Epoch 00029: val_f1_score did not improve from 0.91332\n",
      "2696/2696 [==============================] - 1206s 447ms/step - loss: 0.0568 - acc: 0.9326 - recall: 0.9296 - precision: 0.9412 - f1_score: 0.9223 - val_loss: 0.1079 - val_acc: 0.9162 - val_recall: 0.9177 - val_precision: 0.8957 - val_f1_score: 0.8994\n",
      "Epoch 30/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0530 - acc: 0.9340 - recall: 0.9336 - precision: 0.9437 - f1_score: 0.9250\n",
      "Epoch 00030: val_f1_score did not improve from 0.91332\n",
      "2696/2696 [==============================] - 1222s 453ms/step - loss: 0.0530 - acc: 0.9340 - recall: 0.9336 - precision: 0.9437 - f1_score: 0.9250 - val_loss: 0.1562 - val_acc: 0.9107 - val_recall: 0.8982 - val_precision: 0.9122 - val_f1_score: 0.8978\n",
      "Epoch 31/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0536 - acc: 0.9364 - recall: 0.9344 - precision: 0.9438 - f1_score: 0.9266Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00031: val_f1_score did not improve from 0.91332\n",
      "2696/2696 [==============================] - 1255s 466ms/step - loss: 0.0536 - acc: 0.9364 - recall: 0.9344 - precision: 0.9438 - f1_score: 0.9266 - val_loss: 0.0860 - val_acc: 0.9142 - val_recall: 0.9161 - val_precision: 0.9186 - val_f1_score: 0.9074\n",
      "Epoch 00031: early stopping\n",
      "Epoch 1/100\n",
      "   2/2696 [..............................] - ETA: 1:52:48 - loss: 0.6462 - acc: 0.1667 - recall: 0.3846 - precision: 0.1923 - f1_score: 0.0923WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4791s vs `on_train_batch_end` time: 4.5453s). Check your callbacks.\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.1852 - acc: 0.7970 - recall: 0.7441 - precision: 0.8351 - f1_score: 0.7862\n",
      "Epoch 00001: val_f1_score improved from -inf to 0.85921, saving model to /app/_data/models/final/eff7_full/eff7_full_5.h5\n",
      "2696/2696 [==============================] - 1222s 453ms/step - loss: 0.1852 - acc: 0.7970 - recall: 0.7441 - precision: 0.8351 - f1_score: 0.7862 - val_loss: 0.1224 - val_acc: 0.8684 - val_recall: 0.8396 - val_precision: 0.9041 - val_f1_score: 0.8592\n",
      "Epoch 2/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.1346 - acc: 0.8588 - recall: 0.8265 - precision: 0.8763 - f1_score: 0.8467\n",
      "Epoch 00002: val_f1_score improved from 0.85921 to 0.86315, saving model to /app/_data/models/final/eff7_full/eff7_full_5.h5\n",
      "2696/2696 [==============================] - 1216s 451ms/step - loss: 0.1346 - acc: 0.8588 - recall: 0.8265 - precision: 0.8763 - f1_score: 0.8467 - val_loss: 0.1297 - val_acc: 0.8823 - val_recall: 0.8323 - val_precision: 0.8962 - val_f1_score: 0.8631\n",
      "Epoch 3/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.1225 - acc: 0.8690 - recall: 0.8402 - precision: 0.8843 - f1_score: 0.8579\n",
      "Epoch 00003: val_f1_score improved from 0.86315 to 0.88368, saving model to /app/_data/models/final/eff7_full/eff7_full_5.h5\n",
      "2696/2696 [==============================] - 1228s 456ms/step - loss: 0.1225 - acc: 0.8690 - recall: 0.8402 - precision: 0.8843 - f1_score: 0.8579 - val_loss: 0.1038 - val_acc: 0.8991 - val_recall: 0.8722 - val_precision: 0.9133 - val_f1_score: 0.8837\n",
      "Epoch 4/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.1112 - acc: 0.8808 - recall: 0.8553 - precision: 0.8956 - f1_score: 0.8690\n",
      "Epoch 00004: val_f1_score did not improve from 0.88368\n",
      "2696/2696 [==============================] - 1231s 457ms/step - loss: 0.1112 - acc: 0.8808 - recall: 0.8553 - precision: 0.8956 - f1_score: 0.8690 - val_loss: 0.1114 - val_acc: 0.8939 - val_recall: 0.8545 - val_precision: 0.9024 - val_f1_score: 0.8767\n",
      "Epoch 5/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.1068 - acc: 0.8877 - recall: 0.8629 - precision: 0.8972 - f1_score: 0.8748\n",
      "Epoch 00005: val_f1_score did not improve from 0.88368\n",
      "2696/2696 [==============================] - 1209s 448ms/step - loss: 0.1068 - acc: 0.8877 - recall: 0.8629 - precision: 0.8972 - f1_score: 0.8748 - val_loss: 0.0953 - val_acc: 0.8969 - val_recall: 0.8873 - val_precision: 0.9033 - val_f1_score: 0.8772\n",
      "Epoch 6/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.1014 - acc: 0.8875 - recall: 0.8702 - precision: 0.8981 - f1_score: 0.8762\n",
      "Epoch 00006: val_f1_score improved from 0.88368 to 0.89738, saving model to /app/_data/models/final/eff7_full/eff7_full_5.h5\n",
      "2696/2696 [==============================] - 1257s 466ms/step - loss: 0.1014 - acc: 0.8875 - recall: 0.8702 - precision: 0.8981 - f1_score: 0.8762 - val_loss: 0.0896 - val_acc: 0.9095 - val_recall: 0.8990 - val_precision: 0.9144 - val_f1_score: 0.8974\n",
      "Epoch 7/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0969 - acc: 0.8957 - recall: 0.8768 - precision: 0.9066 - f1_score: 0.8833\n",
      "Epoch 00007: val_f1_score did not improve from 0.89738\n",
      "2696/2696 [==============================] - 1220s 452ms/step - loss: 0.0969 - acc: 0.8957 - recall: 0.8768 - precision: 0.9066 - f1_score: 0.8833 - val_loss: 0.0902 - val_acc: 0.9132 - val_recall: 0.8977 - val_precision: 0.9192 - val_f1_score: 0.8943\n",
      "Epoch 8/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0932 - acc: 0.9003 - recall: 0.8823 - precision: 0.9088 - f1_score: 0.8871\n",
      "Epoch 00008: val_f1_score did not improve from 0.89738\n",
      "2696/2696 [==============================] - 1262s 468ms/step - loss: 0.0932 - acc: 0.9003 - recall: 0.8823 - precision: 0.9088 - f1_score: 0.8871 - val_loss: 0.0921 - val_acc: 0.9013 - val_recall: 0.9197 - val_precision: 0.8747 - val_f1_score: 0.8869\n",
      "Epoch 9/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0895 - acc: 0.9023 - recall: 0.8886 - precision: 0.9113 - f1_score: 0.8905\n",
      "Epoch 00009: val_f1_score did not improve from 0.89738\n",
      "2696/2696 [==============================] - 1223s 454ms/step - loss: 0.0895 - acc: 0.9023 - recall: 0.8886 - precision: 0.9113 - f1_score: 0.8905 - val_loss: 0.1006 - val_acc: 0.9090 - val_recall: 0.8877 - val_precision: 0.9027 - val_f1_score: 0.8909\n",
      "Epoch 10/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0869 - acc: 0.9043 - recall: 0.8887 - precision: 0.9123 - f1_score: 0.8923\n",
      "Epoch 00010: val_f1_score improved from 0.89738 to 0.89930, saving model to /app/_data/models/final/eff7_full/eff7_full_5.h5\n",
      "2696/2696 [==============================] - 1214s 450ms/step - loss: 0.0869 - acc: 0.9043 - recall: 0.8887 - precision: 0.9123 - f1_score: 0.8923 - val_loss: 0.0804 - val_acc: 0.9120 - val_recall: 0.8954 - val_precision: 0.9209 - val_f1_score: 0.8993\n",
      "Epoch 11/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0854 - acc: 0.9050 - recall: 0.8927 - precision: 0.9154 - f1_score: 0.8936\n",
      "Epoch 00011: val_f1_score did not improve from 0.89930\n",
      "2696/2696 [==============================] - 1199s 445ms/step - loss: 0.0854 - acc: 0.9050 - recall: 0.8927 - precision: 0.9154 - f1_score: 0.8936 - val_loss: 0.0801 - val_acc: 0.9130 - val_recall: 0.9188 - val_precision: 0.9092 - val_f1_score: 0.8931\n",
      "Epoch 12/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0831 - acc: 0.9080 - recall: 0.8939 - precision: 0.9172 - f1_score: 0.8965\n",
      "Epoch 00012: val_f1_score did not improve from 0.89930\n",
      "2696/2696 [==============================] - 1207s 448ms/step - loss: 0.0831 - acc: 0.9080 - recall: 0.8939 - precision: 0.9172 - f1_score: 0.8965 - val_loss: 0.0885 - val_acc: 0.9003 - val_recall: 0.9011 - val_precision: 0.9101 - val_f1_score: 0.8862\n",
      "Epoch 13/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0809 - acc: 0.9097 - recall: 0.8978 - precision: 0.9184 - f1_score: 0.8981\n",
      "Epoch 00013: val_f1_score improved from 0.89930 to 0.90713, saving model to /app/_data/models/final/eff7_full/eff7_full_5.h5\n",
      "2696/2696 [==============================] - 1204s 447ms/step - loss: 0.0809 - acc: 0.9097 - recall: 0.8978 - precision: 0.9184 - f1_score: 0.8981 - val_loss: 0.0750 - val_acc: 0.9248 - val_recall: 0.8903 - val_precision: 0.9379 - val_f1_score: 0.9071\n",
      "Epoch 14/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0792 - acc: 0.9115 - recall: 0.9023 - precision: 0.9194 - f1_score: 0.9003\n",
      "Epoch 00014: val_f1_score did not improve from 0.90713\n",
      "2696/2696 [==============================] - 1232s 457ms/step - loss: 0.0792 - acc: 0.9115 - recall: 0.9023 - precision: 0.9194 - f1_score: 0.9003 - val_loss: 0.0806 - val_acc: 0.9184 - val_recall: 0.9075 - val_precision: 0.9193 - val_f1_score: 0.9030\n",
      "Epoch 15/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0774 - acc: 0.9128 - recall: 0.9016 - precision: 0.9200 - f1_score: 0.9015\n",
      "Epoch 00015: val_f1_score did not improve from 0.90713\n",
      "2696/2696 [==============================] - 1220s 452ms/step - loss: 0.0774 - acc: 0.9128 - recall: 0.9016 - precision: 0.9200 - f1_score: 0.9015 - val_loss: 0.0860 - val_acc: 0.9179 - val_recall: 0.8823 - val_precision: 0.9355 - val_f1_score: 0.9004\n",
      "Epoch 16/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0751 - acc: 0.9162 - recall: 0.9065 - precision: 0.9243 - f1_score: 0.9055\n",
      "Epoch 00016: val_f1_score did not improve from 0.90713\n",
      "2696/2696 [==============================] - 1205s 447ms/step - loss: 0.0751 - acc: 0.9162 - recall: 0.9065 - precision: 0.9243 - f1_score: 0.9055 - val_loss: 0.0828 - val_acc: 0.9172 - val_recall: 0.9112 - val_precision: 0.9243 - val_f1_score: 0.9036\n",
      "Epoch 17/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0747 - acc: 0.9186 - recall: 0.9084 - precision: 0.9254 - f1_score: 0.9072\n",
      "Epoch 00017: val_f1_score did not improve from 0.90713\n",
      "2696/2696 [==============================] - 1197s 444ms/step - loss: 0.0747 - acc: 0.9186 - recall: 0.9084 - precision: 0.9254 - f1_score: 0.9072 - val_loss: 0.0818 - val_acc: 0.9174 - val_recall: 0.9137 - val_precision: 0.9245 - val_f1_score: 0.9062\n",
      "Epoch 18/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0731 - acc: 0.9158 - recall: 0.9096 - precision: 0.9259 - f1_score: 0.9066\n",
      "Epoch 00018: val_f1_score did not improve from 0.90713\n",
      "2696/2696 [==============================] - 1215s 451ms/step - loss: 0.0731 - acc: 0.9158 - recall: 0.9096 - precision: 0.9259 - f1_score: 0.9066 - val_loss: 0.0824 - val_acc: 0.9159 - val_recall: 0.9080 - val_precision: 0.9228 - val_f1_score: 0.9025\n",
      "Epoch 19/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0711 - acc: 0.9182 - recall: 0.9095 - precision: 0.9260 - f1_score: 0.9071\n",
      "Epoch 00019: val_f1_score improved from 0.90713 to 0.91122, saving model to /app/_data/models/final/eff7_full/eff7_full_5.h5\n",
      "2696/2696 [==============================] - 1220s 453ms/step - loss: 0.0711 - acc: 0.9182 - recall: 0.9095 - precision: 0.9260 - f1_score: 0.9071 - val_loss: 0.0810 - val_acc: 0.9263 - val_recall: 0.9071 - val_precision: 0.9290 - val_f1_score: 0.9112\n",
      "Epoch 20/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0710 - acc: 0.9195 - recall: 0.9113 - precision: 0.9287 - f1_score: 0.9094\n",
      "Epoch 00020: val_f1_score improved from 0.91122 to 0.91323, saving model to /app/_data/models/final/eff7_full/eff7_full_5.h5\n",
      "2696/2696 [==============================] - 1218s 452ms/step - loss: 0.0710 - acc: 0.9195 - recall: 0.9113 - precision: 0.9287 - f1_score: 0.9094 - val_loss: 0.0747 - val_acc: 0.9315 - val_recall: 0.9137 - val_precision: 0.9326 - val_f1_score: 0.9132\n",
      "Epoch 21/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0689 - acc: 0.9225 - recall: 0.9146 - precision: 0.9310 - f1_score: 0.9104\n",
      "Epoch 00021: val_f1_score did not improve from 0.91323\n",
      "2696/2696 [==============================] - 1227s 455ms/step - loss: 0.0689 - acc: 0.9225 - recall: 0.9146 - precision: 0.9310 - f1_score: 0.9104 - val_loss: 0.0794 - val_acc: 0.9261 - val_recall: 0.9153 - val_precision: 0.9208 - val_f1_score: 0.9063\n",
      "Epoch 22/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0679 - acc: 0.9226 - recall: 0.9154 - precision: 0.9313 - f1_score: 0.9119\n",
      "Epoch 00022: val_f1_score did not improve from 0.91323\n",
      "2696/2696 [==============================] - 1215s 451ms/step - loss: 0.0679 - acc: 0.9226 - recall: 0.9154 - precision: 0.9313 - f1_score: 0.9119 - val_loss: 0.0774 - val_acc: 0.9167 - val_recall: 0.9135 - val_precision: 0.9243 - val_f1_score: 0.9070\n",
      "Epoch 23/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0669 - acc: 0.9212 - recall: 0.9156 - precision: 0.9307 - f1_score: 0.9120\n",
      "Epoch 00023: val_f1_score did not improve from 0.91323\n",
      "2696/2696 [==============================] - 1221s 453ms/step - loss: 0.0669 - acc: 0.9212 - recall: 0.9156 - precision: 0.9307 - f1_score: 0.9120 - val_loss: 0.0749 - val_acc: 0.9231 - val_recall: 0.9215 - val_precision: 0.9247 - val_f1_score: 0.9109\n",
      "Epoch 24/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0647 - acc: 0.9233 - recall: 0.9186 - precision: 0.9342 - f1_score: 0.9143\n",
      "Epoch 00024: val_f1_score did not improve from 0.91323\n",
      "2696/2696 [==============================] - 1205s 447ms/step - loss: 0.0647 - acc: 0.9233 - recall: 0.9186 - precision: 0.9342 - f1_score: 0.9143 - val_loss: 0.0822 - val_acc: 0.9115 - val_recall: 0.9183 - val_precision: 0.9177 - val_f1_score: 0.9042\n",
      "Epoch 25/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0635 - acc: 0.9261 - recall: 0.9211 - precision: 0.9350 - f1_score: 0.9154\n",
      "Epoch 00025: val_f1_score did not improve from 0.91323\n",
      "2696/2696 [==============================] - 1236s 458ms/step - loss: 0.0635 - acc: 0.9261 - recall: 0.9211 - precision: 0.9350 - f1_score: 0.9154 - val_loss: 0.0816 - val_acc: 0.9068 - val_recall: 0.9218 - val_precision: 0.9053 - val_f1_score: 0.9024\n",
      "Epoch 26/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0632 - acc: 0.9256 - recall: 0.9195 - precision: 0.9338 - f1_score: 0.9154\n",
      "Epoch 00026: val_f1_score improved from 0.91323 to 0.91326, saving model to /app/_data/models/final/eff7_full/eff7_full_5.h5\n",
      "2696/2696 [==============================] - 1215s 451ms/step - loss: 0.0632 - acc: 0.9256 - recall: 0.9195 - precision: 0.9338 - f1_score: 0.9154 - val_loss: 0.0781 - val_acc: 0.9295 - val_recall: 0.9192 - val_precision: 0.9312 - val_f1_score: 0.9133\n",
      "Epoch 27/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0613 - acc: 0.9288 - recall: 0.9234 - precision: 0.9389 - f1_score: 0.9192\n",
      "Epoch 00027: val_f1_score did not improve from 0.91326\n",
      "2696/2696 [==============================] - 1194s 443ms/step - loss: 0.0613 - acc: 0.9288 - recall: 0.9234 - precision: 0.9389 - f1_score: 0.9192 - val_loss: 0.1199 - val_acc: 0.9196 - val_recall: 0.9098 - val_precision: 0.9155 - val_f1_score: 0.9032\n",
      "Epoch 28/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0613 - acc: 0.9296 - recall: 0.9236 - precision: 0.9369 - f1_score: 0.9185\n",
      "Epoch 00028: val_f1_score did not improve from 0.91326\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0004500000213738531.\n",
      "2696/2696 [==============================] - 1210s 449ms/step - loss: 0.0613 - acc: 0.9296 - recall: 0.9236 - precision: 0.9369 - f1_score: 0.9185 - val_loss: 0.0772 - val_acc: 0.9256 - val_recall: 0.9181 - val_precision: 0.9264 - val_f1_score: 0.9100\n",
      "Epoch 29/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0566 - acc: 0.9311 - recall: 0.9298 - precision: 0.9407 - f1_score: 0.9214\n",
      "Epoch 00029: val_f1_score did not improve from 0.91326\n",
      "2696/2696 [==============================] - 1202s 446ms/step - loss: 0.0566 - acc: 0.9311 - recall: 0.9298 - precision: 0.9407 - f1_score: 0.9214 - val_loss: 0.0762 - val_acc: 0.9112 - val_recall: 0.9169 - val_precision: 0.9203 - val_f1_score: 0.9081\n",
      "Epoch 30/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0571 - acc: 0.9313 - recall: 0.9300 - precision: 0.9401 - f1_score: 0.9215\n",
      "Epoch 00030: val_f1_score did not improve from 0.91326\n",
      "2696/2696 [==============================] - 1223s 454ms/step - loss: 0.0571 - acc: 0.9313 - recall: 0.9300 - precision: 0.9401 - f1_score: 0.9215 - val_loss: 0.0772 - val_acc: 0.9214 - val_recall: 0.9218 - val_precision: 0.9142 - val_f1_score: 0.9070\n",
      "Epoch 31/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0558 - acc: 0.9332 - recall: 0.9319 - precision: 0.9419 - f1_score: 0.9231\n",
      "Epoch 00031: val_f1_score did not improve from 0.91326\n",
      "2696/2696 [==============================] - 1212s 450ms/step - loss: 0.0558 - acc: 0.9332 - recall: 0.9319 - precision: 0.9419 - f1_score: 0.9231 - val_loss: 0.0861 - val_acc: 0.9174 - val_recall: 0.9160 - val_precision: 0.9236 - val_f1_score: 0.9027\n",
      "Epoch 32/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0542 - acc: 0.9340 - recall: 0.9344 - precision: 0.9429 - f1_score: 0.9248\n",
      "Epoch 00032: val_f1_score did not improve from 0.91326\n",
      "2696/2696 [==============================] - 1209s 448ms/step - loss: 0.0542 - acc: 0.9340 - recall: 0.9344 - precision: 0.9429 - f1_score: 0.9248 - val_loss: 0.0859 - val_acc: 0.9263 - val_recall: 0.8988 - val_precision: 0.9331 - val_f1_score: 0.9072\n",
      "Epoch 33/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0543 - acc: 0.9337 - recall: 0.9329 - precision: 0.9424 - f1_score: 0.9253\n",
      "Epoch 00033: val_f1_score did not improve from 0.91326\n",
      "2696/2696 [==============================] - 1204s 446ms/step - loss: 0.0543 - acc: 0.9337 - recall: 0.9329 - precision: 0.9424 - f1_score: 0.9253 - val_loss: 0.0811 - val_acc: 0.9271 - val_recall: 0.9091 - val_precision: 0.9303 - val_f1_score: 0.9115\n",
      "Epoch 34/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0523 - acc: 0.9356 - recall: 0.9350 - precision: 0.9448 - f1_score: 0.9261\n",
      "Epoch 00034: val_f1_score did not improve from 0.91326\n",
      "2696/2696 [==============================] - 1221s 453ms/step - loss: 0.0523 - acc: 0.9356 - recall: 0.9350 - precision: 0.9448 - f1_score: 0.9261 - val_loss: 0.0745 - val_acc: 0.9283 - val_recall: 0.9300 - val_precision: 0.9205 - val_f1_score: 0.9112\n",
      "Epoch 35/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0517 - acc: 0.9363 - recall: 0.9370 - precision: 0.9463 - f1_score: 0.9267\n",
      "Epoch 00035: val_f1_score did not improve from 0.91326\n",
      "2696/2696 [==============================] - 1236s 458ms/step - loss: 0.0517 - acc: 0.9363 - recall: 0.9370 - precision: 0.9463 - f1_score: 0.9267 - val_loss: 0.0925 - val_acc: 0.9179 - val_recall: 0.9061 - val_precision: 0.9248 - val_f1_score: 0.9029\n",
      "Epoch 36/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0512 - acc: 0.9361 - recall: 0.9391 - precision: 0.9471 - f1_score: 0.9278\n",
      "Epoch 00036: val_f1_score did not improve from 0.91326\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.0004050000192364678.\n",
      "2696/2696 [==============================] - 1209s 448ms/step - loss: 0.0512 - acc: 0.9361 - recall: 0.9391 - precision: 0.9471 - f1_score: 0.9278 - val_loss: 0.0782 - val_acc: 0.9266 - val_recall: 0.9087 - val_precision: 0.9357 - val_f1_score: 0.9114\n",
      "Epoch 37/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0468 - acc: 0.9382 - recall: 0.9433 - precision: 0.9507 - f1_score: 0.9311Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00037: val_f1_score did not improve from 0.91326\n",
      "2696/2696 [==============================] - 1207s 448ms/step - loss: 0.0468 - acc: 0.9382 - recall: 0.9433 - precision: 0.9507 - f1_score: 0.9311 - val_loss: 0.0897 - val_acc: 0.9125 - val_recall: 0.9139 - val_precision: 0.9239 - val_f1_score: 0.9066\n",
      "Epoch 00037: early stopping\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=SEED, shuffle=True)\n",
    "\n",
    "for i, (train_index, valid_index) in enumerate(\n",
    "    skf.split(df_labels[\"image\"], df_labels[\"labels\"])\n",
    "):\n",
    "    if i >= 2:\n",
    "        train, valid = df_labels.loc[train_index], df_labels.loc[valid_index]\n",
    "        model_name = \"eff7_full_\" + str(i + 1) + \".h5\"\n",
    "        log_dir = 'logs_eff7_full_'+str(i + 1)+'/'\n",
    "        callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor=\"val_f1_score\",\n",
    "                patience=11,\n",
    "                restore_best_weights=True,\n",
    "                verbose=1,\n",
    "                mode=\"max\",\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                \"/app/_data/models/final/eff7_full/\" + model_name,\n",
    "                monitor=\"val_f1_score\",\n",
    "                verbose=1,\n",
    "                save_best_only=True,\n",
    "                save_weights_only=False,\n",
    "                mode=\"max\",\n",
    "                save_freq=\"epoch\",\n",
    "            ),\n",
    "            keras.callbacks.ReduceLROnPlateau(\n",
    "                monitor=\"val_f1_score\",\n",
    "                factor=0.9,\n",
    "                patience=8,\n",
    "                verbose=1,\n",
    "                mode=\"max\",\n",
    "                min_delta=1e-4,\n",
    "                min_lr=0.00000001,\n",
    "            ),\n",
    "            keras.callbacks.TensorBoard(\n",
    "                log_dir=\"/app/.tensorboard/\"+log_dir, histogram_freq=0\n",
    "            ),\n",
    "            keras.callbacks.experimental.BackupAndRestore(\n",
    "        '/app/_data/models/final/eff7_full/backup/'\n",
    "    ),\n",
    "            keras.callbacks.TerminateOnNaN()   \n",
    "        ]\n",
    "\n",
    "        gen_train = Generator(\n",
    "            df=train,\n",
    "            images_src_dir=TRAIN_IMG_PATH,\n",
    "            target_image_size=IMAGE_SIZE,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=True,\n",
    "            augment=True,\n",
    "            crop=False,\n",
    "            resize=False,\n",
    "        )\n",
    "        gen_valid = Generator(\n",
    "            df=valid,\n",
    "            images_src_dir=TRAIN_IMG_PATH,\n",
    "            target_image_size=IMAGE_SIZE,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=True,\n",
    "            augment=False,\n",
    "            crop=False,\n",
    "            resize=False,\n",
    "        )\n",
    "        model = get_model()\n",
    "        history = model.fit(\n",
    "            gen_train,\n",
    "            validation_data=gen_valid,\n",
    "            epochs=100,\n",
    "            steps_per_epoch=train.shape[0]//BATCH_SIZE,\n",
    "            validation_steps=valid.shape[0]//BATCH_SIZE,\n",
    "            verbose=1,\n",
    "            workers = 5,\n",
    "            callbacks=callbacks,\n",
    "        )\n",
    "        tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/674 [=====>........................] - ETA: 41s - loss: 0.3218 - acc: 0.8457 - recall: 0.8738 - precision: 0.8563 - f1_score: 0.8389"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "2 root error(s) found.\n  (0) Invalid argument:  assertion failed: [predictions must be >= 0] [Condition x >= y did not hold element-wise:] [x (Cast_7:0) = ] [[0.58203125 0.832519531 0...]...] [y (Cast_9/x:0) = ] [0]\n\t [[{{node assert_greater_equal/Assert/AssertGuard/else/_1/assert_greater_equal/Assert/AssertGuard/Assert}}]]\n\t [[assert_less_equal_1/Assert/AssertGuard/pivot_f/_41/_77]]\n  (1) Invalid argument:  assertion failed: [predictions must be >= 0] [Condition x >= y did not hold element-wise:] [x (Cast_7:0) = ] [[0.58203125 0.832519531 0...]...] [y (Cast_9/x:0) = ] [0]\n\t [[{{node assert_greater_equal/Assert/AssertGuard/else/_1/assert_greater_equal/Assert/AssertGuard/Assert}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_test_function_114966]\n\nFunction call stack:\ntest_function -> test_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-c53716d083ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1377\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TraceContext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1379\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1380\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) Invalid argument:  assertion failed: [predictions must be >= 0] [Condition x >= y did not hold element-wise:] [x (Cast_7:0) = ] [[0.58203125 0.832519531 0...]...] [y (Cast_9/x:0) = ] [0]\n\t [[{{node assert_greater_equal/Assert/AssertGuard/else/_1/assert_greater_equal/Assert/AssertGuard/Assert}}]]\n\t [[assert_less_equal_1/Assert/AssertGuard/pivot_f/_41/_77]]\n  (1) Invalid argument:  assertion failed: [predictions must be >= 0] [Condition x >= y did not hold element-wise:] [x (Cast_7:0) = ] [[0.58203125 0.832519531 0...]...] [y (Cast_9/x:0) = ] [0]\n\t [[{{node assert_greater_equal/Assert/AssertGuard/else/_1/assert_greater_equal/Assert/AssertGuard/Assert}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_test_function_114966]\n\nFunction call stack:\ntest_function -> test_function\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(gen_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices(\"GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_all(file_path):\n",
    "    img = tf.io.read_file(TRAIN_IMG_PATH + file_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    return img\n",
    "\n",
    "\n",
    "def predict_new(path, model):\n",
    "    img = parse_all(path)\n",
    "    img = tf.expand_dims(img, axis=0)\n",
    "    pred = model.predict(img)\n",
    "    return pred_to_labels(pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = pd.DataFrame(columns=[\"image\", \"labels\"])\n",
    "for img_name in os.listdir(TRAIN_IMG_PATH):\n",
    "    pred = predict_new(img_name, model)\n",
    "\n",
    "    df_sub = df_sub.append({\"image\": img_name, \"labels\": pred}, ignore_index=True)\n",
    "\n",
    "print(df_sub.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = df_sub.merge(\n",
    "    labels_21_20[[\"image\", \"labels\"]],\n",
    "    on=\"image\",\n",
    "    how=\"left\",\n",
    "    suffixes=(\"_pred\", \"_true\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.to_csv(\"/app/sandbox/wrong_predictions/eff4/eff4_ns_cropped_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub[df_sub[\"labels_pred\"] == \"\"][\"labels_true\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scab frog_eye_leaf_spot            682\n",
       "complex                            438\n",
       "scab frog_eye_leaf_spot complex    200\n",
       "frog_eye_leaf_spot complex         165\n",
       "scab                               124\n",
       "rust frog_eye_leaf_spot            118\n",
       "rust complex                        91\n",
       "powdery_mildew complex              87\n",
       "rust                                74\n",
       "frog_eye_leaf_spot                  71\n",
       "healthy                             19\n",
       "powdery_mildew                       7\n",
       "Name: labels_true, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub[df_sub[\"labels_pred\"] != df_sub[\"labels_true\"]][\"labels_true\"].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
