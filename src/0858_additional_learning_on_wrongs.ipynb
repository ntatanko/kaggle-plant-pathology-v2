{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /app/kaggle.json'\n"
     ]
    }
   ],
   "source": [
    "import kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /app/kaggle.json'\n",
      "Data package template written to: /app/_data/models/final/0858AddTr/dataset-metadata.json\n"
     ]
    }
   ],
   "source": [
    "! kaggle datasets init -p /app/_data/models/final/0858AddTr/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /app/kaggle.json'\n",
      "Starting upload for file eff4_0858_add_tr_3.h5\n",
      "100%|█████████████████████████████████████████| 203M/203M [05:15<00:00, 675kB/s]\n",
      "Upload successful: eff4_0858_add_tr_3.h5 (203MB)\n",
      "Skipping folder: backup; use '--dir-mode' to upload folders\n",
      "Starting upload for file eff4_0858_add_tr_4.h5\n",
      "100%|█████████████████████████████████████████| 203M/203M [05:22<00:00, 660kB/s]\n",
      "Upload successful: eff4_0858_add_tr_4.h5 (203MB)\n",
      "Starting upload for file eff4_0858_add_tr_1.h5\n",
      "100%|█████████████████████████████████████████| 203M/203M [05:19<00:00, 667kB/s]\n",
      "Upload successful: eff4_0858_add_tr_1.h5 (203MB)\n",
      "Starting upload for file eff4_0858_add_tr_2.h5\n",
      "100%|█████████████████████████████████████████| 203M/203M [05:16<00:00, 672kB/s]\n",
      "Upload successful: eff4_0858_add_tr_2.h5 (203MB)\n",
      "Skipping folder: .ipynb_checkpoints; use '--dir-mode' to upload folders\n",
      "Starting upload for file eff4_0858_add_tr_5.h5\n",
      "100%|█████████████████████████████████████████| 203M/203M [05:12<00:00, 681kB/s]\n",
      "Upload successful: eff4_0858_add_tr_5.h5 (203MB)\n",
      "Your private Dataset is being created. Please check progress at https://www.kaggle.com/nataliayurasova/0858AddTr\n"
     ]
    }
   ],
   "source": [
    "! kaggle datasets create -p /app/_data/models/final/0858AddTr/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.891\n",
    "MODEL_BB_PATH= '../input/model-bb-1/bond_box_999_200.h5'\n",
    "MODEL_PATH = '../input/0865fulltrain/'\n",
    "IMAGE_SIZE = (380, 380)\n",
    "DF_PART = '../input/df-kf-plant/df_kf.csv'\n",
    "PATH = \"/kaggle/input/plant-pathology-2021-fgvc8/\"\n",
    "TRAIN_IMG_PATH = PATH+'train_images/'\n",
    "TEST_IMG_PATH = PATH+'test_images/'\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES=6\n",
    "SEED = 1488\n",
    "- replace ''-'scab'\n",
    "https://www.kaggle.com/nataliayurasova/plant-pathology0891/edit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: albumentations in /usr/local/lib/python3.8/dist-packages (0.5.2)\n",
      "Requirement already satisfied: imgaug>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from albumentations) (0.4.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from albumentations) (1.4.1)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.8/dist-packages (from albumentations) (0.18.1)\n",
      "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.8/dist-packages (from albumentations) (1.17.3)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from albumentations) (5.3.1)\n",
      "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.8/dist-packages (from albumentations) (4.5.1.48)\n",
      "Requirement already satisfied: imageio in /usr/local/lib/python3.8/dist-packages (from imgaug>=0.4.0->albumentations) (2.9.0)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from imgaug>=0.4.0->albumentations) (8.1.2)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (from imgaug>=0.4.0->albumentations) (4.5.1.48)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from imgaug>=0.4.0->albumentations) (3.3.4)\n",
      "Requirement already satisfied: Shapely in /usr/local/lib/python3.8/dist-packages (from imgaug>=0.4.0->albumentations) (1.7.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from imgaug>=0.4.0->albumentations) (1.15.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.16.1->albumentations) (2021.4.8)\n",
      "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.16.1->albumentations) (2.5.1)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.16.1->albumentations) (1.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations) (0.10.0)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.8/dist-packages (from networkx>=2.0->scikit-image>=0.16.1->albumentations) (4.4.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install albumentations\n",
    "import albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import (\n",
    "    StratifiedKFold,\n",
    "    StratifiedShuffleSplit,\n",
    "    train_test_split,\n",
    ")\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB4, EfficientNetB7\n",
    "from tensorflow.keras.layers import (\n",
    "    AveragePooling2D,\n",
    "    AvgPool2D,\n",
    "    Conv2D,\n",
    "    Dense,\n",
    "    Flatten,\n",
    "    GlobalAveragePooling2D,\n",
    "    MaxPooling2D,\n",
    ")\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tqdm import notebook, tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/app/_data/\"\n",
    "BATCH_SIZE = 64\n",
    "SEED = 42\n",
    "IMAGE_SIZE = 380\n",
    "NUM_CLASSES = 6\n",
    "TRAIN_IMG_PATH = \"/app/_data/380_npy/\"\n",
    "TEST_IMG_PATH = \"/app/_data/test_images/\"\n",
    "feature_columns = [\n",
    "    \"complex\",\n",
    "    \"frog_eye_leaf_spot\",\n",
    "    \"healthy\",\n",
    "    \"powdery_mildew\",\n",
    "    \"rust\",\n",
    "    \"scab\",\n",
    "]\n",
    "wrong = [\n",
    "    \"ead085dfac287263.jpg\",\n",
    "    \"95276ccd226ad933.jpg\",\n",
    "    \"da8770e819d2696d.jpg\",\n",
    "    \"cd3a1d64e6806eb5.jpg\",\n",
    "    \"ccec54723ff91860.jpg\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = pd.read_csv(\"../_data/df_csv/labels_21_20.csv\", index_col=[0])\n",
    "df_labels[\"image\"] = df_labels[\"image\"].str.replace(\".jpg\", \".npy\")\n",
    "df_labels = df_labels.query(\"image not in @wrong\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = df_labels.sample(frac=1, random_state=SEED).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>labels</th>\n",
       "      <th>complex</th>\n",
       "      <th>frog_eye_leaf_spot</th>\n",
       "      <th>healthy</th>\n",
       "      <th>powdery_mildew</th>\n",
       "      <th>rust</th>\n",
       "      <th>scab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ed5407e803f4a9d5.npy</td>\n",
       "      <td>scab</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c88ca09ea69597d7.npy</td>\n",
       "      <td>frog_eye_leaf_spot</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train_1610.npy</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90ad674ed881f8b9.npy</td>\n",
       "      <td>scab</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d0c09d9e21eb6367.npy</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20222</th>\n",
       "      <td>cfaab2997580eea0.npy</td>\n",
       "      <td>frog_eye_leaf_spot</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20223</th>\n",
       "      <td>d43871073fa3d217.npy</td>\n",
       "      <td>scab</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20224</th>\n",
       "      <td>a99fd5a64e6e2860.npy</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20225</th>\n",
       "      <td>85ca3c8fa0b4dfd0.npy</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20226</th>\n",
       "      <td>f08f70f59452da26.npy</td>\n",
       "      <td>scab</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20227 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      image              labels  complex  frog_eye_leaf_spot  \\\n",
       "0      ed5407e803f4a9d5.npy                scab        0                   0   \n",
       "1      c88ca09ea69597d7.npy  frog_eye_leaf_spot        0                   1   \n",
       "2            Train_1610.npy             healthy        0                   0   \n",
       "3      90ad674ed881f8b9.npy                scab        0                   0   \n",
       "4      d0c09d9e21eb6367.npy             healthy        0                   0   \n",
       "...                     ...                 ...      ...                 ...   \n",
       "20222  cfaab2997580eea0.npy  frog_eye_leaf_spot        0                   1   \n",
       "20223  d43871073fa3d217.npy                scab        0                   0   \n",
       "20224  a99fd5a64e6e2860.npy             healthy        0                   0   \n",
       "20225  85ca3c8fa0b4dfd0.npy             healthy        0                   0   \n",
       "20226  f08f70f59452da26.npy                scab        0                   0   \n",
       "\n",
       "       healthy  powdery_mildew  rust  scab  \n",
       "0            0               0     0     1  \n",
       "1            0               0     0     0  \n",
       "2            1               0     0     0  \n",
       "3            0               0     0     1  \n",
       "4            1               0     0     0  \n",
       "...        ...             ...   ...   ...  \n",
       "20222        0               0     0     0  \n",
       "20223        0               0     0     1  \n",
       "20224        1               0     0     0  \n",
       "20225        1               0     0     0  \n",
       "20226        0               0     0     1  \n",
       "\n",
       "[20227 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20227, 8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wrong = pd.read_csv(\n",
    "    \"/app/sandbox/wrong_predictions/eff4/eff4_0891.csv\", index_col=[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2819"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_wrong[df_wrong[\"labels_pred\"] != df_wrong[\"labels_true\"]][\"image\"].unique())\n",
    "list_wrong = df_wrong[df_wrong[\"labels_pred\"] != df_wrong[\"labels_true\"]][\n",
    "    \"image\"\n",
    "].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wrong = df_labels.query(\"image in @list_wrong\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 380*380\n",
    "transform = albumentations.Compose(\n",
    "    [\n",
    "        albumentations.CLAHE(p=0.1, clip_limit=(1, 2), tile_grid_size=(8, 8)),\n",
    "        albumentations.OneOf(\n",
    "            [\n",
    "                albumentations.MotionBlur((3, 3)),\n",
    "                albumentations.MedianBlur(blur_limit=3),\n",
    "                albumentations.GaussianBlur(blur_limit=(3, 3), sigma_limit=0),\n",
    "                albumentations.Blur(blur_limit=(3, 3)),\n",
    "            ],\n",
    "            p=0.2,\n",
    "        ),\n",
    "        albumentations.OneOf(\n",
    "            [\n",
    "                albumentations.GaussNoise(var_limit=[10, 50], mean=1),\n",
    "                albumentations.ISONoise(intensity=(0.1, 1), color_shift=(0.01, 0.05)),\n",
    "                albumentations.ImageCompression(\n",
    "                    quality_lower=70, quality_upper=100, compression_type=1\n",
    "                ),\n",
    "                albumentations.MultiplicativeNoise(\n",
    "                    multiplier=(0.95, 1.05), per_channel=True, elementwise=True\n",
    "                ),\n",
    "                albumentations.Downscale(\n",
    "                    scale_min=0.6, scale_max=0.99, interpolation=4\n",
    "                ),\n",
    "            ],\n",
    "            p=0.5,\n",
    "        ),\n",
    "        albumentations.OneOf(\n",
    "            [\n",
    "                albumentations.HueSaturationValue(\n",
    "                    hue_shift_limit=(-7, 7),\n",
    "                    sat_shift_limit=(-10, 10),\n",
    "                    val_shift_limit=(-10, 10),\n",
    "                ),\n",
    "                albumentations.RandomBrightnessContrast(\n",
    "                    brightness_limit=0.15,\n",
    "                    contrast_limit=0.2,\n",
    "                    brightness_by_max=True,\n",
    "                ),\n",
    "            ],\n",
    "            p=0.5,\n",
    "        ),\n",
    "        albumentations.OneOf(\n",
    "            [\n",
    "                albumentations.OpticalDistortion(\n",
    "                    distort_limit=0.05,\n",
    "                    shift_limit=0.05,\n",
    "                    border_mode=2,\n",
    "                ),\n",
    "                albumentations.ElasticTransform(\n",
    "                    alpha=2.0,\n",
    "                    sigma=50.0,\n",
    "                    alpha_affine=10.0,\n",
    "                    interpolation=0,\n",
    "                    border_mode=2,\n",
    "                ),\n",
    "                albumentations.GridDistortion(\n",
    "                    num_steps=5, distort_limit=0.3, interpolation=0, border_mode=2\n",
    "                ),\n",
    "            ],\n",
    "            p=0.5,\n",
    "        ),\n",
    "        albumentations.OneOf(\n",
    "            [\n",
    "                albumentations.HorizontalFlip(),\n",
    "                albumentations.VerticalFlip(),\n",
    "            ],\n",
    "            p=0.5,\n",
    "        ),\n",
    "        albumentations.OneOf(\n",
    "            [\n",
    "                albumentations.Rotate(\n",
    "                    limit=(-180, 180), interpolation=0, border_mode=2\n",
    "                ),\n",
    "                albumentations.ShiftScaleRotate(\n",
    "                    shift_limit=0.05,\n",
    "                    scale_limit=0.05,\n",
    "                    rotate_limit=180,\n",
    "                    interpolation=0,\n",
    "                    border_mode=2,\n",
    "                ),\n",
    "            ],\n",
    "            p=0.5,\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(keras.utils.Sequence):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        images_src_dir,\n",
    "        batch_size,\n",
    "        target_image_size,\n",
    "        shuffle=False,\n",
    "        augment=True,\n",
    "        crop=False,\n",
    "        resize=False,\n",
    "        normalize=False,\n",
    "    ):\n",
    "        self.shuffle = shuffle\n",
    "        self.batch_size = BATCH_SIZE\n",
    "        self.df = df\n",
    "        self.images_dir = images_src_dir\n",
    "        self.target_image_size = (IMAGE_SIZE, IMAGE_SIZE)\n",
    "        self.augment = augment\n",
    "        self.crop = crop\n",
    "        self.resize = resize\n",
    "        self.normalize = normalize\n",
    "        # create label index map\n",
    "        self.labels = self._read_labels()\n",
    "        self.n_samples = self.df.shape[0]\n",
    "        self.n_batches = self.n_samples // self.batch_size\n",
    "        # shuffle data, also repeated after each epoch if needed\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.labels)\n",
    "\n",
    "    def _read_labels(self):\n",
    "        \"\"\"\n",
    "        Returns list images mapping to 1-hot label\n",
    "        \"\"\"\n",
    "\n",
    "        # label indexes\n",
    "        label_ixs = self.df[feature_columns].values\n",
    "        image_ixs = self.df[\"image\"].values\n",
    "        labels = []\n",
    "\n",
    "        for i in range(len(image_ixs)):\n",
    "            labels.append([image_ixs[i], label_ixs[i]])\n",
    "        return labels\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Length in batches\n",
    "        \"\"\"\n",
    "        return self.n_batches\n",
    "\n",
    "    def __getitem__(self, b_ix):\n",
    "        \"\"\"\n",
    "        Produce batch, by batch index\n",
    "        \"\"\"\n",
    "\n",
    "        assert b_ix < self.n_batches\n",
    "\n",
    "        b_X = np.zeros(\n",
    "            (self.batch_size, self.target_image_size[0], self.target_image_size[1], 3),\n",
    "            dtype=np.uint8,\n",
    "        )\n",
    "\n",
    "        b_Y = np.zeros(\n",
    "            (self.batch_size, self.df[feature_columns].shape[1]),\n",
    "            dtype=np.uint8,\n",
    "        )\n",
    "\n",
    "        for i in range(self.batch_size):\n",
    "            b_X[i], b_Y[i] = self.get_one(\n",
    "                i + self.batch_size * b_ix,\n",
    "            )\n",
    "\n",
    "        return (b_X, b_Y)\n",
    "\n",
    "    def get_one(self, one_ix):\n",
    "        \"\"\"\n",
    "        Get single item by absolute index\n",
    "        \"\"\"\n",
    "        id = self.labels[one_ix][0]\n",
    "        src_file = self.images_dir + id\n",
    "\n",
    "        # read file\n",
    "        x = np.load(src_file)\n",
    "        if self.crop:\n",
    "            coord = self.df[self.df[\"image\"] == id][\n",
    "                [\"x_min\", \"y_min\", \"x_max\", \"y_max\"]\n",
    "            ].values[0]\n",
    "            orig_hight = x.shape[0]\n",
    "            orig_width = x.shape[1]\n",
    "            x_min = coord[0]\n",
    "            y_min = coord[1]\n",
    "            x_max = coord[2]\n",
    "            y_max = coord[3]\n",
    "            x = x[\n",
    "                np.int(y_min * orig_hight) : np.int(y_max * orig_hight),\n",
    "                np.int(x_min * orig_width) : np.int(x_max * orig_width),\n",
    "            ]\n",
    "\n",
    "        y = self.labels[one_ix][1]\n",
    "\n",
    "        # augment\n",
    "        if self.augment:\n",
    "            x = self._augment_image(x)\n",
    "\n",
    "        # normalize (sample-wise)\n",
    "        if self.normalize:\n",
    "            x = x.astype(np.float32)\n",
    "            x = x - np.mean(x, axis=(0, 1))\n",
    "            x = x / np.std(x, axis=(0, 1))\n",
    "        return x.astype(np.uint8), y\n",
    "\n",
    "    def _augment_image(self, x):\n",
    "        \"\"\"\n",
    "        Randomply augment image\n",
    "        \"\"\"\n",
    "\n",
    "        x = transform(image=x)[\"image\"]\n",
    "        return x\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA Quadro RTX 5000, compute capability 7.5\n"
     ]
    }
   ],
   "source": [
    "policy = keras.mixed_precision.experimental.Policy(\"mixed_float16\")\n",
    "keras.mixed_precision.experimental.set_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    inputs = keras.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "    base_model = keras.applications.EfficientNetB4(weights=None, include_top=False)\n",
    "    base_model.load_weights(\n",
    "        \"/app/_data/models/efficientnet-b4_noisy-student_notop.h5\",\n",
    "        by_name=True,\n",
    "        skip_mismatch=True,\n",
    "    )\n",
    "    x = base_model(inputs)\n",
    "    x = keras.layers.GlobalAveragePooling2D(name=\"avg_pool\")(x)\n",
    "    x = keras.layers.Flatten(name=\"flatten\")(x)\n",
    "    outputs = keras.layers.Dense(NUM_CLASSES, activation=\"sigmoid\")(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=Adam(lr=0.0005),\n",
    "        metrics=[\n",
    "            \"acc\",\n",
    "            keras.metrics.Recall(),\n",
    "            keras.metrics.Precision(),\n",
    "            tfa.metrics.F1Score(num_classes=NUM_CLASSES, average=\"weighted\"),\n",
    "        ],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_models = [\n",
    "    \"eff4_ns_0865_kf_v2_1.h5\",\n",
    "    \"eff4_ns_0865_kf_v2_2.h5\",\n",
    "    \"eff4_ns_0865_kf_v2_3.h5\",\n",
    "    \"eff4_ns_0865_kf_v2_4.h5\",\n",
    "    \"eff4_ns_0865_kf_v2_5.h5\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6765, 8) (564, 8)\n",
      "Epoch 1/50\n",
      "  1/211 [..............................] - ETA: 0s - loss: 0.5464 - acc: 0.5625 - recall: 0.6531 - precision: 0.9412 - f1_score: 0.7111WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.1857 - acc: 0.6909 - recall: 0.8528 - precision: 0.8755 - f1_score: 0.7049\n",
      "Epoch 00001: val_f1_score improved from -inf to 0.72467, saving model to /app/_data/models/final/0858AddTr/eff4_0858_add_tr_1.h5\n",
      "211/211 [==============================] - 149s 708ms/step - loss: 0.1857 - acc: 0.6909 - recall: 0.8528 - precision: 0.8755 - f1_score: 0.7049 - val_loss: 0.1592 - val_acc: 0.7261 - val_recall: 0.8922 - val_precision: 0.8975 - val_f1_score: 0.7247\n",
      "Epoch 2/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0811 - acc: 0.7504 - recall: 0.9361 - precision: 0.9411 - f1_score: 0.7777\n",
      "Epoch 00002: val_f1_score improved from 0.72467 to 0.76512, saving model to /app/_data/models/final/0858AddTr/eff4_0858_add_tr_1.h5\n",
      "211/211 [==============================] - 139s 661ms/step - loss: 0.0811 - acc: 0.7504 - recall: 0.9361 - precision: 0.9411 - f1_score: 0.7777 - val_loss: 0.1682 - val_acc: 0.7151 - val_recall: 0.9053 - val_precision: 0.8947 - val_f1_score: 0.7651\n",
      "Epoch 3/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0624 - acc: 0.7722 - recall: 0.9533 - precision: 0.9541 - f1_score: 0.8066\n",
      "Epoch 00003: val_f1_score improved from 0.76512 to 0.76827, saving model to /app/_data/models/final/0858AddTr/eff4_0858_add_tr_1.h5\n",
      "211/211 [==============================] - 140s 662ms/step - loss: 0.0624 - acc: 0.7722 - recall: 0.9533 - precision: 0.9541 - f1_score: 0.8066 - val_loss: 0.2098 - val_acc: 0.7408 - val_recall: 0.8923 - val_precision: 0.8966 - val_f1_score: 0.7683\n",
      "Epoch 4/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0429 - acc: 0.8101 - recall: 0.9658 - precision: 0.9678 - f1_score: 0.8311\n",
      "Epoch 00004: val_f1_score improved from 0.76827 to 0.77711, saving model to /app/_data/models/final/0858AddTr/eff4_0858_add_tr_1.h5\n",
      "211/211 [==============================] - 140s 662ms/step - loss: 0.0429 - acc: 0.8101 - recall: 0.9658 - precision: 0.9678 - f1_score: 0.8311 - val_loss: 0.2139 - val_acc: 0.7224 - val_recall: 0.8861 - val_precision: 0.9000 - val_f1_score: 0.7771\n",
      "Epoch 5/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0410 - acc: 0.8078 - recall: 0.9684 - precision: 0.9692 - f1_score: 0.8428\n",
      "Epoch 00005: val_f1_score did not improve from 0.77711\n",
      "211/211 [==============================] - 138s 652ms/step - loss: 0.0410 - acc: 0.8078 - recall: 0.9684 - precision: 0.9692 - f1_score: 0.8428 - val_loss: 0.2360 - val_acc: 0.7059 - val_recall: 0.8665 - val_precision: 0.8791 - val_f1_score: 0.7461\n",
      "Epoch 6/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0375 - acc: 0.8255 - recall: 0.9702 - precision: 0.9731 - f1_score: 0.8518\n",
      "Epoch 00006: val_f1_score did not improve from 0.77711\n",
      "211/211 [==============================] - 138s 653ms/step - loss: 0.0375 - acc: 0.8255 - recall: 0.9702 - precision: 0.9731 - f1_score: 0.8518 - val_loss: 0.2318 - val_acc: 0.7114 - val_recall: 0.8919 - val_precision: 0.8898 - val_f1_score: 0.7604\n",
      "Epoch 7/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0339 - acc: 0.8387 - recall: 0.9748 - precision: 0.9749 - f1_score: 0.8620\n",
      "Epoch 00007: val_f1_score did not improve from 0.77711\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0002560000168159604.\n",
      "211/211 [==============================] - 137s 652ms/step - loss: 0.0339 - acc: 0.8387 - recall: 0.9748 - precision: 0.9749 - f1_score: 0.8620 - val_loss: 0.2862 - val_acc: 0.6949 - val_recall: 0.8541 - val_precision: 0.8633 - val_f1_score: 0.7701\n",
      "Epoch 8/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0266 - acc: 0.8426 - recall: 0.9802 - precision: 0.9814 - f1_score: 0.8736\n",
      "Epoch 00008: val_f1_score did not improve from 0.77711\n",
      "211/211 [==============================] - 137s 651ms/step - loss: 0.0266 - acc: 0.8426 - recall: 0.9802 - precision: 0.9814 - f1_score: 0.8736 - val_loss: 0.2841 - val_acc: 0.7316 - val_recall: 0.8751 - val_precision: 0.8598 - val_f1_score: 0.7771\n",
      "Epoch 9/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0237 - acc: 0.8605 - recall: 0.9823 - precision: 0.9814 - f1_score: 0.8828\n",
      "Epoch 00009: val_f1_score did not improve from 0.77711\n",
      "211/211 [==============================] - 138s 652ms/step - loss: 0.0237 - acc: 0.8605 - recall: 0.9823 - precision: 0.9814 - f1_score: 0.8828 - val_loss: 0.2687 - val_acc: 0.7298 - val_recall: 0.8756 - val_precision: 0.8623 - val_f1_score: 0.7700\n",
      "Epoch 10/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0237 - acc: 0.8586 - recall: 0.9800 - precision: 0.9819 - f1_score: 0.8859\n",
      "Epoch 00010: val_f1_score improved from 0.77711 to 0.78279, saving model to /app/_data/models/final/0858AddTr/eff4_0858_add_tr_1.h5\n",
      "211/211 [==============================] - 139s 660ms/step - loss: 0.0237 - acc: 0.8586 - recall: 0.9800 - precision: 0.9819 - f1_score: 0.8859 - val_loss: 0.2510 - val_acc: 0.7188 - val_recall: 0.8923 - val_precision: 0.8788 - val_f1_score: 0.7828\n",
      "Epoch 11/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0213 - acc: 0.8692 - recall: 0.9828 - precision: 0.9840 - f1_score: 0.8927\n",
      "Epoch 00011: val_f1_score improved from 0.78279 to 0.79058, saving model to /app/_data/models/final/0858AddTr/eff4_0858_add_tr_1.h5\n",
      "211/211 [==============================] - 140s 663ms/step - loss: 0.0213 - acc: 0.8692 - recall: 0.9828 - precision: 0.9840 - f1_score: 0.8927 - val_loss: 0.2737 - val_acc: 0.7463 - val_recall: 0.8861 - val_precision: 0.8727 - val_f1_score: 0.7906\n",
      "Epoch 12/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0196 - acc: 0.8751 - recall: 0.9836 - precision: 0.9848 - f1_score: 0.9036\n",
      "Epoch 00012: val_f1_score did not improve from 0.79058\n",
      "211/211 [==============================] - 137s 651ms/step - loss: 0.0196 - acc: 0.8751 - recall: 0.9836 - precision: 0.9848 - f1_score: 0.9036 - val_loss: 0.3119 - val_acc: 0.7408 - val_recall: 0.8754 - val_precision: 0.8611 - val_f1_score: 0.7710\n",
      "Epoch 13/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0196 - acc: 0.8703 - recall: 0.9842 - precision: 0.9849 - f1_score: 0.9051\n",
      "Epoch 00013: val_f1_score did not improve from 0.79058\n",
      "211/211 [==============================] - 137s 650ms/step - loss: 0.0196 - acc: 0.8703 - recall: 0.9842 - precision: 0.9849 - f1_score: 0.9051 - val_loss: 0.3121 - val_acc: 0.7279 - val_recall: 0.8522 - val_precision: 0.8583 - val_f1_score: 0.7640\n",
      "Epoch 14/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0192 - acc: 0.8636 - recall: 0.9855 - precision: 0.9850 - f1_score: 0.9021\n",
      "Epoch 00014: val_f1_score did not improve from 0.79058\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.00020480002276599408.\n",
      "211/211 [==============================] - 137s 651ms/step - loss: 0.0192 - acc: 0.8636 - recall: 0.9855 - precision: 0.9850 - f1_score: 0.9021 - val_loss: 0.2820 - val_acc: 0.6893 - val_recall: 0.8827 - val_precision: 0.8505 - val_f1_score: 0.7871\n",
      "Epoch 15/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0168 - acc: 0.8826 - recall: 0.9875 - precision: 0.9877 - f1_score: 0.9161\n",
      "Epoch 00015: val_f1_score did not improve from 0.79058\n",
      "211/211 [==============================] - 137s 651ms/step - loss: 0.0168 - acc: 0.8826 - recall: 0.9875 - precision: 0.9877 - f1_score: 0.9161 - val_loss: 0.2971 - val_acc: 0.7206 - val_recall: 0.8800 - val_precision: 0.8586 - val_f1_score: 0.7825\n",
      "Epoch 16/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0150 - acc: 0.8784 - recall: 0.9883 - precision: 0.9878 - f1_score: 0.9178\n",
      "Epoch 00016: val_f1_score did not improve from 0.79058\n",
      "211/211 [==============================] - 138s 652ms/step - loss: 0.0150 - acc: 0.8784 - recall: 0.9883 - precision: 0.9878 - f1_score: 0.9178 - val_loss: 0.3141 - val_acc: 0.7224 - val_recall: 0.8673 - val_precision: 0.8683 - val_f1_score: 0.7902\n",
      "Epoch 17/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0151 - acc: 0.8925 - recall: 0.9864 - precision: 0.9879 - f1_score: 0.9248\n",
      "Epoch 00017: val_f1_score did not improve from 0.79058\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.00016384001355618238.\n",
      "211/211 [==============================] - 137s 650ms/step - loss: 0.0151 - acc: 0.8925 - recall: 0.9864 - precision: 0.9879 - f1_score: 0.9248 - val_loss: 0.2963 - val_acc: 0.7537 - val_recall: 0.8680 - val_precision: 0.8753 - val_f1_score: 0.7804\n",
      "Epoch 18/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0131 - acc: 0.8980 - recall: 0.9887 - precision: 0.9897 - f1_score: 0.9258\n",
      "Epoch 00018: val_f1_score improved from 0.79058 to 0.79548, saving model to /app/_data/models/final/0858AddTr/eff4_0858_add_tr_1.h5\n",
      "211/211 [==============================] - 140s 664ms/step - loss: 0.0131 - acc: 0.8980 - recall: 0.9887 - precision: 0.9897 - f1_score: 0.9258 - val_loss: 0.2966 - val_acc: 0.7243 - val_recall: 0.8863 - val_precision: 0.8728 - val_f1_score: 0.7955\n",
      "Epoch 19/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0102 - acc: 0.9067 - recall: 0.9915 - precision: 0.9919 - f1_score: 0.9335\n",
      "Epoch 00019: val_f1_score did not improve from 0.79548\n",
      "211/211 [==============================] - 137s 651ms/step - loss: 0.0102 - acc: 0.9067 - recall: 0.9915 - precision: 0.9919 - f1_score: 0.9335 - val_loss: 0.3306 - val_acc: 0.7243 - val_recall: 0.8777 - val_precision: 0.8664 - val_f1_score: 0.7938\n",
      "Epoch 20/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0116 - acc: 0.9017 - recall: 0.9903 - precision: 0.9904 - f1_score: 0.9377\n",
      "Epoch 00020: val_f1_score improved from 0.79548 to 0.81179, saving model to /app/_data/models/final/0858AddTr/eff4_0858_add_tr_1.h5\n",
      "211/211 [==============================] - 139s 659ms/step - loss: 0.0116 - acc: 0.9017 - recall: 0.9903 - precision: 0.9904 - f1_score: 0.9377 - val_loss: 0.2853 - val_acc: 0.7518 - val_recall: 0.8935 - val_precision: 0.8788 - val_f1_score: 0.8118\n",
      "Epoch 21/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0111 - acc: 0.9079 - recall: 0.9912 - precision: 0.9904 - f1_score: 0.9405\n",
      "Epoch 00021: val_f1_score did not improve from 0.81179\n",
      "211/211 [==============================] - 137s 651ms/step - loss: 0.0111 - acc: 0.9079 - recall: 0.9912 - precision: 0.9904 - f1_score: 0.9405 - val_loss: 0.2955 - val_acc: 0.7537 - val_recall: 0.8731 - val_precision: 0.8720 - val_f1_score: 0.8063\n",
      "Epoch 22/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0120 - acc: 0.9199 - recall: 0.9902 - precision: 0.9910 - f1_score: 0.9362\n",
      "Epoch 00022: val_f1_score did not improve from 0.81179\n",
      "211/211 [==============================] - 138s 653ms/step - loss: 0.0120 - acc: 0.9199 - recall: 0.9902 - precision: 0.9910 - f1_score: 0.9362 - val_loss: 0.2959 - val_acc: 0.7776 - val_recall: 0.8922 - val_precision: 0.8635 - val_f1_score: 0.8058\n",
      "Epoch 23/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0114 - acc: 0.9134 - recall: 0.9909 - precision: 0.9907 - f1_score: 0.9353\n",
      "Epoch 00023: val_f1_score did not improve from 0.81179\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0001310720108449459.\n",
      "211/211 [==============================] - 138s 652ms/step - loss: 0.0114 - acc: 0.9134 - recall: 0.9909 - precision: 0.9907 - f1_score: 0.9353 - val_loss: 0.3218 - val_acc: 0.7371 - val_recall: 0.8820 - val_precision: 0.8595 - val_f1_score: 0.7989\n",
      "Epoch 24/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0090 - acc: 0.9082 - recall: 0.9925 - precision: 0.9921 - f1_score: 0.9382\n",
      "Epoch 00024: val_f1_score did not improve from 0.81179\n",
      "211/211 [==============================] - 138s 652ms/step - loss: 0.0090 - acc: 0.9082 - recall: 0.9925 - precision: 0.9921 - f1_score: 0.9382 - val_loss: 0.3293 - val_acc: 0.7463 - val_recall: 0.8728 - val_precision: 0.8557 - val_f1_score: 0.7920\n",
      "Epoch 25/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0084 - acc: 0.9270 - recall: 0.9926 - precision: 0.9933 - f1_score: 0.9474\n",
      "Epoch 00025: val_f1_score improved from 0.81179 to 0.81605, saving model to /app/_data/models/final/0858AddTr/eff4_0858_add_tr_1.h5\n",
      "211/211 [==============================] - 139s 660ms/step - loss: 0.0084 - acc: 0.9270 - recall: 0.9926 - precision: 0.9933 - f1_score: 0.9474 - val_loss: 0.3440 - val_acc: 0.7592 - val_recall: 0.8866 - val_precision: 0.8660 - val_f1_score: 0.8160\n",
      "Epoch 26/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0091 - acc: 0.9171 - recall: 0.9932 - precision: 0.9915 - f1_score: 0.9466\n",
      "Epoch 00026: val_f1_score did not improve from 0.81605\n",
      "211/211 [==============================] - 138s 653ms/step - loss: 0.0091 - acc: 0.9171 - recall: 0.9932 - precision: 0.9915 - f1_score: 0.9466 - val_loss: 0.3395 - val_acc: 0.7500 - val_recall: 0.8746 - val_precision: 0.8808 - val_f1_score: 0.8083\n",
      "Epoch 27/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0096 - acc: 0.9289 - recall: 0.9909 - precision: 0.9911 - f1_score: 0.9504\n",
      "Epoch 00027: val_f1_score did not improve from 0.81605\n",
      "211/211 [==============================] - 137s 651ms/step - loss: 0.0096 - acc: 0.9289 - recall: 0.9909 - precision: 0.9911 - f1_score: 0.9504 - val_loss: 0.3551 - val_acc: 0.7463 - val_recall: 0.8716 - val_precision: 0.8695 - val_f1_score: 0.7961\n",
      "Epoch 28/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0097 - acc: 0.9262 - recall: 0.9912 - precision: 0.9911 - f1_score: 0.9504\n",
      "Epoch 00028: val_f1_score did not improve from 0.81605\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.00010485760867595673.\n",
      "211/211 [==============================] - 137s 651ms/step - loss: 0.0097 - acc: 0.9262 - recall: 0.9912 - precision: 0.9911 - f1_score: 0.9504 - val_loss: 0.3833 - val_acc: 0.7371 - val_recall: 0.8790 - val_precision: 0.8646 - val_f1_score: 0.7952\n",
      "Epoch 29/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0100 - acc: 0.9209 - recall: 0.9919 - precision: 0.9905 - f1_score: 0.9468\n",
      "Epoch 00029: val_f1_score did not improve from 0.81605\n",
      "211/211 [==============================] - 138s 652ms/step - loss: 0.0100 - acc: 0.9209 - recall: 0.9919 - precision: 0.9905 - f1_score: 0.9468 - val_loss: 0.3692 - val_acc: 0.7261 - val_recall: 0.8828 - val_precision: 0.8561 - val_f1_score: 0.7987\n",
      "Epoch 30/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0091 - acc: 0.9098 - recall: 0.9921 - precision: 0.9912 - f1_score: 0.9447\n",
      "Epoch 00030: val_f1_score did not improve from 0.81605\n",
      "211/211 [==============================] - 138s 653ms/step - loss: 0.0091 - acc: 0.9098 - recall: 0.9921 - precision: 0.9912 - f1_score: 0.9447 - val_loss: 0.3435 - val_acc: 0.7151 - val_recall: 0.8775 - val_precision: 0.8621 - val_f1_score: 0.7918\n",
      "Epoch 31/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0095 - acc: 0.9193 - recall: 0.9909 - precision: 0.9913 - f1_score: 0.9496\n",
      "Epoch 00031: val_f1_score improved from 0.81605 to 0.82327, saving model to /app/_data/models/final/0858AddTr/eff4_0858_add_tr_1.h5\n",
      "211/211 [==============================] - 140s 662ms/step - loss: 0.0095 - acc: 0.9193 - recall: 0.9909 - precision: 0.9913 - f1_score: 0.9496 - val_loss: 0.3629 - val_acc: 0.7445 - val_recall: 0.8924 - val_precision: 0.8541 - val_f1_score: 0.8233\n",
      "Epoch 32/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0102 - acc: 0.9156 - recall: 0.9908 - precision: 0.9916 - f1_score: 0.9507\n",
      "Epoch 00032: val_f1_score did not improve from 0.82327\n",
      "211/211 [==============================] - 138s 655ms/step - loss: 0.0102 - acc: 0.9156 - recall: 0.9908 - precision: 0.9916 - f1_score: 0.9507 - val_loss: 0.3521 - val_acc: 0.7261 - val_recall: 0.8772 - val_precision: 0.8649 - val_f1_score: 0.8010\n",
      "Epoch 33/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0083 - acc: 0.9091 - recall: 0.9925 - precision: 0.9922 - f1_score: 0.9496\n",
      "Epoch 00033: val_f1_score did not improve from 0.82327\n",
      "211/211 [==============================] - 138s 652ms/step - loss: 0.0083 - acc: 0.9091 - recall: 0.9925 - precision: 0.9922 - f1_score: 0.9496 - val_loss: 0.3519 - val_acc: 0.7463 - val_recall: 0.8830 - val_precision: 0.8737 - val_f1_score: 0.8059\n",
      "Epoch 34/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0088 - acc: 0.9285 - recall: 0.9914 - precision: 0.9923 - f1_score: 0.9523\n",
      "Epoch 00034: val_f1_score did not improve from 0.82327\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 8.388608694076538e-05.\n",
      "211/211 [==============================] - 138s 653ms/step - loss: 0.0088 - acc: 0.9285 - recall: 0.9914 - precision: 0.9923 - f1_score: 0.9523 - val_loss: 0.3247 - val_acc: 0.7555 - val_recall: 0.8828 - val_precision: 0.8744 - val_f1_score: 0.7938\n",
      "Epoch 35/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0075 - acc: 0.9325 - recall: 0.9925 - precision: 0.9933 - f1_score: 0.9550\n",
      "Epoch 00035: val_f1_score did not improve from 0.82327\n",
      "211/211 [==============================] - 137s 651ms/step - loss: 0.0075 - acc: 0.9325 - recall: 0.9925 - precision: 0.9933 - f1_score: 0.9550 - val_loss: 0.3436 - val_acc: 0.7482 - val_recall: 0.8775 - val_precision: 0.8754 - val_f1_score: 0.7932\n",
      "Epoch 36/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0073 - acc: 0.9402 - recall: 0.9928 - precision: 0.9932 - f1_score: 0.9605\n",
      "Epoch 00036: val_f1_score did not improve from 0.82327\n",
      "211/211 [==============================] - 138s 652ms/step - loss: 0.0073 - acc: 0.9402 - recall: 0.9928 - precision: 0.9932 - f1_score: 0.9605 - val_loss: 0.3626 - val_acc: 0.7426 - val_recall: 0.8803 - val_precision: 0.8640 - val_f1_score: 0.8001\n",
      "Epoch 37/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0069 - acc: 0.9375 - recall: 0.9940 - precision: 0.9928 - f1_score: 0.9577\n",
      "Epoch 00037: val_f1_score did not improve from 0.82327\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 6.710886955261231e-05.\n",
      "211/211 [==============================] - 137s 650ms/step - loss: 0.0069 - acc: 0.9375 - recall: 0.9940 - precision: 0.9928 - f1_score: 0.9577 - val_loss: 0.3643 - val_acc: 0.7500 - val_recall: 0.8876 - val_precision: 0.8631 - val_f1_score: 0.7992\n",
      "Epoch 38/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0074 - acc: 0.9353 - recall: 0.9931 - precision: 0.9934 - f1_score: 0.9573\n",
      "Epoch 00038: val_f1_score did not improve from 0.82327\n",
      "211/211 [==============================] - 138s 652ms/step - loss: 0.0074 - acc: 0.9353 - recall: 0.9931 - precision: 0.9934 - f1_score: 0.9573 - val_loss: 0.3494 - val_acc: 0.7592 - val_recall: 0.8889 - val_precision: 0.8744 - val_f1_score: 0.8063\n",
      "Epoch 39/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0074 - acc: 0.9369 - recall: 0.9924 - precision: 0.9932 - f1_score: 0.9602Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00039: val_f1_score did not improve from 0.82327\n",
      "211/211 [==============================] - 138s 654ms/step - loss: 0.0074 - acc: 0.9369 - recall: 0.9924 - precision: 0.9932 - f1_score: 0.9602 - val_loss: 0.3582 - val_acc: 0.7555 - val_recall: 0.8899 - val_precision: 0.8744 - val_f1_score: 0.8101\n",
      "Epoch 00039: early stopping\n",
      "(6765, 8) (564, 8)\n",
      "Epoch 1/50\n",
      "  2/211 [..............................] - ETA: 5:46 - loss: 0.7700 - acc: 0.4062 - recall_1: 0.4747 - precision_1: 0.7581 - f1_score: 0.5310WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.6603s vs `on_train_batch_end` time: 2.6487s). Check your callbacks.\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.2241 - acc: 0.6305 - recall_1: 0.8014 - precision_1: 0.8216 - f1_score: 0.6595\n",
      "Epoch 00001: val_f1_score improved from -inf to 0.65457, saving model to /app/_data/models/final/0858AddTr/eff4_0858_add_tr_2.h5\n",
      "211/211 [==============================] - 146s 693ms/step - loss: 0.2241 - acc: 0.6305 - recall_1: 0.8014 - precision_1: 0.8216 - f1_score: 0.6595 - val_loss: 0.3090 - val_acc: 0.5919 - val_recall_1: 0.7714 - val_precision_1: 0.7588 - val_f1_score: 0.6546\n",
      "Epoch 2/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.1368 - acc: 0.7161 - recall_1: 0.8900 - precision_1: 0.8951 - f1_score: 0.7251\n",
      "Epoch 00002: val_f1_score did not improve from 0.65457\n",
      "211/211 [==============================] - 138s 652ms/step - loss: 0.1368 - acc: 0.7161 - recall_1: 0.8900 - precision_1: 0.8951 - f1_score: 0.7251 - val_loss: 0.2615 - val_acc: 0.6268 - val_recall_1: 0.8062 - val_precision_1: 0.8043 - val_f1_score: 0.6524\n",
      "Epoch 3/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.1022 - acc: 0.7353 - recall_1: 0.9199 - precision_1: 0.9217 - f1_score: 0.7534\n",
      "Epoch 00003: val_f1_score did not improve from 0.65457\n",
      "211/211 [==============================] - 137s 650ms/step - loss: 0.1022 - acc: 0.7353 - recall_1: 0.9199 - precision_1: 0.9217 - f1_score: 0.7534 - val_loss: 0.2905 - val_acc: 0.7059 - val_recall_1: 0.8272 - val_precision_1: 0.7977 - val_f1_score: 0.6494\n",
      "Epoch 4/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0755 - acc: 0.7698 - recall_1: 0.9433 - precision_1: 0.9455 - f1_score: 0.7783\n",
      "Epoch 00004: val_f1_score improved from 0.65457 to 0.66925, saving model to /app/_data/models/final/0858AddTr/eff4_0858_add_tr_2.h5\n",
      "211/211 [==============================] - 139s 660ms/step - loss: 0.0755 - acc: 0.7698 - recall_1: 0.9433 - precision_1: 0.9455 - f1_score: 0.7783 - val_loss: 0.3638 - val_acc: 0.5809 - val_recall_1: 0.8048 - val_precision_1: 0.7593 - val_f1_score: 0.6692\n",
      "Epoch 5/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0609 - acc: 0.7858 - recall_1: 0.9555 - precision_1: 0.9541 - f1_score: 0.8132\n",
      "Epoch 00005: val_f1_score improved from 0.66925 to 0.68088, saving model to /app/_data/models/final/0858AddTr/eff4_0858_add_tr_2.h5\n",
      "211/211 [==============================] - 139s 660ms/step - loss: 0.0609 - acc: 0.7858 - recall_1: 0.9555 - precision_1: 0.9541 - f1_score: 0.8132 - val_loss: 0.3280 - val_acc: 0.6121 - val_recall_1: 0.7858 - val_precision_1: 0.8029 - val_f1_score: 0.6809\n",
      "Epoch 6/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0507 - acc: 0.8107 - recall_1: 0.9642 - precision_1: 0.9652 - f1_score: 0.8187\n",
      "Epoch 00006: val_f1_score improved from 0.68088 to 0.68330, saving model to /app/_data/models/final/0858AddTr/eff4_0858_add_tr_2.h5\n",
      "211/211 [==============================] - 139s 660ms/step - loss: 0.0507 - acc: 0.8107 - recall_1: 0.9642 - precision_1: 0.9652 - f1_score: 0.8187 - val_loss: 0.3632 - val_acc: 0.6783 - val_recall_1: 0.8250 - val_precision_1: 0.7795 - val_f1_score: 0.6833\n",
      "Epoch 7/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0454 - acc: 0.8146 - recall_1: 0.9670 - precision_1: 0.9686 - f1_score: 0.8364\n",
      "Epoch 00007: val_f1_score improved from 0.68330 to 0.68800, saving model to /app/_data/models/final/0858AddTr/eff4_0858_add_tr_2.h5\n",
      "211/211 [==============================] - 139s 659ms/step - loss: 0.0454 - acc: 0.8146 - recall_1: 0.9670 - precision_1: 0.9686 - f1_score: 0.8364 - val_loss: 0.3368 - val_acc: 0.6857 - val_recall_1: 0.7885 - val_precision_1: 0.8148 - val_f1_score: 0.6880\n",
      "Epoch 8/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0446 - acc: 0.8168 - recall_1: 0.9673 - precision_1: 0.9695 - f1_score: 0.8356\n",
      "Epoch 00008: val_f1_score did not improve from 0.68800\n",
      "211/211 [==============================] - 137s 651ms/step - loss: 0.0446 - acc: 0.8168 - recall_1: 0.9673 - precision_1: 0.9695 - f1_score: 0.8356 - val_loss: 0.3867 - val_acc: 0.6875 - val_recall_1: 0.7981 - val_precision_1: 0.7971 - val_f1_score: 0.6817\n",
      "Epoch 9/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0378 - acc: 0.8318 - recall_1: 0.9704 - precision_1: 0.9735 - f1_score: 0.8471\n",
      "Epoch 00009: val_f1_score did not improve from 0.68800\n",
      "211/211 [==============================] - 137s 651ms/step - loss: 0.0378 - acc: 0.8318 - recall_1: 0.9704 - precision_1: 0.9735 - f1_score: 0.8471 - val_loss: 0.4435 - val_acc: 0.6912 - val_recall_1: 0.8022 - val_precision_1: 0.7681 - val_f1_score: 0.6825\n",
      "Epoch 10/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0315 - acc: 0.8353 - recall_1: 0.9769 - precision_1: 0.9776 - f1_score: 0.8650\n",
      "Epoch 00010: val_f1_score did not improve from 0.68800\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00032000001519918444.\n",
      "211/211 [==============================] - 137s 650ms/step - loss: 0.0315 - acc: 0.8353 - recall_1: 0.9769 - precision_1: 0.9776 - f1_score: 0.8650 - val_loss: 0.4256 - val_acc: 0.6158 - val_recall_1: 0.7688 - val_precision_1: 0.7983 - val_f1_score: 0.6778\n",
      "Epoch 11/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0291 - acc: 0.8483 - recall_1: 0.9776 - precision_1: 0.9788 - f1_score: 0.8736\n",
      "Epoch 00011: val_f1_score improved from 0.68800 to 0.70058, saving model to /app/_data/models/final/0858AddTr/eff4_0858_add_tr_2.h5\n",
      "211/211 [==============================] - 139s 660ms/step - loss: 0.0291 - acc: 0.8483 - recall_1: 0.9776 - precision_1: 0.9788 - f1_score: 0.8736 - val_loss: 0.5128 - val_acc: 0.6250 - val_recall_1: 0.8026 - val_precision_1: 0.7483 - val_f1_score: 0.7006\n",
      "Epoch 12/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0261 - acc: 0.8575 - recall_1: 0.9810 - precision_1: 0.9823 - f1_score: 0.8898\n",
      "Epoch 00012: val_f1_score did not improve from 0.70058\n",
      "211/211 [==============================] - 137s 649ms/step - loss: 0.0261 - acc: 0.8575 - recall_1: 0.9810 - precision_1: 0.9823 - f1_score: 0.8898 - val_loss: 0.4409 - val_acc: 0.6066 - val_recall_1: 0.7922 - val_precision_1: 0.7884 - val_f1_score: 0.6794\n",
      "Epoch 13/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0258 - acc: 0.8669 - recall_1: 0.9820 - precision_1: 0.9815 - f1_score: 0.8838\n",
      "Epoch 00013: val_f1_score did not improve from 0.70058\n",
      "211/211 [==============================] - 138s 653ms/step - loss: 0.0258 - acc: 0.8669 - recall_1: 0.9820 - precision_1: 0.9815 - f1_score: 0.8838 - val_loss: 0.4990 - val_acc: 0.6140 - val_recall_1: 0.7527 - val_precision_1: 0.7854 - val_f1_score: 0.6487\n",
      "Epoch 14/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0283 - acc: 0.8609 - recall_1: 0.9797 - precision_1: 0.9806 - f1_score: 0.8846\n",
      "Epoch 00014: val_f1_score did not improve from 0.70058\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0002560000168159604.\n",
      "211/211 [==============================] - 137s 650ms/step - loss: 0.0283 - acc: 0.8609 - recall_1: 0.9797 - precision_1: 0.9806 - f1_score: 0.8846 - val_loss: 0.4492 - val_acc: 0.6783 - val_recall_1: 0.7907 - val_precision_1: 0.7888 - val_f1_score: 0.6870\n",
      "Epoch 15/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0217 - acc: 0.8811 - recall_1: 0.9839 - precision_1: 0.9835 - f1_score: 0.8935\n",
      "Epoch 00015: val_f1_score did not improve from 0.70058\n",
      "211/211 [==============================] - 137s 650ms/step - loss: 0.0217 - acc: 0.8811 - recall_1: 0.9839 - precision_1: 0.9835 - f1_score: 0.8935 - val_loss: 0.5026 - val_acc: 0.6360 - val_recall_1: 0.7950 - val_precision_1: 0.7640 - val_f1_score: 0.6875\n",
      "Epoch 16/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0173 - acc: 0.8860 - recall_1: 0.9861 - precision_1: 0.9868 - f1_score: 0.9038\n",
      "Epoch 00016: val_f1_score improved from 0.70058 to 0.71234, saving model to /app/_data/models/final/0858AddTr/eff4_0858_add_tr_2.h5\n",
      "211/211 [==============================] - 139s 660ms/step - loss: 0.0173 - acc: 0.8860 - recall_1: 0.9861 - precision_1: 0.9868 - f1_score: 0.9038 - val_loss: 0.4614 - val_acc: 0.6544 - val_recall_1: 0.7888 - val_precision_1: 0.7824 - val_f1_score: 0.7123\n",
      "Epoch 17/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0145 - acc: 0.8891 - recall_1: 0.9878 - precision_1: 0.9878 - f1_score: 0.9165\n",
      "Epoch 00017: val_f1_score did not improve from 0.71234\n",
      "211/211 [==============================] - 137s 651ms/step - loss: 0.0145 - acc: 0.8891 - recall_1: 0.9878 - precision_1: 0.9878 - f1_score: 0.9165 - val_loss: 0.5212 - val_acc: 0.6728 - val_recall_1: 0.7762 - val_precision_1: 0.7698 - val_f1_score: 0.6991\n",
      "Epoch 18/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0145 - acc: 0.8897 - recall_1: 0.9893 - precision_1: 0.9883 - f1_score: 0.9222\n",
      "Epoch 00018: val_f1_score did not improve from 0.71234\n",
      "211/211 [==============================] - 137s 649ms/step - loss: 0.0145 - acc: 0.8897 - recall_1: 0.9893 - precision_1: 0.9883 - f1_score: 0.9222 - val_loss: 0.5111 - val_acc: 0.6434 - val_recall_1: 0.7580 - val_precision_1: 0.7635 - val_f1_score: 0.6635\n",
      "Epoch 19/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0161 - acc: 0.8888 - recall_1: 0.9887 - precision_1: 0.9888 - f1_score: 0.9201\n",
      "Epoch 00019: val_f1_score improved from 0.71234 to 0.71248, saving model to /app/_data/models/final/0858AddTr/eff4_0858_add_tr_2.h5\n",
      "211/211 [==============================] - 139s 659ms/step - loss: 0.0161 - acc: 0.8888 - recall_1: 0.9887 - precision_1: 0.9888 - f1_score: 0.9201 - val_loss: 0.5011 - val_acc: 0.6820 - val_recall_1: 0.7770 - val_precision_1: 0.7751 - val_f1_score: 0.7125\n",
      "Epoch 20/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0171 - acc: 0.9028 - recall_1: 0.9873 - precision_1: 0.9882 - f1_score: 0.9150\n",
      "Epoch 00020: val_f1_score did not improve from 0.71248\n",
      "211/211 [==============================] - 137s 649ms/step - loss: 0.0171 - acc: 0.9028 - recall_1: 0.9873 - precision_1: 0.9882 - f1_score: 0.9150 - val_loss: 0.5383 - val_acc: 0.5901 - val_recall_1: 0.7850 - val_precision_1: 0.7677 - val_f1_score: 0.6735\n",
      "Epoch 21/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0170 - acc: 0.9011 - recall_1: 0.9871 - precision_1: 0.9874 - f1_score: 0.9208\n",
      "Epoch 00021: val_f1_score did not improve from 0.71248\n",
      "211/211 [==============================] - 137s 651ms/step - loss: 0.0170 - acc: 0.9011 - recall_1: 0.9871 - precision_1: 0.9874 - f1_score: 0.9208 - val_loss: 0.5784 - val_acc: 0.6195 - val_recall_1: 0.8053 - val_precision_1: 0.7464 - val_f1_score: 0.6972\n",
      "Epoch 22/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0156 - acc: 0.9083 - recall_1: 0.9871 - precision_1: 0.9879 - f1_score: 0.9282\n",
      "Epoch 00022: val_f1_score did not improve from 0.71248\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.00020480002276599408.\n",
      "211/211 [==============================] - 137s 649ms/step - loss: 0.0156 - acc: 0.9083 - recall_1: 0.9871 - precision_1: 0.9879 - f1_score: 0.9282 - val_loss: 0.5759 - val_acc: 0.6746 - val_recall_1: 0.8014 - val_precision_1: 0.7710 - val_f1_score: 0.7078\n",
      "Epoch 23/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0152 - acc: 0.9092 - recall_1: 0.9881 - precision_1: 0.9894 - f1_score: 0.9331\n",
      "Epoch 00023: val_f1_score did not improve from 0.71248\n",
      "211/211 [==============================] - 137s 651ms/step - loss: 0.0152 - acc: 0.9092 - recall_1: 0.9881 - precision_1: 0.9894 - f1_score: 0.9331 - val_loss: 0.5803 - val_acc: 0.6250 - val_recall_1: 0.7990 - val_precision_1: 0.7534 - val_f1_score: 0.6852\n",
      "Epoch 24/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0116 - acc: 0.9111 - recall_1: 0.9916 - precision_1: 0.9919 - f1_score: 0.9329\n",
      "Epoch 00024: val_f1_score did not improve from 0.71248\n",
      "211/211 [==============================] - 137s 650ms/step - loss: 0.0116 - acc: 0.9111 - recall_1: 0.9916 - precision_1: 0.9919 - f1_score: 0.9329 - val_loss: 0.5764 - val_acc: 0.6636 - val_recall_1: 0.8017 - val_precision_1: 0.7732 - val_f1_score: 0.7048\n",
      "Epoch 25/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0120 - acc: 0.9182 - recall_1: 0.9899 - precision_1: 0.9917 - f1_score: 0.9303\n",
      "Epoch 00025: val_f1_score did not improve from 0.71248\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.00016384001355618238.\n",
      "211/211 [==============================] - 138s 654ms/step - loss: 0.0120 - acc: 0.9182 - recall_1: 0.9899 - precision_1: 0.9917 - f1_score: 0.9303 - val_loss: 0.5826 - val_acc: 0.6728 - val_recall_1: 0.8029 - val_precision_1: 0.7602 - val_f1_score: 0.6883\n",
      "Epoch 26/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0117 - acc: 0.9239 - recall_1: 0.9915 - precision_1: 0.9914 - f1_score: 0.9349\n",
      "Epoch 00026: val_f1_score did not improve from 0.71248\n",
      "211/211 [==============================] - 137s 649ms/step - loss: 0.0117 - acc: 0.9239 - recall_1: 0.9915 - precision_1: 0.9914 - f1_score: 0.9349 - val_loss: 0.5667 - val_acc: 0.6654 - val_recall_1: 0.8069 - val_precision_1: 0.7669 - val_f1_score: 0.6960\n",
      "Epoch 27/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0103 - acc: 0.9209 - recall_1: 0.9922 - precision_1: 0.9929 - f1_score: 0.9384Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00027: val_f1_score did not improve from 0.71248\n",
      "211/211 [==============================] - 137s 650ms/step - loss: 0.0103 - acc: 0.9209 - recall_1: 0.9922 - precision_1: 0.9929 - f1_score: 0.9384 - val_loss: 0.5720 - val_acc: 0.6746 - val_recall_1: 0.7829 - val_precision_1: 0.7719 - val_f1_score: 0.7031\n",
      "Epoch 00027: early stopping\n",
      "(6765, 8) (564, 8)\n",
      "Epoch 1/50\n",
      "  2/211 [..............................] - ETA: 6:24 - loss: 0.8191 - acc: 0.2812 - recall_2: 0.3789 - precision_2: 0.6102 - f1_score: 0.4202WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 1.2915s vs `on_train_batch_end` time: 2.3888s). Check your callbacks.\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.2818 - acc: 0.5782 - recall_2: 0.7428 - precision_2: 0.7503 - f1_score: 0.5997\n",
      "Epoch 00001: val_f1_score improved from -inf to 0.56093, saving model to /app/_data/models/final/0858AddTr/eff4_0858_add_tr_3.h5\n",
      "211/211 [==============================] - 147s 698ms/step - loss: 0.2818 - acc: 0.5782 - recall_2: 0.7428 - precision_2: 0.7503 - f1_score: 0.5997 - val_loss: 0.3116 - val_acc: 0.5184 - val_recall_2: 0.6742 - val_precision_2: 0.7286 - val_f1_score: 0.5609\n",
      "Epoch 2/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.2038 - acc: 0.6614 - recall_2: 0.8272 - precision_2: 0.8292 - f1_score: 0.6682\n",
      "Epoch 00002: val_f1_score did not improve from 0.56093\n",
      "211/211 [==============================] - 137s 652ms/step - loss: 0.2038 - acc: 0.6614 - recall_2: 0.8272 - precision_2: 0.8292 - f1_score: 0.6682 - val_loss: 0.4067 - val_acc: 0.5901 - val_recall_2: 0.6517 - val_precision_2: 0.7180 - val_f1_score: 0.5534\n",
      "Epoch 3/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.1602 - acc: 0.7042 - recall_2: 0.8700 - precision_2: 0.8745 - f1_score: 0.7104\n",
      "Epoch 00003: val_f1_score improved from 0.56093 to 0.57670, saving model to /app/_data/models/final/0858AddTr/eff4_0858_add_tr_3.h5\n",
      "211/211 [==============================] - 140s 662ms/step - loss: 0.1602 - acc: 0.7042 - recall_2: 0.8700 - precision_2: 0.8745 - f1_score: 0.7104 - val_loss: 0.4184 - val_acc: 0.5092 - val_recall_2: 0.7607 - val_precision_2: 0.7070 - val_f1_score: 0.5767\n",
      "Epoch 4/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.1255 - acc: 0.7305 - recall_2: 0.8967 - precision_2: 0.9003 - f1_score: 0.7300\n",
      "Epoch 00004: val_f1_score did not improve from 0.57670\n",
      "211/211 [==============================] - 138s 654ms/step - loss: 0.1255 - acc: 0.7305 - recall_2: 0.8967 - precision_2: 0.9003 - f1_score: 0.7300 - val_loss: 0.4264 - val_acc: 0.5901 - val_recall_2: 0.7222 - val_precision_2: 0.6951 - val_f1_score: 0.5538\n",
      "Epoch 5/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0997 - acc: 0.7509 - recall_2: 0.9201 - precision_2: 0.9246 - f1_score: 0.7569\n",
      "Epoch 00005: val_f1_score did not improve from 0.57670\n",
      "211/211 [==============================] - 137s 651ms/step - loss: 0.0997 - acc: 0.7509 - recall_2: 0.9201 - precision_2: 0.9246 - f1_score: 0.7569 - val_loss: 0.4874 - val_acc: 0.5386 - val_recall_2: 0.6904 - val_precision_2: 0.7046 - val_f1_score: 0.5358\n",
      "Epoch 6/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0896 - acc: 0.7543 - recall_2: 0.9318 - precision_2: 0.9350 - f1_score: 0.7702\n",
      "Epoch 00006: val_f1_score did not improve from 0.57670\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "211/211 [==============================] - 137s 651ms/step - loss: 0.0896 - acc: 0.7543 - recall_2: 0.9318 - precision_2: 0.9350 - f1_score: 0.7702 - val_loss: 0.4670 - val_acc: 0.4908 - val_recall_2: 0.7141 - val_precision_2: 0.6888 - val_f1_score: 0.5417\n",
      "Epoch 7/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0604 - acc: 0.7888 - recall_2: 0.9537 - precision_2: 0.9577 - f1_score: 0.7946\n",
      "Epoch 00007: val_f1_score improved from 0.57670 to 0.59041, saving model to /app/_data/models/final/0858AddTr/eff4_0858_add_tr_3.h5\n",
      "211/211 [==============================] - 139s 661ms/step - loss: 0.0604 - acc: 0.7888 - recall_2: 0.9537 - precision_2: 0.9577 - f1_score: 0.7946 - val_loss: 0.5267 - val_acc: 0.5735 - val_recall_2: 0.7392 - val_precision_2: 0.7055 - val_f1_score: 0.5904\n",
      "Epoch 8/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0505 - acc: 0.7969 - recall_2: 0.9618 - precision_2: 0.9628 - f1_score: 0.8209\n",
      "Epoch 00008: val_f1_score did not improve from 0.59041\n",
      "211/211 [==============================] - 138s 652ms/step - loss: 0.0505 - acc: 0.7969 - recall_2: 0.9618 - precision_2: 0.9628 - f1_score: 0.8209 - val_loss: 0.5029 - val_acc: 0.5754 - val_recall_2: 0.6810 - val_precision_2: 0.7123 - val_f1_score: 0.5807\n",
      "Epoch 9/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0508 - acc: 0.8128 - recall_2: 0.9618 - precision_2: 0.9612 - f1_score: 0.8222\n",
      "Epoch 00009: val_f1_score improved from 0.59041 to 0.59584, saving model to /app/_data/models/final/0858AddTr/eff4_0858_add_tr_3.h5\n",
      "211/211 [==============================] - 140s 662ms/step - loss: 0.0508 - acc: 0.8128 - recall_2: 0.9618 - precision_2: 0.9612 - f1_score: 0.8222 - val_loss: 0.5617 - val_acc: 0.4835 - val_recall_2: 0.7057 - val_precision_2: 0.6999 - val_f1_score: 0.5958\n",
      "Epoch 10/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0433 - acc: 0.8057 - recall_2: 0.9678 - precision_2: 0.9693 - f1_score: 0.8396\n",
      "Epoch 00010: val_f1_score did not improve from 0.59584\n",
      "211/211 [==============================] - 137s 651ms/step - loss: 0.0433 - acc: 0.8057 - recall_2: 0.9678 - precision_2: 0.9693 - f1_score: 0.8396 - val_loss: 0.5733 - val_acc: 0.5239 - val_recall_2: 0.7062 - val_precision_2: 0.6898 - val_f1_score: 0.5545\n",
      "Epoch 11/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0370 - acc: 0.8162 - recall_2: 0.9729 - precision_2: 0.9722 - f1_score: 0.8447\n",
      "Epoch 00011: val_f1_score did not improve from 0.59584\n",
      "211/211 [==============================] - 138s 652ms/step - loss: 0.0370 - acc: 0.8162 - recall_2: 0.9729 - precision_2: 0.9722 - f1_score: 0.8447 - val_loss: 0.6194 - val_acc: 0.5717 - val_recall_2: 0.7053 - val_precision_2: 0.6809 - val_f1_score: 0.5609\n",
      "Epoch 12/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0358 - acc: 0.8199 - recall_2: 0.9738 - precision_2: 0.9745 - f1_score: 0.8541\n",
      "Epoch 00012: val_f1_score did not improve from 0.59584\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00032000001519918444.\n",
      "211/211 [==============================] - 138s 653ms/step - loss: 0.0358 - acc: 0.8199 - recall_2: 0.9738 - precision_2: 0.9745 - f1_score: 0.8541 - val_loss: 0.6307 - val_acc: 0.5018 - val_recall_2: 0.6880 - val_precision_2: 0.6980 - val_f1_score: 0.5628\n",
      "Epoch 13/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0291 - acc: 0.8429 - recall_2: 0.9787 - precision_2: 0.9785 - f1_score: 0.8592\n",
      "Epoch 00013: val_f1_score improved from 0.59584 to 0.60723, saving model to /app/_data/models/final/0858AddTr/eff4_0858_add_tr_3.h5\n",
      "211/211 [==============================] - 140s 661ms/step - loss: 0.0291 - acc: 0.8429 - recall_2: 0.9787 - precision_2: 0.9785 - f1_score: 0.8592 - val_loss: 0.6896 - val_acc: 0.5478 - val_recall_2: 0.7473 - val_precision_2: 0.6893 - val_f1_score: 0.6072\n",
      "Epoch 14/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0260 - acc: 0.8415 - recall_2: 0.9804 - precision_2: 0.9795 - f1_score: 0.8734\n",
      "Epoch 00014: val_f1_score did not improve from 0.60723\n",
      "211/211 [==============================] - 138s 653ms/step - loss: 0.0260 - acc: 0.8415 - recall_2: 0.9804 - precision_2: 0.9795 - f1_score: 0.8734 - val_loss: 0.6180 - val_acc: 0.5496 - val_recall_2: 0.7773 - val_precision_2: 0.6898 - val_f1_score: 0.6035\n",
      "Epoch 15/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0217 - acc: 0.8618 - recall_2: 0.9839 - precision_2: 0.9842 - f1_score: 0.8882\n",
      "Epoch 00015: val_f1_score did not improve from 0.60723\n",
      "211/211 [==============================] - 138s 653ms/step - loss: 0.0217 - acc: 0.8618 - recall_2: 0.9839 - precision_2: 0.9842 - f1_score: 0.8882 - val_loss: 0.6469 - val_acc: 0.5074 - val_recall_2: 0.7083 - val_precision_2: 0.6959 - val_f1_score: 0.5848\n",
      "Epoch 16/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0227 - acc: 0.8535 - recall_2: 0.9830 - precision_2: 0.9823 - f1_score: 0.8889\n",
      "Epoch 00016: val_f1_score did not improve from 0.60723\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0002560000168159604.\n",
      "211/211 [==============================] - 137s 651ms/step - loss: 0.0227 - acc: 0.8535 - recall_2: 0.9830 - precision_2: 0.9823 - f1_score: 0.8889 - val_loss: 0.7430 - val_acc: 0.5496 - val_recall_2: 0.7075 - val_precision_2: 0.6879 - val_f1_score: 0.5878\n",
      "Epoch 17/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0191 - acc: 0.8670 - recall_2: 0.9861 - precision_2: 0.9855 - f1_score: 0.8959\n",
      "Epoch 00017: val_f1_score improved from 0.60723 to 0.61731, saving model to /app/_data/models/final/0858AddTr/eff4_0858_add_tr_3.h5\n",
      "211/211 [==============================] - 140s 661ms/step - loss: 0.0191 - acc: 0.8670 - recall_2: 0.9861 - precision_2: 0.9855 - f1_score: 0.8959 - val_loss: 0.7047 - val_acc: 0.5349 - val_recall_2: 0.7506 - val_precision_2: 0.6895 - val_f1_score: 0.6173\n",
      "Epoch 18/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0165 - acc: 0.8778 - recall_2: 0.9869 - precision_2: 0.9877 - f1_score: 0.9073\n",
      "Epoch 00018: val_f1_score did not improve from 0.61731\n",
      "211/211 [==============================] - 137s 651ms/step - loss: 0.0165 - acc: 0.8778 - recall_2: 0.9869 - precision_2: 0.9877 - f1_score: 0.9073 - val_loss: 0.6727 - val_acc: 0.5257 - val_recall_2: 0.7084 - val_precision_2: 0.6961 - val_f1_score: 0.6157\n",
      "Epoch 19/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0160 - acc: 0.8784 - recall_2: 0.9876 - precision_2: 0.9882 - f1_score: 0.9178\n",
      "Epoch 00019: val_f1_score did not improve from 0.61731\n",
      "211/211 [==============================] - 137s 650ms/step - loss: 0.0160 - acc: 0.8784 - recall_2: 0.9876 - precision_2: 0.9882 - f1_score: 0.9178 - val_loss: 0.7195 - val_acc: 0.5588 - val_recall_2: 0.7040 - val_precision_2: 0.7090 - val_f1_score: 0.6055\n",
      "Epoch 20/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0203 - acc: 0.8817 - recall_2: 0.9847 - precision_2: 0.9851 - f1_score: 0.9048\n",
      "Epoch 00020: val_f1_score did not improve from 0.61731\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.00020480002276599408.\n",
      "211/211 [==============================] - 138s 654ms/step - loss: 0.0203 - acc: 0.8817 - recall_2: 0.9847 - precision_2: 0.9851 - f1_score: 0.9048 - val_loss: 0.6974 - val_acc: 0.5588 - val_recall_2: 0.7387 - val_precision_2: 0.6997 - val_f1_score: 0.6052\n",
      "Epoch 21/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0162 - acc: 0.8845 - recall_2: 0.9875 - precision_2: 0.9864 - f1_score: 0.9140\n",
      "Epoch 00021: val_f1_score did not improve from 0.61731\n",
      "211/211 [==============================] - 137s 650ms/step - loss: 0.0162 - acc: 0.8845 - recall_2: 0.9875 - precision_2: 0.9864 - f1_score: 0.9140 - val_loss: 0.7375 - val_acc: 0.5551 - val_recall_2: 0.7050 - val_precision_2: 0.7025 - val_f1_score: 0.6048\n",
      "Epoch 22/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0129 - acc: 0.9051 - recall_2: 0.9889 - precision_2: 0.9897 - f1_score: 0.9202\n",
      "Epoch 00022: val_f1_score improved from 0.61731 to 0.61996, saving model to /app/_data/models/final/0858AddTr/eff4_0858_add_tr_3.h5\n",
      "211/211 [==============================] - 140s 661ms/step - loss: 0.0129 - acc: 0.9051 - recall_2: 0.9889 - precision_2: 0.9897 - f1_score: 0.9202 - val_loss: 0.6990 - val_acc: 0.5496 - val_recall_2: 0.7470 - val_precision_2: 0.7166 - val_f1_score: 0.6200\n",
      "Epoch 23/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0132 - acc: 0.8965 - recall_2: 0.9901 - precision_2: 0.9885 - f1_score: 0.9223\n",
      "Epoch 00023: val_f1_score did not improve from 0.61996\n",
      "211/211 [==============================] - 138s 652ms/step - loss: 0.0132 - acc: 0.8965 - recall_2: 0.9901 - precision_2: 0.9885 - f1_score: 0.9223 - val_loss: 0.7451 - val_acc: 0.6066 - val_recall_2: 0.7437 - val_precision_2: 0.6903 - val_f1_score: 0.6197\n",
      "Epoch 24/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0124 - acc: 0.9091 - recall_2: 0.9894 - precision_2: 0.9894 - f1_score: 0.9271\n",
      "Epoch 00024: val_f1_score improved from 0.61996 to 0.63516, saving model to /app/_data/models/final/0858AddTr/eff4_0858_add_tr_3.h5\n",
      "211/211 [==============================] - 140s 663ms/step - loss: 0.0124 - acc: 0.9091 - recall_2: 0.9894 - precision_2: 0.9894 - f1_score: 0.9271 - val_loss: 0.7092 - val_acc: 0.5938 - val_recall_2: 0.7589 - val_precision_2: 0.7092 - val_f1_score: 0.6352\n",
      "Epoch 25/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0098 - acc: 0.9162 - recall_2: 0.9919 - precision_2: 0.9912 - f1_score: 0.9330\n",
      "Epoch 00025: val_f1_score did not improve from 0.63516\n",
      "211/211 [==============================] - 138s 652ms/step - loss: 0.0098 - acc: 0.9162 - recall_2: 0.9919 - precision_2: 0.9912 - f1_score: 0.9330 - val_loss: 0.7987 - val_acc: 0.5754 - val_recall_2: 0.7205 - val_precision_2: 0.6975 - val_f1_score: 0.6309\n",
      "Epoch 26/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0114 - acc: 0.9163 - recall_2: 0.9902 - precision_2: 0.9895 - f1_score: 0.9261\n",
      "Epoch 00026: val_f1_score did not improve from 0.63516\n",
      "211/211 [==============================] - 137s 652ms/step - loss: 0.0114 - acc: 0.9163 - recall_2: 0.9902 - precision_2: 0.9895 - f1_score: 0.9261 - val_loss: 0.7914 - val_acc: 0.5827 - val_recall_2: 0.7284 - val_precision_2: 0.7106 - val_f1_score: 0.6305\n",
      "Epoch 27/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0140 - acc: 0.9042 - recall_2: 0.9882 - precision_2: 0.9887 - f1_score: 0.9248\n",
      "Epoch 00027: val_f1_score did not improve from 0.63516\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.00016384001355618238.\n",
      "211/211 [==============================] - 137s 651ms/step - loss: 0.0140 - acc: 0.9042 - recall_2: 0.9882 - precision_2: 0.9887 - f1_score: 0.9248 - val_loss: 0.7666 - val_acc: 0.5790 - val_recall_2: 0.6635 - val_precision_2: 0.7170 - val_f1_score: 0.5982\n",
      "Epoch 28/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0117 - acc: 0.9017 - recall_2: 0.9919 - precision_2: 0.9900 - f1_score: 0.9248\n",
      "Epoch 00028: val_f1_score did not improve from 0.63516\n",
      "211/211 [==============================] - 137s 651ms/step - loss: 0.0117 - acc: 0.9017 - recall_2: 0.9919 - precision_2: 0.9900 - f1_score: 0.9248 - val_loss: 0.7875 - val_acc: 0.5643 - val_recall_2: 0.7214 - val_precision_2: 0.7121 - val_f1_score: 0.6281\n",
      "Epoch 29/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0092 - acc: 0.9154 - recall_2: 0.9931 - precision_2: 0.9910 - f1_score: 0.9358\n",
      "Epoch 00029: val_f1_score did not improve from 0.63516\n",
      "211/211 [==============================] - 137s 650ms/step - loss: 0.0092 - acc: 0.9154 - recall_2: 0.9931 - precision_2: 0.9910 - f1_score: 0.9358 - val_loss: 0.7852 - val_acc: 0.5974 - val_recall_2: 0.6928 - val_precision_2: 0.7139 - val_f1_score: 0.6268\n",
      "Epoch 30/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0102 - acc: 0.9190 - recall_2: 0.9919 - precision_2: 0.9912 - f1_score: 0.9379\n",
      "Epoch 00030: val_f1_score did not improve from 0.63516\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0001310720108449459.\n",
      "211/211 [==============================] - 137s 651ms/step - loss: 0.0102 - acc: 0.9190 - recall_2: 0.9919 - precision_2: 0.9912 - f1_score: 0.9379 - val_loss: 0.7799 - val_acc: 0.5625 - val_recall_2: 0.7106 - val_precision_2: 0.6998 - val_f1_score: 0.6158\n",
      "Epoch 31/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0090 - acc: 0.9154 - recall_2: 0.9922 - precision_2: 0.9926 - f1_score: 0.9382\n",
      "Epoch 00031: val_f1_score did not improve from 0.63516\n",
      "211/211 [==============================] - 138s 653ms/step - loss: 0.0090 - acc: 0.9154 - recall_2: 0.9922 - precision_2: 0.9926 - f1_score: 0.9382 - val_loss: 0.7759 - val_acc: 0.5515 - val_recall_2: 0.7241 - val_precision_2: 0.7000 - val_f1_score: 0.6221\n",
      "Epoch 32/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0083 - acc: 0.9224 - recall_2: 0.9925 - precision_2: 0.9930 - f1_score: 0.9442Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00032: val_f1_score did not improve from 0.63516\n",
      "211/211 [==============================] - 138s 652ms/step - loss: 0.0083 - acc: 0.9224 - recall_2: 0.9925 - precision_2: 0.9930 - f1_score: 0.9442 - val_loss: 0.7795 - val_acc: 0.5901 - val_recall_2: 0.7290 - val_precision_2: 0.7064 - val_f1_score: 0.6304\n",
      "Epoch 00032: early stopping\n",
      "(6765, 8) (564, 8)\n",
      "Epoch 1/50\n",
      "  2/211 [..............................] - ETA: 5:16 - loss: 0.8740 - acc: 0.3281 - recall_3: 0.4490 - precision_3: 0.6377 - f1_score: 0.4638WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.6717s vs `on_train_batch_end` time: 2.3595s). Check your callbacks.\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.2614 - acc: 0.6086 - recall_3: 0.7656 - precision_3: 0.7847 - f1_score: 0.6314\n",
      "Epoch 00001: val_f1_score improved from -inf to 0.51312, saving model to /app/_data/models/final/0858AddTr/eff4_0858_add_tr_4.h5\n",
      "211/211 [==============================] - 147s 698ms/step - loss: 0.2614 - acc: 0.6086 - recall_3: 0.7656 - precision_3: 0.7847 - f1_score: 0.6314 - val_loss: 0.3577 - val_acc: 0.6434 - val_recall_3: 0.7216 - val_precision_3: 0.7049 - val_f1_score: 0.5131\n",
      "Epoch 2/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.1689 - acc: 0.6822 - recall_3: 0.8582 - precision_3: 0.8616 - f1_score: 0.6975\n",
      "Epoch 00002: val_f1_score improved from 0.51312 to 0.61906, saving model to /app/_data/models/final/0858AddTr/eff4_0858_add_tr_4.h5\n",
      "211/211 [==============================] - 140s 663ms/step - loss: 0.1689 - acc: 0.6822 - recall_3: 0.8582 - precision_3: 0.8616 - f1_score: 0.6975 - val_loss: 0.2988 - val_acc: 0.5588 - val_recall_3: 0.7803 - val_precision_3: 0.7552 - val_f1_score: 0.6191\n",
      "Epoch 3/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.1300 - acc: 0.7257 - recall_3: 0.8937 - precision_3: 0.8968 - f1_score: 0.7326\n",
      "Epoch 00003: val_f1_score did not improve from 0.61906\n",
      "211/211 [==============================] - 138s 652ms/step - loss: 0.1300 - acc: 0.7257 - recall_3: 0.8937 - precision_3: 0.8968 - f1_score: 0.7326 - val_loss: 0.3701 - val_acc: 0.5257 - val_recall_3: 0.7910 - val_precision_3: 0.7534 - val_f1_score: 0.6083\n",
      "Epoch 4/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.1016 - acc: 0.7266 - recall_3: 0.9189 - precision_3: 0.9219 - f1_score: 0.7462\n",
      "Epoch 00004: val_f1_score did not improve from 0.61906\n",
      "211/211 [==============================] - 138s 653ms/step - loss: 0.1016 - acc: 0.7266 - recall_3: 0.9189 - precision_3: 0.9219 - f1_score: 0.7462 - val_loss: 0.3530 - val_acc: 0.5533 - val_recall_3: 0.7408 - val_precision_3: 0.7709 - val_f1_score: 0.6098\n",
      "Epoch 5/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0809 - acc: 0.7456 - recall_3: 0.9386 - precision_3: 0.9400 - f1_score: 0.7755\n",
      "Epoch 00005: val_f1_score did not improve from 0.61906\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00032000001519918444.\n",
      "211/211 [==============================] - 138s 652ms/step - loss: 0.0809 - acc: 0.7456 - recall_3: 0.9386 - precision_3: 0.9400 - f1_score: 0.7755 - val_loss: 0.4074 - val_acc: 0.5662 - val_recall_3: 0.7328 - val_precision_3: 0.7571 - val_f1_score: 0.6068\n",
      "Epoch 6/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0585 - acc: 0.7773 - recall_3: 0.9534 - precision_3: 0.9585 - f1_score: 0.8005\n",
      "Epoch 00006: val_f1_score improved from 0.61906 to 0.62001, saving model to /app/_data/models/final/0858AddTr/eff4_0858_add_tr_4.h5\n",
      "211/211 [==============================] - 139s 660ms/step - loss: 0.0585 - acc: 0.7773 - recall_3: 0.9534 - precision_3: 0.9585 - f1_score: 0.8005 - val_loss: 0.4173 - val_acc: 0.6029 - val_recall_3: 0.7836 - val_precision_3: 0.7514 - val_f1_score: 0.6200\n",
      "Epoch 7/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0531 - acc: 0.7930 - recall_3: 0.9610 - precision_3: 0.9617 - f1_score: 0.8037\n",
      "Epoch 00007: val_f1_score improved from 0.62001 to 0.63454, saving model to /app/_data/models/final/0858AddTr/eff4_0858_add_tr_4.h5\n",
      "211/211 [==============================] - 140s 662ms/step - loss: 0.0531 - acc: 0.7930 - recall_3: 0.9610 - precision_3: 0.9617 - f1_score: 0.8037 - val_loss: 0.4248 - val_acc: 0.6140 - val_recall_3: 0.8098 - val_precision_3: 0.7402 - val_f1_score: 0.6345\n",
      "Epoch 8/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0457 - acc: 0.7783 - recall_3: 0.9670 - precision_3: 0.9681 - f1_score: 0.8225\n",
      "Epoch 00008: val_f1_score did not improve from 0.63454\n",
      "211/211 [==============================] - 138s 653ms/step - loss: 0.0457 - acc: 0.7783 - recall_3: 0.9670 - precision_3: 0.9681 - f1_score: 0.8225 - val_loss: 0.4350 - val_acc: 0.5588 - val_recall_3: 0.7571 - val_precision_3: 0.7465 - val_f1_score: 0.6145\n",
      "Epoch 9/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0398 - acc: 0.8004 - recall_3: 0.9695 - precision_3: 0.9714 - f1_score: 0.8378\n",
      "Epoch 00009: val_f1_score improved from 0.63454 to 0.63525, saving model to /app/_data/models/final/0858AddTr/eff4_0858_add_tr_4.h5\n",
      "211/211 [==============================] - 140s 664ms/step - loss: 0.0398 - acc: 0.8004 - recall_3: 0.9695 - precision_3: 0.9714 - f1_score: 0.8378 - val_loss: 0.4701 - val_acc: 0.6029 - val_recall_3: 0.7372 - val_precision_3: 0.7607 - val_f1_score: 0.6353\n",
      "Epoch 10/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0372 - acc: 0.8315 - recall_3: 0.9708 - precision_3: 0.9719 - f1_score: 0.8486\n",
      "Epoch 00010: val_f1_score did not improve from 0.63525\n",
      "211/211 [==============================] - 138s 652ms/step - loss: 0.0372 - acc: 0.8315 - recall_3: 0.9708 - precision_3: 0.9719 - f1_score: 0.8486 - val_loss: 0.5121 - val_acc: 0.5735 - val_recall_3: 0.7616 - val_precision_3: 0.7535 - val_f1_score: 0.6315\n",
      "Epoch 11/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0338 - acc: 0.8362 - recall_3: 0.9754 - precision_3: 0.9754 - f1_score: 0.8655\n",
      "Epoch 00011: val_f1_score did not improve from 0.63525\n",
      "211/211 [==============================] - 138s 655ms/step - loss: 0.0338 - acc: 0.8362 - recall_3: 0.9754 - precision_3: 0.9754 - f1_score: 0.8655 - val_loss: 0.5554 - val_acc: 0.5551 - val_recall_3: 0.6918 - val_precision_3: 0.7366 - val_f1_score: 0.5719\n",
      "Epoch 12/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0347 - acc: 0.8335 - recall_3: 0.9740 - precision_3: 0.9737 - f1_score: 0.8625\n",
      "Epoch 00012: val_f1_score improved from 0.63525 to 0.65382, saving model to /app/_data/models/final/0858AddTr/eff4_0858_add_tr_4.h5\n",
      "211/211 [==============================] - 140s 661ms/step - loss: 0.0347 - acc: 0.8335 - recall_3: 0.9740 - precision_3: 0.9737 - f1_score: 0.8625 - val_loss: 0.4298 - val_acc: 0.5699 - val_recall_3: 0.7969 - val_precision_3: 0.7599 - val_f1_score: 0.6538\n",
      "Epoch 13/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0330 - acc: 0.8362 - recall_3: 0.9758 - precision_3: 0.9765 - f1_score: 0.8633\n",
      "Epoch 00013: val_f1_score did not improve from 0.65382\n",
      "211/211 [==============================] - 138s 653ms/step - loss: 0.0330 - acc: 0.8362 - recall_3: 0.9758 - precision_3: 0.9765 - f1_score: 0.8633 - val_loss: 0.5232 - val_acc: 0.5441 - val_recall_3: 0.7509 - val_precision_3: 0.7572 - val_f1_score: 0.6299\n",
      "Epoch 14/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0293 - acc: 0.8405 - recall_3: 0.9772 - precision_3: 0.9794 - f1_score: 0.8700\n",
      "Epoch 00014: val_f1_score did not improve from 0.65382\n",
      "211/211 [==============================] - 138s 652ms/step - loss: 0.0293 - acc: 0.8405 - recall_3: 0.9772 - precision_3: 0.9794 - f1_score: 0.8700 - val_loss: 0.5140 - val_acc: 0.5901 - val_recall_3: 0.7834 - val_precision_3: 0.7315 - val_f1_score: 0.6167\n",
      "Epoch 15/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0332 - acc: 0.8424 - recall_3: 0.9751 - precision_3: 0.9764 - f1_score: 0.8729\n",
      "Epoch 00015: val_f1_score did not improve from 0.65382\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0002560000168159604.\n",
      "211/211 [==============================] - 139s 658ms/step - loss: 0.0332 - acc: 0.8424 - recall_3: 0.9751 - precision_3: 0.9764 - f1_score: 0.8729 - val_loss: 0.5270 - val_acc: 0.5772 - val_recall_3: 0.7485 - val_precision_3: 0.7389 - val_f1_score: 0.6333\n",
      "Epoch 16/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0241 - acc: 0.8446 - recall_3: 0.9814 - precision_3: 0.9834 - f1_score: 0.8887\n",
      "Epoch 00016: val_f1_score did not improve from 0.65382\n",
      "211/211 [==============================] - 138s 653ms/step - loss: 0.0241 - acc: 0.8446 - recall_3: 0.9814 - precision_3: 0.9834 - f1_score: 0.8887 - val_loss: 0.5131 - val_acc: 0.5257 - val_recall_3: 0.7565 - val_precision_3: 0.7512 - val_f1_score: 0.6487\n",
      "Epoch 17/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0227 - acc: 0.8658 - recall_3: 0.9824 - precision_3: 0.9815 - f1_score: 0.8910\n",
      "Epoch 00017: val_f1_score improved from 0.65382 to 0.66199, saving model to /app/_data/models/final/0858AddTr/eff4_0858_add_tr_4.h5\n",
      "211/211 [==============================] - 140s 662ms/step - loss: 0.0227 - acc: 0.8658 - recall_3: 0.9824 - precision_3: 0.9815 - f1_score: 0.8910 - val_loss: 0.5090 - val_acc: 0.6011 - val_recall_3: 0.7743 - val_precision_3: 0.7617 - val_f1_score: 0.6620\n",
      "Epoch 18/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0194 - acc: 0.8763 - recall_3: 0.9840 - precision_3: 0.9868 - f1_score: 0.8985\n",
      "Epoch 00018: val_f1_score did not improve from 0.66199\n",
      "211/211 [==============================] - 138s 652ms/step - loss: 0.0194 - acc: 0.8763 - recall_3: 0.9840 - precision_3: 0.9868 - f1_score: 0.8985 - val_loss: 0.5538 - val_acc: 0.6011 - val_recall_3: 0.7378 - val_precision_3: 0.7308 - val_f1_score: 0.6206\n",
      "Epoch 19/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0213 - acc: 0.8720 - recall_3: 0.9838 - precision_3: 0.9825 - f1_score: 0.9008\n",
      "Epoch 00019: val_f1_score did not improve from 0.66199\n",
      "211/211 [==============================] - 138s 652ms/step - loss: 0.0213 - acc: 0.8720 - recall_3: 0.9838 - precision_3: 0.9825 - f1_score: 0.9008 - val_loss: 0.5302 - val_acc: 0.5864 - val_recall_3: 0.7372 - val_precision_3: 0.7635 - val_f1_score: 0.6331\n",
      "Epoch 20/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0180 - acc: 0.8716 - recall_3: 0.9859 - precision_3: 0.9861 - f1_score: 0.9054\n",
      "Epoch 00020: val_f1_score improved from 0.66199 to 0.67696, saving model to /app/_data/models/final/0858AddTr/eff4_0858_add_tr_4.h5\n",
      "211/211 [==============================] - 140s 662ms/step - loss: 0.0180 - acc: 0.8716 - recall_3: 0.9859 - precision_3: 0.9861 - f1_score: 0.9054 - val_loss: 0.5863 - val_acc: 0.6011 - val_recall_3: 0.8017 - val_precision_3: 0.7341 - val_f1_score: 0.6770\n",
      "Epoch 21/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0164 - acc: 0.8763 - recall_3: 0.9867 - precision_3: 0.9880 - f1_score: 0.9146\n",
      "Epoch 00021: val_f1_score did not improve from 0.67696\n",
      "211/211 [==============================] - 138s 653ms/step - loss: 0.0164 - acc: 0.8763 - recall_3: 0.9867 - precision_3: 0.9880 - f1_score: 0.9146 - val_loss: 0.6181 - val_acc: 0.5901 - val_recall_3: 0.7533 - val_precision_3: 0.7453 - val_f1_score: 0.6681\n",
      "Epoch 22/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0187 - acc: 0.8852 - recall_3: 0.9838 - precision_3: 0.9853 - f1_score: 0.9124\n",
      "Epoch 00022: val_f1_score did not improve from 0.67696\n",
      "211/211 [==============================] - 138s 653ms/step - loss: 0.0187 - acc: 0.8852 - recall_3: 0.9838 - precision_3: 0.9853 - f1_score: 0.9124 - val_loss: 0.6929 - val_acc: 0.6544 - val_recall_3: 0.7912 - val_precision_3: 0.7242 - val_f1_score: 0.6710\n",
      "Epoch 23/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0194 - acc: 0.8928 - recall_3: 0.9851 - precision_3: 0.9847 - f1_score: 0.9136\n",
      "Epoch 00023: val_f1_score did not improve from 0.67696\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.00020480002276599408.\n",
      "211/211 [==============================] - 138s 652ms/step - loss: 0.0194 - acc: 0.8928 - recall_3: 0.9851 - precision_3: 0.9847 - f1_score: 0.9136 - val_loss: 0.6324 - val_acc: 0.5901 - val_recall_3: 0.7556 - val_precision_3: 0.7255 - val_f1_score: 0.6540\n",
      "Epoch 24/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0173 - acc: 0.8854 - recall_3: 0.9867 - precision_3: 0.9869 - f1_score: 0.9165\n",
      "Epoch 00024: val_f1_score did not improve from 0.67696\n",
      "211/211 [==============================] - 138s 653ms/step - loss: 0.0173 - acc: 0.8854 - recall_3: 0.9867 - precision_3: 0.9869 - f1_score: 0.9165 - val_loss: 0.6107 - val_acc: 0.5956 - val_recall_3: 0.7634 - val_precision_3: 0.7345 - val_f1_score: 0.6710\n",
      "Epoch 25/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0137 - acc: 0.8894 - recall_3: 0.9878 - precision_3: 0.9897 - f1_score: 0.9218\n",
      "Epoch 00025: val_f1_score did not improve from 0.67696\n",
      "211/211 [==============================] - 138s 652ms/step - loss: 0.0137 - acc: 0.8894 - recall_3: 0.9878 - precision_3: 0.9897 - f1_score: 0.9218 - val_loss: 0.6154 - val_acc: 0.6121 - val_recall_3: 0.7598 - val_precision_3: 0.7491 - val_f1_score: 0.6638\n",
      "Epoch 26/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0136 - acc: 0.9055 - recall_3: 0.9887 - precision_3: 0.9889 - f1_score: 0.9279\n",
      "Epoch 00026: val_f1_score did not improve from 0.67696\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.00016384001355618238.\n",
      "211/211 [==============================] - 138s 652ms/step - loss: 0.0136 - acc: 0.9055 - recall_3: 0.9887 - precision_3: 0.9889 - f1_score: 0.9279 - val_loss: 0.6039 - val_acc: 0.5735 - val_recall_3: 0.7082 - val_precision_3: 0.7444 - val_f1_score: 0.6199\n",
      "Epoch 27/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0121 - acc: 0.8996 - recall_3: 0.9887 - precision_3: 0.9899 - f1_score: 0.9269\n",
      "Epoch 00027: val_f1_score did not improve from 0.67696\n",
      "211/211 [==============================] - 138s 652ms/step - loss: 0.0121 - acc: 0.8996 - recall_3: 0.9887 - precision_3: 0.9899 - f1_score: 0.9269 - val_loss: 0.5859 - val_acc: 0.6195 - val_recall_3: 0.7521 - val_precision_3: 0.7441 - val_f1_score: 0.6573\n",
      "Epoch 28/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0124 - acc: 0.9095 - recall_3: 0.9912 - precision_3: 0.9895 - f1_score: 0.9310Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00028: val_f1_score did not improve from 0.67696\n",
      "211/211 [==============================] - 138s 654ms/step - loss: 0.0124 - acc: 0.9095 - recall_3: 0.9912 - precision_3: 0.9895 - f1_score: 0.9310 - val_loss: 0.5779 - val_acc: 0.5882 - val_recall_3: 0.7733 - val_precision_3: 0.7561 - val_f1_score: 0.6626\n",
      "Epoch 00028: early stopping\n",
      "(6768, 8) (563, 8)\n",
      "Epoch 1/50\n",
      "  2/211 [..............................] - ETA: 5:39 - loss: 0.9351 - acc: 0.5000 - recall_4: 0.6413 - precision_4: 0.7867 - f1_score: 0.6265WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.7011s vs `on_train_batch_end` time: 2.5492s). Check your callbacks.\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.1941 - acc: 0.6925 - recall_4: 0.8576 - precision_4: 0.8707 - f1_score: 0.7031\n",
      "Epoch 00001: val_f1_score improved from -inf to 0.73654, saving model to /app/_data/models/final/0858AddTr/eff4_0858_add_tr_5.h5\n",
      "211/211 [==============================] - 148s 700ms/step - loss: 0.1941 - acc: 0.6925 - recall_4: 0.8576 - precision_4: 0.8707 - f1_score: 0.7031 - val_loss: 0.1615 - val_acc: 0.7684 - val_recall_4: 0.8568 - val_precision_4: 0.8964 - val_f1_score: 0.7365\n",
      "Epoch 2/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0875 - acc: 0.7573 - recall_4: 0.9312 - precision_4: 0.9346 - f1_score: 0.7721\n",
      "Epoch 00002: val_f1_score did not improve from 0.73654\n",
      "211/211 [==============================] - 138s 653ms/step - loss: 0.0875 - acc: 0.7573 - recall_4: 0.9312 - precision_4: 0.9346 - f1_score: 0.7721 - val_loss: 0.1849 - val_acc: 0.7721 - val_recall_4: 0.8671 - val_precision_4: 0.8871 - val_f1_score: 0.7066\n",
      "Epoch 3/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0664 - acc: 0.7573 - recall_4: 0.9489 - precision_4: 0.9540 - f1_score: 0.8006\n",
      "Epoch 00003: val_f1_score improved from 0.73654 to 0.73868, saving model to /app/_data/models/final/0858AddTr/eff4_0858_add_tr_5.h5\n",
      "211/211 [==============================] - 140s 665ms/step - loss: 0.0664 - acc: 0.7573 - recall_4: 0.9489 - precision_4: 0.9540 - f1_score: 0.8006 - val_loss: 0.2233 - val_acc: 0.7188 - val_recall_4: 0.8701 - val_precision_4: 0.8690 - val_f1_score: 0.7387\n",
      "Epoch 4/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0524 - acc: 0.7793 - recall_4: 0.9606 - precision_4: 0.9649 - f1_score: 0.8195\n",
      "Epoch 00004: val_f1_score improved from 0.73868 to 0.76147, saving model to /app/_data/models/final/0858AddTr/eff4_0858_add_tr_5.h5\n",
      "211/211 [==============================] - 140s 663ms/step - loss: 0.0524 - acc: 0.7793 - recall_4: 0.9606 - precision_4: 0.9649 - f1_score: 0.8195 - val_loss: 0.2028 - val_acc: 0.7518 - val_recall_4: 0.8969 - val_precision_4: 0.8906 - val_f1_score: 0.7615\n",
      "Epoch 5/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0412 - acc: 0.7950 - recall_4: 0.9705 - precision_4: 0.9719 - f1_score: 0.8330\n",
      "Epoch 00005: val_f1_score did not improve from 0.76147\n",
      "211/211 [==============================] - 138s 652ms/step - loss: 0.0412 - acc: 0.7950 - recall_4: 0.9705 - precision_4: 0.9719 - f1_score: 0.8330 - val_loss: 0.2339 - val_acc: 0.7629 - val_recall_4: 0.8768 - val_precision_4: 0.8634 - val_f1_score: 0.7443\n",
      "Epoch 6/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0413 - acc: 0.8045 - recall_4: 0.9689 - precision_4: 0.9721 - f1_score: 0.8491\n",
      "Epoch 00006: val_f1_score did not improve from 0.76147\n",
      "211/211 [==============================] - 137s 651ms/step - loss: 0.0413 - acc: 0.8045 - recall_4: 0.9689 - precision_4: 0.9721 - f1_score: 0.8491 - val_loss: 0.2636 - val_acc: 0.7353 - val_recall_4: 0.8504 - val_precision_4: 0.8848 - val_f1_score: 0.7432\n",
      "Epoch 7/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0364 - acc: 0.8166 - recall_4: 0.9721 - precision_4: 0.9747 - f1_score: 0.8525\n",
      "Epoch 00007: val_f1_score did not improve from 0.76147\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0002560000168159604.\n",
      "211/211 [==============================] - 138s 652ms/step - loss: 0.0364 - acc: 0.8166 - recall_4: 0.9721 - precision_4: 0.9747 - f1_score: 0.8525 - val_loss: 0.2877 - val_acc: 0.7684 - val_recall_4: 0.8381 - val_precision_4: 0.8753 - val_f1_score: 0.7416\n",
      "Epoch 8/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0308 - acc: 0.8355 - recall_4: 0.9769 - precision_4: 0.9783 - f1_score: 0.8679\n",
      "Epoch 00008: val_f1_score improved from 0.76147 to 0.79688, saving model to /app/_data/models/final/0858AddTr/eff4_0858_add_tr_5.h5\n",
      "211/211 [==============================] - 140s 663ms/step - loss: 0.0308 - acc: 0.8355 - recall_4: 0.9769 - precision_4: 0.9783 - f1_score: 0.8679 - val_loss: 0.2279 - val_acc: 0.7610 - val_recall_4: 0.8738 - val_precision_4: 0.8812 - val_f1_score: 0.7969\n",
      "Epoch 9/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0219 - acc: 0.8550 - recall_4: 0.9830 - precision_4: 0.9836 - f1_score: 0.8847\n",
      "Epoch 00009: val_f1_score did not improve from 0.79688\n",
      "211/211 [==============================] - 138s 655ms/step - loss: 0.0219 - acc: 0.8550 - recall_4: 0.9830 - precision_4: 0.9836 - f1_score: 0.8847 - val_loss: 0.2399 - val_acc: 0.7684 - val_recall_4: 0.8827 - val_precision_4: 0.8901 - val_f1_score: 0.7921\n",
      "Epoch 10/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0195 - acc: 0.8790 - recall_4: 0.9862 - precision_4: 0.9853 - f1_score: 0.9057\n",
      "Epoch 00010: val_f1_score did not improve from 0.79688\n",
      "211/211 [==============================] - 138s 653ms/step - loss: 0.0195 - acc: 0.8790 - recall_4: 0.9862 - precision_4: 0.9853 - f1_score: 0.9057 - val_loss: 0.2712 - val_acc: 0.7316 - val_recall_4: 0.8604 - val_precision_4: 0.8890 - val_f1_score: 0.7957\n",
      "Epoch 11/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0236 - acc: 0.8637 - recall_4: 0.9819 - precision_4: 0.9831 - f1_score: 0.8897\n",
      "Epoch 00011: val_f1_score improved from 0.79688 to 0.80634, saving model to /app/_data/models/final/0858AddTr/eff4_0858_add_tr_5.h5\n",
      "211/211 [==============================] - 140s 663ms/step - loss: 0.0236 - acc: 0.8637 - recall_4: 0.9819 - precision_4: 0.9831 - f1_score: 0.8897 - val_loss: 0.2656 - val_acc: 0.7224 - val_recall_4: 0.8694 - val_precision_4: 0.8602 - val_f1_score: 0.8063\n",
      "Epoch 12/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0210 - acc: 0.8663 - recall_4: 0.9840 - precision_4: 0.9841 - f1_score: 0.8963\n",
      "Epoch 00012: val_f1_score did not improve from 0.80634\n",
      "211/211 [==============================] - 138s 655ms/step - loss: 0.0210 - acc: 0.8663 - recall_4: 0.9840 - precision_4: 0.9841 - f1_score: 0.8963 - val_loss: 0.2688 - val_acc: 0.7610 - val_recall_4: 0.8668 - val_precision_4: 0.8710 - val_f1_score: 0.7692\n",
      "Epoch 13/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0182 - acc: 0.8695 - recall_4: 0.9863 - precision_4: 0.9866 - f1_score: 0.9024\n",
      "Epoch 00013: val_f1_score did not improve from 0.80634\n",
      "211/211 [==============================] - 138s 655ms/step - loss: 0.0182 - acc: 0.8695 - recall_4: 0.9863 - precision_4: 0.9866 - f1_score: 0.9024 - val_loss: 0.2969 - val_acc: 0.7555 - val_recall_4: 0.8670 - val_precision_4: 0.8774 - val_f1_score: 0.7912\n",
      "Epoch 14/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0160 - acc: 0.8892 - recall_4: 0.9875 - precision_4: 0.9875 - f1_score: 0.9170\n",
      "Epoch 00014: val_f1_score did not improve from 0.80634\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.00020480002276599408.\n",
      "211/211 [==============================] - 138s 655ms/step - loss: 0.0160 - acc: 0.8892 - recall_4: 0.9875 - precision_4: 0.9875 - f1_score: 0.9170 - val_loss: 0.3205 - val_acc: 0.7206 - val_recall_4: 0.8529 - val_precision_4: 0.8932 - val_f1_score: 0.7597\n",
      "Epoch 15/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0187 - acc: 0.8861 - recall_4: 0.9842 - precision_4: 0.9869 - f1_score: 0.9162\n",
      "Epoch 00015: val_f1_score did not improve from 0.80634\n",
      "211/211 [==============================] - 139s 658ms/step - loss: 0.0187 - acc: 0.8861 - recall_4: 0.9842 - precision_4: 0.9869 - f1_score: 0.9162 - val_loss: 0.3194 - val_acc: 0.7279 - val_recall_4: 0.8555 - val_precision_4: 0.8636 - val_f1_score: 0.7665\n",
      "Epoch 16/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0165 - acc: 0.8971 - recall_4: 0.9877 - precision_4: 0.9873 - f1_score: 0.9145\n",
      "Epoch 00016: val_f1_score did not improve from 0.80634\n",
      "211/211 [==============================] - 139s 657ms/step - loss: 0.0165 - acc: 0.8971 - recall_4: 0.9877 - precision_4: 0.9873 - f1_score: 0.9145 - val_loss: 0.3502 - val_acc: 0.7261 - val_recall_4: 0.8612 - val_precision_4: 0.8571 - val_f1_score: 0.7728\n",
      "Epoch 17/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0139 - acc: 0.9097 - recall_4: 0.9886 - precision_4: 0.9894 - f1_score: 0.9220\n",
      "Epoch 00017: val_f1_score did not improve from 0.80634\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.00016384001355618238.\n",
      "211/211 [==============================] - 139s 657ms/step - loss: 0.0139 - acc: 0.9097 - recall_4: 0.9886 - precision_4: 0.9894 - f1_score: 0.9220 - val_loss: 0.3204 - val_acc: 0.7665 - val_recall_4: 0.8844 - val_precision_4: 0.8699 - val_f1_score: 0.7985\n",
      "Epoch 18/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0144 - acc: 0.8898 - recall_4: 0.9877 - precision_4: 0.9893 - f1_score: 0.9236\n",
      "Epoch 00018: val_f1_score did not improve from 0.80634\n",
      "211/211 [==============================] - 139s 659ms/step - loss: 0.0144 - acc: 0.8898 - recall_4: 0.9877 - precision_4: 0.9893 - f1_score: 0.9236 - val_loss: 0.3294 - val_acc: 0.7684 - val_recall_4: 0.8720 - val_precision_4: 0.8751 - val_f1_score: 0.7764\n",
      "Epoch 19/50\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0110 - acc: 0.9134 - recall_4: 0.9908 - precision_4: 0.9920 - f1_score: 0.9296Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00019: val_f1_score did not improve from 0.80634\n",
      "211/211 [==============================] - 139s 661ms/step - loss: 0.0110 - acc: 0.9134 - recall_4: 0.9908 - precision_4: 0.9920 - f1_score: 0.9296 - val_loss: 0.3142 - val_acc: 0.7482 - val_recall_4: 0.8812 - val_precision_4: 0.8823 - val_f1_score: 0.7927\n",
      "Epoch 00019: early stopping\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=SEED, shuffle=True)\n",
    "\n",
    "for i, (train_index, valid_index) in enumerate(\n",
    "    skf.split(df_wrong[\"image\"], df_wrong[\"labels\"])\n",
    "):\n",
    "    train, valid = df_wrong.loc[train_index], df_wrong.loc[valid_index]\n",
    "    train = train.sample(frac=3, random_state=SEED, replace=True).reset_index(drop=True)\n",
    "    print(train.shape, valid.shape)\n",
    "\n",
    "\n",
    "    model_name = \"eff4_0858_add_tr_\" + str(i + 1) + \".h5\"\n",
    "    log_dir = \"logs_0865_add_tr_\" + str(i + 1) + \"/\"\n",
    "    callbacks = [\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_f1_score\",\n",
    "            patience=8,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1,\n",
    "            mode=\"max\",\n",
    "        ),\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            \"/app/_data/models/final/0858AddTr/\" + model_name,\n",
    "            monitor=\"val_f1_score\",\n",
    "            verbose=1,\n",
    "            save_best_only=True,\n",
    "            save_weights_only=False,\n",
    "            mode=\"max\",\n",
    "            save_freq=\"epoch\",\n",
    "        ),\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor=\"val_f1_score\",\n",
    "            factor=0.8,\n",
    "            patience=3,\n",
    "            verbose=1,\n",
    "            mode=\"max\",\n",
    "            min_delta=1e-4,\n",
    "            min_lr=0.00000001,\n",
    "        ),\n",
    "        keras.callbacks.TensorBoard(\n",
    "            log_dir=\"/app/.tensorboard/\" + log_dir, histogram_freq=0\n",
    "        ),\n",
    "        keras.callbacks.experimental.BackupAndRestore(\"/app/_data/models/final/0858AddTr/backup/\")\n",
    "    ]\n",
    "\n",
    "    gen_train = Generator(\n",
    "        df=train,\n",
    "        images_src_dir=TRAIN_IMG_PATH,\n",
    "        target_image_size=IMAGE_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        augment=True,\n",
    "        crop=False,\n",
    "        resize=False,\n",
    "    )\n",
    "    gen_valid = Generator(\n",
    "        df=valid,\n",
    "        images_src_dir=TRAIN_IMG_PATH,\n",
    "        target_image_size=IMAGE_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        augment=False,\n",
    "        crop=False,\n",
    "        resize=False,\n",
    "    )\n",
    "    model = keras.models.load_model('/app/_data/models/eff4_kf/0865fulltrain/'+list_models[i])\n",
    "    history = model.fit(\n",
    "        gen_train,\n",
    "        validation_data=gen_valid,\n",
    "        epochs=50,\n",
    "        steps_per_epoch=train.shape[0] // BATCH_SIZE,\n",
    "        validation_steps=valid.shape[0] // BATCH_SIZE,\n",
    "        verbose=1,\n",
    "        workers=5,\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "    tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices(\"GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eff4_ns_0865_kf_v2_5.h5',\n",
       " 'dataset-metadata.json',\n",
       " 'eff4_ns_0865_kf_v2_3.h5',\n",
       " 'eff4_ns_0865_kf_v2_2.h5',\n",
       " 'eff4_ns_0865_kf_v2_4.h5',\n",
       " '.ipynb_checkpoints',\n",
       " 'eff4_ns_0865_kf_v2_1.h5']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"/app/_data/models/eff4_kf/0865fulltrain/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_all(file_path):\n",
    "    #     img = tf.io.read_file(TRAIN_IMG_PATH + file_path)\n",
    "    #     img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = np.load(TRAIN_IMG_PATH + file_path)\n",
    "    return img\n",
    "\n",
    "\n",
    "def predict_new(path, model):\n",
    "    img = parse_all(path)\n",
    "    img = tf.expand_dims(img, axis=0)\n",
    "    pred = model.predict(img)\n",
    "    return pred_to_labels(pred[0])\n",
    "\n",
    "\n",
    "def pred_to_labels(pred, thresh=0.5, labels=feature_columns):\n",
    "    pred = [labels[i] for i in range(len(labels)) if pred[i] > thresh]\n",
    "    pred = \" \".join(pred)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. '/app/_data/models/eff4_kf/0865fulltrain/'  best\n",
    "2. '/app/_data/models/complex/HandComplex/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_LIST = ['eff4_ns_0865_kf_v2_5.h5',\n",
    "#  'eff4_ns_0865_kf_v2_3.h5',\n",
    "#  'eff4_ns_0865_kf_v2_2.h5',\n",
    "#  'eff4_ns_0865_kf_v2_4.h5',\n",
    "#  'eff4_ns_0865_kf_v2_1.h5']\n",
    "# MODEL_LIST = [\n",
    "#     \"eff4_ns_cr_hand_complex_0.h5\",\n",
    "#     \"eff4_ns_cr_hand_complex_1.h5\",\n",
    "#     \"eff4_ns_cr_hand_complex_2.h5\",\n",
    "#     \"eff4_ns_cr_hand_complex_3.h5\",\n",
    "#     \"eff4_ns_cr_hand_complex_4.h5\",\n",
    "# ]\n",
    "MODEL_LIST = [\n",
    "    \"eff4_ns_cr_with_predicted_complex_v2_kf1.h5\",\n",
    "    \"eff4_ns_cr_with_predicted_complex_v2_kf2.h5\",\n",
    "    \"eff4_ns_cr_with_predicted_complex_v2_kf3.h5\",\n",
    "    \"eff4_ns_cr_with_predicted_complex_v2_kf4.h5\",\n",
    "    \"eff4_ns_cr_with_predicted_complex_v2_kf5.h5\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eff4_ns_cr_with_predicted_complex_v2_kf2.h5',\n",
       " 'dataset-metadata.json',\n",
       " 'eff4_ns_cr_with_predicted_complex_v2_kf1.h5',\n",
       " 'eff4_ns_cr_with_predicted_complex_v2_kf4.h5',\n",
       " 'eff4_ns_cr_with_predicted_complex_v2_kf5.h5',\n",
       " '.ipynb_checkpoints',\n",
       " 'eff4_ns_cr_with_predicted_complex_v2_kf3.h5']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"../_data/models/complex/eff4PredictedComplex1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20227/20227 [26:32<00:00, 12.70it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  image              labels  model\n",
      "0  ed5407e803f4a9d5.npy                scab    1.0\n",
      "1  c88ca09ea69597d7.npy  frog_eye_leaf_spot    1.0\n",
      "2        Train_1610.npy             healthy    1.0\n",
      "3  90ad674ed881f8b9.npy                scab    1.0\n",
      "4  d0c09d9e21eb6367.npy             healthy    1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20227/20227 [27:00<00:00, 12.48it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  image              labels  model\n",
      "0  ed5407e803f4a9d5.npy                scab    1.0\n",
      "1  c88ca09ea69597d7.npy  frog_eye_leaf_spot    1.0\n",
      "2        Train_1610.npy             healthy    1.0\n",
      "3  90ad674ed881f8b9.npy                scab    1.0\n",
      "4  d0c09d9e21eb6367.npy             healthy    1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20227/20227 [27:13<00:00, 12.39it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  image              labels  model\n",
      "0  ed5407e803f4a9d5.npy                scab    1.0\n",
      "1  c88ca09ea69597d7.npy  frog_eye_leaf_spot    1.0\n",
      "2        Train_1610.npy             healthy    1.0\n",
      "3  90ad674ed881f8b9.npy                scab    1.0\n",
      "4  d0c09d9e21eb6367.npy             healthy    1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20227/20227 [27:23<00:00, 12.31it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  image              labels  model\n",
      "0  ed5407e803f4a9d5.npy                scab    1.0\n",
      "1  c88ca09ea69597d7.npy  frog_eye_leaf_spot    1.0\n",
      "2        Train_1610.npy             healthy    1.0\n",
      "3  90ad674ed881f8b9.npy                scab    1.0\n",
      "4  d0c09d9e21eb6367.npy             healthy    1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20227/20227 [27:46<00:00, 12.14it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  image              labels  model\n",
      "0  ed5407e803f4a9d5.npy                scab    1.0\n",
      "1  c88ca09ea69597d7.npy  frog_eye_leaf_spot    1.0\n",
      "2        Train_1610.npy             healthy    1.0\n",
      "3  90ad674ed881f8b9.npy                scab    1.0\n",
      "4  d0c09d9e21eb6367.npy             healthy    1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_pred_complex = pd.DataFrame(columns=[\"image\", \"labels\"])\n",
    "for i, model_name in enumerate(MODEL_LIST):\n",
    "    model = keras.models.load_model(\n",
    "        \"/app/_data/models/complex/eff4PredictedComplex1/\" + model_name\n",
    "    )\n",
    "    for img_name in tqdm(df_labels[\"image\"].values.tolist()):\n",
    "        pred = predict_new(img_name, model)\n",
    "        df_pred_complex = df_pred_complex.append(\n",
    "            {\"image\": img_name, \"labels\": pred, \"model\": i + 1}, ignore_index=True\n",
    "        )\n",
    "\n",
    "    print(df_pred_complex.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_complex = df_pred_complex.merge(\n",
    "    df_labels[[\"image\", \"labels\"]],\n",
    "    on=\"image\",\n",
    "    how=\"left\",\n",
    "    suffixes=(\"_pred\", \"_true\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_complex.to_csv(\"/app/sandbox/wrong_predictions/eff4/df_pred_complex.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_hand_complex.to_csv(\"/app/sandbox/wrong_predictions/eff4/df_hand_complex.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0    3265\n",
       "1.0    3251\n",
       "3.0    3016\n",
       "4.0    3010\n",
       "2.0    2959\n",
       "Name: model, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred_complex[df_pred_complex[\"labels_pred\"] != df_pred_complex[\"labels_true\"]][\n",
    "    \"model\"\n",
    "].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sub.to_csv(\"/app/sandbox/wrong_predictions/eff4/eff4_0891.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = pd.read_csv(\"/app/sandbox/wrong_predictions/eff4/eff4_0891.csv\", index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>labels_pred</th>\n",
       "      <th>model</th>\n",
       "      <th>labels_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ed5407e803f4a9d5.npy</td>\n",
       "      <td>scab</td>\n",
       "      <td>1.0</td>\n",
       "      <td>scab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c88ca09ea69597d7.npy</td>\n",
       "      <td>frog_eye_leaf_spot</td>\n",
       "      <td>1.0</td>\n",
       "      <td>frog_eye_leaf_spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train_1610.npy</td>\n",
       "      <td>healthy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90ad674ed881f8b9.npy</td>\n",
       "      <td>scab</td>\n",
       "      <td>1.0</td>\n",
       "      <td>scab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d0c09d9e21eb6367.npy</td>\n",
       "      <td>healthy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101130</th>\n",
       "      <td>cfaab2997580eea0.npy</td>\n",
       "      <td>frog_eye_leaf_spot</td>\n",
       "      <td>5.0</td>\n",
       "      <td>frog_eye_leaf_spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101131</th>\n",
       "      <td>d43871073fa3d217.npy</td>\n",
       "      <td>scab</td>\n",
       "      <td>5.0</td>\n",
       "      <td>scab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101132</th>\n",
       "      <td>a99fd5a64e6e2860.npy</td>\n",
       "      <td>healthy</td>\n",
       "      <td>5.0</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101133</th>\n",
       "      <td>85ca3c8fa0b4dfd0.npy</td>\n",
       "      <td>healthy</td>\n",
       "      <td>5.0</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101134</th>\n",
       "      <td>f08f70f59452da26.npy</td>\n",
       "      <td>scab</td>\n",
       "      <td>5.0</td>\n",
       "      <td>scab</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101135 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       image         labels_pred  model         labels_true\n",
       "0       ed5407e803f4a9d5.npy                scab    1.0                scab\n",
       "1       c88ca09ea69597d7.npy  frog_eye_leaf_spot    1.0  frog_eye_leaf_spot\n",
       "2             Train_1610.npy             healthy    1.0             healthy\n",
       "3       90ad674ed881f8b9.npy                scab    1.0                scab\n",
       "4       d0c09d9e21eb6367.npy             healthy    1.0             healthy\n",
       "...                      ...                 ...    ...                 ...\n",
       "101130  cfaab2997580eea0.npy  frog_eye_leaf_spot    5.0  frog_eye_leaf_spot\n",
       "101131  d43871073fa3d217.npy                scab    5.0                scab\n",
       "101132  a99fd5a64e6e2860.npy             healthy    5.0             healthy\n",
       "101133  85ca3c8fa0b4dfd0.npy             healthy    5.0             healthy\n",
       "101134  f08f70f59452da26.npy                scab    5.0                scab\n",
       "\n",
       "[101135 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: labels_true, dtype: int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub[df_sub[\"labels_pred\"] == \"\"][\"labels_true\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scab frog_eye_leaf_spot            3410\n",
       "complex                            1012\n",
       "scab frog_eye_leaf_spot complex    1000\n",
       "frog_eye_leaf_spot complex          825\n",
       "rust frog_eye_leaf_spot             590\n",
       "rust complex                        455\n",
       "powdery_mildew complex              435\n",
       "scab                                342\n",
       "rust                                302\n",
       "frog_eye_leaf_spot                  200\n",
       "powdery_mildew                      117\n",
       "healthy                             106\n",
       "Name: labels_true, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub[df_sub[\"labels_pred\"] != df_sub[\"labels_true\"]][\"labels_true\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    1974\n",
       "3.0    1772\n",
       "4.0    1758\n",
       "1.0    1666\n",
       "5.0    1624\n",
       "Name: model, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub[df_sub[\"labels_pred\"] != df_sub[\"labels_true\"]][\"model\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_imgs = df_sub[df_sub[\"labels_pred\"] != df_sub[\"labels_true\"]][\"image\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8794"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2819"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(list_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
