{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /app/kaggle.json'\n"
     ]
    }
   ],
   "source": [
    "import kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /app/kaggle.json'\n",
      "Data package template written to: /app/_data/models/final/ScabHealthy/dataset-metadata.json\n"
     ]
    }
   ],
   "source": [
    "! kaggle datasets init -p /app/_data/models/final/ScabHealthy/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /app/kaggle.json'\n",
      "Starting upload for file eff4_hs__1.h5\n",
      "100%|█████████████████████████████████████████| 203M/203M [05:07<00:00, 691kB/s]\n",
      "Upload successful: eff4_hs__1.h5 (203MB)\n",
      "Starting upload for file eff4_hs__5.h5\n",
      "100%|█████████████████████████████████████████| 203M/203M [05:07<00:00, 692kB/s]\n",
      "Upload successful: eff4_hs__5.h5 (203MB)\n",
      "Starting upload for file eff4_hs__4.h5\n",
      "100%|█████████████████████████████████████████| 203M/203M [05:17<00:00, 670kB/s]\n",
      "Upload successful: eff4_hs__4.h5 (203MB)\n",
      "Skipping folder: .ipynb_checkpoints; use '--dir-mode' to upload folders\n",
      "Starting upload for file eff4_hs__2.h5\n",
      "100%|█████████████████████████████████████████| 203M/203M [05:09<00:00, 687kB/s]\n",
      "Upload successful: eff4_hs__2.h5 (203MB)\n",
      "Starting upload for file eff4_hs__3.h5\n",
      "100%|█████████████████████████████████████████| 203M/203M [05:14<00:00, 677kB/s]\n",
      "Upload successful: eff4_hs__3.h5 (203MB)\n",
      "Your private Dataset is being created. Please check progress at https://www.kaggle.com/nataliayurasova/ScabHealthy\n"
     ]
    }
   ],
   "source": [
    "! kaggle datasets create -p /app/_data/models/final/ScabHealthy/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.891\n",
    "MODEL_BB_PATH= '../input/model-bb-1/bond_box_999_200.h5'\n",
    "MODEL_PATH = '../input/0865fulltrain/'\n",
    "IMAGE_SIZE = (380, 380)\n",
    "DF_PART = '../input/df-kf-plant/df_kf.csv'\n",
    "PATH = \"/kaggle/input/plant-pathology-2021-fgvc8/\"\n",
    "TRAIN_IMG_PATH = PATH+'train_images/'\n",
    "TEST_IMG_PATH = PATH+'test_images/'\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES=6\n",
    "SEED = 1488\n",
    "- replace ''-'scab'\n",
    "https://www.kaggle.com/nataliayurasova/plant-pathology0891/edit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: albumentations in /usr/local/lib/python3.8/dist-packages (0.5.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from albumentations) (1.4.1)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.8/dist-packages (from albumentations) (0.18.1)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from albumentations) (5.3.1)\n",
      "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.8/dist-packages (from albumentations) (4.5.1.48)\n",
      "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.8/dist-packages (from albumentations) (1.17.3)\n",
      "Requirement already satisfied: imgaug>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from albumentations) (0.4.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from imgaug>=0.4.0->albumentations) (1.15.0)\n",
      "Requirement already satisfied: imageio in /usr/local/lib/python3.8/dist-packages (from imgaug>=0.4.0->albumentations) (2.9.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from imgaug>=0.4.0->albumentations) (3.3.4)\n",
      "Requirement already satisfied: Shapely in /usr/local/lib/python3.8/dist-packages (from imgaug>=0.4.0->albumentations) (1.7.1)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (from imgaug>=0.4.0->albumentations) (4.5.1.48)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from imgaug>=0.4.0->albumentations) (8.1.2)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.16.1->albumentations) (2021.4.8)\n",
      "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.16.1->albumentations) (2.5.1)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.16.1->albumentations) (1.1.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations) (2.8.1)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.8/dist-packages (from networkx>=2.0->scikit-image>=0.16.1->albumentations) (4.4.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install albumentations\n",
    "import albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import (\n",
    "    StratifiedKFold,\n",
    "    StratifiedShuffleSplit,\n",
    "    train_test_split,\n",
    ")\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB4, EfficientNetB7\n",
    "from tensorflow.keras.layers import (\n",
    "    AveragePooling2D,\n",
    "    AvgPool2D,\n",
    "    Conv2D,\n",
    "    Dense,\n",
    "    Flatten,\n",
    "    GlobalAveragePooling2D,\n",
    "    MaxPooling2D,\n",
    ")\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tqdm import notebook, tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/app/_data/\"\n",
    "BATCH_SIZE = 54\n",
    "SEED = 42\n",
    "IMAGE_SIZE = 380\n",
    "NUM_CLASSES = 2\n",
    "TRAIN_IMG_PATH = \"/app/_data/380_npy/\"\n",
    "TEST_IMG_PATH = \"/app/_data/test_images/\"\n",
    "feature_columns = [\n",
    "    \"complex\",\n",
    "    \"frog_eye_leaf_spot\",\n",
    "    \"healthy\",\n",
    "    \"powdery_mildew\",\n",
    "    \"rust\",\n",
    "    \"scab\",\n",
    "]\n",
    "wrong = [\n",
    "    \"ead085dfac287263.jpg\",\n",
    "    \"95276ccd226ad933.jpg\",\n",
    "    \"da8770e819d2696d.jpg\",\n",
    "    \"cd3a1d64e6806eb5.jpg\",\n",
    "    \"ccec54723ff91860.jpg\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = pd.read_csv(\"../_data/df_csv/labels_21_20.csv\", index_col=[0])\n",
    "df_labels = df_labels.query(\"image not in @wrong\").reset_index(drop=True)\n",
    "wrong_eff4_ns = pd.read_csv(\n",
    "    \"/app/sandbox/wrong_predictions/eff4/wrong_eff4_ns.csv\", index_col=[0]\n",
    ")\n",
    "wrong_eff4_ids = pd.read_csv(\n",
    "    \"/app/sandbox/wrong_predictions/eff4/wrong_eff4_ids.csv\", index_col=[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wrong_eff4_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_hsc = wrong_eff4_ids.query(\n",
    "    \"frog_eye_leaf_spot == 0 and frog_eye_leaf_spot_true== 0 and powdery_mildew==0 and powdery_mildew_true==0 and rust==0 and rust_true == 0\"\n",
    ")[[\"complex\", \"complex_true\", \"healthy\", \"healthy_true\", \"scab\", \"scab_true\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['complex', 'complex_true', 'healthy', 'healthy_true', 'scab',\n",
       "       'scab_true'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_hsc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complex</th>\n",
       "      <th>complex_true</th>\n",
       "      <th>healthy</th>\n",
       "      <th>healthy_true</th>\n",
       "      <th>scab</th>\n",
       "      <th>scab_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1933</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2036</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2049</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      complex  complex_true  healthy  healthy_true  scab  scab_true\n",
       "28          0             0        8             0     1          9\n",
       "86          0             0       11             0     0         11\n",
       "121         0             0       11             0     1         11\n",
       "126         0             0        7             0     2          8\n",
       "127         0             0        8             0     0          9\n",
       "...       ...           ...      ...           ...   ...        ...\n",
       "1933        0             8        1             0     5          0\n",
       "1939        0             9        5             0     1          0\n",
       "2019        0             0        8             0     0          8\n",
       "2036        0             0       11             0     0         11\n",
       "2049        0             0        7             0     2         10\n",
       "\n",
       "[74 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_hsc.query(\"healthy_true == 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complex complex_true\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complex</th>\n",
       "      <th>complex_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>872.000000</td>\n",
       "      <td>872.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.176606</td>\n",
       "      <td>11.634174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.290379</td>\n",
       "      <td>2.004674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          complex  complex_true\n",
       "count  872.000000    872.000000\n",
       "mean     7.176606     11.634174\n",
       "std      4.290379      2.004674\n",
       "min      1.000000      5.000000\n",
       "25%      3.000000     10.000000\n",
       "50%      7.000000     13.000000\n",
       "75%     12.000000     13.000000\n",
       "max     13.000000     13.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frog_eye_leaf_spot frog_eye_leaf_spot_true\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frog_eye_leaf_spot</th>\n",
       "      <th>frog_eye_leaf_spot_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1194.000000</td>\n",
       "      <td>1194.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.999162</td>\n",
       "      <td>12.920436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.365796</td>\n",
       "      <td>0.553463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       frog_eye_leaf_spot  frog_eye_leaf_spot_true\n",
       "count         1194.000000              1194.000000\n",
       "mean             8.999162                12.920436\n",
       "std              3.365796                 0.553463\n",
       "min              1.000000                 8.000000\n",
       "25%              6.000000                13.000000\n",
       "50%              9.000000                13.000000\n",
       "75%             12.000000                13.000000\n",
       "max             13.000000                13.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "healthy healthy_true\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>healthy</th>\n",
       "      <th>healthy_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.083333</td>\n",
       "      <td>8.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.240112</td>\n",
       "      <td>1.114641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         healthy  healthy_true\n",
       "count  12.000000     12.000000\n",
       "mean    2.083333      8.833333\n",
       "std     1.240112      1.114641\n",
       "min     1.000000      8.000000\n",
       "25%     1.000000      8.000000\n",
       "50%     2.000000      8.000000\n",
       "75%     3.000000     10.000000\n",
       "max     5.000000     11.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "powdery_mildew powdery_mildew_true\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>powdery_mildew</th>\n",
       "      <th>powdery_mildew_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>98.000000</td>\n",
       "      <td>98.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.418367</td>\n",
       "      <td>12.561224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.522896</td>\n",
       "      <td>1.308705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       powdery_mildew  powdery_mildew_true\n",
       "count       98.000000            98.000000\n",
       "mean        10.418367            12.561224\n",
       "std          3.522896             1.308705\n",
       "min          1.000000             8.000000\n",
       "25%          8.000000            13.000000\n",
       "50%         12.000000            13.000000\n",
       "75%         13.000000            13.000000\n",
       "max         13.000000            13.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rust rust_true\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rust</th>\n",
       "      <th>rust_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>249.000000</td>\n",
       "      <td>249.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.714859</td>\n",
       "      <td>12.421687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.235390</td>\n",
       "      <td>1.415244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             rust   rust_true\n",
       "count  249.000000  249.000000\n",
       "mean     8.714859   12.421687\n",
       "std      4.235390    1.415244\n",
       "min      1.000000    8.000000\n",
       "25%      5.000000   13.000000\n",
       "50%     10.000000   13.000000\n",
       "75%     13.000000   13.000000\n",
       "max     13.000000   13.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scab scab_true\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scab</th>\n",
       "      <th>scab_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>943.000000</td>\n",
       "      <td>943.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.113468</td>\n",
       "      <td>12.787911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.439631</td>\n",
       "      <td>0.869135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             scab   scab_true\n",
       "count  943.000000  943.000000\n",
       "mean     7.113468   12.787911\n",
       "std      3.439631    0.869135\n",
       "min      1.000000    8.000000\n",
       "25%      4.000000   13.000000\n",
       "50%      7.000000   13.000000\n",
       "75%     10.000000   13.000000\n",
       "max     13.000000   13.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(0, len(wrong_eff4_ids.columns), 2):\n",
    "    col1 = wrong_eff4_ids.columns[i]\n",
    "    col2 = wrong_eff4_ids.columns[i + 1]\n",
    "    print(col1, col2)\n",
    "    wrong_eff4_ids[(wrong_eff4_ids[col1] != 0) & (wrong_eff4_ids[col2] != 0)][\n",
    "        [col1, col2]\n",
    "    ].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wrong_eff4_ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = pd.read_csv(\"../_data/df_csv/labels_21_20.csv\", index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "wr_img = wrong_eff4_ns.image.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scab frog_eye_leaf_spot            682\n",
       "complex                            414\n",
       "scab frog_eye_leaf_spot complex    200\n",
       "frog_eye_leaf_spot complex         165\n",
       "rust frog_eye_leaf_spot            118\n",
       "scab                               109\n",
       "rust complex                        91\n",
       "powdery_mildew complex              87\n",
       "rust                                49\n",
       "healthy                             38\n",
       "frog_eye_leaf_spot                  34\n",
       "powdery_mildew                      25\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels.query(\"image in @wr_img\")[\"labels\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## only scab and healthy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10520, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels = df_labels.query('labels==\"scab\" or labels == \"healthy\"')\n",
    "df_labels[\"image\"] = df_labels[\"image\"].str.replace(\".jpg\", \".npy\")\n",
    "df_labels = df_labels.sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
    "df_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns_hs = ['healthy', 'scab']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 380*380\n",
    "transform = albumentations.Compose(\n",
    "    [\n",
    "        albumentations.CLAHE(p=0.1, clip_limit=(1, 2), tile_grid_size=(8, 8)),\n",
    "        albumentations.OneOf(\n",
    "            [\n",
    "                albumentations.MotionBlur((3, 3)),\n",
    "                albumentations.MedianBlur(blur_limit=3),\n",
    "                albumentations.GaussianBlur(blur_limit=(3, 3), sigma_limit=0),\n",
    "                albumentations.Blur(blur_limit=(3, 3)),\n",
    "            ],\n",
    "            p=0.2,\n",
    "        ),\n",
    "        albumentations.OneOf(\n",
    "            [\n",
    "                albumentations.GaussNoise(var_limit=[10, 50], mean=1),\n",
    "                albumentations.ISONoise(intensity=(0.1, 1), color_shift=(0.01, 0.05)),\n",
    "                albumentations.ImageCompression(\n",
    "                    quality_lower=70, quality_upper=100, compression_type=1\n",
    "                ),\n",
    "                albumentations.MultiplicativeNoise(\n",
    "                    multiplier=(0.95, 1.05), per_channel=True, elementwise=True\n",
    "                ),\n",
    "                albumentations.Downscale(\n",
    "                    scale_min=0.6, scale_max=0.99, interpolation=4\n",
    "                ),\n",
    "            ],\n",
    "            p=0.5,\n",
    "        ),\n",
    "        albumentations.OneOf(\n",
    "            [\n",
    "                albumentations.HueSaturationValue(\n",
    "                    hue_shift_limit=(-7, 7),\n",
    "                    sat_shift_limit=(-10, 10),\n",
    "                    val_shift_limit=(-10, 10),\n",
    "                ),\n",
    "                albumentations.RandomBrightnessContrast(\n",
    "                    brightness_limit=0.15,\n",
    "                    contrast_limit=0.2,\n",
    "                    brightness_by_max=True,\n",
    "                ),\n",
    "            ],\n",
    "            p=0.5,\n",
    "        ),\n",
    "        albumentations.OneOf(\n",
    "            [\n",
    "                albumentations.OpticalDistortion(\n",
    "                    distort_limit=0.05,\n",
    "                    shift_limit=0.05,\n",
    "                    border_mode=2,\n",
    "                ),\n",
    "                albumentations.ElasticTransform(\n",
    "                    alpha=2.0,\n",
    "                    sigma=50.0,\n",
    "                    alpha_affine=10.0,\n",
    "                    interpolation=0,\n",
    "                    border_mode=2,\n",
    "                ),\n",
    "                albumentations.GridDistortion(\n",
    "                    num_steps=5, distort_limit=0.3, interpolation=0, border_mode=2\n",
    "                ),\n",
    "            ],\n",
    "            p=0.5,\n",
    "        ),\n",
    "        albumentations.OneOf(\n",
    "            [\n",
    "                albumentations.HorizontalFlip(),\n",
    "                albumentations.VerticalFlip(),\n",
    "            ],\n",
    "            p=0.5,\n",
    "        ),\n",
    "        albumentations.OneOf(\n",
    "            [\n",
    "                albumentations.Rotate(\n",
    "                    limit=(-180, 180), interpolation=0, border_mode=2\n",
    "                ),\n",
    "                albumentations.ShiftScaleRotate(\n",
    "                    shift_limit=0.05,\n",
    "                    scale_limit=0.05,\n",
    "                    rotate_limit=180,\n",
    "                    interpolation=0,\n",
    "                    border_mode=2,\n",
    "                ),\n",
    "            ],\n",
    "            p=0.5,\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(keras.utils.Sequence):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        feature_columns,\n",
    "        images_src_dir,\n",
    "        batch_size,\n",
    "        target_image_size,\n",
    "        shuffle=False,\n",
    "        augment=True,\n",
    "        crop=False,\n",
    "        resize=False,\n",
    "        normalize=False,\n",
    "    ):\n",
    "        self.shuffle = shuffle\n",
    "        self.batch_size = BATCH_SIZE\n",
    "        self.df = df\n",
    "        self.images_dir = images_src_dir\n",
    "        self.target_image_size = (IMAGE_SIZE, IMAGE_SIZE)\n",
    "        self.augment = augment\n",
    "        self.crop = crop\n",
    "        self.resize = resize\n",
    "        self.normalize = normalize\n",
    "        self.feature_columns = feature_columns\n",
    "        # create label index map\n",
    "        self.labels = self._read_labels()\n",
    "        self.n_samples = self.df.shape[0]\n",
    "        self.n_batches = self.n_samples // self.batch_size\n",
    "        # shuffle data, also repeated after each epoch if needed\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.labels)\n",
    "\n",
    "    def _read_labels(self):\n",
    "        \"\"\"\n",
    "        Returns list images mapping to 1-hot label\n",
    "        \"\"\"\n",
    "\n",
    "        # label indexes\n",
    "        label_ixs = self.df[self.feature_columns].values\n",
    "        image_ixs = self.df[\"image\"].values\n",
    "        labels = []\n",
    "\n",
    "        for i in range(len(image_ixs)):\n",
    "            labels.append([image_ixs[i], label_ixs[i]])\n",
    "        return labels\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Length in batches\n",
    "        \"\"\"\n",
    "        return self.n_batches\n",
    "\n",
    "    def __getitem__(self, b_ix):\n",
    "        \"\"\"\n",
    "        Produce batch, by batch index\n",
    "        \"\"\"\n",
    "\n",
    "        assert b_ix < self.n_batches\n",
    "\n",
    "        b_X = np.zeros(\n",
    "            (self.batch_size, self.target_image_size[0], self.target_image_size[1], 3),\n",
    "            dtype=np.uint8,\n",
    "        )\n",
    "\n",
    "        b_Y = np.zeros(\n",
    "            (self.batch_size, self.df[self.feature_columns].shape[1]),\n",
    "            dtype=np.uint8,\n",
    "        )\n",
    "\n",
    "        for i in range(self.batch_size):\n",
    "            b_X[i], b_Y[i] = self.get_one(\n",
    "                i + self.batch_size * b_ix,\n",
    "            )\n",
    "\n",
    "        return (b_X, b_Y)\n",
    "\n",
    "    def get_one(self, one_ix):\n",
    "        \"\"\"\n",
    "        Get single item by absolute index\n",
    "        \"\"\"\n",
    "        id = self.labels[one_ix][0]\n",
    "        src_file = self.images_dir + id\n",
    "\n",
    "        # read file\n",
    "        x = np.load(src_file)\n",
    "        if self.crop:\n",
    "            coord = self.df[self.df[\"image\"] == id][\n",
    "                [\"x_min\", \"y_min\", \"x_max\", \"y_max\"]\n",
    "            ].values[0]\n",
    "            orig_hight = x.shape[0]\n",
    "            orig_width = x.shape[1]\n",
    "            x_min = coord[0]\n",
    "            y_min = coord[1]\n",
    "            x_max = coord[2]\n",
    "            y_max = coord[3]\n",
    "            x = x[\n",
    "                np.int(y_min * orig_hight) : np.int(y_max * orig_hight),\n",
    "                np.int(x_min * orig_width) : np.int(x_max * orig_width),\n",
    "            ]\n",
    "\n",
    "        y = self.labels[one_ix][1]\n",
    "\n",
    "        # augment\n",
    "        if self.augment:\n",
    "            x = self._augment_image(x)\n",
    "\n",
    "        # normalize (sample-wise)\n",
    "        if self.normalize:\n",
    "            x = x.astype(np.float32)\n",
    "            x = x - np.mean(x, axis=(0, 1))\n",
    "            x = x / np.std(x, axis=(0, 1))\n",
    "        return x.astype(np.uint8), y\n",
    "\n",
    "    def _augment_image(self, x):\n",
    "        \"\"\"\n",
    "        Randomply augment image\n",
    "        \"\"\"\n",
    "\n",
    "        x = transform(image=x)[\"image\"]\n",
    "        return x\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator(\n",
    "    df=df_labels.head(100),\n",
    "    feature_columns = feature_columns_hs,\n",
    "    images_src_dir=TRAIN_IMG_PATH,\n",
    "    target_image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    augment=True,\n",
    "    crop=False,\n",
    "    resize=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = next(iter(gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(380, 380, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=uint8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0].shape\n",
    "b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3090, compute capability 8.6\n"
     ]
    }
   ],
   "source": [
    "policy = keras.mixed_precision.experimental.Policy(\"mixed_float16\")\n",
    "keras.mixed_precision.experimental.set_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    inputs = keras.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "    base_model = keras.applications.EfficientNetB4(weights=None, include_top=False)\n",
    "    base_model.load_weights(\n",
    "        \"/app/_data/models/efficientnet-b4_noisy-student_notop.h5\",\n",
    "        by_name=True,\n",
    "        skip_mismatch=True,\n",
    "    )\n",
    "    x = base_model(inputs)\n",
    "    x = keras.layers.GlobalAveragePooling2D(name=\"avg_pool\")(x)\n",
    "    x = keras.layers.Flatten(name=\"flatten\")(x)\n",
    "    outputs = keras.layers.Dense(NUM_CLASSES, activation=\"sigmoid\")(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=Adam(lr=0.0005),\n",
    "        metrics=[\n",
    "            \"acc\",\n",
    "            tfa.metrics.F1Score(num_classes=NUM_CLASSES, average=\"weighted\"),\n",
    "        ],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lr_logger(self, logs: dict):\n",
    "#     \"\"\" Sample logger - adds LR \"\"\"\n",
    "#     logs.update({\"lr\": keras.backend.eval(self.model.optimizer.lr)})\n",
    "\n",
    "\n",
    "# def gpu_temp_logger(self, logs: dict):\n",
    "#     stream = os.popen(\"nvidia-smi -i 0 --query-gpu='temperature.gpu' --format=csv,noheader\")\n",
    "#     output = stream.read()\n",
    "#     gpu_temp = int(output)\n",
    "#     logs.update({\"gpu_temp\": gpu_temp})\n",
    "\n",
    "\n",
    "# class TensorBoard_Logger(keras.callbacks.TensorBoard):\n",
    "#     def __init__(self, loggers=[lr_logger], **kwargs):\n",
    "#         self._loggers = loggers\n",
    "#         super().__init__(**kwargs)\n",
    "\n",
    "#     def on_epoch_end(self, epoch, logs=None):\n",
    "#         logs = logs or {}\n",
    "#         for logger in self._loggers:\n",
    "#             logger(self, logs)\n",
    "#         super().on_epoch_end(epoch, logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting 1 skf\n",
      "\n",
      "Epoch 1/100\n",
      "  1/155 [..............................] - ETA: 0s - loss: 0.6968 - acc: 0.5185 - f1_score: 0.5159WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.1309 - acc: 0.9497 - f1_score: 0.9497\n",
      "Epoch 00001: val_f1_score improved from -inf to 0.80113, saving model to /app/_data/models/final/ScabHealthy/eff4_hs__1.h5\n",
      "155/155 [==============================] - 77s 495ms/step - loss: 0.1309 - acc: 0.9497 - f1_score: 0.9497 - val_loss: 0.8696 - val_acc: 0.8075 - val_f1_score: 0.8011\n",
      "Epoch 2/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0655 - acc: 0.9771 - f1_score: 0.9771\n",
      "Epoch 00002: val_f1_score improved from 0.80113 to 0.90298, saving model to /app/_data/models/final/ScabHealthy/eff4_hs__1.h5\n",
      "155/155 [==============================] - 103s 665ms/step - loss: 0.0655 - acc: 0.9771 - f1_score: 0.9771 - val_loss: 0.6809 - val_acc: 0.9035 - val_f1_score: 0.9030\n",
      "Epoch 3/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0577 - acc: 0.9787 - f1_score: 0.9787\n",
      "Epoch 00003: val_f1_score improved from 0.90298 to 0.98246, saving model to /app/_data/models/final/ScabHealthy/eff4_hs__1.h5\n",
      "155/155 [==============================] - 123s 792ms/step - loss: 0.0577 - acc: 0.9787 - f1_score: 0.9787 - val_loss: 0.0622 - val_acc: 0.9825 - val_f1_score: 0.9825\n",
      "Epoch 4/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0501 - acc: 0.9821 - f1_score: 0.9821\n",
      "Epoch 00004: val_f1_score did not improve from 0.98246\n",
      "155/155 [==============================] - 141s 907ms/step - loss: 0.0501 - acc: 0.9821 - f1_score: 0.9821 - val_loss: 0.0611 - val_acc: 0.9790 - val_f1_score: 0.9790\n",
      "Epoch 5/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0380 - acc: 0.9885 - f1_score: 0.9886\n",
      "Epoch 00005: val_f1_score improved from 0.98246 to 0.98440, saving model to /app/_data/models/final/ScabHealthy/eff4_hs__1.h5\n",
      "155/155 [==============================] - 148s 954ms/step - loss: 0.0380 - acc: 0.9885 - f1_score: 0.9886 - val_loss: 0.0455 - val_acc: 0.9844 - val_f1_score: 0.9844\n",
      "Epoch 6/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0425 - acc: 0.9849 - f1_score: 0.9849\n",
      "Epoch 00006: val_f1_score did not improve from 0.98440\n",
      "155/155 [==============================] - 153s 984ms/step - loss: 0.0425 - acc: 0.9849 - f1_score: 0.9849 - val_loss: 0.0738 - val_acc: 0.9732 - val_f1_score: 0.9732\n",
      "Epoch 7/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0310 - acc: 0.9892 - f1_score: 0.9892\n",
      "Epoch 00007: val_f1_score improved from 0.98440 to 0.98879, saving model to /app/_data/models/final/ScabHealthy/eff4_hs__1.h5\n",
      "155/155 [==============================] - 154s 991ms/step - loss: 0.0310 - acc: 0.9892 - f1_score: 0.9892 - val_loss: 0.0288 - val_acc: 0.9888 - val_f1_score: 0.9888\n",
      "Epoch 8/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0245 - acc: 0.9910 - f1_score: 0.9910\n",
      "Epoch 00008: val_f1_score did not improve from 0.98879\n",
      "155/155 [==============================] - 145s 937ms/step - loss: 0.0245 - acc: 0.9910 - f1_score: 0.9910 - val_loss: 0.0304 - val_acc: 0.9868 - val_f1_score: 0.9868\n",
      "Epoch 9/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0301 - acc: 0.9894 - f1_score: 0.9894\n",
      "Epoch 00009: val_f1_score improved from 0.98879 to 0.99464, saving model to /app/_data/models/final/ScabHealthy/eff4_hs__1.h5\n",
      "155/155 [==============================] - 147s 949ms/step - loss: 0.0301 - acc: 0.9894 - f1_score: 0.9894 - val_loss: 0.0161 - val_acc: 0.9946 - val_f1_score: 0.9946\n",
      "Epoch 10/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0322 - acc: 0.9901 - f1_score: 0.9901\n",
      "Epoch 00010: val_f1_score did not improve from 0.99464\n",
      "155/155 [==============================] - 143s 924ms/step - loss: 0.0322 - acc: 0.9901 - f1_score: 0.9901 - val_loss: 0.0712 - val_acc: 0.9751 - val_f1_score: 0.9754\n",
      "Epoch 11/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0249 - acc: 0.9918 - f1_score: 0.9918\n",
      "Epoch 00011: val_f1_score did not improve from 0.99464\n",
      "155/155 [==============================] - 150s 966ms/step - loss: 0.0249 - acc: 0.9918 - f1_score: 0.9918 - val_loss: 0.3529 - val_acc: 0.9274 - val_f1_score: 0.9272\n",
      "Epoch 12/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0277 - acc: 0.9901 - f1_score: 0.9901\n",
      "Epoch 00012: val_f1_score did not improve from 0.99464\n",
      "155/155 [==============================] - 154s 991ms/step - loss: 0.0277 - acc: 0.9901 - f1_score: 0.9901 - val_loss: 0.0237 - val_acc: 0.9922 - val_f1_score: 0.9922\n",
      "Epoch 13/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0243 - acc: 0.9932 - f1_score: 0.9932\n",
      "Epoch 00013: val_f1_score did not improve from 0.99464\n",
      "155/155 [==============================] - 140s 902ms/step - loss: 0.0243 - acc: 0.9932 - f1_score: 0.9932 - val_loss: 0.0273 - val_acc: 0.9898 - val_f1_score: 0.9898\n",
      "Epoch 14/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0253 - acc: 0.9910 - f1_score: 0.9910\n",
      "Epoch 00014: val_f1_score improved from 0.99464 to 0.99464, saving model to /app/_data/models/final/ScabHealthy/eff4_hs__1.h5\n",
      "155/155 [==============================] - 151s 974ms/step - loss: 0.0253 - acc: 0.9910 - f1_score: 0.9910 - val_loss: 0.0166 - val_acc: 0.9946 - val_f1_score: 0.9946\n",
      "Epoch 15/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0207 - acc: 0.9927 - f1_score: 0.9927\n",
      "Epoch 00015: val_f1_score did not improve from 0.99464\n",
      "155/155 [==============================] - 143s 921ms/step - loss: 0.0207 - acc: 0.9927 - f1_score: 0.9927 - val_loss: 0.0293 - val_acc: 0.9912 - val_f1_score: 0.9912\n",
      "Epoch 16/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0163 - acc: 0.9952 - f1_score: 0.9952\n",
      "Epoch 00016: val_f1_score did not improve from 0.99464\n",
      "155/155 [==============================] - 136s 880ms/step - loss: 0.0163 - acc: 0.9952 - f1_score: 0.9952 - val_loss: 0.0237 - val_acc: 0.9898 - val_f1_score: 0.9898\n",
      "Epoch 17/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0151 - acc: 0.9949 - f1_score: 0.9949\n",
      "Epoch 00017: val_f1_score did not improve from 0.99464\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0004500000213738531.\n",
      "155/155 [==============================] - 145s 936ms/step - loss: 0.0151 - acc: 0.9949 - f1_score: 0.9949 - val_loss: 0.0361 - val_acc: 0.9922 - val_f1_score: 0.9922\n",
      "Epoch 18/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0133 - acc: 0.9947 - f1_score: 0.9947\n",
      "Epoch 00018: val_f1_score did not improve from 0.99464\n",
      "155/155 [==============================] - 145s 935ms/step - loss: 0.0133 - acc: 0.9947 - f1_score: 0.9947 - val_loss: 0.5692 - val_acc: 0.9191 - val_f1_score: 0.9188\n",
      "Epoch 19/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0229 - acc: 0.9921 - f1_score: 0.9921\n",
      "Epoch 00019: val_f1_score did not improve from 0.99464\n",
      "155/155 [==============================] - 149s 961ms/step - loss: 0.0229 - acc: 0.9921 - f1_score: 0.9921 - val_loss: 0.0302 - val_acc: 0.9883 - val_f1_score: 0.9883\n",
      "Epoch 20/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0157 - acc: 0.9955 - f1_score: 0.9955\n",
      "Epoch 00020: val_f1_score improved from 0.99464 to 0.99610, saving model to /app/_data/models/final/ScabHealthy/eff4_hs__1.h5\n",
      "155/155 [==============================] - 148s 954ms/step - loss: 0.0157 - acc: 0.9955 - f1_score: 0.9955 - val_loss: 0.0100 - val_acc: 0.9961 - val_f1_score: 0.9961\n",
      "Epoch 21/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0164 - acc: 0.9949 - f1_score: 0.9949\n",
      "Epoch 00021: val_f1_score did not improve from 0.99610\n",
      "155/155 [==============================] - 144s 931ms/step - loss: 0.0164 - acc: 0.9949 - f1_score: 0.9949 - val_loss: 0.0330 - val_acc: 0.9898 - val_f1_score: 0.9898\n",
      "Epoch 22/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0168 - acc: 0.9938 - f1_score: 0.9938\n",
      "Epoch 00022: val_f1_score did not improve from 0.99610\n",
      "155/155 [==============================] - 142s 915ms/step - loss: 0.0168 - acc: 0.9938 - f1_score: 0.9938 - val_loss: 0.0306 - val_acc: 0.9898 - val_f1_score: 0.9898\n",
      "Epoch 23/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0122 - acc: 0.9961 - f1_score: 0.9961\n",
      "Epoch 00023: val_f1_score did not improve from 0.99610\n",
      "155/155 [==============================] - 147s 946ms/step - loss: 0.0122 - acc: 0.9961 - f1_score: 0.9961 - val_loss: 0.0235 - val_acc: 0.9932 - val_f1_score: 0.9932\n",
      "Epoch 24/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0156 - acc: 0.9950 - f1_score: 0.9950\n",
      "Epoch 00024: val_f1_score did not improve from 0.99610\n",
      "155/155 [==============================] - 147s 945ms/step - loss: 0.0156 - acc: 0.9950 - f1_score: 0.9950 - val_loss: 0.0271 - val_acc: 0.9937 - val_f1_score: 0.9937\n",
      "Epoch 25/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0147 - acc: 0.9947 - f1_score: 0.9947\n",
      "Epoch 00025: val_f1_score did not improve from 0.99610\n",
      "155/155 [==============================] - 154s 996ms/step - loss: 0.0147 - acc: 0.9947 - f1_score: 0.9947 - val_loss: 0.0323 - val_acc: 0.9903 - val_f1_score: 0.9903\n",
      "Epoch 26/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0151 - acc: 0.9957 - f1_score: 0.9957\n",
      "Epoch 00026: val_f1_score did not improve from 0.99610\n",
      "155/155 [==============================] - 140s 902ms/step - loss: 0.0151 - acc: 0.9957 - f1_score: 0.9957 - val_loss: 0.0352 - val_acc: 0.9878 - val_f1_score: 0.9878\n",
      "Epoch 27/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0144 - acc: 0.9957 - f1_score: 0.9957\n",
      "Epoch 00027: val_f1_score did not improve from 0.99610\n",
      "155/155 [==============================] - 151s 972ms/step - loss: 0.0144 - acc: 0.9957 - f1_score: 0.9957 - val_loss: 0.0205 - val_acc: 0.9946 - val_f1_score: 0.9946\n",
      "Epoch 28/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0103 - acc: 0.9963 - f1_score: 0.9963\n",
      "Epoch 00028: val_f1_score did not improve from 0.99610\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0004050000192364678.\n",
      "155/155 [==============================] - 150s 966ms/step - loss: 0.0103 - acc: 0.9963 - f1_score: 0.9963 - val_loss: 0.0238 - val_acc: 0.9907 - val_f1_score: 0.9907\n",
      "Epoch 29/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0181 - acc: 0.9941 - f1_score: 0.9941\n",
      "Epoch 00029: val_f1_score did not improve from 0.99610\n",
      "155/155 [==============================] - 141s 907ms/step - loss: 0.0181 - acc: 0.9941 - f1_score: 0.9941 - val_loss: 0.0315 - val_acc: 0.9907 - val_f1_score: 0.9907\n",
      "Epoch 30/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0072 - acc: 0.9975 - f1_score: 0.9975\n",
      "Epoch 00030: val_f1_score did not improve from 0.99610\n",
      "155/155 [==============================] - 142s 915ms/step - loss: 0.0072 - acc: 0.9975 - f1_score: 0.9975 - val_loss: 0.0368 - val_acc: 0.9873 - val_f1_score: 0.9873\n",
      "Epoch 31/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0150 - acc: 0.9945 - f1_score: 0.9945Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00031: val_f1_score did not improve from 0.99610\n",
      "155/155 [==============================] - 148s 957ms/step - loss: 0.0150 - acc: 0.9945 - f1_score: 0.9945 - val_loss: 0.0206 - val_acc: 0.9922 - val_f1_score: 0.9922\n",
      "Epoch 00031: early stopping\n",
      "\n",
      "Starting 2 skf\n",
      "\n",
      "Epoch 1/100\n",
      "  2/155 [..............................] - ETA: 3:33 - loss: 0.6829 - acc: 0.5556 - f1_score: 0.5556WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.3776s vs `on_train_batch_end` time: 2.4136s). Check your callbacks.\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.1411 - acc: 0.9447 - f1_score: 0.9447\n",
      "Epoch 00001: val_f1_score improved from -inf to 0.95270, saving model to /app/_data/models/final/ScabHealthy/eff4_hs__2.h5\n",
      "155/155 [==============================] - 138s 891ms/step - loss: 0.1411 - acc: 0.9447 - f1_score: 0.9447 - val_loss: 0.2406 - val_acc: 0.9527 - val_f1_score: 0.9527\n",
      "Epoch 2/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0661 - acc: 0.9780 - f1_score: 0.9780\n",
      "Epoch 00002: val_f1_score improved from 0.95270 to 0.96394, saving model to /app/_data/models/final/ScabHealthy/eff4_hs__2.h5\n",
      "155/155 [==============================] - 153s 987ms/step - loss: 0.0661 - acc: 0.9780 - f1_score: 0.9780 - val_loss: 0.1318 - val_acc: 0.9639 - val_f1_score: 0.9639\n",
      "Epoch 3/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0588 - acc: 0.9791 - f1_score: 0.9791\n",
      "Epoch 00003: val_f1_score did not improve from 0.96394\n",
      "155/155 [==============================] - 151s 972ms/step - loss: 0.0588 - acc: 0.9791 - f1_score: 0.9791 - val_loss: 0.1916 - val_acc: 0.9396 - val_f1_score: 0.9394\n",
      "Epoch 4/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0458 - acc: 0.9841 - f1_score: 0.9841\n",
      "Epoch 00004: val_f1_score improved from 0.96394 to 0.98733, saving model to /app/_data/models/final/ScabHealthy/eff4_hs__2.h5\n",
      "155/155 [==============================] - 144s 932ms/step - loss: 0.0458 - acc: 0.9841 - f1_score: 0.9841 - val_loss: 0.0352 - val_acc: 0.9873 - val_f1_score: 0.9873\n",
      "Epoch 5/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0415 - acc: 0.9851 - f1_score: 0.9851\n",
      "Epoch 00005: val_f1_score did not improve from 0.98733\n",
      "155/155 [==============================] - 154s 992ms/step - loss: 0.0415 - acc: 0.9851 - f1_score: 0.9851 - val_loss: 0.0705 - val_acc: 0.9766 - val_f1_score: 0.9766\n",
      "Epoch 6/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0390 - acc: 0.9861 - f1_score: 0.9861\n",
      "Epoch 00006: val_f1_score did not improve from 0.98733\n",
      "155/155 [==============================] - 147s 946ms/step - loss: 0.0390 - acc: 0.9861 - f1_score: 0.9861 - val_loss: 0.0391 - val_acc: 0.9864 - val_f1_score: 0.9864\n",
      "Epoch 7/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0285 - acc: 0.9892 - f1_score: 0.9892\n",
      "Epoch 00007: val_f1_score did not improve from 0.98733\n",
      "155/155 [==============================] - 146s 941ms/step - loss: 0.0285 - acc: 0.9892 - f1_score: 0.9892 - val_loss: 0.0787 - val_acc: 0.9790 - val_f1_score: 0.9790\n",
      "Epoch 8/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0326 - acc: 0.9900 - f1_score: 0.9899\n",
      "Epoch 00008: val_f1_score improved from 0.98733 to 0.98830, saving model to /app/_data/models/final/ScabHealthy/eff4_hs__2.h5\n",
      "155/155 [==============================] - 151s 976ms/step - loss: 0.0326 - acc: 0.9900 - f1_score: 0.9899 - val_loss: 0.0389 - val_acc: 0.9883 - val_f1_score: 0.9883\n",
      "Epoch 9/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0296 - acc: 0.9890 - f1_score: 0.9890\n",
      "Epoch 00009: val_f1_score did not improve from 0.98830\n",
      "155/155 [==============================] - 153s 986ms/step - loss: 0.0296 - acc: 0.9890 - f1_score: 0.9890 - val_loss: 0.0414 - val_acc: 0.9815 - val_f1_score: 0.9815\n",
      "Epoch 10/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0238 - acc: 0.9925 - f1_score: 0.9925\n",
      "Epoch 00010: val_f1_score did not improve from 0.98830\n",
      "155/155 [==============================] - 152s 983ms/step - loss: 0.0238 - acc: 0.9925 - f1_score: 0.9925 - val_loss: 0.0505 - val_acc: 0.9825 - val_f1_score: 0.9825\n",
      "Epoch 11/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0242 - acc: 0.9913 - f1_score: 0.9913\n",
      "Epoch 00011: val_f1_score did not improve from 0.98830\n",
      "155/155 [==============================] - 143s 924ms/step - loss: 0.0242 - acc: 0.9913 - f1_score: 0.9913 - val_loss: 0.0296 - val_acc: 0.9878 - val_f1_score: 0.9878\n",
      "Epoch 12/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0271 - acc: 0.9901 - f1_score: 0.9901\n",
      "Epoch 00012: val_f1_score did not improve from 0.98830\n",
      "155/155 [==============================] - 144s 931ms/step - loss: 0.0271 - acc: 0.9901 - f1_score: 0.9901 - val_loss: 0.0333 - val_acc: 0.9883 - val_f1_score: 0.9883\n",
      "Epoch 13/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0214 - acc: 0.9926 - f1_score: 0.9926\n",
      "Epoch 00013: val_f1_score did not improve from 0.98830\n",
      "155/155 [==============================] - 157s 1s/step - loss: 0.0214 - acc: 0.9926 - f1_score: 0.9926 - val_loss: 0.0495 - val_acc: 0.9873 - val_f1_score: 0.9873\n",
      "Epoch 14/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0223 - acc: 0.9930 - f1_score: 0.9930\n",
      "Epoch 00014: val_f1_score did not improve from 0.98830\n",
      "155/155 [==============================] - 149s 961ms/step - loss: 0.0223 - acc: 0.9930 - f1_score: 0.9930 - val_loss: 0.1402 - val_acc: 0.9659 - val_f1_score: 0.9659\n",
      "Epoch 15/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0246 - acc: 0.9908 - f1_score: 0.9908\n",
      "Epoch 00015: val_f1_score improved from 0.98830 to 0.99220, saving model to /app/_data/models/final/ScabHealthy/eff4_hs__2.h5\n",
      "155/155 [==============================] - 152s 983ms/step - loss: 0.0246 - acc: 0.9908 - f1_score: 0.9908 - val_loss: 0.0219 - val_acc: 0.9922 - val_f1_score: 0.9922\n",
      "Epoch 16/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0228 - acc: 0.9920 - f1_score: 0.9920\n",
      "Epoch 00016: val_f1_score did not improve from 0.99220\n",
      "155/155 [==============================] - 154s 993ms/step - loss: 0.0228 - acc: 0.9920 - f1_score: 0.9920 - val_loss: 0.0494 - val_acc: 0.9873 - val_f1_score: 0.9873\n",
      "Epoch 17/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0202 - acc: 0.9927 - f1_score: 0.9927\n",
      "Epoch 00017: val_f1_score did not improve from 0.99220\n",
      "155/155 [==============================] - 161s 1s/step - loss: 0.0202 - acc: 0.9927 - f1_score: 0.9927 - val_loss: 0.0222 - val_acc: 0.9907 - val_f1_score: 0.9907\n",
      "Epoch 18/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0227 - acc: 0.9916 - f1_score: 0.9916\n",
      "Epoch 00018: val_f1_score did not improve from 0.99220\n",
      "155/155 [==============================] - 147s 948ms/step - loss: 0.0227 - acc: 0.9916 - f1_score: 0.9916 - val_loss: 0.0489 - val_acc: 0.9888 - val_f1_score: 0.9888\n",
      "Epoch 19/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0161 - acc: 0.9939 - f1_score: 0.9939\n",
      "Epoch 00019: val_f1_score did not improve from 0.99220\n",
      "155/155 [==============================] - 149s 960ms/step - loss: 0.0161 - acc: 0.9939 - f1_score: 0.9939 - val_loss: 0.0462 - val_acc: 0.9854 - val_f1_score: 0.9854\n",
      "Epoch 20/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0146 - acc: 0.9958 - f1_score: 0.9958\n",
      "Epoch 00020: val_f1_score did not improve from 0.99220\n",
      "155/155 [==============================] - 147s 949ms/step - loss: 0.0146 - acc: 0.9958 - f1_score: 0.9958 - val_loss: 0.0552 - val_acc: 0.9864 - val_f1_score: 0.9864\n",
      "Epoch 21/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0147 - acc: 0.9947 - f1_score: 0.9947\n",
      "Epoch 00021: val_f1_score did not improve from 0.99220\n",
      "155/155 [==============================] - 145s 938ms/step - loss: 0.0147 - acc: 0.9947 - f1_score: 0.9947 - val_loss: 0.0296 - val_acc: 0.9883 - val_f1_score: 0.9883\n",
      "Epoch 22/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0176 - acc: 0.9933 - f1_score: 0.9933\n",
      "Epoch 00022: val_f1_score did not improve from 0.99220\n",
      "155/155 [==============================] - 149s 959ms/step - loss: 0.0176 - acc: 0.9933 - f1_score: 0.9933 - val_loss: 0.0321 - val_acc: 0.9912 - val_f1_score: 0.9912\n",
      "Epoch 23/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0146 - acc: 0.9953 - f1_score: 0.9953\n",
      "Epoch 00023: val_f1_score did not improve from 0.99220\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0004500000213738531.\n",
      "155/155 [==============================] - 146s 939ms/step - loss: 0.0146 - acc: 0.9953 - f1_score: 0.9953 - val_loss: 0.0300 - val_acc: 0.9912 - val_f1_score: 0.9912\n",
      "Epoch 24/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0141 - acc: 0.9949 - f1_score: 0.9949\n",
      "Epoch 00024: val_f1_score did not improve from 0.99220\n",
      "155/155 [==============================] - 150s 966ms/step - loss: 0.0141 - acc: 0.9949 - f1_score: 0.9949 - val_loss: 0.0409 - val_acc: 0.9883 - val_f1_score: 0.9883\n",
      "Epoch 25/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0117 - acc: 0.9955 - f1_score: 0.9955\n",
      "Epoch 00025: val_f1_score did not improve from 0.99220\n",
      "155/155 [==============================] - 154s 991ms/step - loss: 0.0117 - acc: 0.9955 - f1_score: 0.9955 - val_loss: 0.0341 - val_acc: 0.9898 - val_f1_score: 0.9898\n",
      "Epoch 26/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0162 - acc: 0.9947 - f1_score: 0.9947Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00026: val_f1_score did not improve from 0.99220\n",
      "155/155 [==============================] - 147s 946ms/step - loss: 0.0162 - acc: 0.9947 - f1_score: 0.9947 - val_loss: 0.0460 - val_acc: 0.9883 - val_f1_score: 0.9883\n",
      "Epoch 00026: early stopping\n",
      "\n",
      "Starting 3 skf\n",
      "\n",
      "Epoch 1/100\n",
      "  2/155 [..............................] - ETA: 3:36 - loss: 0.6904 - acc: 0.5278 - f1_score: 0.5237WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.3892s vs `on_train_batch_end` time: 2.4406s). Check your callbacks.\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.1438 - acc: 0.9440 - f1_score: 0.9440\n",
      "Epoch 00001: val_f1_score improved from -inf to 0.93064, saving model to /app/_data/models/final/ScabHealthy/eff4_hs__3.h5\n",
      "155/155 [==============================] - 152s 980ms/step - loss: 0.1438 - acc: 0.9440 - f1_score: 0.9440 - val_loss: 0.2833 - val_acc: 0.9308 - val_f1_score: 0.9306\n",
      "Epoch 2/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0731 - acc: 0.9742 - f1_score: 0.9742\n",
      "Epoch 00002: val_f1_score improved from 0.93064 to 0.98051, saving model to /app/_data/models/final/ScabHealthy/eff4_hs__3.h5\n",
      "155/155 [==============================] - 144s 930ms/step - loss: 0.0731 - acc: 0.9742 - f1_score: 0.9742 - val_loss: 0.0583 - val_acc: 0.9805 - val_f1_score: 0.9805\n",
      "Epoch 3/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0515 - acc: 0.9824 - f1_score: 0.9824\n",
      "Epoch 00003: val_f1_score improved from 0.98051 to 0.98343, saving model to /app/_data/models/final/ScabHealthy/eff4_hs__3.h5\n",
      "155/155 [==============================] - 154s 993ms/step - loss: 0.0515 - acc: 0.9824 - f1_score: 0.9824 - val_loss: 0.0467 - val_acc: 0.9834 - val_f1_score: 0.9834\n",
      "Epoch 4/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0437 - acc: 0.9847 - f1_score: 0.9847\n",
      "Epoch 00004: val_f1_score improved from 0.98343 to 0.98758, saving model to /app/_data/models/final/ScabHealthy/eff4_hs__3.h5\n",
      "155/155 [==============================] - 144s 927ms/step - loss: 0.0437 - acc: 0.9847 - f1_score: 0.9847 - val_loss: 0.0311 - val_acc: 0.9873 - val_f1_score: 0.9876\n",
      "Epoch 5/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0359 - acc: 0.9866 - f1_score: 0.9866\n",
      "Epoch 00005: val_f1_score did not improve from 0.98758\n",
      "155/155 [==============================] - 152s 983ms/step - loss: 0.0359 - acc: 0.9866 - f1_score: 0.9866 - val_loss: 0.0550 - val_acc: 0.9805 - val_f1_score: 0.9805\n",
      "Epoch 6/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0353 - acc: 0.9877 - f1_score: 0.9877\n",
      "Epoch 00006: val_f1_score did not improve from 0.98758\n",
      "155/155 [==============================] - 152s 980ms/step - loss: 0.0353 - acc: 0.9877 - f1_score: 0.9877 - val_loss: 0.0413 - val_acc: 0.9864 - val_f1_score: 0.9864\n",
      "Epoch 7/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0346 - acc: 0.9881 - f1_score: 0.9881\n",
      "Epoch 00007: val_f1_score did not improve from 0.98758\n",
      "155/155 [==============================] - 156s 1s/step - loss: 0.0346 - acc: 0.9881 - f1_score: 0.9881 - val_loss: 0.1437 - val_acc: 0.9664 - val_f1_score: 0.9664\n",
      "Epoch 8/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0255 - acc: 0.9915 - f1_score: 0.9915\n",
      "Epoch 00008: val_f1_score did not improve from 0.98758\n",
      "155/155 [==============================] - 149s 959ms/step - loss: 0.0255 - acc: 0.9915 - f1_score: 0.9915 - val_loss: 0.0624 - val_acc: 0.9815 - val_f1_score: 0.9815\n",
      "Epoch 9/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0280 - acc: 0.9912 - f1_score: 0.9912\n",
      "Epoch 00009: val_f1_score improved from 0.98758 to 0.98928, saving model to /app/_data/models/final/ScabHealthy/eff4_hs__3.h5\n",
      "155/155 [==============================] - 154s 992ms/step - loss: 0.0280 - acc: 0.9912 - f1_score: 0.9912 - val_loss: 0.0254 - val_acc: 0.9893 - val_f1_score: 0.9893\n",
      "Epoch 10/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0312 - acc: 0.9903 - f1_score: 0.9903\n",
      "Epoch 00010: val_f1_score improved from 0.98928 to 0.98928, saving model to /app/_data/models/final/ScabHealthy/eff4_hs__3.h5\n",
      "155/155 [==============================] - 154s 993ms/step - loss: 0.0312 - acc: 0.9903 - f1_score: 0.9903 - val_loss: 0.0300 - val_acc: 0.9893 - val_f1_score: 0.9893\n",
      "Epoch 11/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0229 - acc: 0.9927 - f1_score: 0.9927\n",
      "Epoch 00011: val_f1_score did not improve from 0.98928\n",
      "155/155 [==============================] - 140s 900ms/step - loss: 0.0229 - acc: 0.9927 - f1_score: 0.9927 - val_loss: 0.0419 - val_acc: 0.9888 - val_f1_score: 0.9888\n",
      "Epoch 12/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0218 - acc: 0.9927 - f1_score: 0.9927\n",
      "Epoch 00012: val_f1_score improved from 0.98928 to 0.99220, saving model to /app/_data/models/final/ScabHealthy/eff4_hs__3.h5\n",
      "155/155 [==============================] - 149s 964ms/step - loss: 0.0218 - acc: 0.9927 - f1_score: 0.9927 - val_loss: 0.0317 - val_acc: 0.9922 - val_f1_score: 0.9922\n",
      "Epoch 13/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0232 - acc: 0.9913 - f1_score: 0.9913\n",
      "Epoch 00013: val_f1_score did not improve from 0.99220\n",
      "155/155 [==============================] - 148s 955ms/step - loss: 0.0232 - acc: 0.9913 - f1_score: 0.9913 - val_loss: 0.0472 - val_acc: 0.9878 - val_f1_score: 0.9878\n",
      "Epoch 14/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0266 - acc: 0.9915 - f1_score: 0.9915\n",
      "Epoch 00014: val_f1_score did not improve from 0.99220\n",
      "155/155 [==============================] - 147s 947ms/step - loss: 0.0266 - acc: 0.9915 - f1_score: 0.9915 - val_loss: 0.0283 - val_acc: 0.9903 - val_f1_score: 0.9903\n",
      "Epoch 15/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0196 - acc: 0.9932 - f1_score: 0.9932\n",
      "Epoch 00015: val_f1_score did not improve from 0.99220\n",
      "155/155 [==============================] - 155s 998ms/step - loss: 0.0196 - acc: 0.9932 - f1_score: 0.9932 - val_loss: 0.0316 - val_acc: 0.9917 - val_f1_score: 0.9917\n",
      "Epoch 16/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0179 - acc: 0.9938 - f1_score: 0.9938\n",
      "Epoch 00016: val_f1_score did not improve from 0.99220\n",
      "155/155 [==============================] - 147s 947ms/step - loss: 0.0179 - acc: 0.9938 - f1_score: 0.9938 - val_loss: 0.0249 - val_acc: 0.9917 - val_f1_score: 0.9917\n",
      "Epoch 17/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0230 - acc: 0.9925 - f1_score: 0.9925\n",
      "Epoch 00017: val_f1_score did not improve from 0.99220\n",
      "155/155 [==============================] - 158s 1s/step - loss: 0.0230 - acc: 0.9925 - f1_score: 0.9925 - val_loss: 0.1507 - val_acc: 0.9664 - val_f1_score: 0.9664\n",
      "Epoch 18/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0177 - acc: 0.9946 - f1_score: 0.9946\n",
      "Epoch 00018: val_f1_score did not improve from 0.99220\n",
      "155/155 [==============================] - 150s 969ms/step - loss: 0.0177 - acc: 0.9946 - f1_score: 0.9946 - val_loss: 0.0290 - val_acc: 0.9907 - val_f1_score: 0.9907\n",
      "Epoch 19/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0188 - acc: 0.9939 - f1_score: 0.9939\n",
      "Epoch 00019: val_f1_score improved from 0.99220 to 0.99318, saving model to /app/_data/models/final/ScabHealthy/eff4_hs__3.h5\n",
      "155/155 [==============================] - 153s 985ms/step - loss: 0.0188 - acc: 0.9939 - f1_score: 0.9939 - val_loss: 0.0179 - val_acc: 0.9932 - val_f1_score: 0.9932\n",
      "Epoch 20/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0153 - acc: 0.9947 - f1_score: 0.9947\n",
      "Epoch 00020: val_f1_score did not improve from 0.99318\n",
      "155/155 [==============================] - 156s 1s/step - loss: 0.0153 - acc: 0.9947 - f1_score: 0.9947 - val_loss: 0.0253 - val_acc: 0.9898 - val_f1_score: 0.9898\n",
      "Epoch 21/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0202 - acc: 0.9932 - f1_score: 0.9932\n",
      "Epoch 00021: val_f1_score did not improve from 0.99318\n",
      "155/155 [==============================] - 153s 988ms/step - loss: 0.0202 - acc: 0.9932 - f1_score: 0.9932 - val_loss: 0.0340 - val_acc: 0.9903 - val_f1_score: 0.9903\n",
      "Epoch 22/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0216 - acc: 0.9927 - f1_score: 0.9927\n",
      "Epoch 00022: val_f1_score did not improve from 0.99318\n",
      "155/155 [==============================] - 149s 959ms/step - loss: 0.0216 - acc: 0.9927 - f1_score: 0.9927 - val_loss: 0.0241 - val_acc: 0.9912 - val_f1_score: 0.9912\n",
      "Epoch 23/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0163 - acc: 0.9938 - f1_score: 0.9938\n",
      "Epoch 00023: val_f1_score improved from 0.99318 to 0.99318, saving model to /app/_data/models/final/ScabHealthy/eff4_hs__3.h5\n",
      "155/155 [==============================] - 145s 935ms/step - loss: 0.0163 - acc: 0.9938 - f1_score: 0.9938 - val_loss: 0.0195 - val_acc: 0.9932 - val_f1_score: 0.9932\n",
      "Epoch 24/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0138 - acc: 0.9951 - f1_score: 0.9951\n",
      "Epoch 00024: val_f1_score did not improve from 0.99318\n",
      "155/155 [==============================] - 157s 1s/step - loss: 0.0138 - acc: 0.9951 - f1_score: 0.9951 - val_loss: 0.0505 - val_acc: 0.9854 - val_f1_score: 0.9854\n",
      "Epoch 25/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0196 - acc: 0.9935 - f1_score: 0.9935\n",
      "Epoch 00025: val_f1_score did not improve from 0.99318\n",
      "155/155 [==============================] - 143s 920ms/step - loss: 0.0196 - acc: 0.9935 - f1_score: 0.9935 - val_loss: 0.0331 - val_acc: 0.9927 - val_f1_score: 0.9927\n",
      "Epoch 26/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0151 - acc: 0.9953 - f1_score: 0.9953\n",
      "Epoch 00026: val_f1_score did not improve from 0.99318\n",
      "155/155 [==============================] - 148s 953ms/step - loss: 0.0151 - acc: 0.9953 - f1_score: 0.9953 - val_loss: 0.0329 - val_acc: 0.9912 - val_f1_score: 0.9912\n",
      "Epoch 27/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0164 - acc: 0.9951 - f1_score: 0.9951\n",
      "Epoch 00027: val_f1_score did not improve from 0.99318\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0004500000213738531.\n",
      "155/155 [==============================] - 159s 1s/step - loss: 0.0164 - acc: 0.9951 - f1_score: 0.9951 - val_loss: 0.0413 - val_acc: 0.9903 - val_f1_score: 0.9903\n",
      "Epoch 28/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0083 - acc: 0.9975 - f1_score: 0.9975\n",
      "Epoch 00028: val_f1_score did not improve from 0.99318\n",
      "155/155 [==============================] - 151s 975ms/step - loss: 0.0083 - acc: 0.9975 - f1_score: 0.9975 - val_loss: 0.0314 - val_acc: 0.9912 - val_f1_score: 0.9912\n",
      "Epoch 29/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0134 - acc: 0.9957 - f1_score: 0.9957\n",
      "Epoch 00029: val_f1_score did not improve from 0.99318\n",
      "155/155 [==============================] - 145s 935ms/step - loss: 0.0134 - acc: 0.9957 - f1_score: 0.9957 - val_loss: 0.0519 - val_acc: 0.9868 - val_f1_score: 0.9868\n",
      "Epoch 30/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0094 - acc: 0.9970 - f1_score: 0.9970\n",
      "Epoch 00030: val_f1_score did not improve from 0.99318\n",
      "155/155 [==============================] - 149s 961ms/step - loss: 0.0094 - acc: 0.9970 - f1_score: 0.9970 - val_loss: 0.0248 - val_acc: 0.9903 - val_f1_score: 0.9903\n",
      "Epoch 31/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0100 - acc: 0.9959 - f1_score: 0.9959\n",
      "Epoch 00031: val_f1_score did not improve from 0.99318\n",
      "155/155 [==============================] - 155s 1s/step - loss: 0.0100 - acc: 0.9959 - f1_score: 0.9959 - val_loss: 0.0488 - val_acc: 0.9878 - val_f1_score: 0.9878\n",
      "Epoch 32/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0108 - acc: 0.9957 - f1_score: 0.9957\n",
      "Epoch 00032: val_f1_score did not improve from 0.99318\n",
      "155/155 [==============================] - 150s 968ms/step - loss: 0.0108 - acc: 0.9957 - f1_score: 0.9957 - val_loss: 0.0407 - val_acc: 0.9868 - val_f1_score: 0.9868\n",
      "Epoch 33/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0131 - acc: 0.9949 - f1_score: 0.9949\n",
      "Epoch 00033: val_f1_score did not improve from 0.99318\n",
      "155/155 [==============================] - 150s 970ms/step - loss: 0.0131 - acc: 0.9949 - f1_score: 0.9949 - val_loss: 0.0681 - val_acc: 0.9790 - val_f1_score: 0.9790\n",
      "Epoch 34/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0138 - acc: 0.9950 - f1_score: 0.9950Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00034: val_f1_score did not improve from 0.99318\n",
      "155/155 [==============================] - 152s 982ms/step - loss: 0.0138 - acc: 0.9950 - f1_score: 0.9950 - val_loss: 0.0256 - val_acc: 0.9912 - val_f1_score: 0.9912\n",
      "Epoch 00034: early stopping\n",
      "\n",
      "Starting 4 skf\n",
      "\n",
      "Epoch 1/100\n",
      "  2/155 [..............................] - ETA: 3:21 - loss: 0.6875 - acc: 0.5741 - f1_score: 0.5724WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.3743s vs `on_train_batch_end` time: 2.2624s). Check your callbacks.\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.1381 - acc: 0.9435 - f1_score: 0.9434\n",
      "Epoch 00001: val_f1_score improved from -inf to 0.91925, saving model to /app/_data/models/final/ScabHealthy/eff4_hs__4.h5\n",
      "155/155 [==============================] - 141s 909ms/step - loss: 0.1381 - acc: 0.9435 - f1_score: 0.9434 - val_loss: 0.4905 - val_acc: 0.9196 - val_f1_score: 0.9193\n",
      "Epoch 2/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0703 - acc: 0.9743 - f1_score: 0.9743\n",
      "Epoch 00002: val_f1_score improved from 0.91925 to 0.95220, saving model to /app/_data/models/final/ScabHealthy/eff4_hs__4.h5\n",
      "155/155 [==============================] - 157s 1s/step - loss: 0.0703 - acc: 0.9743 - f1_score: 0.9743 - val_loss: 0.1569 - val_acc: 0.9522 - val_f1_score: 0.9522\n",
      "Epoch 3/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0571 - acc: 0.9799 - f1_score: 0.9799\n",
      "Epoch 00003: val_f1_score improved from 0.95220 to 0.98197, saving model to /app/_data/models/final/ScabHealthy/eff4_hs__4.h5\n",
      "155/155 [==============================] - 144s 930ms/step - loss: 0.0571 - acc: 0.9799 - f1_score: 0.9799 - val_loss: 0.0577 - val_acc: 0.9820 - val_f1_score: 0.9820\n",
      "Epoch 4/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0449 - acc: 0.9830 - f1_score: 0.9830\n",
      "Epoch 00004: val_f1_score did not improve from 0.98197\n",
      "155/155 [==============================] - 163s 1s/step - loss: 0.0449 - acc: 0.9830 - f1_score: 0.9830 - val_loss: 0.0651 - val_acc: 0.9771 - val_f1_score: 0.9771\n",
      "Epoch 5/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0399 - acc: 0.9855 - f1_score: 0.9855\n",
      "Epoch 00005: val_f1_score did not improve from 0.98197\n",
      "155/155 [==============================] - 154s 995ms/step - loss: 0.0399 - acc: 0.9855 - f1_score: 0.9855 - val_loss: 0.0767 - val_acc: 0.9766 - val_f1_score: 0.9766\n",
      "Epoch 6/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0347 - acc: 0.9882 - f1_score: 0.9882\n",
      "Epoch 00006: val_f1_score improved from 0.98197 to 0.98732, saving model to /app/_data/models/final/ScabHealthy/eff4_hs__4.h5\n",
      "155/155 [==============================] - 147s 949ms/step - loss: 0.0347 - acc: 0.9882 - f1_score: 0.9882 - val_loss: 0.0369 - val_acc: 0.9873 - val_f1_score: 0.9873\n",
      "Epoch 7/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0319 - acc: 0.9884 - f1_score: 0.9885\n",
      "Epoch 00007: val_f1_score improved from 0.98732 to 0.99025, saving model to /app/_data/models/final/ScabHealthy/eff4_hs__4.h5\n",
      "155/155 [==============================] - 154s 995ms/step - loss: 0.0319 - acc: 0.9884 - f1_score: 0.9885 - val_loss: 0.0327 - val_acc: 0.9903 - val_f1_score: 0.9903\n",
      "Epoch 8/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0306 - acc: 0.9894 - f1_score: 0.9894\n",
      "Epoch 00008: val_f1_score did not improve from 0.99025\n",
      "155/155 [==============================] - 149s 960ms/step - loss: 0.0306 - acc: 0.9894 - f1_score: 0.9894 - val_loss: 0.0398 - val_acc: 0.9898 - val_f1_score: 0.9898\n",
      "Epoch 9/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0272 - acc: 0.9900 - f1_score: 0.9900\n",
      "Epoch 00009: val_f1_score did not improve from 0.99025\n",
      "155/155 [==============================] - 149s 963ms/step - loss: 0.0272 - acc: 0.9900 - f1_score: 0.9900 - val_loss: 0.0756 - val_acc: 0.9825 - val_f1_score: 0.9825\n",
      "Epoch 10/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0294 - acc: 0.9898 - f1_score: 0.9898\n",
      "Epoch 00010: val_f1_score did not improve from 0.99025\n",
      "155/155 [==============================] - 144s 931ms/step - loss: 0.0294 - acc: 0.9898 - f1_score: 0.9898 - val_loss: 0.0450 - val_acc: 0.9825 - val_f1_score: 0.9824\n",
      "Epoch 11/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0200 - acc: 0.9934 - f1_score: 0.9934\n",
      "Epoch 00011: val_f1_score did not improve from 0.99025\n",
      "155/155 [==============================] - 144s 926ms/step - loss: 0.0200 - acc: 0.9934 - f1_score: 0.9934 - val_loss: 0.0367 - val_acc: 0.9893 - val_f1_score: 0.9890\n",
      "Epoch 12/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0237 - acc: 0.9926 - f1_score: 0.9926\n",
      "Epoch 00012: val_f1_score improved from 0.99025 to 0.99074, saving model to /app/_data/models/final/ScabHealthy/eff4_hs__4.h5\n",
      "155/155 [==============================] - 148s 953ms/step - loss: 0.0237 - acc: 0.9926 - f1_score: 0.9926 - val_loss: 0.0489 - val_acc: 0.9907 - val_f1_score: 0.9907\n",
      "Epoch 13/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0271 - acc: 0.9909 - f1_score: 0.9909\n",
      "Epoch 00013: val_f1_score improved from 0.99074 to 0.99123, saving model to /app/_data/models/final/ScabHealthy/eff4_hs__4.h5\n",
      "155/155 [==============================] - 154s 993ms/step - loss: 0.0271 - acc: 0.9909 - f1_score: 0.9909 - val_loss: 0.0292 - val_acc: 0.9912 - val_f1_score: 0.9912\n",
      "Epoch 14/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0208 - acc: 0.9915 - f1_score: 0.9915\n",
      "Epoch 00014: val_f1_score did not improve from 0.99123\n",
      "155/155 [==============================] - 135s 870ms/step - loss: 0.0208 - acc: 0.9915 - f1_score: 0.9915 - val_loss: 0.0386 - val_acc: 0.9873 - val_f1_score: 0.9873\n",
      "Epoch 15/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0236 - acc: 0.9920 - f1_score: 0.9920\n",
      "Epoch 00015: val_f1_score improved from 0.99123 to 0.99220, saving model to /app/_data/models/final/ScabHealthy/eff4_hs__4.h5\n",
      "155/155 [==============================] - 150s 971ms/step - loss: 0.0236 - acc: 0.9920 - f1_score: 0.9920 - val_loss: 0.0332 - val_acc: 0.9922 - val_f1_score: 0.9922\n",
      "Epoch 16/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0214 - acc: 0.9914 - f1_score: 0.9914\n",
      "Epoch 00016: val_f1_score did not improve from 0.99220\n",
      "155/155 [==============================] - 136s 880ms/step - loss: 0.0214 - acc: 0.9914 - f1_score: 0.9914 - val_loss: 0.0382 - val_acc: 0.9868 - val_f1_score: 0.9868\n",
      "Epoch 17/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0274 - acc: 0.9907 - f1_score: 0.9907\n",
      "Epoch 00017: val_f1_score improved from 0.99220 to 0.99318, saving model to /app/_data/models/final/ScabHealthy/eff4_hs__4.h5\n",
      "155/155 [==============================] - 154s 995ms/step - loss: 0.0274 - acc: 0.9907 - f1_score: 0.9907 - val_loss: 0.0289 - val_acc: 0.9932 - val_f1_score: 0.9932\n",
      "Epoch 18/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0193 - acc: 0.9921 - f1_score: 0.9921\n",
      "Epoch 00018: val_f1_score did not improve from 0.99318\n",
      "155/155 [==============================] - 135s 868ms/step - loss: 0.0193 - acc: 0.9921 - f1_score: 0.9921 - val_loss: 0.0413 - val_acc: 0.9854 - val_f1_score: 0.9854\n",
      "Epoch 19/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0135 - acc: 0.9953 - f1_score: 0.9953\n",
      "Epoch 00019: val_f1_score did not improve from 0.99318\n",
      "155/155 [==============================] - 145s 938ms/step - loss: 0.0135 - acc: 0.9953 - f1_score: 0.9953 - val_loss: 0.0475 - val_acc: 0.9883 - val_f1_score: 0.9883\n",
      "Epoch 20/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0114 - acc: 0.9962 - f1_score: 0.9962\n",
      "Epoch 00020: val_f1_score did not improve from 0.99318\n",
      "155/155 [==============================] - 148s 956ms/step - loss: 0.0114 - acc: 0.9962 - f1_score: 0.9962 - val_loss: 0.0244 - val_acc: 0.9932 - val_f1_score: 0.9932\n",
      "Epoch 21/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0196 - acc: 0.9932 - f1_score: 0.9932\n",
      "Epoch 00021: val_f1_score improved from 0.99318 to 0.99366, saving model to /app/_data/models/final/ScabHealthy/eff4_hs__4.h5\n",
      "155/155 [==============================] - 149s 961ms/step - loss: 0.0196 - acc: 0.9932 - f1_score: 0.9932 - val_loss: 0.0249 - val_acc: 0.9937 - val_f1_score: 0.9937\n",
      "Epoch 22/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0164 - acc: 0.9938 - f1_score: 0.9938\n",
      "Epoch 00022: val_f1_score did not improve from 0.99366\n",
      "155/155 [==============================] - 142s 913ms/step - loss: 0.0164 - acc: 0.9938 - f1_score: 0.9938 - val_loss: 0.0472 - val_acc: 0.9868 - val_f1_score: 0.9868\n",
      "Epoch 23/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0205 - acc: 0.9930 - f1_score: 0.9930\n",
      "Epoch 00023: val_f1_score did not improve from 0.99366\n",
      "155/155 [==============================] - 150s 969ms/step - loss: 0.0205 - acc: 0.9930 - f1_score: 0.9930 - val_loss: 0.0243 - val_acc: 0.9937 - val_f1_score: 0.9937\n",
      "Epoch 24/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0167 - acc: 0.9937 - f1_score: 0.9937\n",
      "Epoch 00024: val_f1_score did not improve from 0.99366\n",
      "155/155 [==============================] - 150s 965ms/step - loss: 0.0167 - acc: 0.9937 - f1_score: 0.9937 - val_loss: 0.0261 - val_acc: 0.9907 - val_f1_score: 0.9907\n",
      "Epoch 25/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0159 - acc: 0.9943 - f1_score: 0.9943\n",
      "Epoch 00025: val_f1_score did not improve from 0.99366\n",
      "155/155 [==============================] - 142s 915ms/step - loss: 0.0159 - acc: 0.9943 - f1_score: 0.9943 - val_loss: 0.0323 - val_acc: 0.9912 - val_f1_score: 0.9912\n",
      "Epoch 26/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0142 - acc: 0.9952 - f1_score: 0.9952\n",
      "Epoch 00026: val_f1_score did not improve from 0.99366\n",
      "155/155 [==============================] - 140s 903ms/step - loss: 0.0142 - acc: 0.9952 - f1_score: 0.9952 - val_loss: 0.0562 - val_acc: 0.9854 - val_f1_score: 0.9854\n",
      "Epoch 27/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0139 - acc: 0.9952 - f1_score: 0.9952\n",
      "Epoch 00027: val_f1_score did not improve from 0.99366\n",
      "155/155 [==============================] - 146s 945ms/step - loss: 0.0139 - acc: 0.9952 - f1_score: 0.9952 - val_loss: 0.0361 - val_acc: 0.9878 - val_f1_score: 0.9878\n",
      "Epoch 28/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0188 - acc: 0.9932 - f1_score: 0.9932\n",
      "Epoch 00028: val_f1_score improved from 0.99366 to 0.99415, saving model to /app/_data/models/final/ScabHealthy/eff4_hs__4.h5\n",
      "155/155 [==============================] - 152s 980ms/step - loss: 0.0188 - acc: 0.9932 - f1_score: 0.9932 - val_loss: 0.0215 - val_acc: 0.9942 - val_f1_score: 0.9942\n",
      "Epoch 29/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0211 - acc: 0.9934 - f1_score: 0.9934\n",
      "Epoch 00029: val_f1_score did not improve from 0.99415\n",
      "155/155 [==============================] - 150s 965ms/step - loss: 0.0211 - acc: 0.9934 - f1_score: 0.9934 - val_loss: 0.0635 - val_acc: 0.9844 - val_f1_score: 0.9844\n",
      "Epoch 30/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0160 - acc: 0.9943 - f1_score: 0.9943\n",
      "Epoch 00030: val_f1_score did not improve from 0.99415\n",
      "155/155 [==============================] - 142s 913ms/step - loss: 0.0160 - acc: 0.9943 - f1_score: 0.9943 - val_loss: 0.0351 - val_acc: 0.9893 - val_f1_score: 0.9893\n",
      "Epoch 31/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0139 - acc: 0.9949 - f1_score: 0.9949\n",
      "Epoch 00031: val_f1_score improved from 0.99415 to 0.99513, saving model to /app/_data/models/final/ScabHealthy/eff4_hs__4.h5\n",
      "155/155 [==============================] - 147s 946ms/step - loss: 0.0139 - acc: 0.9949 - f1_score: 0.9949 - val_loss: 0.0173 - val_acc: 0.9951 - val_f1_score: 0.9951\n",
      "Epoch 32/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0150 - acc: 0.9947 - f1_score: 0.9947\n",
      "Epoch 00032: val_f1_score did not improve from 0.99513\n",
      "155/155 [==============================] - 131s 845ms/step - loss: 0.0150 - acc: 0.9947 - f1_score: 0.9947 - val_loss: 0.0197 - val_acc: 0.9917 - val_f1_score: 0.9917\n",
      "Epoch 33/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0097 - acc: 0.9963 - f1_score: 0.9963\n",
      "Epoch 00033: val_f1_score did not improve from 0.99513\n",
      "155/155 [==============================] - 149s 962ms/step - loss: 0.0097 - acc: 0.9963 - f1_score: 0.9963 - val_loss: 0.0264 - val_acc: 0.9903 - val_f1_score: 0.9903\n",
      "Epoch 34/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0129 - acc: 0.9964 - f1_score: 0.9964\n",
      "Epoch 00034: val_f1_score did not improve from 0.99513\n",
      "155/155 [==============================] - 149s 958ms/step - loss: 0.0129 - acc: 0.9964 - f1_score: 0.9964 - val_loss: 0.0376 - val_acc: 0.9883 - val_f1_score: 0.9883\n",
      "Epoch 35/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0147 - acc: 0.9945 - f1_score: 0.9945\n",
      "Epoch 00035: val_f1_score did not improve from 0.99513\n",
      "155/155 [==============================] - 132s 853ms/step - loss: 0.0147 - acc: 0.9945 - f1_score: 0.9945 - val_loss: 0.0547 - val_acc: 0.9898 - val_f1_score: 0.9898\n",
      "Epoch 36/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0092 - acc: 0.9964 - f1_score: 0.9964\n",
      "Epoch 00036: val_f1_score improved from 0.99513 to 0.99561, saving model to /app/_data/models/final/ScabHealthy/eff4_hs__4.h5\n",
      "155/155 [==============================] - 152s 980ms/step - loss: 0.0092 - acc: 0.9964 - f1_score: 0.9964 - val_loss: 0.0178 - val_acc: 0.9956 - val_f1_score: 0.9956\n",
      "Epoch 37/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0083 - acc: 0.9974 - f1_score: 0.9974\n",
      "Epoch 00037: val_f1_score did not improve from 0.99561\n",
      "155/155 [==============================] - 143s 925ms/step - loss: 0.0083 - acc: 0.9974 - f1_score: 0.9974 - val_loss: 0.0229 - val_acc: 0.9922 - val_f1_score: 0.9922\n",
      "Epoch 38/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0144 - acc: 0.9949 - f1_score: 0.9949\n",
      "Epoch 00038: val_f1_score did not improve from 0.99561\n",
      "155/155 [==============================] - 148s 958ms/step - loss: 0.0144 - acc: 0.9949 - f1_score: 0.9949 - val_loss: 0.0324 - val_acc: 0.9922 - val_f1_score: 0.9922\n",
      "Epoch 39/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0122 - acc: 0.9958 - f1_score: 0.9958\n",
      "Epoch 00039: val_f1_score did not improve from 0.99561\n",
      "155/155 [==============================] - 158s 1s/step - loss: 0.0122 - acc: 0.9958 - f1_score: 0.9958 - val_loss: 0.0868 - val_acc: 0.9810 - val_f1_score: 0.9810\n",
      "Epoch 40/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0137 - acc: 0.9953 - f1_score: 0.9953\n",
      "Epoch 00040: val_f1_score did not improve from 0.99561\n",
      "155/155 [==============================] - 144s 930ms/step - loss: 0.0137 - acc: 0.9953 - f1_score: 0.9953 - val_loss: 0.0168 - val_acc: 0.9951 - val_f1_score: 0.9951\n",
      "Epoch 41/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0118 - acc: 0.9962 - f1_score: 0.9962\n",
      "Epoch 00041: val_f1_score did not improve from 0.99561\n",
      "155/155 [==============================] - 154s 991ms/step - loss: 0.0118 - acc: 0.9962 - f1_score: 0.9962 - val_loss: 0.0468 - val_acc: 0.9873 - val_f1_score: 0.9873\n",
      "Epoch 42/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0142 - acc: 0.9955 - f1_score: 0.9955\n",
      "Epoch 00042: val_f1_score did not improve from 0.99561\n",
      "155/155 [==============================] - 151s 976ms/step - loss: 0.0142 - acc: 0.9955 - f1_score: 0.9955 - val_loss: 0.0228 - val_acc: 0.9922 - val_f1_score: 0.9922\n",
      "Epoch 43/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0104 - acc: 0.9962 - f1_score: 0.9962\n",
      "Epoch 00043: val_f1_score did not improve from 0.99561\n",
      "155/155 [==============================] - 156s 1s/step - loss: 0.0104 - acc: 0.9962 - f1_score: 0.9962 - val_loss: 0.0278 - val_acc: 0.9927 - val_f1_score: 0.9927\n",
      "Epoch 44/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0125 - acc: 0.9956 - f1_score: 0.9956\n",
      "Epoch 00044: val_f1_score did not improve from 0.99561\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.0004500000213738531.\n",
      "155/155 [==============================] - 151s 977ms/step - loss: 0.0125 - acc: 0.9956 - f1_score: 0.9956 - val_loss: 0.0528 - val_acc: 0.9888 - val_f1_score: 0.9888\n",
      "Epoch 45/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0153 - acc: 0.9950 - f1_score: 0.9950\n",
      "Epoch 00045: val_f1_score did not improve from 0.99561\n",
      "155/155 [==============================] - 149s 958ms/step - loss: 0.0153 - acc: 0.9950 - f1_score: 0.9950 - val_loss: 0.0354 - val_acc: 0.9864 - val_f1_score: 0.9863\n",
      "Epoch 46/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0086 - acc: 0.9969 - f1_score: 0.9969\n",
      "Epoch 00046: val_f1_score did not improve from 0.99561\n",
      "155/155 [==============================] - 151s 972ms/step - loss: 0.0086 - acc: 0.9969 - f1_score: 0.9969 - val_loss: 0.0209 - val_acc: 0.9907 - val_f1_score: 0.9907\n",
      "Epoch 47/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0081 - acc: 0.9977 - f1_score: 0.9977Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00047: val_f1_score did not improve from 0.99561\n",
      "155/155 [==============================] - 159s 1s/step - loss: 0.0081 - acc: 0.9977 - f1_score: 0.9977 - val_loss: 0.0241 - val_acc: 0.9927 - val_f1_score: 0.9927\n",
      "Epoch 00047: early stopping\n",
      "\n",
      "Starting 5 skf\n",
      "\n",
      "Epoch 1/100\n",
      "  2/155 [..............................] - ETA: 4:09 - loss: 0.6985 - acc: 0.5926 - f1_score: 0.5896WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.9953s vs `on_train_batch_end` time: 2.2635s). Check your callbacks.\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.1350 - acc: 0.9473 - f1_score: 0.9473\n",
      "Epoch 00001: val_f1_score improved from -inf to 0.93411, saving model to /app/_data/models/final/ScabHealthy/eff4_hs__5.h5\n",
      "155/155 [==============================] - 145s 937ms/step - loss: 0.1350 - acc: 0.9473 - f1_score: 0.9473 - val_loss: 0.2070 - val_acc: 0.9342 - val_f1_score: 0.9341\n",
      "Epoch 2/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0649 - acc: 0.9748 - f1_score: 0.9747\n",
      "Epoch 00002: val_f1_score improved from 0.93411 to 0.97710, saving model to /app/_data/models/final/ScabHealthy/eff4_hs__5.h5\n",
      "155/155 [==============================] - 164s 1s/step - loss: 0.0649 - acc: 0.9748 - f1_score: 0.9747 - val_loss: 0.0792 - val_acc: 0.9771 - val_f1_score: 0.9771\n",
      "Epoch 3/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0554 - acc: 0.9809 - f1_score: 0.9809\n",
      "Epoch 00003: val_f1_score improved from 0.97710 to 0.98879, saving model to /app/_data/models/final/ScabHealthy/eff4_hs__5.h5\n",
      "155/155 [==============================] - 152s 984ms/step - loss: 0.0554 - acc: 0.9809 - f1_score: 0.9809 - val_loss: 0.0334 - val_acc: 0.9888 - val_f1_score: 0.9888\n",
      "Epoch 4/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0456 - acc: 0.9821 - f1_score: 0.9821\n",
      "Epoch 00004: val_f1_score did not improve from 0.98879\n",
      "155/155 [==============================] - 145s 939ms/step - loss: 0.0456 - acc: 0.9821 - f1_score: 0.9821 - val_loss: 0.0464 - val_acc: 0.9864 - val_f1_score: 0.9864\n",
      "Epoch 5/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0416 - acc: 0.9852 - f1_score: 0.9852\n",
      "Epoch 00005: val_f1_score did not improve from 0.98879\n",
      "155/155 [==============================] - 151s 977ms/step - loss: 0.0416 - acc: 0.9852 - f1_score: 0.9852 - val_loss: 0.0483 - val_acc: 0.9868 - val_f1_score: 0.9868\n",
      "Epoch 6/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0359 - acc: 0.9872 - f1_score: 0.9872\n",
      "Epoch 00006: val_f1_score improved from 0.98879 to 0.98928, saving model to /app/_data/models/final/ScabHealthy/eff4_hs__5.h5\n",
      "155/155 [==============================] - 160s 1s/step - loss: 0.0359 - acc: 0.9872 - f1_score: 0.9872 - val_loss: 0.0378 - val_acc: 0.9893 - val_f1_score: 0.9893\n",
      "Epoch 7/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0306 - acc: 0.9902 - f1_score: 0.9902\n",
      "Epoch 00007: val_f1_score did not improve from 0.98928\n",
      "155/155 [==============================] - 152s 983ms/step - loss: 0.0306 - acc: 0.9902 - f1_score: 0.9902 - val_loss: 0.0337 - val_acc: 0.9878 - val_f1_score: 0.9878\n",
      "Epoch 8/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0247 - acc: 0.9915 - f1_score: 0.9915\n",
      "Epoch 00008: val_f1_score did not improve from 0.98928\n",
      "155/155 [==============================] - 156s 1s/step - loss: 0.0247 - acc: 0.9915 - f1_score: 0.9915 - val_loss: 0.0504 - val_acc: 0.9859 - val_f1_score: 0.9859\n",
      "Epoch 9/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0306 - acc: 0.9897 - f1_score: 0.9897\n",
      "Epoch 00009: val_f1_score did not improve from 0.98928\n",
      "155/155 [==============================] - 153s 985ms/step - loss: 0.0306 - acc: 0.9897 - f1_score: 0.9897 - val_loss: 0.0694 - val_acc: 0.9776 - val_f1_score: 0.9776\n",
      "Epoch 10/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0339 - acc: 0.9881 - f1_score: 0.9881\n",
      "Epoch 00010: val_f1_score improved from 0.98928 to 0.99074, saving model to /app/_data/models/final/ScabHealthy/eff4_hs__5.h5\n",
      "155/155 [==============================] - 162s 1s/step - loss: 0.0339 - acc: 0.9881 - f1_score: 0.9881 - val_loss: 0.0372 - val_acc: 0.9907 - val_f1_score: 0.9907\n",
      "Epoch 11/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0247 - acc: 0.9921 - f1_score: 0.9921\n",
      "Epoch 00011: val_f1_score did not improve from 0.99074\n",
      "155/155 [==============================] - 153s 989ms/step - loss: 0.0247 - acc: 0.9921 - f1_score: 0.9921 - val_loss: 0.0350 - val_acc: 0.9903 - val_f1_score: 0.9903\n",
      "Epoch 12/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0198 - acc: 0.9924 - f1_score: 0.9924\n",
      "Epoch 00012: val_f1_score improved from 0.99074 to 0.99171, saving model to /app/_data/models/final/ScabHealthy/eff4_hs__5.h5\n",
      "155/155 [==============================] - 150s 966ms/step - loss: 0.0198 - acc: 0.9924 - f1_score: 0.9924 - val_loss: 0.0264 - val_acc: 0.9917 - val_f1_score: 0.9917\n",
      "Epoch 13/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0184 - acc: 0.9932 - f1_score: 0.9932\n",
      "Epoch 00013: val_f1_score did not improve from 0.99171\n",
      "155/155 [==============================] - 161s 1s/step - loss: 0.0184 - acc: 0.9932 - f1_score: 0.9932 - val_loss: 0.0412 - val_acc: 0.9883 - val_f1_score: 0.9883\n",
      "Epoch 14/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0199 - acc: 0.9935 - f1_score: 0.9935\n",
      "Epoch 00014: val_f1_score did not improve from 0.99171\n",
      "155/155 [==============================] - 158s 1s/step - loss: 0.0199 - acc: 0.9935 - f1_score: 0.9935 - val_loss: 0.0707 - val_acc: 0.9795 - val_f1_score: 0.9795\n",
      "Epoch 15/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0268 - acc: 0.9903 - f1_score: 0.9903\n",
      "Epoch 00015: val_f1_score improved from 0.99171 to 0.99220, saving model to /app/_data/models/final/ScabHealthy/eff4_hs__5.h5\n",
      "155/155 [==============================] - 166s 1s/step - loss: 0.0268 - acc: 0.9903 - f1_score: 0.9903 - val_loss: 0.0288 - val_acc: 0.9922 - val_f1_score: 0.9922\n",
      "Epoch 16/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0212 - acc: 0.9930 - f1_score: 0.9930\n",
      "Epoch 00016: val_f1_score did not improve from 0.99220\n",
      "155/155 [==============================] - 147s 948ms/step - loss: 0.0212 - acc: 0.9930 - f1_score: 0.9930 - val_loss: 0.0350 - val_acc: 0.9878 - val_f1_score: 0.9878\n",
      "Epoch 17/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0217 - acc: 0.9912 - f1_score: 0.9912\n",
      "Epoch 00017: val_f1_score did not improve from 0.99220\n",
      "155/155 [==============================] - 158s 1s/step - loss: 0.0217 - acc: 0.9912 - f1_score: 0.9912 - val_loss: 0.0307 - val_acc: 0.9912 - val_f1_score: 0.9912\n",
      "Epoch 18/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0175 - acc: 0.9940 - f1_score: 0.9940\n",
      "Epoch 00018: val_f1_score did not improve from 0.99220\n",
      "155/155 [==============================] - 162s 1s/step - loss: 0.0175 - acc: 0.9940 - f1_score: 0.9940 - val_loss: 0.0344 - val_acc: 0.9912 - val_f1_score: 0.9912\n",
      "Epoch 19/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0195 - acc: 0.9938 - f1_score: 0.9938\n",
      "Epoch 00019: val_f1_score did not improve from 0.99220\n",
      "155/155 [==============================] - 159s 1s/step - loss: 0.0195 - acc: 0.9938 - f1_score: 0.9938 - val_loss: 0.0349 - val_acc: 0.9907 - val_f1_score: 0.9907\n",
      "Epoch 20/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0171 - acc: 0.9940 - f1_score: 0.9940\n",
      "Epoch 00020: val_f1_score did not improve from 0.99220\n",
      "155/155 [==============================] - 172s 1s/step - loss: 0.0171 - acc: 0.9940 - f1_score: 0.9940 - val_loss: 0.0302 - val_acc: 0.9917 - val_f1_score: 0.9917\n",
      "Epoch 21/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0213 - acc: 0.9934 - f1_score: 0.9934\n",
      "Epoch 00021: val_f1_score did not improve from 0.99220\n",
      "155/155 [==============================] - 167s 1s/step - loss: 0.0213 - acc: 0.9934 - f1_score: 0.9934 - val_loss: 0.0417 - val_acc: 0.9854 - val_f1_score: 0.9854\n",
      "Epoch 22/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0157 - acc: 0.9938 - f1_score: 0.9938\n",
      "Epoch 00022: val_f1_score did not improve from 0.99220\n",
      "155/155 [==============================] - 156s 1s/step - loss: 0.0157 - acc: 0.9938 - f1_score: 0.9938 - val_loss: 0.0272 - val_acc: 0.9922 - val_f1_score: 0.9922\n",
      "Epoch 23/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0214 - acc: 0.9924 - f1_score: 0.9924\n",
      "Epoch 00023: val_f1_score did not improve from 0.99220\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0004500000213738531.\n",
      "155/155 [==============================] - 156s 1s/step - loss: 0.0214 - acc: 0.9924 - f1_score: 0.9924 - val_loss: 0.0892 - val_acc: 0.9771 - val_f1_score: 0.9771\n",
      "Epoch 24/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0161 - acc: 0.9941 - f1_score: 0.9941\n",
      "Epoch 00024: val_f1_score improved from 0.99220 to 0.99415, saving model to /app/_data/models/final/ScabHealthy/eff4_hs__5.h5\n",
      "155/155 [==============================] - 156s 1s/step - loss: 0.0161 - acc: 0.9941 - f1_score: 0.9941 - val_loss: 0.0344 - val_acc: 0.9942 - val_f1_score: 0.9942\n",
      "Epoch 25/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0156 - acc: 0.9939 - f1_score: 0.9939\n",
      "Epoch 00025: val_f1_score did not improve from 0.99415\n",
      "155/155 [==============================] - 165s 1s/step - loss: 0.0156 - acc: 0.9939 - f1_score: 0.9939 - val_loss: 0.0275 - val_acc: 0.9903 - val_f1_score: 0.9903\n",
      "Epoch 26/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0152 - acc: 0.9943 - f1_score: 0.9943\n",
      "Epoch 00026: val_f1_score did not improve from 0.99415\n",
      "155/155 [==============================] - 169s 1s/step - loss: 0.0152 - acc: 0.9943 - f1_score: 0.9943 - val_loss: 0.0670 - val_acc: 0.9834 - val_f1_score: 0.9834\n",
      "Epoch 27/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0149 - acc: 0.9957 - f1_score: 0.9957\n",
      "Epoch 00027: val_f1_score did not improve from 0.99415\n",
      "155/155 [==============================] - 168s 1s/step - loss: 0.0149 - acc: 0.9957 - f1_score: 0.9957 - val_loss: 0.0353 - val_acc: 0.9903 - val_f1_score: 0.9903\n",
      "Epoch 28/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0118 - acc: 0.9961 - f1_score: 0.9961\n",
      "Epoch 00028: val_f1_score did not improve from 0.99415\n",
      "155/155 [==============================] - 156s 1s/step - loss: 0.0118 - acc: 0.9961 - f1_score: 0.9961 - val_loss: 0.0331 - val_acc: 0.9898 - val_f1_score: 0.9898\n",
      "Epoch 29/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0145 - acc: 0.9950 - f1_score: 0.9950\n",
      "Epoch 00029: val_f1_score did not improve from 0.99415\n",
      "155/155 [==============================] - 152s 981ms/step - loss: 0.0145 - acc: 0.9950 - f1_score: 0.9950 - val_loss: 0.0362 - val_acc: 0.9898 - val_f1_score: 0.9898\n",
      "Epoch 30/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0169 - acc: 0.9937 - f1_score: 0.9937\n",
      "Epoch 00030: val_f1_score did not improve from 0.99415\n",
      "155/155 [==============================] - 162s 1s/step - loss: 0.0169 - acc: 0.9937 - f1_score: 0.9937 - val_loss: 0.0330 - val_acc: 0.9927 - val_f1_score: 0.9927\n",
      "Epoch 31/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0126 - acc: 0.9955 - f1_score: 0.9955\n",
      "Epoch 00031: val_f1_score did not improve from 0.99415\n",
      "155/155 [==============================] - 162s 1s/step - loss: 0.0126 - acc: 0.9955 - f1_score: 0.9955 - val_loss: 0.0292 - val_acc: 0.9922 - val_f1_score: 0.9922\n",
      "Epoch 32/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0139 - acc: 0.9949 - f1_score: 0.9949\n",
      "Epoch 00032: val_f1_score did not improve from 0.99415\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0004050000192364678.\n",
      "155/155 [==============================] - 171s 1s/step - loss: 0.0139 - acc: 0.9949 - f1_score: 0.9949 - val_loss: 0.0322 - val_acc: 0.9912 - val_f1_score: 0.9912\n",
      "Epoch 33/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0060 - acc: 0.9984 - f1_score: 0.9984\n",
      "Epoch 00033: val_f1_score did not improve from 0.99415\n",
      "155/155 [==============================] - 151s 972ms/step - loss: 0.0060 - acc: 0.9984 - f1_score: 0.9984 - val_loss: 0.0413 - val_acc: 0.9898 - val_f1_score: 0.9898\n",
      "Epoch 34/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0101 - acc: 0.9962 - f1_score: 0.9962\n",
      "Epoch 00034: val_f1_score did not improve from 0.99415\n",
      "155/155 [==============================] - 155s 1s/step - loss: 0.0101 - acc: 0.9962 - f1_score: 0.9962 - val_loss: 0.0351 - val_acc: 0.9907 - val_f1_score: 0.9907\n",
      "Epoch 35/100\n",
      "155/155 [==============================] - ETA: 0s - loss: 0.0135 - acc: 0.9947 - f1_score: 0.9947Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00035: val_f1_score did not improve from 0.99415\n",
      "155/155 [==============================] - 164s 1s/step - loss: 0.0135 - acc: 0.9947 - f1_score: 0.9947 - val_loss: 0.0290 - val_acc: 0.9932 - val_f1_score: 0.9932\n",
      "Epoch 00035: early stopping\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=SEED, shuffle=True)\n",
    "\n",
    "for i, (train_index, valid_index) in enumerate(\n",
    "    skf.split(df_labels[\"image\"], df_labels[\"labels\"])\n",
    "):\n",
    "    train, valid = df_labels.loc[train_index], df_labels.loc[valid_index]\n",
    "    print(\"\\nStarting \" + str(i+1) + \" skf\\n\")\n",
    "    model_name = \"eff4_hs__\" + str(i + 1) + \".h5\"\n",
    "    log_dir = \"logs_hs_\" + str(i + 1) + \"/\"\n",
    "    callbacks = [\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_f1_score\",\n",
    "            patience=11,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1,\n",
    "            mode=\"max\",\n",
    "        ),\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            \"/app/_data/models/final/ScabHealthy/\" + model_name,\n",
    "            monitor=\"val_f1_score\",\n",
    "            verbose=1,\n",
    "            save_best_only=True,\n",
    "            save_weights_only=False,\n",
    "            mode=\"max\",\n",
    "            save_freq=\"epoch\",\n",
    "        ),\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor=\"val_f1_score\",\n",
    "            factor=0.9,\n",
    "            patience=8,\n",
    "            verbose=1,\n",
    "            mode=\"max\",\n",
    "            min_delta=1e-4,\n",
    "            min_lr=0.00000001,\n",
    "        ),\n",
    "        keras.callbacks.TensorBoard(\n",
    "            log_dir=\"/app/.tensorboard/\" + log_dir, histogram_freq=0\n",
    "        ),\n",
    "        keras.callbacks.experimental.BackupAndRestore(\n",
    "            \"/app/_data/models/final/ScabHealthy/backup/\"\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    gen_train = Generator(\n",
    "        df=train,\n",
    "        feature_columns = feature_columns_hs,\n",
    "        images_src_dir=TRAIN_IMG_PATH,\n",
    "        target_image_size=IMAGE_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        augment=True,\n",
    "        crop=False,\n",
    "        resize=False,\n",
    "    )\n",
    "    gen_valid = Generator(\n",
    "        df=valid,\n",
    "        feature_columns = feature_columns_hs,\n",
    "        images_src_dir=TRAIN_IMG_PATH,\n",
    "        target_image_size=IMAGE_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        augment=False,\n",
    "        crop=False,\n",
    "        resize=False,\n",
    "    )\n",
    "    model = get_model()\n",
    "    history = model.fit(\n",
    "        gen_train,\n",
    "        validation_data=gen_valid,\n",
    "        epochs=100,\n",
    "        steps_per_epoch=train.shape[0] // BATCH_SIZE,\n",
    "        validation_steps=valid.shape[0] // BATCH_SIZE,\n",
    "        verbose=1,\n",
    "        workers=15,\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "    tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
