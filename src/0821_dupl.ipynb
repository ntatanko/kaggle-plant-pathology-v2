{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /app/kaggle.json'\n"
     ]
    }
   ],
   "source": [
    "import kaggle\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eff4_ns_0891_kf_dup_1.h5',\n",
       " 'eff4_ns_0891_kf_dup_4.h5',\n",
       " 'eff4_ns_0891_kf_dup_5.h5',\n",
       " 'eff4_ns_0891_kf_dup_2.h5',\n",
       " 'eff4_ns_0891_kf_dup_3.h5']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/app/_data/models/final/with_dup/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /app/kaggle.json'\n",
      "Data package template written to: /app/_data/models/final/with_dup/dataset-metadata.json\n"
     ]
    }
   ],
   "source": [
    "! kaggle datasets init -p /app/_data/models/final/with_dup/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /app/kaggle.json'\n",
      "Starting upload for file eff4_ns_0891_kf_dup_1.h5\n",
      "100%|█████████████████████████████████████████| 203M/203M [05:15<00:00, 676kB/s]\n",
      "Upload successful: eff4_ns_0891_kf_dup_1.h5 (203MB)\n",
      "Starting upload for file eff4_ns_0891_kf_dup_4.h5\n",
      "100%|█████████████████████████████████████████| 203M/203M [05:11<00:00, 684kB/s]\n",
      "Upload successful: eff4_ns_0891_kf_dup_4.h5 (203MB)\n",
      "Starting upload for file eff4_ns_0891_kf_dup_5.h5\n",
      "100%|█████████████████████████████████████████| 203M/203M [05:16<00:00, 673kB/s]\n",
      "Upload successful: eff4_ns_0891_kf_dup_5.h5 (203MB)\n",
      "Starting upload for file eff4_ns_0891_kf_dup_2.h5\n",
      "100%|█████████████████████████████████████████| 203M/203M [05:16<00:00, 672kB/s]\n",
      "Upload successful: eff4_ns_0891_kf_dup_2.h5 (203MB)\n",
      "Starting upload for file eff4_ns_0891_kf_dup_3.h5\n",
      "100%|█████████████████████████████████████████| 203M/203M [05:16<00:00, 674kB/s]\n",
      "Upload successful: eff4_ns_0891_kf_dup_3.h5 (203MB)\n",
      "Skipping folder: .ipynb_checkpoints; use '--dir-mode' to upload folders\n",
      "Your private Dataset is being created. Please check progress at https://www.kaggle.com/nataliayurasova/WithDup\n"
     ]
    }
   ],
   "source": [
    "! kaggle datasets create -p /app/_data/models/final/with_dup/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.891\n",
    "MODEL_BB_PATH= '../input/model-bb-1/bond_box_999_200.h5'\n",
    "MODEL_PATH = '../input/0865fulltrain/'\n",
    "IMAGE_SIZE = (380, 380)\n",
    "DF_PART = '../input/df-kf-plant/df_kf.csv'\n",
    "PATH = \"/kaggle/input/plant-pathology-2021-fgvc8/\"\n",
    "TRAIN_IMG_PATH = PATH+'train_images/'\n",
    "TEST_IMG_PATH = PATH+'test_images/'\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES=6\n",
    "SEED = 1488\n",
    "- replace ''-'scab'\n",
    "https://www.kaggle.com/nataliayurasova/plant-pathology0891/edit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: albumentations in /usr/local/lib/python3.8/dist-packages (0.5.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from albumentations) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.8/dist-packages (from albumentations) (1.17.3)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.8/dist-packages (from albumentations) (0.18.1)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from albumentations) (5.3.1)\n",
      "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.8/dist-packages (from albumentations) (4.5.1.48)\n",
      "Requirement already satisfied: imgaug>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from albumentations) (0.4.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from imgaug>=0.4.0->albumentations) (3.3.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from imgaug>=0.4.0->albumentations) (1.15.0)\n",
      "Requirement already satisfied: imageio in /usr/local/lib/python3.8/dist-packages (from imgaug>=0.4.0->albumentations) (2.9.0)\n",
      "Requirement already satisfied: Shapely in /usr/local/lib/python3.8/dist-packages (from imgaug>=0.4.0->albumentations) (1.7.1)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from imgaug>=0.4.0->albumentations) (8.1.2)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (from imgaug>=0.4.0->albumentations) (4.5.1.48)\n",
      "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.16.1->albumentations) (2.5.1)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.16.1->albumentations) (1.1.1)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.16.1->albumentations) (2021.4.8)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations) (2.8.1)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.8/dist-packages (from networkx>=2.0->scikit-image>=0.16.1->albumentations) (4.4.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install albumentations\n",
    "import albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import (\n",
    "    StratifiedKFold,\n",
    "    StratifiedShuffleSplit,\n",
    "    train_test_split,\n",
    ")\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB4, EfficientNetB7\n",
    "from tensorflow.keras.layers import (\n",
    "    AveragePooling2D,\n",
    "    AvgPool2D,\n",
    "    Conv2D,\n",
    "    Dense,\n",
    "    Flatten,\n",
    "    GlobalAveragePooling2D,\n",
    "    MaxPooling2D,\n",
    ")\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tqdm import notebook, tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong = ['ead085dfac287263.jpg', '95276ccd226ad933.jpg',\"da8770e819d2696d.jpg\", 'cd3a1d64e6806eb5.jpg', 'ccec54723ff91860.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/app/_data/\"\n",
    "BATCH_SIZE = 64\n",
    "SEED = 42\n",
    "IMAGE_SIZE = 380\n",
    "NUM_CLASSES = 6\n",
    "TRAIN_IMG_PATH = \"/app/_data/380_npy/\"\n",
    "TEST_IMG_PATH = \"/app/_data/test_images/\"\n",
    "feature_columns = [\n",
    "    \"complex\",\n",
    "    \"frog_eye_leaf_spot\",\n",
    "    \"healthy\",\n",
    "    \"powdery_mildew\",\n",
    "    \"rust\",\n",
    "    \"scab\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_labels = pd.read_csv('../_data/df_csv/train.csv', index_col=[0])\n",
    "orig_labels = orig_labels.query('image not in @wrong').reset_index(drop=True)\n",
    "orig_labels = orig_labels.join(orig_labels['labels'].str.get_dummies(' '))\n",
    "labels_2020 = pd.read_csv('../_data/df_csv/train_20.csv')\n",
    "labels_2020.columns = ['image', 'healthy', 'multiple_diseases', 'rust', 'scab']\n",
    "labels_2020 = labels_2020.query('multiple_diseases != 1')\n",
    "labels_2020 = labels_2020.drop('multiple_diseases', axis=1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns_20 = [\"healthy\", \"rust\", \"scab\"]\n",
    "for i in labels_2020.index:\n",
    "    labels_2020.loc[i, \"labels\"] = \"\".join(\n",
    "        list(\n",
    "            map(\n",
    "                lambda x, y: x * y,\n",
    "                labels_2020.loc[i, feature_columns_20].values,\n",
    "                feature_columns_20,\n",
    "            )\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_2020['image'] = labels_2020['image']+'.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>healthy</th>\n",
       "      <th>rust</th>\n",
       "      <th>scab</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train_0.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>scab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train_2.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train_3.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train_4.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train_5.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>Train_1816.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>scab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>Train_1817.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727</th>\n",
       "      <td>Train_1818.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1728</th>\n",
       "      <td>Train_1819.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1729</th>\n",
       "      <td>Train_1820.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>scab</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1730 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               image  healthy  rust  scab   labels\n",
       "0        Train_0.jpg        0     0     1     scab\n",
       "1        Train_2.jpg        1     0     0  healthy\n",
       "2        Train_3.jpg        0     1     0     rust\n",
       "3        Train_4.jpg        1     0     0  healthy\n",
       "4        Train_5.jpg        1     0     0  healthy\n",
       "...              ...      ...   ...   ...      ...\n",
       "1725  Train_1816.jpg        0     0     1     scab\n",
       "1726  Train_1817.jpg        1     0     0  healthy\n",
       "1727  Train_1818.jpg        1     0     0  healthy\n",
       "1728  Train_1819.jpg        0     1     0     rust\n",
       "1729  Train_1820.jpg        0     0     1     scab\n",
       "\n",
       "[1730 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20357, 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_21_20 = pd.concat([orig_labels, labels_2020], axis=0, join=\"outer\", ignore_index=True)\n",
    "labels_21_20[feature_columns] = labels_21_20[feature_columns].fillna(0).astype(\"int\")\n",
    "labels_21_20[\"image\"] = labels_21_20[\"image\"].str.replace(\".jpg\", \".npy\")\n",
    "df_labels = labels_21_20.sample(frac=1, random_state=SEED)\n",
    "df_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20357, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 380*380\n",
    "transform = albumentations.Compose(\n",
    "    [\n",
    "        albumentations.CLAHE(p=0.1, clip_limit=(1, 2), tile_grid_size=(8, 8)),\n",
    "        albumentations.OneOf(\n",
    "            [\n",
    "                albumentations.MotionBlur((3, 3)),\n",
    "                albumentations.MedianBlur(blur_limit=3),\n",
    "                albumentations.GaussianBlur(blur_limit=(3, 3), sigma_limit=0),\n",
    "                albumentations.Blur(blur_limit=(3, 3)),\n",
    "            ],\n",
    "            p=0.2,\n",
    "        ),\n",
    "        albumentations.OneOf(\n",
    "            [\n",
    "                albumentations.GaussNoise(var_limit=[10, 50], mean=1),\n",
    "                albumentations.ISONoise(intensity=(0.1, 1), color_shift=(0.01, 0.05)),\n",
    "                albumentations.ImageCompression(\n",
    "                    quality_lower=70, quality_upper=100, compression_type=1\n",
    "                ),\n",
    "                albumentations.MultiplicativeNoise(\n",
    "                    multiplier=(0.95, 1.05), per_channel=True, elementwise=True\n",
    "                ),\n",
    "                albumentations.Downscale(\n",
    "                    scale_min=0.6, scale_max=0.99, interpolation=4\n",
    "                ),\n",
    "            ],\n",
    "            p=0.5,\n",
    "        ),\n",
    "        albumentations.OneOf(\n",
    "            [\n",
    "                albumentations.HueSaturationValue(\n",
    "                    hue_shift_limit=(-7, 7),\n",
    "                    sat_shift_limit=(-10, 10),\n",
    "                    val_shift_limit=(-10, 10),\n",
    "                ),\n",
    "                albumentations.RandomBrightnessContrast(\n",
    "                    brightness_limit=0.15,\n",
    "                    contrast_limit=0.2,\n",
    "                    brightness_by_max=True,\n",
    "                ),\n",
    "            ],\n",
    "            p=0.5,\n",
    "        ),\n",
    "        albumentations.OneOf(\n",
    "            [\n",
    "                albumentations.OpticalDistortion(\n",
    "                    distort_limit=0.05,\n",
    "                    shift_limit=0.05,\n",
    "                    border_mode=2,\n",
    "                ),\n",
    "                albumentations.ElasticTransform(\n",
    "                    alpha=2.0,\n",
    "                    sigma=50.0,\n",
    "                    alpha_affine=10.0,\n",
    "                    interpolation=0,\n",
    "                    border_mode=2,\n",
    "                ),\n",
    "                albumentations.GridDistortion(\n",
    "                    num_steps=5, distort_limit=0.3, interpolation=0, border_mode=2\n",
    "                ),\n",
    "            ],\n",
    "            p=0.5,\n",
    "        ),\n",
    "        albumentations.OneOf(\n",
    "            [\n",
    "                albumentations.HorizontalFlip(),\n",
    "                albumentations.VerticalFlip(),\n",
    "            ],\n",
    "            p=0.5,\n",
    "        ),\n",
    "        albumentations.OneOf(\n",
    "            [\n",
    "                albumentations.Rotate(\n",
    "                    limit=(-180, 180), interpolation=0, border_mode=2\n",
    "                ),\n",
    "                albumentations.ShiftScaleRotate(\n",
    "                    shift_limit=0.05,\n",
    "                    scale_limit=0.05,\n",
    "                    rotate_limit=180,\n",
    "                    interpolation=0,\n",
    "                    border_mode=2,\n",
    "                ),\n",
    "            ],\n",
    "            p=0.5,\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(keras.utils.Sequence):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        images_src_dir,\n",
    "        batch_size,\n",
    "        target_image_size,\n",
    "        shuffle=False,\n",
    "        augment=True,\n",
    "        crop=False,\n",
    "        resize=False,\n",
    "        normalize=False,\n",
    "    ):\n",
    "        self.shuffle = shuffle\n",
    "        self.batch_size = BATCH_SIZE\n",
    "        self.df = df\n",
    "        self.images_dir = images_src_dir\n",
    "        self.target_image_size = (IMAGE_SIZE, IMAGE_SIZE)\n",
    "        self.augment = augment\n",
    "        self.crop = crop\n",
    "        self.resize = resize\n",
    "        self.normalize = normalize\n",
    "        # create label index map\n",
    "        self.labels = self._read_labels()\n",
    "        self.n_samples = self.df.shape[0]\n",
    "        self.n_batches = self.n_samples // self.batch_size\n",
    "        # shuffle data, also repeated after each epoch if needed\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.labels)\n",
    "\n",
    "    def _read_labels(self):\n",
    "        \"\"\"\n",
    "        Returns list images mapping to 1-hot label\n",
    "        \"\"\"\n",
    "\n",
    "        # label indexes\n",
    "        label_ixs = self.df[feature_columns].values\n",
    "        image_ixs = self.df[\"image\"].values\n",
    "        labels = []\n",
    "\n",
    "        for i in range(len(image_ixs)):\n",
    "            labels.append([image_ixs[i], label_ixs[i]])\n",
    "        return labels\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Length in batches\n",
    "        \"\"\"\n",
    "        return self.n_batches\n",
    "\n",
    "    def __getitem__(self, b_ix):\n",
    "        \"\"\"\n",
    "        Produce batch, by batch index\n",
    "        \"\"\"\n",
    "\n",
    "        assert b_ix < self.n_batches\n",
    "\n",
    "        b_X = np.zeros(\n",
    "            (self.batch_size, self.target_image_size[0], self.target_image_size[1], 3),\n",
    "            dtype=np.uint8,\n",
    "        )\n",
    "\n",
    "        b_Y = np.zeros(\n",
    "            (self.batch_size, self.df[feature_columns].shape[1]),\n",
    "            dtype=np.uint8,\n",
    "        )\n",
    "\n",
    "        for i in range(self.batch_size):\n",
    "            b_X[i], b_Y[i] = self.get_one(\n",
    "                i + self.batch_size * b_ix,\n",
    "            )\n",
    "\n",
    "        return (b_X, b_Y)\n",
    "\n",
    "    def get_one(self, one_ix):\n",
    "        \"\"\"\n",
    "        Get single item by absolute index\n",
    "        \"\"\"\n",
    "        id = self.labels[one_ix][0]\n",
    "        src_file = self.images_dir + id\n",
    "\n",
    "        # read file\n",
    "        x = np.load(src_file)\n",
    "        if self.crop:\n",
    "            coord = self.df[self.df[\"image\"] == id][\n",
    "                [\"x_min\", \"y_min\", \"x_max\", \"y_max\"]\n",
    "            ].values[0]\n",
    "            orig_hight = x.shape[0]\n",
    "            orig_width = x.shape[1]\n",
    "            x_min = coord[0]\n",
    "            y_min = coord[1]\n",
    "            x_max = coord[2]\n",
    "            y_max = coord[3]\n",
    "            x = x[\n",
    "                np.int(y_min * orig_hight) : np.int(y_max * orig_hight),\n",
    "                np.int(x_min * orig_width) : np.int(x_max * orig_width),\n",
    "            ]\n",
    "\n",
    "        y = self.labels[one_ix][1]\n",
    "\n",
    "        # augment\n",
    "        if self.augment:\n",
    "            x = self._augment_image(x)\n",
    "\n",
    "        # normalize (sample-wise)\n",
    "        if self.normalize:\n",
    "            x = x.astype(np.float32)\n",
    "            x = x - np.mean(x, axis=(0, 1))\n",
    "            x = x / np.std(x, axis=(0, 1))\n",
    "        return x.astype(np.uint8), y\n",
    "\n",
    "    def _augment_image(self, x):\n",
    "        \"\"\"\n",
    "        Randomply augment image\n",
    "        \"\"\"\n",
    "\n",
    "        x = transform(image=x)[\"image\"]\n",
    "        return x\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3090, compute capability 8.6\n"
     ]
    }
   ],
   "source": [
    "policy = keras.mixed_precision.experimental.Policy(\"mixed_float16\")\n",
    "keras.mixed_precision.experimental.set_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    inputs = keras.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "    base_model = keras.applications.EfficientNetB4(weights=None, include_top=False)\n",
    "    base_model.load_weights(\n",
    "        \"/app/_data/models/efficientnet-b4_noisy-student_notop.h5\",\n",
    "        by_name=True,\n",
    "        skip_mismatch=True,\n",
    "    )\n",
    "    x = base_model(inputs)\n",
    "    x = keras.layers.GlobalAveragePooling2D(name=\"avg_pool\")(x)\n",
    "    x = keras.layers.Flatten(name=\"flatten\")(x)\n",
    "    outputs = keras.layers.Dense(NUM_CLASSES, activation=\"sigmoid\")(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=Adam(lr=0.0005),\n",
    "        metrics=[\n",
    "            \"acc\",\n",
    "            keras.metrics.Recall(),\n",
    "            keras.metrics.Precision(),\n",
    "            tfa.metrics.F1Score(num_classes=NUM_CLASSES, average=\"weighted\"),\n",
    "        ],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  1/290 [..............................] - ETA: 0s - loss: 0.6997 - acc: 0.1607 - recall: 0.5625 - precision: 0.2143 - f1_score: 0.1354WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.1452 - acc: 0.8470 - recall: 0.8096 - precision: 0.8636 - f1_score: 0.8345\n",
      "Epoch 00001: val_f1_score improved from -inf to 0.86637, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_1.h5\n",
      "290/290 [==============================] - 138s 477ms/step - loss: 0.1452 - acc: 0.8470 - recall: 0.8096 - precision: 0.8636 - f1_score: 0.8345 - val_loss: 0.1158 - val_acc: 0.8775 - val_recall: 0.8379 - val_precision: 0.9010 - val_f1_score: 0.8664\n",
      "Epoch 2/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0988 - acc: 0.8932 - recall: 0.8708 - precision: 0.9051 - f1_score: 0.8813\n",
      "Epoch 00002: val_f1_score improved from 0.86637 to 0.89484, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_1.h5\n",
      "290/290 [==============================] - 136s 469ms/step - loss: 0.0988 - acc: 0.8932 - recall: 0.8708 - precision: 0.9051 - f1_score: 0.8813 - val_loss: 0.0887 - val_acc: 0.9139 - val_recall: 0.8767 - val_precision: 0.9264 - val_f1_score: 0.8948\n",
      "Epoch 3/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0890 - acc: 0.9027 - recall: 0.8843 - precision: 0.9137 - f1_score: 0.8904\n",
      "Epoch 00003: val_f1_score did not improve from 0.89484\n",
      "290/290 [==============================] - 137s 472ms/step - loss: 0.0890 - acc: 0.9027 - recall: 0.8843 - precision: 0.9137 - f1_score: 0.8904 - val_loss: 0.0830 - val_acc: 0.9105 - val_recall: 0.9187 - val_precision: 0.8926 - val_f1_score: 0.8942\n",
      "Epoch 4/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0805 - acc: 0.9113 - recall: 0.8992 - precision: 0.9204 - f1_score: 0.8989\n",
      "Epoch 00004: val_f1_score improved from 0.89484 to 0.89773, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_1.h5\n",
      "290/290 [==============================] - 141s 486ms/step - loss: 0.0805 - acc: 0.9113 - recall: 0.8992 - precision: 0.9204 - f1_score: 0.8989 - val_loss: 0.0861 - val_acc: 0.9211 - val_recall: 0.8812 - val_precision: 0.9246 - val_f1_score: 0.8977\n",
      "Epoch 5/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0752 - acc: 0.9172 - recall: 0.9059 - precision: 0.9265 - f1_score: 0.9054\n",
      "Epoch 00005: val_f1_score improved from 0.89773 to 0.90493, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_1.h5\n",
      "290/290 [==============================] - 140s 482ms/step - loss: 0.0752 - acc: 0.9172 - recall: 0.9059 - precision: 0.9265 - f1_score: 0.9054 - val_loss: 0.0741 - val_acc: 0.9221 - val_recall: 0.9001 - val_precision: 0.9294 - val_f1_score: 0.9049\n",
      "Epoch 6/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0725 - acc: 0.9198 - recall: 0.9074 - precision: 0.9274 - f1_score: 0.9079\n",
      "Epoch 00006: val_f1_score did not improve from 0.90493\n",
      "290/290 [==============================] - 136s 470ms/step - loss: 0.0725 - acc: 0.9198 - recall: 0.9074 - precision: 0.9274 - f1_score: 0.9079 - val_loss: 0.0882 - val_acc: 0.8988 - val_recall: 0.8902 - val_precision: 0.9153 - val_f1_score: 0.8897\n",
      "Epoch 7/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0664 - acc: 0.9217 - recall: 0.9172 - precision: 0.9325 - f1_score: 0.9118\n",
      "Epoch 00007: val_f1_score did not improve from 0.90493\n",
      "290/290 [==============================] - 134s 463ms/step - loss: 0.0664 - acc: 0.9217 - recall: 0.9172 - precision: 0.9325 - f1_score: 0.9118 - val_loss: 0.0756 - val_acc: 0.9234 - val_recall: 0.9001 - val_precision: 0.9259 - val_f1_score: 0.9048\n",
      "Epoch 8/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0624 - acc: 0.9274 - recall: 0.9217 - precision: 0.9361 - f1_score: 0.9156\n",
      "Epoch 00008: val_f1_score did not improve from 0.90493\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "290/290 [==============================] - 133s 458ms/step - loss: 0.0624 - acc: 0.9274 - recall: 0.9217 - precision: 0.9361 - f1_score: 0.9156 - val_loss: 0.0827 - val_acc: 0.9127 - val_recall: 0.9095 - val_precision: 0.9160 - val_f1_score: 0.9008\n",
      "Epoch 9/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0552 - acc: 0.9320 - recall: 0.9328 - precision: 0.9438 - f1_score: 0.9233\n",
      "Epoch 00009: val_f1_score did not improve from 0.90493\n",
      "290/290 [==============================] - 134s 461ms/step - loss: 0.0552 - acc: 0.9320 - recall: 0.9328 - precision: 0.9438 - f1_score: 0.9233 - val_loss: 0.0808 - val_acc: 0.9097 - val_recall: 0.9312 - val_precision: 0.9086 - val_f1_score: 0.9023\n",
      "Epoch 10/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0540 - acc: 0.9380 - recall: 0.9359 - precision: 0.9465 - f1_score: 0.9268\n",
      "Epoch 00010: val_f1_score did not improve from 0.90493\n",
      "290/290 [==============================] - 134s 461ms/step - loss: 0.0540 - acc: 0.9380 - recall: 0.9359 - precision: 0.9465 - f1_score: 0.9268 - val_loss: 0.0831 - val_acc: 0.9075 - val_recall: 0.9215 - val_precision: 0.8892 - val_f1_score: 0.8931\n",
      "Epoch 11/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0510 - acc: 0.9366 - recall: 0.9385 - precision: 0.9472 - f1_score: 0.9266\n",
      "Epoch 00011: val_f1_score did not improve from 0.90493\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00032000001519918444.\n",
      "290/290 [==============================] - 134s 461ms/step - loss: 0.0510 - acc: 0.9366 - recall: 0.9385 - precision: 0.9472 - f1_score: 0.9266 - val_loss: 0.0795 - val_acc: 0.9085 - val_recall: 0.9017 - val_precision: 0.9221 - val_f1_score: 0.9007\n",
      "Epoch 12/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0419 - acc: 0.9456 - recall: 0.9479 - precision: 0.9572 - f1_score: 0.9357\n",
      "Epoch 00012: val_f1_score improved from 0.90493 to 0.91055, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_1.h5\n",
      "290/290 [==============================] - 138s 477ms/step - loss: 0.0419 - acc: 0.9456 - recall: 0.9479 - precision: 0.9572 - f1_score: 0.9357 - val_loss: 0.0786 - val_acc: 0.9199 - val_recall: 0.9137 - val_precision: 0.9302 - val_f1_score: 0.9105\n",
      "Epoch 13/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0385 - acc: 0.9469 - recall: 0.9527 - precision: 0.9607 - f1_score: 0.9377\n",
      "Epoch 00013: val_f1_score did not improve from 0.91055\n",
      "290/290 [==============================] - 135s 465ms/step - loss: 0.0385 - acc: 0.9469 - recall: 0.9527 - precision: 0.9607 - f1_score: 0.9377 - val_loss: 0.0786 - val_acc: 0.9261 - val_recall: 0.9241 - val_precision: 0.9207 - val_f1_score: 0.9087\n",
      "Epoch 14/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0374 - acc: 0.9476 - recall: 0.9562 - precision: 0.9632 - f1_score: 0.9387\n",
      "Epoch 00014: val_f1_score did not improve from 0.91055\n",
      "290/290 [==============================] - 135s 467ms/step - loss: 0.0374 - acc: 0.9476 - recall: 0.9562 - precision: 0.9632 - f1_score: 0.9387 - val_loss: 0.0923 - val_acc: 0.9125 - val_recall: 0.9185 - val_precision: 0.8975 - val_f1_score: 0.8961\n",
      "Epoch 15/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0347 - acc: 0.9486 - recall: 0.9599 - precision: 0.9630 - f1_score: 0.9409\n",
      "Epoch 00015: val_f1_score did not improve from 0.91055\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0002560000168159604.\n",
      "290/290 [==============================] - 138s 475ms/step - loss: 0.0347 - acc: 0.9486 - recall: 0.9599 - precision: 0.9630 - f1_score: 0.9409 - val_loss: 0.0995 - val_acc: 0.9172 - val_recall: 0.8955 - val_precision: 0.9203 - val_f1_score: 0.9013\n",
      "Epoch 16/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0286 - acc: 0.9547 - recall: 0.9671 - precision: 0.9709 - f1_score: 0.9469\n",
      "Epoch 00016: val_f1_score did not improve from 0.91055\n",
      "290/290 [==============================] - 134s 463ms/step - loss: 0.0286 - acc: 0.9547 - recall: 0.9671 - precision: 0.9709 - f1_score: 0.9469 - val_loss: 0.0919 - val_acc: 0.9216 - val_recall: 0.9335 - val_precision: 0.9115 - val_f1_score: 0.9076\n",
      "Epoch 17/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0258 - acc: 0.9547 - recall: 0.9701 - precision: 0.9741 - f1_score: 0.9487\n",
      "Epoch 00017: val_f1_score did not improve from 0.91055\n",
      "290/290 [==============================] - 135s 467ms/step - loss: 0.0258 - acc: 0.9547 - recall: 0.9701 - precision: 0.9741 - f1_score: 0.9487 - val_loss: 0.1027 - val_acc: 0.9187 - val_recall: 0.9102 - val_precision: 0.9241 - val_f1_score: 0.9048\n",
      "Epoch 18/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0261 - acc: 0.9556 - recall: 0.9700 - precision: 0.9732 - f1_score: 0.9487\n",
      "Epoch 00018: val_f1_score did not improve from 0.91055\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.00020480002276599408.\n",
      "290/290 [==============================] - 137s 473ms/step - loss: 0.0261 - acc: 0.9556 - recall: 0.9700 - precision: 0.9732 - f1_score: 0.9487 - val_loss: 0.0976 - val_acc: 0.9246 - val_recall: 0.9259 - val_precision: 0.9174 - val_f1_score: 0.9093\n",
      "Epoch 19/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0210 - acc: 0.9599 - recall: 0.9757 - precision: 0.9784 - f1_score: 0.9523\n",
      "Epoch 00019: val_f1_score did not improve from 0.91055\n",
      "290/290 [==============================] - 135s 465ms/step - loss: 0.0210 - acc: 0.9599 - recall: 0.9757 - precision: 0.9784 - f1_score: 0.9523 - val_loss: 0.0951 - val_acc: 0.9204 - val_recall: 0.9202 - val_precision: 0.9217 - val_f1_score: 0.9091\n",
      "Epoch 20/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0189 - acc: 0.9613 - recall: 0.9788 - precision: 0.9817 - f1_score: 0.9552\n",
      "Epoch 00020: val_f1_score improved from 0.91055 to 0.91059, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_1.h5\n",
      "290/290 [==============================] - 137s 471ms/step - loss: 0.0189 - acc: 0.9613 - recall: 0.9788 - precision: 0.9817 - f1_score: 0.9552 - val_loss: 0.1087 - val_acc: 0.9221 - val_recall: 0.9233 - val_precision: 0.9172 - val_f1_score: 0.9106\n",
      "Epoch 21/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0181 - acc: 0.9619 - recall: 0.9792 - precision: 0.9822 - f1_score: 0.9556\n",
      "Epoch 00021: val_f1_score improved from 0.91059 to 0.91104, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_1.h5\n",
      "290/290 [==============================] - 137s 473ms/step - loss: 0.0181 - acc: 0.9619 - recall: 0.9792 - precision: 0.9822 - f1_score: 0.9556 - val_loss: 0.1022 - val_acc: 0.9246 - val_recall: 0.9321 - val_precision: 0.9158 - val_f1_score: 0.9110\n",
      "Epoch 22/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0180 - acc: 0.9584 - recall: 0.9792 - precision: 0.9826 - f1_score: 0.9559\n",
      "Epoch 00022: val_f1_score did not improve from 0.91104\n",
      "290/290 [==============================] - 132s 455ms/step - loss: 0.0180 - acc: 0.9584 - recall: 0.9792 - precision: 0.9826 - f1_score: 0.9559 - val_loss: 0.1060 - val_acc: 0.9219 - val_recall: 0.9261 - val_precision: 0.9147 - val_f1_score: 0.9079\n",
      "Epoch 23/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0163 - acc: 0.9581 - recall: 0.9816 - precision: 0.9834 - f1_score: 0.9573\n",
      "Epoch 00023: val_f1_score did not improve from 0.91104\n",
      "290/290 [==============================] - 135s 465ms/step - loss: 0.0163 - acc: 0.9581 - recall: 0.9816 - precision: 0.9834 - f1_score: 0.9573 - val_loss: 0.1009 - val_acc: 0.9209 - val_recall: 0.9325 - val_precision: 0.9140 - val_f1_score: 0.9090\n",
      "Epoch 24/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0156 - acc: 0.9638 - recall: 0.9813 - precision: 0.9842 - f1_score: 0.9575\n",
      "Epoch 00024: val_f1_score improved from 0.91104 to 0.91183, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_1.h5\n",
      "290/290 [==============================] - 138s 475ms/step - loss: 0.0156 - acc: 0.9638 - recall: 0.9813 - precision: 0.9842 - f1_score: 0.9575 - val_loss: 0.1134 - val_acc: 0.9281 - val_recall: 0.9231 - val_precision: 0.9227 - val_f1_score: 0.9118\n",
      "Epoch 25/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0146 - acc: 0.9635 - recall: 0.9830 - precision: 0.9845 - f1_score: 0.9580\n",
      "Epoch 00025: val_f1_score did not improve from 0.91183\n",
      "290/290 [==============================] - 135s 466ms/step - loss: 0.0146 - acc: 0.9635 - recall: 0.9830 - precision: 0.9845 - f1_score: 0.9580 - val_loss: 0.1187 - val_acc: 0.9268 - val_recall: 0.9174 - val_precision: 0.9244 - val_f1_score: 0.9111\n",
      "Epoch 26/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0132 - acc: 0.9629 - recall: 0.9841 - precision: 0.9868 - f1_score: 0.9605\n",
      "Epoch 00026: val_f1_score did not improve from 0.91183\n",
      "290/290 [==============================] - 134s 463ms/step - loss: 0.0132 - acc: 0.9629 - recall: 0.9841 - precision: 0.9868 - f1_score: 0.9605 - val_loss: 0.1197 - val_acc: 0.9206 - val_recall: 0.9252 - val_precision: 0.9158 - val_f1_score: 0.9102\n",
      "Epoch 27/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0143 - acc: 0.9635 - recall: 0.9840 - precision: 0.9861 - f1_score: 0.9600\n",
      "Epoch 00027: val_f1_score did not improve from 0.91183\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.00016384001355618238.\n",
      "290/290 [==============================] - 137s 472ms/step - loss: 0.0143 - acc: 0.9635 - recall: 0.9840 - precision: 0.9861 - f1_score: 0.9600 - val_loss: 0.1131 - val_acc: 0.9234 - val_recall: 0.9219 - val_precision: 0.9219 - val_f1_score: 0.9095\n",
      "Epoch 28/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0104 - acc: 0.9667 - recall: 0.9870 - precision: 0.9896 - f1_score: 0.9628\n",
      "Epoch 00028: val_f1_score improved from 0.91183 to 0.91247, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_1.h5\n",
      "290/290 [==============================] - 136s 468ms/step - loss: 0.0104 - acc: 0.9667 - recall: 0.9870 - precision: 0.9896 - f1_score: 0.9628 - val_loss: 0.1178 - val_acc: 0.9253 - val_recall: 0.9240 - val_precision: 0.9245 - val_f1_score: 0.9125\n",
      "Epoch 29/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0102 - acc: 0.9684 - recall: 0.9887 - precision: 0.9895 - f1_score: 0.9642\n",
      "Epoch 00029: val_f1_score improved from 0.91247 to 0.91280, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_1.h5\n",
      "290/290 [==============================] - 137s 474ms/step - loss: 0.0102 - acc: 0.9684 - recall: 0.9887 - precision: 0.9895 - f1_score: 0.9642 - val_loss: 0.1131 - val_acc: 0.9301 - val_recall: 0.9231 - val_precision: 0.9244 - val_f1_score: 0.9128\n",
      "Epoch 30/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0096 - acc: 0.9659 - recall: 0.9893 - precision: 0.9905 - f1_score: 0.9650\n",
      "Epoch 00030: val_f1_score improved from 0.91280 to 0.91760, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_1.h5\n",
      "290/290 [==============================] - 139s 478ms/step - loss: 0.0096 - acc: 0.9659 - recall: 0.9893 - precision: 0.9905 - f1_score: 0.9650 - val_loss: 0.1173 - val_acc: 0.9315 - val_recall: 0.9270 - val_precision: 0.9238 - val_f1_score: 0.9176\n",
      "Epoch 31/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0101 - acc: 0.9660 - recall: 0.9884 - precision: 0.9892 - f1_score: 0.9670\n",
      "Epoch 00031: val_f1_score did not improve from 0.91760\n",
      "290/290 [==============================] - 138s 477ms/step - loss: 0.0101 - acc: 0.9660 - recall: 0.9884 - precision: 0.9892 - f1_score: 0.9670 - val_loss: 0.1232 - val_acc: 0.9172 - val_recall: 0.9199 - val_precision: 0.9155 - val_f1_score: 0.9065\n",
      "Epoch 32/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0092 - acc: 0.9671 - recall: 0.9894 - precision: 0.9904 - f1_score: 0.9663\n",
      "Epoch 00032: val_f1_score did not improve from 0.91760\n",
      "290/290 [==============================] - 134s 463ms/step - loss: 0.0092 - acc: 0.9671 - recall: 0.9894 - precision: 0.9904 - f1_score: 0.9663 - val_loss: 0.1313 - val_acc: 0.9206 - val_recall: 0.9189 - val_precision: 0.9189 - val_f1_score: 0.9096\n",
      "Epoch 33/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0096 - acc: 0.9698 - recall: 0.9885 - precision: 0.9901 - f1_score: 0.9675\n",
      "Epoch 00033: val_f1_score did not improve from 0.91760\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.0001310720108449459.\n",
      "290/290 [==============================] - 132s 456ms/step - loss: 0.0096 - acc: 0.9698 - recall: 0.9885 - precision: 0.9901 - f1_score: 0.9675 - val_loss: 0.1250 - val_acc: 0.9206 - val_recall: 0.9289 - val_precision: 0.9112 - val_f1_score: 0.9114\n",
      "Epoch 34/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0075 - acc: 0.9720 - recall: 0.9923 - precision: 0.9915 - f1_score: 0.9699\n",
      "Epoch 00034: val_f1_score did not improve from 0.91760\n",
      "290/290 [==============================] - 134s 464ms/step - loss: 0.0075 - acc: 0.9720 - recall: 0.9923 - precision: 0.9915 - f1_score: 0.9699 - val_loss: 0.1337 - val_acc: 0.9283 - val_recall: 0.9203 - val_precision: 0.9250 - val_f1_score: 0.9167\n",
      "Epoch 35/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0076 - acc: 0.9711 - recall: 0.9918 - precision: 0.9922 - f1_score: 0.9707\n",
      "Epoch 00035: val_f1_score did not improve from 0.91760\n",
      "290/290 [==============================] - 137s 474ms/step - loss: 0.0076 - acc: 0.9711 - recall: 0.9918 - precision: 0.9922 - f1_score: 0.9707 - val_loss: 0.1276 - val_acc: 0.9278 - val_recall: 0.9188 - val_precision: 0.9232 - val_f1_score: 0.9140\n",
      "Epoch 36/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0076 - acc: 0.9692 - recall: 0.9922 - precision: 0.9922 - f1_score: 0.9689\n",
      "Epoch 00036: val_f1_score did not improve from 0.91760\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.00010485760867595673.\n",
      "290/290 [==============================] - 137s 473ms/step - loss: 0.0076 - acc: 0.9692 - recall: 0.9922 - precision: 0.9922 - f1_score: 0.9689 - val_loss: 0.1345 - val_acc: 0.9261 - val_recall: 0.9175 - val_precision: 0.9265 - val_f1_score: 0.9116\n",
      "Epoch 37/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0061 - acc: 0.9704 - recall: 0.9930 - precision: 0.9930 - f1_score: 0.9716\n",
      "Epoch 00037: val_f1_score did not improve from 0.91760\n",
      "290/290 [==============================] - 134s 462ms/step - loss: 0.0061 - acc: 0.9704 - recall: 0.9930 - precision: 0.9930 - f1_score: 0.9716 - val_loss: 0.1328 - val_acc: 0.9271 - val_recall: 0.9245 - val_precision: 0.9237 - val_f1_score: 0.9157\n",
      "Epoch 38/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0059 - acc: 0.9717 - recall: 0.9930 - precision: 0.9936 - f1_score: 0.9734Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00038: val_f1_score did not improve from 0.91760\n",
      "290/290 [==============================] - 135s 466ms/step - loss: 0.0059 - acc: 0.9717 - recall: 0.9930 - precision: 0.9936 - f1_score: 0.9734 - val_loss: 0.1380 - val_acc: 0.9256 - val_recall: 0.9220 - val_precision: 0.9248 - val_f1_score: 0.9142\n",
      "Epoch 00038: early stopping\n",
      "Epoch 1/100\n",
      "  2/290 [..............................] - ETA: 7:39 - loss: 0.6851 - acc: 0.2500 - recall_1: 0.5207 - precision_1: 0.2052 - f1_score: 0.2795WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4120s vs `on_train_batch_end` time: 2.7760s). Check your callbacks.\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.1502 - acc: 0.8382 - recall_1: 0.7913 - precision_1: 0.8607 - f1_score: 0.8246\n",
      "Epoch 00001: val_f1_score improved from -inf to 0.86898, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_2.h5\n",
      "290/290 [==============================] - 145s 501ms/step - loss: 0.1502 - acc: 0.8382 - recall_1: 0.7913 - precision_1: 0.8607 - f1_score: 0.8246 - val_loss: 0.1138 - val_acc: 0.8862 - val_recall_1: 0.8466 - val_precision_1: 0.9143 - val_f1_score: 0.8690\n",
      "Epoch 2/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.1003 - acc: 0.8942 - recall_1: 0.8731 - precision_1: 0.9040 - f1_score: 0.8819\n",
      "Epoch 00002: val_f1_score improved from 0.86898 to 0.88613, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_2.h5\n",
      "290/290 [==============================] - 133s 458ms/step - loss: 0.1003 - acc: 0.8942 - recall_1: 0.8731 - precision_1: 0.9040 - f1_score: 0.8819 - val_loss: 0.0977 - val_acc: 0.9018 - val_recall_1: 0.8929 - val_precision_1: 0.9031 - val_f1_score: 0.8861\n",
      "Epoch 3/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0897 - acc: 0.9010 - recall_1: 0.8861 - precision_1: 0.9108 - f1_score: 0.8898\n",
      "Epoch 00003: val_f1_score improved from 0.88613 to 0.89564, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_2.h5\n",
      "290/290 [==============================] - 128s 441ms/step - loss: 0.0897 - acc: 0.9010 - recall_1: 0.8861 - precision_1: 0.9108 - f1_score: 0.8898 - val_loss: 0.0870 - val_acc: 0.9072 - val_recall_1: 0.8891 - val_precision_1: 0.9185 - val_f1_score: 0.8956\n",
      "Epoch 4/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0812 - acc: 0.9097 - recall_1: 0.8966 - precision_1: 0.9201 - f1_score: 0.8988\n",
      "Epoch 00004: val_f1_score did not improve from 0.89564\n",
      "290/290 [==============================] - 127s 437ms/step - loss: 0.0812 - acc: 0.9097 - recall_1: 0.8966 - precision_1: 0.9201 - f1_score: 0.8988 - val_loss: 0.1665 - val_acc: 0.8579 - val_recall_1: 0.8315 - val_precision_1: 0.8744 - val_f1_score: 0.8384\n",
      "Epoch 5/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0770 - acc: 0.9110 - recall_1: 0.9007 - precision_1: 0.9224 - f1_score: 0.9013\n",
      "Epoch 00005: val_f1_score did not improve from 0.89564\n",
      "290/290 [==============================] - 125s 431ms/step - loss: 0.0770 - acc: 0.9110 - recall_1: 0.9007 - precision_1: 0.9224 - f1_score: 0.9013 - val_loss: 0.0878 - val_acc: 0.9077 - val_recall_1: 0.8933 - val_precision_1: 0.9250 - val_f1_score: 0.8919\n",
      "Epoch 6/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0704 - acc: 0.9192 - recall_1: 0.9101 - precision_1: 0.9271 - f1_score: 0.9078\n",
      "Epoch 00006: val_f1_score improved from 0.89564 to 0.90699, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_2.h5\n",
      "290/290 [==============================] - 129s 445ms/step - loss: 0.0704 - acc: 0.9192 - recall_1: 0.9101 - precision_1: 0.9271 - f1_score: 0.9078 - val_loss: 0.0785 - val_acc: 0.9206 - val_recall_1: 0.9018 - val_precision_1: 0.9301 - val_f1_score: 0.9070\n",
      "Epoch 7/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0679 - acc: 0.9222 - recall_1: 0.9150 - precision_1: 0.9299 - f1_score: 0.9109\n",
      "Epoch 00007: val_f1_score did not improve from 0.90699\n",
      "290/290 [==============================] - 124s 427ms/step - loss: 0.0679 - acc: 0.9222 - recall_1: 0.9150 - precision_1: 0.9299 - f1_score: 0.9109 - val_loss: 0.0785 - val_acc: 0.9075 - val_recall_1: 0.9130 - val_precision_1: 0.9151 - val_f1_score: 0.9030\n",
      "Epoch 8/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0660 - acc: 0.9235 - recall_1: 0.9187 - precision_1: 0.9351 - f1_score: 0.9130\n",
      "Epoch 00008: val_f1_score improved from 0.90699 to 0.91031, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_2.h5\n",
      "290/290 [==============================] - 127s 439ms/step - loss: 0.0660 - acc: 0.9235 - recall_1: 0.9187 - precision_1: 0.9351 - f1_score: 0.9130 - val_loss: 0.0772 - val_acc: 0.9273 - val_recall_1: 0.8885 - val_precision_1: 0.9483 - val_f1_score: 0.9103\n",
      "Epoch 9/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0614 - acc: 0.9256 - recall_1: 0.9244 - precision_1: 0.9356 - f1_score: 0.9172\n",
      "Epoch 00009: val_f1_score did not improve from 0.91031\n",
      "290/290 [==============================] - 124s 427ms/step - loss: 0.0614 - acc: 0.9256 - recall_1: 0.9244 - precision_1: 0.9356 - f1_score: 0.9172 - val_loss: 0.0751 - val_acc: 0.9196 - val_recall_1: 0.9003 - val_precision_1: 0.9369 - val_f1_score: 0.9058\n",
      "Epoch 10/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0568 - acc: 0.9308 - recall_1: 0.9288 - precision_1: 0.9418 - f1_score: 0.9204\n",
      "Epoch 00010: val_f1_score improved from 0.91031 to 0.91275, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_2.h5\n",
      "290/290 [==============================] - 128s 442ms/step - loss: 0.0568 - acc: 0.9308 - recall_1: 0.9288 - precision_1: 0.9418 - f1_score: 0.9204 - val_loss: 0.0723 - val_acc: 0.9286 - val_recall_1: 0.9106 - val_precision_1: 0.9360 - val_f1_score: 0.9127\n",
      "Epoch 11/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0550 - acc: 0.9347 - recall_1: 0.9322 - precision_1: 0.9463 - f1_score: 0.9249\n",
      "Epoch 00011: val_f1_score did not improve from 0.91275\n",
      "290/290 [==============================] - 124s 427ms/step - loss: 0.0550 - acc: 0.9347 - recall_1: 0.9322 - precision_1: 0.9463 - f1_score: 0.9249 - val_loss: 0.0804 - val_acc: 0.9234 - val_recall_1: 0.9207 - val_precision_1: 0.9269 - val_f1_score: 0.9090\n",
      "Epoch 12/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0541 - acc: 0.9318 - recall_1: 0.9330 - precision_1: 0.9457 - f1_score: 0.9237\n",
      "Epoch 00012: val_f1_score did not improve from 0.91275\n",
      "290/290 [==============================] - 124s 428ms/step - loss: 0.0541 - acc: 0.9318 - recall_1: 0.9330 - precision_1: 0.9457 - f1_score: 0.9237 - val_loss: 0.0836 - val_acc: 0.9154 - val_recall_1: 0.9127 - val_precision_1: 0.9218 - val_f1_score: 0.9020\n",
      "Epoch 13/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0501 - acc: 0.9362 - recall_1: 0.9399 - precision_1: 0.9476 - f1_score: 0.9274\n",
      "Epoch 00013: val_f1_score did not improve from 0.91275\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "290/290 [==============================] - 124s 426ms/step - loss: 0.0501 - acc: 0.9362 - recall_1: 0.9399 - precision_1: 0.9476 - f1_score: 0.9274 - val_loss: 0.0960 - val_acc: 0.9149 - val_recall_1: 0.9188 - val_precision_1: 0.9148 - val_f1_score: 0.9068\n",
      "Epoch 14/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0415 - acc: 0.9467 - recall_1: 0.9488 - precision_1: 0.9583 - f1_score: 0.9363\n",
      "Epoch 00014: val_f1_score improved from 0.91275 to 0.91615, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_2.h5\n",
      "290/290 [==============================] - 126s 433ms/step - loss: 0.0415 - acc: 0.9467 - recall_1: 0.9488 - precision_1: 0.9583 - f1_score: 0.9363 - val_loss: 0.0738 - val_acc: 0.9303 - val_recall_1: 0.9207 - val_precision_1: 0.9301 - val_f1_score: 0.9161\n",
      "Epoch 15/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0374 - acc: 0.9434 - recall_1: 0.9546 - precision_1: 0.9606 - f1_score: 0.9389\n",
      "Epoch 00015: val_f1_score did not improve from 0.91615\n",
      "290/290 [==============================] - 124s 427ms/step - loss: 0.0374 - acc: 0.9434 - recall_1: 0.9546 - precision_1: 0.9606 - f1_score: 0.9389 - val_loss: 0.0924 - val_acc: 0.9204 - val_recall_1: 0.9065 - val_precision_1: 0.9305 - val_f1_score: 0.9063\n",
      "Epoch 16/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0359 - acc: 0.9509 - recall_1: 0.9568 - precision_1: 0.9643 - f1_score: 0.9408\n",
      "Epoch 00016: val_f1_score did not improve from 0.91615\n",
      "290/290 [==============================] - 125s 430ms/step - loss: 0.0359 - acc: 0.9509 - recall_1: 0.9568 - precision_1: 0.9643 - f1_score: 0.9408 - val_loss: 0.0908 - val_acc: 0.9219 - val_recall_1: 0.9283 - val_precision_1: 0.9076 - val_f1_score: 0.9072\n",
      "Epoch 17/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0356 - acc: 0.9483 - recall_1: 0.9579 - precision_1: 0.9635 - f1_score: 0.9406\n",
      "Epoch 00017: val_f1_score did not improve from 0.91615\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.00032000001519918444.\n",
      "290/290 [==============================] - 124s 429ms/step - loss: 0.0356 - acc: 0.9483 - recall_1: 0.9579 - precision_1: 0.9635 - f1_score: 0.9406 - val_loss: 0.1160 - val_acc: 0.9132 - val_recall_1: 0.8903 - val_precision_1: 0.9191 - val_f1_score: 0.8958\n",
      "Epoch 18/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0286 - acc: 0.9541 - recall_1: 0.9662 - precision_1: 0.9709 - f1_score: 0.9468\n",
      "Epoch 00018: val_f1_score did not improve from 0.91615\n",
      "290/290 [==============================] - 121s 418ms/step - loss: 0.0286 - acc: 0.9541 - recall_1: 0.9662 - precision_1: 0.9709 - f1_score: 0.9468 - val_loss: 0.0804 - val_acc: 0.9231 - val_recall_1: 0.9236 - val_precision_1: 0.9224 - val_f1_score: 0.9138\n",
      "Epoch 19/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0247 - acc: 0.9549 - recall_1: 0.9708 - precision_1: 0.9759 - f1_score: 0.9512\n",
      "Epoch 00019: val_f1_score did not improve from 0.91615\n",
      "290/290 [==============================] - 126s 435ms/step - loss: 0.0247 - acc: 0.9549 - recall_1: 0.9708 - precision_1: 0.9759 - f1_score: 0.9512 - val_loss: 0.0936 - val_acc: 0.9241 - val_recall_1: 0.9235 - val_precision_1: 0.9260 - val_f1_score: 0.9135\n",
      "Epoch 20/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0244 - acc: 0.9559 - recall_1: 0.9729 - precision_1: 0.9763 - f1_score: 0.9510\n",
      "Epoch 00020: val_f1_score did not improve from 0.91615\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0002560000168159604.\n",
      "290/290 [==============================] - 125s 433ms/step - loss: 0.0244 - acc: 0.9559 - recall_1: 0.9729 - precision_1: 0.9763 - f1_score: 0.9510 - val_loss: 0.0939 - val_acc: 0.9311 - val_recall_1: 0.9164 - val_precision_1: 0.9347 - val_f1_score: 0.9161\n",
      "Epoch 21/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0205 - acc: 0.9599 - recall_1: 0.9761 - precision_1: 0.9804 - f1_score: 0.9528\n",
      "Epoch 00021: val_f1_score improved from 0.91615 to 0.91672, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_2.h5\n",
      "290/290 [==============================] - 127s 437ms/step - loss: 0.0205 - acc: 0.9599 - recall_1: 0.9761 - precision_1: 0.9804 - f1_score: 0.9528 - val_loss: 0.0970 - val_acc: 0.9296 - val_recall_1: 0.9232 - val_precision_1: 0.9327 - val_f1_score: 0.9167\n",
      "Epoch 22/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0181 - acc: 0.9591 - recall_1: 0.9791 - precision_1: 0.9809 - f1_score: 0.9541\n",
      "Epoch 00022: val_f1_score did not improve from 0.91672\n",
      "290/290 [==============================] - 125s 431ms/step - loss: 0.0181 - acc: 0.9591 - recall_1: 0.9791 - precision_1: 0.9809 - f1_score: 0.9541 - val_loss: 0.0971 - val_acc: 0.9293 - val_recall_1: 0.9253 - val_precision_1: 0.9268 - val_f1_score: 0.9151\n",
      "Epoch 23/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0179 - acc: 0.9619 - recall_1: 0.9801 - precision_1: 0.9816 - f1_score: 0.9548\n",
      "Epoch 00023: val_f1_score did not improve from 0.91672\n",
      "290/290 [==============================] - 127s 436ms/step - loss: 0.0179 - acc: 0.9619 - recall_1: 0.9801 - precision_1: 0.9816 - f1_score: 0.9548 - val_loss: 0.1015 - val_acc: 0.9315 - val_recall_1: 0.9286 - val_precision_1: 0.9218 - val_f1_score: 0.9152\n",
      "Epoch 24/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0173 - acc: 0.9580 - recall_1: 0.9810 - precision_1: 0.9819 - f1_score: 0.9556\n",
      "Epoch 00024: val_f1_score improved from 0.91672 to 0.91736, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_2.h5\n",
      "290/290 [==============================] - 125s 430ms/step - loss: 0.0173 - acc: 0.9580 - recall_1: 0.9810 - precision_1: 0.9819 - f1_score: 0.9556 - val_loss: 0.1064 - val_acc: 0.9325 - val_recall_1: 0.9209 - val_precision_1: 0.9378 - val_f1_score: 0.9174\n",
      "Epoch 25/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0138 - acc: 0.9659 - recall_1: 0.9841 - precision_1: 0.9855 - f1_score: 0.9595\n",
      "Epoch 00025: val_f1_score improved from 0.91736 to 0.91755, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_2.h5\n",
      "290/290 [==============================] - 130s 449ms/step - loss: 0.0138 - acc: 0.9659 - recall_1: 0.9841 - precision_1: 0.9855 - f1_score: 0.9595 - val_loss: 0.1003 - val_acc: 0.9325 - val_recall_1: 0.9267 - val_precision_1: 0.9269 - val_f1_score: 0.9176\n",
      "Epoch 26/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0159 - acc: 0.9645 - recall_1: 0.9826 - precision_1: 0.9854 - f1_score: 0.9602\n",
      "Epoch 00026: val_f1_score did not improve from 0.91755\n",
      "290/290 [==============================] - 125s 431ms/step - loss: 0.0159 - acc: 0.9645 - recall_1: 0.9826 - precision_1: 0.9854 - f1_score: 0.9602 - val_loss: 0.1002 - val_acc: 0.9251 - val_recall_1: 0.9214 - val_precision_1: 0.9311 - val_f1_score: 0.9164\n",
      "Epoch 27/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0155 - acc: 0.9647 - recall_1: 0.9830 - precision_1: 0.9849 - f1_score: 0.9573\n",
      "Epoch 00027: val_f1_score did not improve from 0.91755\n",
      "290/290 [==============================] - 127s 436ms/step - loss: 0.0155 - acc: 0.9647 - recall_1: 0.9830 - precision_1: 0.9849 - f1_score: 0.9573 - val_loss: 0.1018 - val_acc: 0.9283 - val_recall_1: 0.9228 - val_precision_1: 0.9286 - val_f1_score: 0.9145\n",
      "Epoch 28/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0141 - acc: 0.9608 - recall_1: 0.9842 - precision_1: 0.9860 - f1_score: 0.9594\n",
      "Epoch 00028: val_f1_score improved from 0.91755 to 0.91880, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_2.h5\n",
      "290/290 [==============================] - 127s 438ms/step - loss: 0.0141 - acc: 0.9608 - recall_1: 0.9842 - precision_1: 0.9860 - f1_score: 0.9594 - val_loss: 0.1098 - val_acc: 0.9306 - val_recall_1: 0.9169 - val_precision_1: 0.9318 - val_f1_score: 0.9188\n",
      "Epoch 29/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0137 - acc: 0.9648 - recall_1: 0.9850 - precision_1: 0.9857 - f1_score: 0.9606\n",
      "Epoch 00029: val_f1_score did not improve from 0.91880\n",
      "290/290 [==============================] - 126s 435ms/step - loss: 0.0137 - acc: 0.9648 - recall_1: 0.9850 - precision_1: 0.9857 - f1_score: 0.9606 - val_loss: 0.1103 - val_acc: 0.9268 - val_recall_1: 0.9073 - val_precision_1: 0.9380 - val_f1_score: 0.9133\n",
      "Epoch 30/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0126 - acc: 0.9622 - recall_1: 0.9855 - precision_1: 0.9871 - f1_score: 0.9605\n",
      "Epoch 00030: val_f1_score did not improve from 0.91880\n",
      "290/290 [==============================] - 127s 438ms/step - loss: 0.0126 - acc: 0.9622 - recall_1: 0.9855 - precision_1: 0.9871 - f1_score: 0.9605 - val_loss: 0.1064 - val_acc: 0.9298 - val_recall_1: 0.9350 - val_precision_1: 0.9216 - val_f1_score: 0.9187\n",
      "Epoch 31/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0132 - acc: 0.9622 - recall_1: 0.9857 - precision_1: 0.9870 - f1_score: 0.9615\n",
      "Epoch 00031: val_f1_score did not improve from 0.91880\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.00020480002276599408.\n",
      "290/290 [==============================] - 125s 430ms/step - loss: 0.0132 - acc: 0.9622 - recall_1: 0.9857 - precision_1: 0.9870 - f1_score: 0.9615 - val_loss: 0.1143 - val_acc: 0.9303 - val_recall_1: 0.9101 - val_precision_1: 0.9367 - val_f1_score: 0.9171\n",
      "Epoch 32/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0108 - acc: 0.9644 - recall_1: 0.9876 - precision_1: 0.9881 - f1_score: 0.9640\n",
      "Epoch 00032: val_f1_score did not improve from 0.91880\n",
      "290/290 [==============================] - 128s 443ms/step - loss: 0.0108 - acc: 0.9644 - recall_1: 0.9876 - precision_1: 0.9881 - f1_score: 0.9640 - val_loss: 0.1137 - val_acc: 0.9271 - val_recall_1: 0.9283 - val_precision_1: 0.9234 - val_f1_score: 0.9167\n",
      "Epoch 33/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0097 - acc: 0.9671 - recall_1: 0.9895 - precision_1: 0.9901 - f1_score: 0.9647\n",
      "Epoch 00033: val_f1_score did not improve from 0.91880\n",
      "290/290 [==============================] - 126s 435ms/step - loss: 0.0097 - acc: 0.9671 - recall_1: 0.9895 - precision_1: 0.9901 - f1_score: 0.9647 - val_loss: 0.1045 - val_acc: 0.9288 - val_recall_1: 0.9251 - val_precision_1: 0.9266 - val_f1_score: 0.9186\n",
      "Epoch 34/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0093 - acc: 0.9686 - recall_1: 0.9904 - precision_1: 0.9902 - f1_score: 0.9656\n",
      "Epoch 00034: val_f1_score did not improve from 0.91880\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.00016384001355618238.\n",
      "290/290 [==============================] - 128s 442ms/step - loss: 0.0093 - acc: 0.9686 - recall_1: 0.9904 - precision_1: 0.9902 - f1_score: 0.9656 - val_loss: 0.1194 - val_acc: 0.9288 - val_recall_1: 0.9177 - val_precision_1: 0.9358 - val_f1_score: 0.9180\n",
      "Epoch 35/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0076 - acc: 0.9714 - recall_1: 0.9915 - precision_1: 0.9927 - f1_score: 0.9698\n",
      "Epoch 00035: val_f1_score improved from 0.91880 to 0.92006, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_2.h5\n",
      "290/290 [==============================] - 129s 443ms/step - loss: 0.0076 - acc: 0.9714 - recall_1: 0.9915 - precision_1: 0.9927 - f1_score: 0.9698 - val_loss: 0.1208 - val_acc: 0.9306 - val_recall_1: 0.9270 - val_precision_1: 0.9267 - val_f1_score: 0.9201\n",
      "Epoch 36/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0074 - acc: 0.9711 - recall_1: 0.9915 - precision_1: 0.9926 - f1_score: 0.9717\n",
      "Epoch 00036: val_f1_score improved from 0.92006 to 0.92185, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_2.h5\n",
      "290/290 [==============================] - 127s 439ms/step - loss: 0.0074 - acc: 0.9711 - recall_1: 0.9915 - precision_1: 0.9926 - f1_score: 0.9717 - val_loss: 0.1169 - val_acc: 0.9315 - val_recall_1: 0.9237 - val_precision_1: 0.9364 - val_f1_score: 0.9218\n",
      "Epoch 37/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0072 - acc: 0.9717 - recall_1: 0.9916 - precision_1: 0.9931 - f1_score: 0.9713\n",
      "Epoch 00037: val_f1_score did not improve from 0.92185\n",
      "290/290 [==============================] - 127s 439ms/step - loss: 0.0072 - acc: 0.9717 - recall_1: 0.9916 - precision_1: 0.9931 - f1_score: 0.9713 - val_loss: 0.1197 - val_acc: 0.9323 - val_recall_1: 0.9253 - val_precision_1: 0.9294 - val_f1_score: 0.9214\n",
      "Epoch 38/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0066 - acc: 0.9729 - recall_1: 0.9927 - precision_1: 0.9929 - f1_score: 0.9714\n",
      "Epoch 00038: val_f1_score did not improve from 0.92185\n",
      "290/290 [==============================] - 127s 438ms/step - loss: 0.0066 - acc: 0.9729 - recall_1: 0.9927 - precision_1: 0.9929 - f1_score: 0.9714 - val_loss: 0.1237 - val_acc: 0.9311 - val_recall_1: 0.9190 - val_precision_1: 0.9372 - val_f1_score: 0.9208\n",
      "Epoch 39/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0066 - acc: 0.9722 - recall_1: 0.9921 - precision_1: 0.9927 - f1_score: 0.9729\n",
      "Epoch 00039: val_f1_score did not improve from 0.92185\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.0001310720108449459.\n",
      "290/290 [==============================] - 124s 429ms/step - loss: 0.0066 - acc: 0.9722 - recall_1: 0.9921 - precision_1: 0.9927 - f1_score: 0.9729 - val_loss: 0.1304 - val_acc: 0.9313 - val_recall_1: 0.9230 - val_precision_1: 0.9335 - val_f1_score: 0.9199\n",
      "Epoch 40/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0067 - acc: 0.9728 - recall_1: 0.9924 - precision_1: 0.9932 - f1_score: 0.9726\n",
      "Epoch 00040: val_f1_score did not improve from 0.92185\n",
      "290/290 [==============================] - 127s 438ms/step - loss: 0.0067 - acc: 0.9728 - recall_1: 0.9924 - precision_1: 0.9932 - f1_score: 0.9726 - val_loss: 0.1265 - val_acc: 0.9325 - val_recall_1: 0.9224 - val_precision_1: 0.9286 - val_f1_score: 0.9210\n",
      "Epoch 41/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0056 - acc: 0.9743 - recall_1: 0.9937 - precision_1: 0.9938 - f1_score: 0.9748\n",
      "Epoch 00041: val_f1_score did not improve from 0.92185\n",
      "290/290 [==============================] - 127s 437ms/step - loss: 0.0056 - acc: 0.9743 - recall_1: 0.9937 - precision_1: 0.9938 - f1_score: 0.9748 - val_loss: 0.1261 - val_acc: 0.9296 - val_recall_1: 0.9200 - val_precision_1: 0.9290 - val_f1_score: 0.9194\n",
      "Epoch 42/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0053 - acc: 0.9752 - recall_1: 0.9938 - precision_1: 0.9949 - f1_score: 0.9763\n",
      "Epoch 00042: val_f1_score did not improve from 0.92185\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.00010485760867595673.\n",
      "290/290 [==============================] - 126s 434ms/step - loss: 0.0053 - acc: 0.9752 - recall_1: 0.9938 - precision_1: 0.9949 - f1_score: 0.9763 - val_loss: 0.1264 - val_acc: 0.9283 - val_recall_1: 0.9195 - val_precision_1: 0.9344 - val_f1_score: 0.9191\n",
      "Epoch 43/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0051 - acc: 0.9749 - recall_1: 0.9941 - precision_1: 0.9940 - f1_score: 0.9763\n",
      "Epoch 00043: val_f1_score did not improve from 0.92185\n",
      "290/290 [==============================] - 127s 439ms/step - loss: 0.0051 - acc: 0.9749 - recall_1: 0.9941 - precision_1: 0.9940 - f1_score: 0.9763 - val_loss: 0.1335 - val_acc: 0.9308 - val_recall_1: 0.9136 - val_precision_1: 0.9342 - val_f1_score: 0.9203\n",
      "Epoch 44/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0053 - acc: 0.9769 - recall_1: 0.9941 - precision_1: 0.9943 - f1_score: 0.9766Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00044: val_f1_score did not improve from 0.92185\n",
      "290/290 [==============================] - 128s 440ms/step - loss: 0.0053 - acc: 0.9769 - recall_1: 0.9941 - precision_1: 0.9943 - f1_score: 0.9766 - val_loss: 0.1287 - val_acc: 0.9328 - val_recall_1: 0.9177 - val_precision_1: 0.9352 - val_f1_score: 0.9193\n",
      "Epoch 00044: early stopping\n",
      "Epoch 1/100\n",
      "  2/290 [..............................] - ETA: 6:33 - loss: 0.6592 - acc: 0.2411 - recall_2: 0.4355 - precision_2: 0.2118 - f1_score: 0.2642WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4766s vs `on_train_batch_end` time: 2.2537s). Check your callbacks.\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.1487 - acc: 0.8394 - recall_2: 0.8036 - precision_2: 0.8589 - f1_score: 0.8286\n",
      "Epoch 00001: val_f1_score improved from -inf to 0.79359, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_3.h5\n",
      "290/290 [==============================] - 132s 456ms/step - loss: 0.1487 - acc: 0.8394 - recall_2: 0.8036 - precision_2: 0.8589 - f1_score: 0.8286 - val_loss: 0.1745 - val_acc: 0.8155 - val_recall_2: 0.7966 - val_precision_2: 0.8133 - val_f1_score: 0.7936\n",
      "Epoch 2/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.1001 - acc: 0.8925 - recall_2: 0.8736 - precision_2: 0.9051 - f1_score: 0.8815\n",
      "Epoch 00002: val_f1_score improved from 0.79359 to 0.90065, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_3.h5\n",
      "290/290 [==============================] - 129s 445ms/step - loss: 0.1001 - acc: 0.8925 - recall_2: 0.8736 - precision_2: 0.9051 - f1_score: 0.8815 - val_loss: 0.0834 - val_acc: 0.9105 - val_recall_2: 0.8742 - val_precision_2: 0.9348 - val_f1_score: 0.9007\n",
      "Epoch 3/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0885 - acc: 0.9046 - recall_2: 0.8899 - precision_2: 0.9126 - f1_score: 0.8919\n",
      "Epoch 00003: val_f1_score did not improve from 0.90065\n",
      "290/290 [==============================] - 126s 436ms/step - loss: 0.0885 - acc: 0.9046 - recall_2: 0.8899 - precision_2: 0.9126 - f1_score: 0.8919 - val_loss: 0.0841 - val_acc: 0.9142 - val_recall_2: 0.9043 - val_precision_2: 0.9078 - val_f1_score: 0.8971\n",
      "Epoch 4/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0828 - acc: 0.9095 - recall_2: 0.8944 - precision_2: 0.9169 - f1_score: 0.8970\n",
      "Epoch 00004: val_f1_score improved from 0.90065 to 0.90130, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_3.h5\n",
      "290/290 [==============================] - 130s 449ms/step - loss: 0.0828 - acc: 0.9095 - recall_2: 0.8944 - precision_2: 0.9169 - f1_score: 0.8970 - val_loss: 0.0810 - val_acc: 0.9236 - val_recall_2: 0.8958 - val_precision_2: 0.9233 - val_f1_score: 0.9013\n",
      "Epoch 5/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0766 - acc: 0.9155 - recall_2: 0.9054 - precision_2: 0.9225 - f1_score: 0.9038\n",
      "Epoch 00005: val_f1_score did not improve from 0.90130\n",
      "290/290 [==============================] - 126s 434ms/step - loss: 0.0766 - acc: 0.9155 - recall_2: 0.9054 - precision_2: 0.9225 - f1_score: 0.9038 - val_loss: 0.0882 - val_acc: 0.9072 - val_recall_2: 0.8864 - val_precision_2: 0.9366 - val_f1_score: 0.8963\n",
      "Epoch 6/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0727 - acc: 0.9175 - recall_2: 0.9109 - precision_2: 0.9260 - f1_score: 0.9063\n",
      "Epoch 00006: val_f1_score improved from 0.90130 to 0.90923, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_3.h5\n",
      "290/290 [==============================] - 131s 452ms/step - loss: 0.0727 - acc: 0.9175 - recall_2: 0.9109 - precision_2: 0.9260 - f1_score: 0.9063 - val_loss: 0.0714 - val_acc: 0.9261 - val_recall_2: 0.9090 - val_precision_2: 0.9332 - val_f1_score: 0.9092\n",
      "Epoch 7/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0661 - acc: 0.9225 - recall_2: 0.9174 - precision_2: 0.9324 - f1_score: 0.9123\n",
      "Epoch 00007: val_f1_score did not improve from 0.90923\n",
      "290/290 [==============================] - 128s 441ms/step - loss: 0.0661 - acc: 0.9225 - recall_2: 0.9174 - precision_2: 0.9324 - f1_score: 0.9123 - val_loss: 0.0743 - val_acc: 0.9082 - val_recall_2: 0.9173 - val_precision_2: 0.9195 - val_f1_score: 0.9025\n",
      "Epoch 8/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0665 - acc: 0.9241 - recall_2: 0.9184 - precision_2: 0.9332 - f1_score: 0.9133\n",
      "Epoch 00008: val_f1_score did not improve from 0.90923\n",
      "290/290 [==============================] - 127s 438ms/step - loss: 0.0665 - acc: 0.9241 - recall_2: 0.9184 - precision_2: 0.9332 - f1_score: 0.9133 - val_loss: 0.0825 - val_acc: 0.9206 - val_recall_2: 0.8885 - val_precision_2: 0.9313 - val_f1_score: 0.9048\n",
      "Epoch 9/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0615 - acc: 0.9267 - recall_2: 0.9240 - precision_2: 0.9379 - f1_score: 0.9172\n",
      "Epoch 00009: val_f1_score did not improve from 0.90923\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "290/290 [==============================] - 130s 447ms/step - loss: 0.0615 - acc: 0.9267 - recall_2: 0.9240 - precision_2: 0.9379 - f1_score: 0.9172 - val_loss: 0.0764 - val_acc: 0.9172 - val_recall_2: 0.9033 - val_precision_2: 0.9207 - val_f1_score: 0.8996\n",
      "Epoch 10/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0535 - acc: 0.9351 - recall_2: 0.9345 - precision_2: 0.9463 - f1_score: 0.9249\n",
      "Epoch 00010: val_f1_score improved from 0.90923 to 0.91148, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_3.h5\n",
      "290/290 [==============================] - 132s 454ms/step - loss: 0.0535 - acc: 0.9351 - recall_2: 0.9345 - precision_2: 0.9463 - f1_score: 0.9249 - val_loss: 0.0709 - val_acc: 0.9256 - val_recall_2: 0.9234 - val_precision_2: 0.9292 - val_f1_score: 0.9115\n",
      "Epoch 11/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0495 - acc: 0.9361 - recall_2: 0.9391 - precision_2: 0.9484 - f1_score: 0.9265\n",
      "Epoch 00011: val_f1_score did not improve from 0.91148\n",
      "290/290 [==============================] - 126s 436ms/step - loss: 0.0495 - acc: 0.9361 - recall_2: 0.9391 - precision_2: 0.9484 - f1_score: 0.9265 - val_loss: 0.0759 - val_acc: 0.9219 - val_recall_2: 0.9319 - val_precision_2: 0.9119 - val_f1_score: 0.9070\n",
      "Epoch 12/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0473 - acc: 0.9397 - recall_2: 0.9439 - precision_2: 0.9515 - f1_score: 0.9301\n",
      "Epoch 00012: val_f1_score did not improve from 0.91148\n",
      "290/290 [==============================] - 127s 437ms/step - loss: 0.0473 - acc: 0.9397 - recall_2: 0.9439 - precision_2: 0.9515 - f1_score: 0.9301 - val_loss: 0.0841 - val_acc: 0.9038 - val_recall_2: 0.9153 - val_precision_2: 0.9014 - val_f1_score: 0.8900\n",
      "Epoch 13/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0424 - acc: 0.9438 - recall_2: 0.9498 - precision_2: 0.9578 - f1_score: 0.9349\n",
      "Epoch 00013: val_f1_score improved from 0.91148 to 0.91581, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_3.h5\n",
      "290/290 [==============================] - 131s 453ms/step - loss: 0.0424 - acc: 0.9438 - recall_2: 0.9498 - precision_2: 0.9578 - f1_score: 0.9349 - val_loss: 0.0794 - val_acc: 0.9318 - val_recall_2: 0.9069 - val_precision_2: 0.9390 - val_f1_score: 0.9158\n",
      "Epoch 14/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0426 - acc: 0.9454 - recall_2: 0.9489 - precision_2: 0.9574 - f1_score: 0.9343\n",
      "Epoch 00014: val_f1_score did not improve from 0.91581\n",
      "290/290 [==============================] - 127s 438ms/step - loss: 0.0426 - acc: 0.9454 - recall_2: 0.9489 - precision_2: 0.9574 - f1_score: 0.9343 - val_loss: 0.0810 - val_acc: 0.9169 - val_recall_2: 0.9252 - val_precision_2: 0.9138 - val_f1_score: 0.9072\n",
      "Epoch 15/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0379 - acc: 0.9474 - recall_2: 0.9555 - precision_2: 0.9620 - f1_score: 0.9380\n",
      "Epoch 00015: val_f1_score did not improve from 0.91581\n",
      "290/290 [==============================] - 128s 440ms/step - loss: 0.0379 - acc: 0.9474 - recall_2: 0.9555 - precision_2: 0.9620 - f1_score: 0.9380 - val_loss: 0.1087 - val_acc: 0.9097 - val_recall_2: 0.8855 - val_precision_2: 0.9179 - val_f1_score: 0.8958\n",
      "Epoch 16/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0383 - acc: 0.9481 - recall_2: 0.9548 - precision_2: 0.9597 - f1_score: 0.9384\n",
      "Epoch 00016: val_f1_score did not improve from 0.91581\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.00032000001519918444.\n",
      "290/290 [==============================] - 128s 441ms/step - loss: 0.0383 - acc: 0.9481 - recall_2: 0.9548 - precision_2: 0.9597 - f1_score: 0.9384 - val_loss: 0.0952 - val_acc: 0.9162 - val_recall_2: 0.8883 - val_precision_2: 0.9259 - val_f1_score: 0.9005\n",
      "Epoch 17/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0307 - acc: 0.9513 - recall_2: 0.9640 - precision_2: 0.9696 - f1_score: 0.9443\n",
      "Epoch 00017: val_f1_score improved from 0.91581 to 0.91765, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_3.h5\n",
      "290/290 [==============================] - 132s 454ms/step - loss: 0.0307 - acc: 0.9513 - recall_2: 0.9640 - precision_2: 0.9696 - f1_score: 0.9443 - val_loss: 0.0838 - val_acc: 0.9328 - val_recall_2: 0.9271 - val_precision_2: 0.9275 - val_f1_score: 0.9176\n",
      "Epoch 18/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0282 - acc: 0.9560 - recall_2: 0.9671 - precision_2: 0.9701 - f1_score: 0.9476\n",
      "Epoch 00018: val_f1_score did not improve from 0.91765\n",
      "290/290 [==============================] - 128s 441ms/step - loss: 0.0282 - acc: 0.9560 - recall_2: 0.9671 - precision_2: 0.9701 - f1_score: 0.9476 - val_loss: 0.0875 - val_acc: 0.9303 - val_recall_2: 0.9229 - val_precision_2: 0.9268 - val_f1_score: 0.9146\n",
      "Epoch 19/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0266 - acc: 0.9539 - recall_2: 0.9688 - precision_2: 0.9733 - f1_score: 0.9476\n",
      "Epoch 00019: val_f1_score did not improve from 0.91765\n",
      "290/290 [==============================] - 128s 443ms/step - loss: 0.0266 - acc: 0.9539 - recall_2: 0.9688 - precision_2: 0.9733 - f1_score: 0.9476 - val_loss: 0.0987 - val_acc: 0.9122 - val_recall_2: 0.9245 - val_precision_2: 0.9039 - val_f1_score: 0.9025\n",
      "Epoch 20/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0244 - acc: 0.9573 - recall_2: 0.9720 - precision_2: 0.9752 - f1_score: 0.9497\n",
      "Epoch 00020: val_f1_score did not improve from 0.91765\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0002560000168159604.\n",
      "290/290 [==============================] - 126s 435ms/step - loss: 0.0244 - acc: 0.9573 - recall_2: 0.9720 - precision_2: 0.9752 - f1_score: 0.9497 - val_loss: 0.0983 - val_acc: 0.9251 - val_recall_2: 0.9243 - val_precision_2: 0.9179 - val_f1_score: 0.9099\n",
      "Epoch 21/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0197 - acc: 0.9597 - recall_2: 0.9770 - precision_2: 0.9799 - f1_score: 0.9535\n",
      "Epoch 00021: val_f1_score did not improve from 0.91765\n",
      "290/290 [==============================] - 129s 446ms/step - loss: 0.0197 - acc: 0.9597 - recall_2: 0.9770 - precision_2: 0.9799 - f1_score: 0.9535 - val_loss: 0.0945 - val_acc: 0.9303 - val_recall_2: 0.9241 - val_precision_2: 0.9158 - val_f1_score: 0.9126\n",
      "Epoch 22/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0169 - acc: 0.9624 - recall_2: 0.9810 - precision_2: 0.9824 - f1_score: 0.9570\n",
      "Epoch 00022: val_f1_score did not improve from 0.91765\n",
      "290/290 [==============================] - 126s 435ms/step - loss: 0.0169 - acc: 0.9624 - recall_2: 0.9810 - precision_2: 0.9824 - f1_score: 0.9570 - val_loss: 0.0944 - val_acc: 0.9226 - val_recall_2: 0.9284 - val_precision_2: 0.9167 - val_f1_score: 0.9136\n",
      "Epoch 23/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0164 - acc: 0.9632 - recall_2: 0.9810 - precision_2: 0.9836 - f1_score: 0.9582\n",
      "Epoch 00023: val_f1_score improved from 0.91765 to 0.91853, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_3.h5\n",
      "290/290 [==============================] - 130s 448ms/step - loss: 0.0164 - acc: 0.9632 - recall_2: 0.9810 - precision_2: 0.9836 - f1_score: 0.9582 - val_loss: 0.1065 - val_acc: 0.9298 - val_recall_2: 0.9256 - val_precision_2: 0.9214 - val_f1_score: 0.9185\n",
      "Epoch 24/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0176 - acc: 0.9594 - recall_2: 0.9798 - precision_2: 0.9815 - f1_score: 0.9558\n",
      "Epoch 00024: val_f1_score did not improve from 0.91853\n",
      "290/290 [==============================] - 127s 440ms/step - loss: 0.0176 - acc: 0.9594 - recall_2: 0.9798 - precision_2: 0.9815 - f1_score: 0.9558 - val_loss: 0.1052 - val_acc: 0.9263 - val_recall_2: 0.9227 - val_precision_2: 0.9198 - val_f1_score: 0.9127\n",
      "Epoch 25/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0167 - acc: 0.9645 - recall_2: 0.9817 - precision_2: 0.9841 - f1_score: 0.9564\n",
      "Epoch 00025: val_f1_score did not improve from 0.91853\n",
      "290/290 [==============================] - 127s 439ms/step - loss: 0.0167 - acc: 0.9645 - recall_2: 0.9817 - precision_2: 0.9841 - f1_score: 0.9564 - val_loss: 0.1035 - val_acc: 0.9296 - val_recall_2: 0.9238 - val_precision_2: 0.9249 - val_f1_score: 0.9171\n",
      "Epoch 26/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0137 - acc: 0.9644 - recall_2: 0.9855 - precision_2: 0.9867 - f1_score: 0.9597\n",
      "Epoch 00026: val_f1_score improved from 0.91853 to 0.92005, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_3.h5\n",
      "290/290 [==============================] - 129s 444ms/step - loss: 0.0137 - acc: 0.9644 - recall_2: 0.9855 - precision_2: 0.9867 - f1_score: 0.9597 - val_loss: 0.1042 - val_acc: 0.9315 - val_recall_2: 0.9247 - val_precision_2: 0.9290 - val_f1_score: 0.9201\n",
      "Epoch 27/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0158 - acc: 0.9626 - recall_2: 0.9834 - precision_2: 0.9850 - f1_score: 0.9573\n",
      "Epoch 00027: val_f1_score did not improve from 0.92005\n",
      "290/290 [==============================] - 129s 446ms/step - loss: 0.0158 - acc: 0.9626 - recall_2: 0.9834 - precision_2: 0.9850 - f1_score: 0.9573 - val_loss: 0.1100 - val_acc: 0.9335 - val_recall_2: 0.9241 - val_precision_2: 0.9299 - val_f1_score: 0.9172\n",
      "Epoch 28/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0153 - acc: 0.9630 - recall_2: 0.9846 - precision_2: 0.9849 - f1_score: 0.9594\n",
      "Epoch 00028: val_f1_score did not improve from 0.92005\n",
      "290/290 [==============================] - 127s 439ms/step - loss: 0.0153 - acc: 0.9630 - recall_2: 0.9846 - precision_2: 0.9849 - f1_score: 0.9594 - val_loss: 0.1081 - val_acc: 0.9221 - val_recall_2: 0.9238 - val_precision_2: 0.9234 - val_f1_score: 0.9135\n",
      "Epoch 29/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0148 - acc: 0.9619 - recall_2: 0.9837 - precision_2: 0.9845 - f1_score: 0.9584\n",
      "Epoch 00029: val_f1_score did not improve from 0.92005\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.00020480002276599408.\n",
      "290/290 [==============================] - 128s 442ms/step - loss: 0.0148 - acc: 0.9619 - recall_2: 0.9837 - precision_2: 0.9845 - f1_score: 0.9584 - val_loss: 0.1120 - val_acc: 0.9273 - val_recall_2: 0.9259 - val_precision_2: 0.9189 - val_f1_score: 0.9165\n",
      "Epoch 30/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0120 - acc: 0.9659 - recall_2: 0.9873 - precision_2: 0.9880 - f1_score: 0.9630\n",
      "Epoch 00030: val_f1_score did not improve from 0.92005\n",
      "290/290 [==============================] - 125s 431ms/step - loss: 0.0120 - acc: 0.9659 - recall_2: 0.9873 - precision_2: 0.9880 - f1_score: 0.9630 - val_loss: 0.1113 - val_acc: 0.9253 - val_recall_2: 0.9231 - val_precision_2: 0.9292 - val_f1_score: 0.9156\n",
      "Epoch 31/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0100 - acc: 0.9674 - recall_2: 0.9891 - precision_2: 0.9899 - f1_score: 0.9665\n",
      "Epoch 00031: val_f1_score improved from 0.92005 to 0.92073, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_3.h5\n",
      "290/290 [==============================] - 130s 449ms/step - loss: 0.0100 - acc: 0.9674 - recall_2: 0.9891 - precision_2: 0.9899 - f1_score: 0.9665 - val_loss: 0.1155 - val_acc: 0.9301 - val_recall_2: 0.9307 - val_precision_2: 0.9230 - val_f1_score: 0.9207\n",
      "Epoch 32/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0099 - acc: 0.9711 - recall_2: 0.9887 - precision_2: 0.9901 - f1_score: 0.9665\n",
      "Epoch 00032: val_f1_score did not improve from 0.92073\n",
      "290/290 [==============================] - 127s 437ms/step - loss: 0.0099 - acc: 0.9711 - recall_2: 0.9887 - precision_2: 0.9901 - f1_score: 0.9665 - val_loss: 0.1191 - val_acc: 0.9328 - val_recall_2: 0.9227 - val_precision_2: 0.9224 - val_f1_score: 0.9170\n",
      "Epoch 33/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0098 - acc: 0.9687 - recall_2: 0.9892 - precision_2: 0.9898 - f1_score: 0.9633\n",
      "Epoch 00033: val_f1_score did not improve from 0.92073\n",
      "290/290 [==============================] - 127s 437ms/step - loss: 0.0098 - acc: 0.9687 - recall_2: 0.9892 - precision_2: 0.9898 - f1_score: 0.9633 - val_loss: 0.1170 - val_acc: 0.9263 - val_recall_2: 0.9279 - val_precision_2: 0.9241 - val_f1_score: 0.9164\n",
      "Epoch 34/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0102 - acc: 0.9669 - recall_2: 0.9887 - precision_2: 0.9898 - f1_score: 0.9668\n",
      "Epoch 00034: val_f1_score did not improve from 0.92073\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.00016384001355618238.\n",
      "290/290 [==============================] - 129s 445ms/step - loss: 0.0102 - acc: 0.9669 - recall_2: 0.9887 - precision_2: 0.9898 - f1_score: 0.9668 - val_loss: 0.1152 - val_acc: 0.9298 - val_recall_2: 0.9248 - val_precision_2: 0.9288 - val_f1_score: 0.9190\n",
      "Epoch 35/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0086 - acc: 0.9675 - recall_2: 0.9910 - precision_2: 0.9918 - f1_score: 0.9676\n",
      "Epoch 00035: val_f1_score improved from 0.92073 to 0.92135, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_3.h5\n",
      "290/290 [==============================] - 130s 449ms/step - loss: 0.0086 - acc: 0.9675 - recall_2: 0.9910 - precision_2: 0.9918 - f1_score: 0.9676 - val_loss: 0.1219 - val_acc: 0.9291 - val_recall_2: 0.9294 - val_precision_2: 0.9294 - val_f1_score: 0.9214\n",
      "Epoch 36/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0087 - acc: 0.9692 - recall_2: 0.9899 - precision_2: 0.9916 - f1_score: 0.9686\n",
      "Epoch 00036: val_f1_score did not improve from 0.92135\n",
      "290/290 [==============================] - 127s 440ms/step - loss: 0.0087 - acc: 0.9692 - recall_2: 0.9899 - precision_2: 0.9916 - f1_score: 0.9686 - val_loss: 0.1262 - val_acc: 0.9273 - val_recall_2: 0.9296 - val_precision_2: 0.9253 - val_f1_score: 0.9196\n",
      "Epoch 37/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0074 - acc: 0.9717 - recall_2: 0.9924 - precision_2: 0.9918 - f1_score: 0.9705\n",
      "Epoch 00037: val_f1_score did not improve from 0.92135\n",
      "290/290 [==============================] - 128s 442ms/step - loss: 0.0074 - acc: 0.9717 - recall_2: 0.9924 - precision_2: 0.9918 - f1_score: 0.9705 - val_loss: 0.1186 - val_acc: 0.9291 - val_recall_2: 0.9254 - val_precision_2: 0.9295 - val_f1_score: 0.9204\n",
      "Epoch 38/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0078 - acc: 0.9733 - recall_2: 0.9918 - precision_2: 0.9918 - f1_score: 0.9724\n",
      "Epoch 00038: val_f1_score did not improve from 0.92135\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.0001310720108449459.\n",
      "290/290 [==============================] - 126s 435ms/step - loss: 0.0078 - acc: 0.9733 - recall_2: 0.9918 - precision_2: 0.9918 - f1_score: 0.9724 - val_loss: 0.1436 - val_acc: 0.9229 - val_recall_2: 0.9234 - val_precision_2: 0.9208 - val_f1_score: 0.9141\n",
      "Epoch 39/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0073 - acc: 0.9706 - recall_2: 0.9922 - precision_2: 0.9917 - f1_score: 0.9695\n",
      "Epoch 00039: val_f1_score did not improve from 0.92135\n",
      "290/290 [==============================] - 127s 437ms/step - loss: 0.0073 - acc: 0.9706 - recall_2: 0.9922 - precision_2: 0.9917 - f1_score: 0.9695 - val_loss: 0.1239 - val_acc: 0.9338 - val_recall_2: 0.9232 - val_precision_2: 0.9385 - val_f1_score: 0.9201\n",
      "Epoch 40/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0056 - acc: 0.9724 - recall_2: 0.9937 - precision_2: 0.9932 - f1_score: 0.9724\n",
      "Epoch 00040: val_f1_score did not improve from 0.92135\n",
      "290/290 [==============================] - 127s 440ms/step - loss: 0.0056 - acc: 0.9724 - recall_2: 0.9937 - precision_2: 0.9932 - f1_score: 0.9724 - val_loss: 0.1284 - val_acc: 0.9325 - val_recall_2: 0.9234 - val_precision_2: 0.9272 - val_f1_score: 0.9200\n",
      "Epoch 41/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0054 - acc: 0.9736 - recall_2: 0.9937 - precision_2: 0.9947 - f1_score: 0.9753\n",
      "Epoch 00041: val_f1_score did not improve from 0.92135\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.00010485760867595673.\n",
      "290/290 [==============================] - 127s 438ms/step - loss: 0.0054 - acc: 0.9736 - recall_2: 0.9937 - precision_2: 0.9947 - f1_score: 0.9753 - val_loss: 0.1320 - val_acc: 0.9301 - val_recall_2: 0.9270 - val_precision_2: 0.9305 - val_f1_score: 0.9210\n",
      "Epoch 42/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0056 - acc: 0.9752 - recall_2: 0.9941 - precision_2: 0.9939 - f1_score: 0.9743\n",
      "Epoch 00042: val_f1_score did not improve from 0.92135\n",
      "290/290 [==============================] - 124s 427ms/step - loss: 0.0056 - acc: 0.9752 - recall_2: 0.9941 - precision_2: 0.9939 - f1_score: 0.9743 - val_loss: 0.1369 - val_acc: 0.9315 - val_recall_2: 0.9238 - val_precision_2: 0.9305 - val_f1_score: 0.9210\n",
      "Epoch 43/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0048 - acc: 0.9778 - recall_2: 0.9948 - precision_2: 0.9945 - f1_score: 0.9756Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00043: val_f1_score did not improve from 0.92135\n",
      "290/290 [==============================] - 127s 439ms/step - loss: 0.0048 - acc: 0.9778 - recall_2: 0.9948 - precision_2: 0.9945 - f1_score: 0.9756 - val_loss: 0.1371 - val_acc: 0.9338 - val_recall_2: 0.9272 - val_precision_2: 0.9292 - val_f1_score: 0.9209\n",
      "Epoch 00043: early stopping\n",
      "Epoch 1/100\n",
      "  2/290 [..............................] - ETA: 5:40 - loss: 0.6912 - acc: 0.1875 - recall_3: 0.4667 - precision_3: 0.1886 - f1_score: 0.1689WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.3835s vs `on_train_batch_end` time: 1.9839s). Check your callbacks.\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.1495 - acc: 0.8375 - recall_3: 0.7969 - precision_3: 0.8599 - f1_score: 0.8240\n",
      "Epoch 00001: val_f1_score improved from -inf to 0.85394, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_4.h5\n",
      "290/290 [==============================] - 131s 452ms/step - loss: 0.1495 - acc: 0.8375 - recall_3: 0.7969 - precision_3: 0.8599 - f1_score: 0.8240 - val_loss: 0.1293 - val_acc: 0.8614 - val_recall_3: 0.8414 - val_precision_3: 0.8816 - val_f1_score: 0.8539\n",
      "Epoch 2/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0998 - acc: 0.8924 - recall_3: 0.8722 - precision_3: 0.9042 - f1_score: 0.8791\n",
      "Epoch 00002: val_f1_score improved from 0.85394 to 0.88841, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_4.h5\n",
      "290/290 [==============================] - 127s 436ms/step - loss: 0.0998 - acc: 0.8924 - recall_3: 0.8722 - precision_3: 0.9042 - f1_score: 0.8791 - val_loss: 0.0922 - val_acc: 0.9025 - val_recall_3: 0.8695 - val_precision_3: 0.9213 - val_f1_score: 0.8884\n",
      "Epoch 3/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0873 - acc: 0.9046 - recall_3: 0.8893 - precision_3: 0.9109 - f1_score: 0.8919\n",
      "Epoch 00003: val_f1_score improved from 0.88841 to 0.89802, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_4.h5\n",
      "290/290 [==============================] - 127s 437ms/step - loss: 0.0873 - acc: 0.9046 - recall_3: 0.8893 - precision_3: 0.9109 - f1_score: 0.8919 - val_loss: 0.0903 - val_acc: 0.9030 - val_recall_3: 0.8926 - val_precision_3: 0.9227 - val_f1_score: 0.8980\n",
      "Epoch 4/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0812 - acc: 0.9097 - recall_3: 0.8971 - precision_3: 0.9169 - f1_score: 0.8974\n",
      "Epoch 00004: val_f1_score did not improve from 0.89802\n",
      "290/290 [==============================] - 128s 440ms/step - loss: 0.0812 - acc: 0.9097 - recall_3: 0.8971 - precision_3: 0.9169 - f1_score: 0.8974 - val_loss: 0.0873 - val_acc: 0.9045 - val_recall_3: 0.9119 - val_precision_3: 0.9070 - val_f1_score: 0.8972\n",
      "Epoch 5/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0764 - acc: 0.9154 - recall_3: 0.9032 - precision_3: 0.9235 - f1_score: 0.9027\n",
      "Epoch 00005: val_f1_score improved from 0.89802 to 0.90487, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_4.h5\n",
      "290/290 [==============================] - 127s 439ms/step - loss: 0.0764 - acc: 0.9154 - recall_3: 0.9032 - precision_3: 0.9235 - f1_score: 0.9027 - val_loss: 0.0800 - val_acc: 0.9201 - val_recall_3: 0.9069 - val_precision_3: 0.9228 - val_f1_score: 0.9049\n",
      "Epoch 6/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0727 - acc: 0.9203 - recall_3: 0.9100 - precision_3: 0.9278 - f1_score: 0.9086\n",
      "Epoch 00006: val_f1_score did not improve from 0.90487\n",
      "290/290 [==============================] - 125s 432ms/step - loss: 0.0727 - acc: 0.9203 - recall_3: 0.9100 - precision_3: 0.9278 - f1_score: 0.9086 - val_loss: 0.0956 - val_acc: 0.8886 - val_recall_3: 0.8943 - val_precision_3: 0.8974 - val_f1_score: 0.8726\n",
      "Epoch 7/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0663 - acc: 0.9221 - recall_3: 0.9145 - precision_3: 0.9306 - f1_score: 0.9119\n",
      "Epoch 00007: val_f1_score did not improve from 0.90487\n",
      "290/290 [==============================] - 125s 433ms/step - loss: 0.0663 - acc: 0.9221 - recall_3: 0.9145 - precision_3: 0.9306 - f1_score: 0.9119 - val_loss: 0.0838 - val_acc: 0.8993 - val_recall_3: 0.9180 - val_precision_3: 0.9073 - val_f1_score: 0.8981\n",
      "Epoch 8/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0648 - acc: 0.9240 - recall_3: 0.9201 - precision_3: 0.9354 - f1_score: 0.9150\n",
      "Epoch 00008: val_f1_score did not improve from 0.90487\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "290/290 [==============================] - 127s 439ms/step - loss: 0.0648 - acc: 0.9240 - recall_3: 0.9201 - precision_3: 0.9354 - f1_score: 0.9150 - val_loss: 0.0830 - val_acc: 0.9122 - val_recall_3: 0.9132 - val_precision_3: 0.9160 - val_f1_score: 0.9016\n",
      "Epoch 9/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0564 - acc: 0.9317 - recall_3: 0.9296 - precision_3: 0.9418 - f1_score: 0.9214\n",
      "Epoch 00009: val_f1_score improved from 0.90487 to 0.90661, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_4.h5\n",
      "290/290 [==============================] - 127s 438ms/step - loss: 0.0564 - acc: 0.9317 - recall_3: 0.9296 - precision_3: 0.9418 - f1_score: 0.9214 - val_loss: 0.0764 - val_acc: 0.9149 - val_recall_3: 0.9072 - val_precision_3: 0.9283 - val_f1_score: 0.9066\n",
      "Epoch 10/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0533 - acc: 0.9345 - recall_3: 0.9321 - precision_3: 0.9452 - f1_score: 0.9231\n",
      "Epoch 00010: val_f1_score improved from 0.90661 to 0.90987, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_4.h5\n",
      "290/290 [==============================] - 128s 441ms/step - loss: 0.0533 - acc: 0.9345 - recall_3: 0.9321 - precision_3: 0.9452 - f1_score: 0.9231 - val_loss: 0.0739 - val_acc: 0.9234 - val_recall_3: 0.9132 - val_precision_3: 0.9287 - val_f1_score: 0.9099\n",
      "Epoch 11/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0486 - acc: 0.9401 - recall_3: 0.9414 - precision_3: 0.9497 - f1_score: 0.9292\n",
      "Epoch 00011: val_f1_score did not improve from 0.90987\n",
      "290/290 [==============================] - 125s 430ms/step - loss: 0.0486 - acc: 0.9401 - recall_3: 0.9414 - precision_3: 0.9497 - f1_score: 0.9292 - val_loss: 0.0890 - val_acc: 0.9092 - val_recall_3: 0.9122 - val_precision_3: 0.9150 - val_f1_score: 0.9009\n",
      "Epoch 12/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0471 - acc: 0.9421 - recall_3: 0.9426 - precision_3: 0.9511 - f1_score: 0.9305\n",
      "Epoch 00012: val_f1_score improved from 0.90987 to 0.91035, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_4.h5\n",
      "290/290 [==============================] - 128s 443ms/step - loss: 0.0471 - acc: 0.9421 - recall_3: 0.9426 - precision_3: 0.9511 - f1_score: 0.9305 - val_loss: 0.0791 - val_acc: 0.9266 - val_recall_3: 0.9227 - val_precision_3: 0.9218 - val_f1_score: 0.9104\n",
      "Epoch 13/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0460 - acc: 0.9411 - recall_3: 0.9443 - precision_3: 0.9532 - f1_score: 0.9315\n",
      "Epoch 00013: val_f1_score did not improve from 0.91035\n",
      "290/290 [==============================] - 126s 435ms/step - loss: 0.0460 - acc: 0.9411 - recall_3: 0.9443 - precision_3: 0.9532 - f1_score: 0.9315 - val_loss: 0.0936 - val_acc: 0.9105 - val_recall_3: 0.9146 - val_precision_3: 0.9127 - val_f1_score: 0.8989\n",
      "Epoch 14/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0422 - acc: 0.9432 - recall_3: 0.9504 - precision_3: 0.9562 - f1_score: 0.9338\n",
      "Epoch 00014: val_f1_score did not improve from 0.91035\n",
      "290/290 [==============================] - 125s 433ms/step - loss: 0.0422 - acc: 0.9432 - recall_3: 0.9504 - precision_3: 0.9562 - f1_score: 0.9338 - val_loss: 0.0908 - val_acc: 0.9211 - val_recall_3: 0.9239 - val_precision_3: 0.9125 - val_f1_score: 0.9055\n",
      "Epoch 15/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0415 - acc: 0.9427 - recall_3: 0.9525 - precision_3: 0.9576 - f1_score: 0.9349\n",
      "Epoch 00015: val_f1_score did not improve from 0.91035\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00032000001519918444.\n",
      "290/290 [==============================] - 126s 434ms/step - loss: 0.0415 - acc: 0.9427 - recall_3: 0.9525 - precision_3: 0.9576 - f1_score: 0.9349 - val_loss: 0.0900 - val_acc: 0.9231 - val_recall_3: 0.9132 - val_precision_3: 0.9250 - val_f1_score: 0.9073\n",
      "Epoch 16/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0333 - acc: 0.9527 - recall_3: 0.9605 - precision_3: 0.9668 - f1_score: 0.9428\n",
      "Epoch 00016: val_f1_score improved from 0.91035 to 0.91501, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_4.h5\n",
      "290/290 [==============================] - 126s 436ms/step - loss: 0.0333 - acc: 0.9527 - recall_3: 0.9605 - precision_3: 0.9668 - f1_score: 0.9428 - val_loss: 0.0902 - val_acc: 0.9296 - val_recall_3: 0.9256 - val_precision_3: 0.9239 - val_f1_score: 0.9150\n",
      "Epoch 17/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0323 - acc: 0.9509 - recall_3: 0.9604 - precision_3: 0.9660 - f1_score: 0.9406\n",
      "Epoch 00017: val_f1_score did not improve from 0.91501\n",
      "290/290 [==============================] - 124s 427ms/step - loss: 0.0323 - acc: 0.9509 - recall_3: 0.9604 - precision_3: 0.9660 - f1_score: 0.9406 - val_loss: 0.0900 - val_acc: 0.9164 - val_recall_3: 0.9183 - val_precision_3: 0.9192 - val_f1_score: 0.9063\n",
      "Epoch 18/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0296 - acc: 0.9522 - recall_3: 0.9643 - precision_3: 0.9707 - f1_score: 0.9450\n",
      "Epoch 00018: val_f1_score did not improve from 0.91501\n",
      "290/290 [==============================] - 126s 436ms/step - loss: 0.0296 - acc: 0.9522 - recall_3: 0.9643 - precision_3: 0.9707 - f1_score: 0.9450 - val_loss: 0.0928 - val_acc: 0.9169 - val_recall_3: 0.9162 - val_precision_3: 0.9276 - val_f1_score: 0.9107\n",
      "Epoch 19/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0261 - acc: 0.9539 - recall_3: 0.9694 - precision_3: 0.9733 - f1_score: 0.9477\n",
      "Epoch 00019: val_f1_score did not improve from 0.91501\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0002560000168159604.\n",
      "290/290 [==============================] - 125s 430ms/step - loss: 0.0261 - acc: 0.9539 - recall_3: 0.9694 - precision_3: 0.9733 - f1_score: 0.9477 - val_loss: 0.0970 - val_acc: 0.9241 - val_recall_3: 0.9310 - val_precision_3: 0.9081 - val_f1_score: 0.9092\n",
      "Epoch 20/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0223 - acc: 0.9539 - recall_3: 0.9750 - precision_3: 0.9760 - f1_score: 0.9507\n",
      "Epoch 00020: val_f1_score did not improve from 0.91501\n",
      "290/290 [==============================] - 125s 432ms/step - loss: 0.0223 - acc: 0.9539 - recall_3: 0.9750 - precision_3: 0.9760 - f1_score: 0.9507 - val_loss: 0.0971 - val_acc: 0.9234 - val_recall_3: 0.9234 - val_precision_3: 0.9262 - val_f1_score: 0.9125\n",
      "Epoch 21/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0199 - acc: 0.9607 - recall_3: 0.9770 - precision_3: 0.9811 - f1_score: 0.9542\n",
      "Epoch 00021: val_f1_score did not improve from 0.91501\n",
      "290/290 [==============================] - 124s 427ms/step - loss: 0.0199 - acc: 0.9607 - recall_3: 0.9770 - precision_3: 0.9811 - f1_score: 0.9542 - val_loss: 0.0916 - val_acc: 0.9273 - val_recall_3: 0.9278 - val_precision_3: 0.9235 - val_f1_score: 0.9133\n",
      "Epoch 22/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0207 - acc: 0.9592 - recall_3: 0.9771 - precision_3: 0.9790 - f1_score: 0.9523\n",
      "Epoch 00022: val_f1_score improved from 0.91501 to 0.91588, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_4.h5\n",
      "290/290 [==============================] - 128s 442ms/step - loss: 0.0207 - acc: 0.9592 - recall_3: 0.9771 - precision_3: 0.9790 - f1_score: 0.9523 - val_loss: 0.0954 - val_acc: 0.9256 - val_recall_3: 0.9284 - val_precision_3: 0.9216 - val_f1_score: 0.9159\n",
      "Epoch 23/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0187 - acc: 0.9602 - recall_3: 0.9778 - precision_3: 0.9812 - f1_score: 0.9548\n",
      "Epoch 00023: val_f1_score did not improve from 0.91588\n",
      "290/290 [==============================] - 125s 432ms/step - loss: 0.0187 - acc: 0.9602 - recall_3: 0.9778 - precision_3: 0.9812 - f1_score: 0.9548 - val_loss: 0.1033 - val_acc: 0.9199 - val_recall_3: 0.9273 - val_precision_3: 0.9169 - val_f1_score: 0.9077\n",
      "Epoch 24/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0189 - acc: 0.9600 - recall_3: 0.9790 - precision_3: 0.9805 - f1_score: 0.9538\n",
      "Epoch 00024: val_f1_score did not improve from 0.91588\n",
      "290/290 [==============================] - 125s 432ms/step - loss: 0.0189 - acc: 0.9600 - recall_3: 0.9790 - precision_3: 0.9805 - f1_score: 0.9538 - val_loss: 0.1077 - val_acc: 0.9211 - val_recall_3: 0.9167 - val_precision_3: 0.9266 - val_f1_score: 0.9134\n",
      "Epoch 25/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0164 - acc: 0.9604 - recall_3: 0.9814 - precision_3: 0.9831 - f1_score: 0.9561\n",
      "Epoch 00025: val_f1_score improved from 0.91588 to 0.91737, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_4.h5\n",
      "290/290 [==============================] - 128s 440ms/step - loss: 0.0164 - acc: 0.9604 - recall_3: 0.9814 - precision_3: 0.9831 - f1_score: 0.9561 - val_loss: 0.1026 - val_acc: 0.9241 - val_recall_3: 0.9280 - val_precision_3: 0.9263 - val_f1_score: 0.9174\n",
      "Epoch 26/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0165 - acc: 0.9608 - recall_3: 0.9822 - precision_3: 0.9837 - f1_score: 0.9584\n",
      "Epoch 00026: val_f1_score did not improve from 0.91737\n",
      "290/290 [==============================] - 127s 437ms/step - loss: 0.0165 - acc: 0.9608 - recall_3: 0.9822 - precision_3: 0.9837 - f1_score: 0.9584 - val_loss: 0.1127 - val_acc: 0.9258 - val_recall_3: 0.9252 - val_precision_3: 0.9244 - val_f1_score: 0.9142\n",
      "Epoch 27/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0158 - acc: 0.9632 - recall_3: 0.9827 - precision_3: 0.9840 - f1_score: 0.9581\n",
      "Epoch 00027: val_f1_score did not improve from 0.91737\n",
      "290/290 [==============================] - 126s 436ms/step - loss: 0.0158 - acc: 0.9632 - recall_3: 0.9827 - precision_3: 0.9840 - f1_score: 0.9581 - val_loss: 0.1159 - val_acc: 0.9224 - val_recall_3: 0.9236 - val_precision_3: 0.9268 - val_f1_score: 0.9131\n",
      "Epoch 28/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0139 - acc: 0.9621 - recall_3: 0.9851 - precision_3: 0.9862 - f1_score: 0.9594\n",
      "Epoch 00028: val_f1_score did not improve from 0.91737\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.00020480002276599408.\n",
      "290/290 [==============================] - 125s 430ms/step - loss: 0.0139 - acc: 0.9621 - recall_3: 0.9851 - precision_3: 0.9862 - f1_score: 0.9594 - val_loss: 0.1229 - val_acc: 0.9219 - val_recall_3: 0.9243 - val_precision_3: 0.9239 - val_f1_score: 0.9141\n",
      "Epoch 29/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0130 - acc: 0.9634 - recall_3: 0.9845 - precision_3: 0.9859 - f1_score: 0.9607\n",
      "Epoch 00029: val_f1_score improved from 0.91737 to 0.91912, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_4.h5\n",
      "290/290 [==============================] - 128s 442ms/step - loss: 0.0130 - acc: 0.9634 - recall_3: 0.9845 - precision_3: 0.9859 - f1_score: 0.9607 - val_loss: 0.1124 - val_acc: 0.9311 - val_recall_3: 0.9311 - val_precision_3: 0.9225 - val_f1_score: 0.9191\n",
      "Epoch 30/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0108 - acc: 0.9652 - recall_3: 0.9876 - precision_3: 0.9887 - f1_score: 0.9623\n",
      "Epoch 00030: val_f1_score did not improve from 0.91912\n",
      "290/290 [==============================] - 126s 435ms/step - loss: 0.0108 - acc: 0.9652 - recall_3: 0.9876 - precision_3: 0.9887 - f1_score: 0.9623 - val_loss: 0.1159 - val_acc: 0.9226 - val_recall_3: 0.9166 - val_precision_3: 0.9300 - val_f1_score: 0.9135\n",
      "Epoch 31/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0112 - acc: 0.9645 - recall_3: 0.9878 - precision_3: 0.9886 - f1_score: 0.9623\n",
      "Epoch 00031: val_f1_score did not improve from 0.91912\n",
      "290/290 [==============================] - 125s 432ms/step - loss: 0.0112 - acc: 0.9645 - recall_3: 0.9878 - precision_3: 0.9886 - f1_score: 0.9623 - val_loss: 0.1233 - val_acc: 0.9311 - val_recall_3: 0.9246 - val_precision_3: 0.9201 - val_f1_score: 0.9181\n",
      "Epoch 32/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0124 - acc: 0.9656 - recall_3: 0.9861 - precision_3: 0.9869 - f1_score: 0.9613\n",
      "Epoch 00032: val_f1_score improved from 0.91912 to 0.92375, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_4.h5\n",
      "290/290 [==============================] - 128s 441ms/step - loss: 0.0124 - acc: 0.9656 - recall_3: 0.9861 - precision_3: 0.9869 - f1_score: 0.9613 - val_loss: 0.1191 - val_acc: 0.9308 - val_recall_3: 0.9326 - val_precision_3: 0.9254 - val_f1_score: 0.9238\n",
      "Epoch 33/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0100 - acc: 0.9688 - recall_3: 0.9887 - precision_3: 0.9898 - f1_score: 0.9660\n",
      "Epoch 00033: val_f1_score did not improve from 0.92375\n",
      "290/290 [==============================] - 125s 432ms/step - loss: 0.0100 - acc: 0.9688 - recall_3: 0.9887 - precision_3: 0.9898 - f1_score: 0.9660 - val_loss: 0.1321 - val_acc: 0.9224 - val_recall_3: 0.9185 - val_precision_3: 0.9243 - val_f1_score: 0.9117\n",
      "Epoch 34/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0105 - acc: 0.9646 - recall_3: 0.9881 - precision_3: 0.9890 - f1_score: 0.9633\n",
      "Epoch 00034: val_f1_score did not improve from 0.92375\n",
      "290/290 [==============================] - 126s 435ms/step - loss: 0.0105 - acc: 0.9646 - recall_3: 0.9881 - precision_3: 0.9890 - f1_score: 0.9633 - val_loss: 0.1277 - val_acc: 0.9226 - val_recall_3: 0.9262 - val_precision_3: 0.9204 - val_f1_score: 0.9166\n",
      "Epoch 35/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0096 - acc: 0.9644 - recall_3: 0.9887 - precision_3: 0.9905 - f1_score: 0.9651\n",
      "Epoch 00035: val_f1_score did not improve from 0.92375\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.00016384001355618238.\n",
      "290/290 [==============================] - 126s 433ms/step - loss: 0.0096 - acc: 0.9644 - recall_3: 0.9887 - precision_3: 0.9905 - f1_score: 0.9651 - val_loss: 0.1297 - val_acc: 0.9286 - val_recall_3: 0.9183 - val_precision_3: 0.9343 - val_f1_score: 0.9193\n",
      "Epoch 36/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0084 - acc: 0.9661 - recall_3: 0.9894 - precision_3: 0.9912 - f1_score: 0.9678\n",
      "Epoch 00036: val_f1_score did not improve from 0.92375\n",
      "290/290 [==============================] - 126s 434ms/step - loss: 0.0084 - acc: 0.9661 - recall_3: 0.9894 - precision_3: 0.9912 - f1_score: 0.9678 - val_loss: 0.1335 - val_acc: 0.9315 - val_recall_3: 0.9255 - val_precision_3: 0.9313 - val_f1_score: 0.9219\n",
      "Epoch 37/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0078 - acc: 0.9685 - recall_3: 0.9914 - precision_3: 0.9915 - f1_score: 0.9696\n",
      "Epoch 00037: val_f1_score did not improve from 0.92375\n",
      "290/290 [==============================] - 122s 420ms/step - loss: 0.0078 - acc: 0.9685 - recall_3: 0.9914 - precision_3: 0.9915 - f1_score: 0.9696 - val_loss: 0.1274 - val_acc: 0.9216 - val_recall_3: 0.9227 - val_precision_3: 0.9298 - val_f1_score: 0.9158\n",
      "Epoch 38/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0066 - acc: 0.9684 - recall_3: 0.9919 - precision_3: 0.9926 - f1_score: 0.9697\n",
      "Epoch 00038: val_f1_score did not improve from 0.92375\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.0001310720108449459.\n",
      "290/290 [==============================] - 128s 442ms/step - loss: 0.0066 - acc: 0.9684 - recall_3: 0.9919 - precision_3: 0.9926 - f1_score: 0.9697 - val_loss: 0.1393 - val_acc: 0.9263 - val_recall_3: 0.9251 - val_precision_3: 0.9309 - val_f1_score: 0.9186\n",
      "Epoch 39/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0071 - acc: 0.9680 - recall_3: 0.9915 - precision_3: 0.9929 - f1_score: 0.9702\n",
      "Epoch 00039: val_f1_score did not improve from 0.92375\n",
      "290/290 [==============================] - 125s 431ms/step - loss: 0.0071 - acc: 0.9680 - recall_3: 0.9915 - precision_3: 0.9929 - f1_score: 0.9702 - val_loss: 0.1283 - val_acc: 0.9261 - val_recall_3: 0.9244 - val_precision_3: 0.9326 - val_f1_score: 0.9198\n",
      "Epoch 40/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0071 - acc: 0.9684 - recall_3: 0.9915 - precision_3: 0.9929 - f1_score: 0.9725\n",
      "Epoch 00040: val_f1_score improved from 0.92375 to 0.92443, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_4.h5\n",
      "290/290 [==============================] - 129s 445ms/step - loss: 0.0071 - acc: 0.9684 - recall_3: 0.9915 - precision_3: 0.9929 - f1_score: 0.9725 - val_loss: 0.1332 - val_acc: 0.9318 - val_recall_3: 0.9268 - val_precision_3: 0.9294 - val_f1_score: 0.9244\n",
      "Epoch 41/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0068 - acc: 0.9688 - recall_3: 0.9916 - precision_3: 0.9928 - f1_score: 0.9711\n",
      "Epoch 00041: val_f1_score did not improve from 0.92443\n",
      "290/290 [==============================] - 123s 425ms/step - loss: 0.0068 - acc: 0.9688 - recall_3: 0.9916 - precision_3: 0.9928 - f1_score: 0.9711 - val_loss: 0.1425 - val_acc: 0.9241 - val_recall_3: 0.9171 - val_precision_3: 0.9329 - val_f1_score: 0.9160\n",
      "Epoch 42/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0065 - acc: 0.9691 - recall_3: 0.9931 - precision_3: 0.9926 - f1_score: 0.9707\n",
      "Epoch 00042: val_f1_score did not improve from 0.92443\n",
      "290/290 [==============================] - 127s 439ms/step - loss: 0.0065 - acc: 0.9691 - recall_3: 0.9931 - precision_3: 0.9926 - f1_score: 0.9707 - val_loss: 0.1359 - val_acc: 0.9263 - val_recall_3: 0.9182 - val_precision_3: 0.9305 - val_f1_score: 0.9175\n",
      "Epoch 43/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0058 - acc: 0.9720 - recall_3: 0.9937 - precision_3: 0.9934 - f1_score: 0.9747\n",
      "Epoch 00043: val_f1_score did not improve from 0.92443\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.00010485760867595673.\n",
      "290/290 [==============================] - 125s 432ms/step - loss: 0.0058 - acc: 0.9720 - recall_3: 0.9937 - precision_3: 0.9934 - f1_score: 0.9747 - val_loss: 0.1379 - val_acc: 0.9263 - val_recall_3: 0.9229 - val_precision_3: 0.9296 - val_f1_score: 0.9186\n",
      "Epoch 44/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0053 - acc: 0.9721 - recall_3: 0.9941 - precision_3: 0.9943 - f1_score: 0.9724\n",
      "Epoch 00044: val_f1_score did not improve from 0.92443\n",
      "290/290 [==============================] - 126s 435ms/step - loss: 0.0053 - acc: 0.9721 - recall_3: 0.9941 - precision_3: 0.9943 - f1_score: 0.9724 - val_loss: 0.1352 - val_acc: 0.9278 - val_recall_3: 0.9261 - val_precision_3: 0.9317 - val_f1_score: 0.9185\n",
      "Epoch 45/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0056 - acc: 0.9746 - recall_3: 0.9933 - precision_3: 0.9934 - f1_score: 0.9756\n",
      "Epoch 00045: val_f1_score did not improve from 0.92443\n",
      "290/290 [==============================] - 128s 440ms/step - loss: 0.0056 - acc: 0.9746 - recall_3: 0.9933 - precision_3: 0.9934 - f1_score: 0.9756 - val_loss: 0.1317 - val_acc: 0.9296 - val_recall_3: 0.9326 - val_precision_3: 0.9272 - val_f1_score: 0.9204\n",
      "Epoch 46/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0042 - acc: 0.9774 - recall_3: 0.9949 - precision_3: 0.9948 - f1_score: 0.9766\n",
      "Epoch 00046: val_f1_score did not improve from 0.92443\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 8.388608694076538e-05.\n",
      "290/290 [==============================] - 125s 431ms/step - loss: 0.0042 - acc: 0.9774 - recall_3: 0.9949 - precision_3: 0.9948 - f1_score: 0.9766 - val_loss: 0.1409 - val_acc: 0.9306 - val_recall_3: 0.9276 - val_precision_3: 0.9332 - val_f1_score: 0.9225\n",
      "Epoch 47/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0036 - acc: 0.9783 - recall_3: 0.9949 - precision_3: 0.9954 - f1_score: 0.9796\n",
      "Epoch 00047: val_f1_score did not improve from 0.92443\n",
      "290/290 [==============================] - 127s 437ms/step - loss: 0.0036 - acc: 0.9783 - recall_3: 0.9949 - precision_3: 0.9954 - f1_score: 0.9796 - val_loss: 0.1484 - val_acc: 0.9266 - val_recall_3: 0.9298 - val_precision_3: 0.9268 - val_f1_score: 0.9194\n",
      "Epoch 48/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0041 - acc: 0.9765 - recall_3: 0.9949 - precision_3: 0.9951 - f1_score: 0.9802Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00048: val_f1_score did not improve from 0.92443\n",
      "290/290 [==============================] - 127s 439ms/step - loss: 0.0041 - acc: 0.9765 - recall_3: 0.9949 - precision_3: 0.9951 - f1_score: 0.9802 - val_loss: 0.1512 - val_acc: 0.9276 - val_recall_3: 0.9230 - val_precision_3: 0.9281 - val_f1_score: 0.9192\n",
      "Epoch 00048: early stopping\n",
      "Epoch 1/100\n",
      "  2/290 [..............................] - ETA: 5:49 - loss: 0.6672 - acc: 0.2411 - recall_4: 0.3814 - precision_4: 0.1772 - f1_score: 0.2224WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.3880s vs `on_train_batch_end` time: 2.0400s). Check your callbacks.\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.1454 - acc: 0.8432 - recall_4: 0.8036 - precision_4: 0.8639 - f1_score: 0.8312\n",
      "Epoch 00001: val_f1_score improved from -inf to 0.83049, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_5.h5\n",
      "290/290 [==============================] - 132s 456ms/step - loss: 0.1454 - acc: 0.8432 - recall_4: 0.8036 - precision_4: 0.8639 - f1_score: 0.8312 - val_loss: 0.1468 - val_acc: 0.8452 - val_recall_4: 0.8443 - val_precision_4: 0.8651 - val_f1_score: 0.8305\n",
      "Epoch 2/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0977 - acc: 0.8946 - recall_4: 0.8745 - precision_4: 0.9055 - f1_score: 0.8820\n",
      "Epoch 00002: val_f1_score improved from 0.83049 to 0.85347, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_5.h5\n",
      "290/290 [==============================] - 129s 446ms/step - loss: 0.0977 - acc: 0.8946 - recall_4: 0.8745 - precision_4: 0.9055 - f1_score: 0.8820 - val_loss: 0.1157 - val_acc: 0.8601 - val_recall_4: 0.8645 - val_precision_4: 0.8820 - val_f1_score: 0.8535\n",
      "Epoch 3/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0878 - acc: 0.9037 - recall_4: 0.8908 - precision_4: 0.9133 - f1_score: 0.8925\n",
      "Epoch 00003: val_f1_score improved from 0.85347 to 0.86817, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_5.h5\n",
      "290/290 [==============================] - 130s 448ms/step - loss: 0.0878 - acc: 0.9037 - recall_4: 0.8908 - precision_4: 0.9133 - f1_score: 0.8925 - val_loss: 0.1206 - val_acc: 0.8782 - val_recall_4: 0.8699 - val_precision_4: 0.8991 - val_f1_score: 0.8682\n",
      "Epoch 4/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0798 - acc: 0.9129 - recall_4: 0.9029 - precision_4: 0.9209 - f1_score: 0.9016\n",
      "Epoch 00004: val_f1_score improved from 0.86817 to 0.88941, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_5.h5\n",
      "290/290 [==============================] - 128s 440ms/step - loss: 0.0798 - acc: 0.9129 - recall_4: 0.9029 - precision_4: 0.9209 - f1_score: 0.9016 - val_loss: 0.0925 - val_acc: 0.9025 - val_recall_4: 0.8722 - val_precision_4: 0.9243 - val_f1_score: 0.8894\n",
      "Epoch 5/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0744 - acc: 0.9157 - recall_4: 0.9059 - precision_4: 0.9259 - f1_score: 0.9044\n",
      "Epoch 00005: val_f1_score improved from 0.88941 to 0.89412, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_5.h5\n",
      "290/290 [==============================] - 129s 443ms/step - loss: 0.0744 - acc: 0.9157 - recall_4: 0.9059 - precision_4: 0.9259 - f1_score: 0.9044 - val_loss: 0.0857 - val_acc: 0.9077 - val_recall_4: 0.8955 - val_precision_4: 0.9248 - val_f1_score: 0.8941\n",
      "Epoch 6/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0699 - acc: 0.9208 - recall_4: 0.9121 - precision_4: 0.9292 - f1_score: 0.9098\n",
      "Epoch 00006: val_f1_score improved from 0.89412 to 0.89499, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_5.h5\n",
      "290/290 [==============================] - 128s 442ms/step - loss: 0.0699 - acc: 0.9208 - recall_4: 0.9121 - precision_4: 0.9292 - f1_score: 0.9098 - val_loss: 0.0896 - val_acc: 0.9120 - val_recall_4: 0.9036 - val_precision_4: 0.9075 - val_f1_score: 0.8950\n",
      "Epoch 7/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0650 - acc: 0.9239 - recall_4: 0.9206 - precision_4: 0.9336 - f1_score: 0.9130\n",
      "Epoch 00007: val_f1_score did not improve from 0.89499\n",
      "290/290 [==============================] - 126s 436ms/step - loss: 0.0650 - acc: 0.9239 - recall_4: 0.9206 - precision_4: 0.9336 - f1_score: 0.9130 - val_loss: 0.1004 - val_acc: 0.9095 - val_recall_4: 0.8663 - val_precision_4: 0.9311 - val_f1_score: 0.8937\n",
      "Epoch 8/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0609 - acc: 0.9277 - recall_4: 0.9261 - precision_4: 0.9388 - f1_score: 0.9190\n",
      "Epoch 00008: val_f1_score improved from 0.89499 to 0.89578, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_5.h5\n",
      "290/290 [==============================] - 129s 444ms/step - loss: 0.0609 - acc: 0.9277 - recall_4: 0.9261 - precision_4: 0.9388 - f1_score: 0.9190 - val_loss: 0.0941 - val_acc: 0.9048 - val_recall_4: 0.9063 - val_precision_4: 0.9070 - val_f1_score: 0.8958\n",
      "Epoch 9/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0585 - acc: 0.9325 - recall_4: 0.9307 - precision_4: 0.9409 - f1_score: 0.9217\n",
      "Epoch 00009: val_f1_score improved from 0.89578 to 0.89937, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_5.h5\n",
      "290/290 [==============================] - 126s 435ms/step - loss: 0.0585 - acc: 0.9325 - recall_4: 0.9307 - precision_4: 0.9409 - f1_score: 0.9217 - val_loss: 0.0904 - val_acc: 0.9115 - val_recall_4: 0.9072 - val_precision_4: 0.9093 - val_f1_score: 0.8994\n",
      "Epoch 10/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0555 - acc: 0.9328 - recall_4: 0.9323 - precision_4: 0.9452 - f1_score: 0.9229\n",
      "Epoch 00010: val_f1_score did not improve from 0.89937\n",
      "290/290 [==============================] - 129s 446ms/step - loss: 0.0555 - acc: 0.9328 - recall_4: 0.9323 - precision_4: 0.9452 - f1_score: 0.9229 - val_loss: 0.0957 - val_acc: 0.9050 - val_recall_4: 0.8792 - val_precision_4: 0.9210 - val_f1_score: 0.8922\n",
      "Epoch 11/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0541 - acc: 0.9328 - recall_4: 0.9343 - precision_4: 0.9434 - f1_score: 0.9235\n",
      "Epoch 00011: val_f1_score did not improve from 0.89937\n",
      "290/290 [==============================] - 127s 438ms/step - loss: 0.0541 - acc: 0.9328 - recall_4: 0.9343 - precision_4: 0.9434 - f1_score: 0.9235 - val_loss: 0.0898 - val_acc: 0.9035 - val_recall_4: 0.9127 - val_precision_4: 0.9092 - val_f1_score: 0.8933\n",
      "Epoch 12/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0513 - acc: 0.9357 - recall_4: 0.9378 - precision_4: 0.9463 - f1_score: 0.9267\n",
      "Epoch 00012: val_f1_score did not improve from 0.89937\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "290/290 [==============================] - 128s 441ms/step - loss: 0.0513 - acc: 0.9357 - recall_4: 0.9378 - precision_4: 0.9463 - f1_score: 0.9267 - val_loss: 0.0961 - val_acc: 0.9035 - val_recall_4: 0.8933 - val_precision_4: 0.9126 - val_f1_score: 0.8925\n",
      "Epoch 13/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0433 - acc: 0.9425 - recall_4: 0.9452 - precision_4: 0.9539 - f1_score: 0.9335\n",
      "Epoch 00013: val_f1_score improved from 0.89937 to 0.90260, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_5.h5\n",
      "290/290 [==============================] - 128s 440ms/step - loss: 0.0433 - acc: 0.9425 - recall_4: 0.9452 - precision_4: 0.9539 - f1_score: 0.9335 - val_loss: 0.0969 - val_acc: 0.9142 - val_recall_4: 0.9111 - val_precision_4: 0.9157 - val_f1_score: 0.9026\n",
      "Epoch 14/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0398 - acc: 0.9469 - recall_4: 0.9530 - precision_4: 0.9588 - f1_score: 0.9379\n",
      "Epoch 00014: val_f1_score did not improve from 0.90260\n",
      "290/290 [==============================] - 128s 441ms/step - loss: 0.0398 - acc: 0.9469 - recall_4: 0.9530 - precision_4: 0.9588 - f1_score: 0.9379 - val_loss: 0.0971 - val_acc: 0.9129 - val_recall_4: 0.8976 - val_precision_4: 0.9249 - val_f1_score: 0.9001\n",
      "Epoch 15/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0385 - acc: 0.9457 - recall_4: 0.9547 - precision_4: 0.9604 - f1_score: 0.9386\n",
      "Epoch 00015: val_f1_score did not improve from 0.90260\n",
      "290/290 [==============================] - 126s 434ms/step - loss: 0.0385 - acc: 0.9457 - recall_4: 0.9547 - precision_4: 0.9604 - f1_score: 0.9386 - val_loss: 0.1254 - val_acc: 0.8867 - val_recall_4: 0.8981 - val_precision_4: 0.8991 - val_f1_score: 0.8823\n",
      "Epoch 16/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0362 - acc: 0.9489 - recall_4: 0.9561 - precision_4: 0.9615 - f1_score: 0.9392\n",
      "Epoch 00016: val_f1_score did not improve from 0.90260\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.00032000001519918444.\n",
      "290/290 [==============================] - 128s 442ms/step - loss: 0.0362 - acc: 0.9489 - recall_4: 0.9561 - precision_4: 0.9615 - f1_score: 0.9392 - val_loss: 0.1213 - val_acc: 0.9010 - val_recall_4: 0.9150 - val_precision_4: 0.8935 - val_f1_score: 0.8931\n",
      "Epoch 17/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0293 - acc: 0.9541 - recall_4: 0.9659 - precision_4: 0.9701 - f1_score: 0.9463\n",
      "Epoch 00017: val_f1_score did not improve from 0.90260\n",
      "290/290 [==============================] - 126s 436ms/step - loss: 0.0293 - acc: 0.9541 - recall_4: 0.9659 - precision_4: 0.9701 - f1_score: 0.9463 - val_loss: 0.1106 - val_acc: 0.9038 - val_recall_4: 0.9090 - val_precision_4: 0.9012 - val_f1_score: 0.8953\n",
      "Epoch 18/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0276 - acc: 0.9552 - recall_4: 0.9688 - precision_4: 0.9713 - f1_score: 0.9480\n",
      "Epoch 00018: val_f1_score improved from 0.90260 to 0.90660, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_5.h5\n",
      "290/290 [==============================] - 129s 445ms/step - loss: 0.0276 - acc: 0.9552 - recall_4: 0.9688 - precision_4: 0.9713 - f1_score: 0.9480 - val_loss: 0.1013 - val_acc: 0.9182 - val_recall_4: 0.9313 - val_precision_4: 0.9010 - val_f1_score: 0.9066\n",
      "Epoch 19/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0259 - acc: 0.9548 - recall_4: 0.9698 - precision_4: 0.9737 - f1_score: 0.9498\n",
      "Epoch 00019: val_f1_score did not improve from 0.90660\n",
      "290/290 [==============================] - 127s 440ms/step - loss: 0.0259 - acc: 0.9548 - recall_4: 0.9698 - precision_4: 0.9737 - f1_score: 0.9498 - val_loss: 0.1031 - val_acc: 0.9182 - val_recall_4: 0.9107 - val_precision_4: 0.9243 - val_f1_score: 0.9063\n",
      "Epoch 20/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0240 - acc: 0.9577 - recall_4: 0.9730 - precision_4: 0.9758 - f1_score: 0.9495\n",
      "Epoch 00020: val_f1_score did not improve from 0.90660\n",
      "290/290 [==============================] - 127s 439ms/step - loss: 0.0240 - acc: 0.9577 - recall_4: 0.9730 - precision_4: 0.9758 - f1_score: 0.9495 - val_loss: 0.1248 - val_acc: 0.9072 - val_recall_4: 0.9093 - val_precision_4: 0.9044 - val_f1_score: 0.8936\n",
      "Epoch 21/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0223 - acc: 0.9585 - recall_4: 0.9742 - precision_4: 0.9779 - f1_score: 0.9520\n",
      "Epoch 00021: val_f1_score improved from 0.90660 to 0.90710, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_5.h5\n",
      "290/290 [==============================] - 126s 435ms/step - loss: 0.0223 - acc: 0.9585 - recall_4: 0.9742 - precision_4: 0.9779 - f1_score: 0.9520 - val_loss: 0.1088 - val_acc: 0.9172 - val_recall_4: 0.9143 - val_precision_4: 0.9154 - val_f1_score: 0.9071\n",
      "Epoch 22/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0225 - acc: 0.9595 - recall_4: 0.9755 - precision_4: 0.9778 - f1_score: 0.9516\n",
      "Epoch 00022: val_f1_score did not improve from 0.90710\n",
      "290/290 [==============================] - 127s 437ms/step - loss: 0.0225 - acc: 0.9595 - recall_4: 0.9755 - precision_4: 0.9778 - f1_score: 0.9516 - val_loss: 0.1202 - val_acc: 0.9172 - val_recall_4: 0.9134 - val_precision_4: 0.9120 - val_f1_score: 0.9024\n",
      "Epoch 23/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0195 - acc: 0.9592 - recall_4: 0.9770 - precision_4: 0.9802 - f1_score: 0.9540\n",
      "Epoch 00023: val_f1_score did not improve from 0.90710\n",
      "290/290 [==============================] - 124s 429ms/step - loss: 0.0195 - acc: 0.9592 - recall_4: 0.9770 - precision_4: 0.9802 - f1_score: 0.9540 - val_loss: 0.1251 - val_acc: 0.9082 - val_recall_4: 0.9075 - val_precision_4: 0.9167 - val_f1_score: 0.9001\n",
      "Epoch 24/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0210 - acc: 0.9585 - recall_4: 0.9763 - precision_4: 0.9773 - f1_score: 0.9515\n",
      "Epoch 00024: val_f1_score did not improve from 0.90710\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0002560000168159604.\n",
      "290/290 [==============================] - 127s 437ms/step - loss: 0.0210 - acc: 0.9585 - recall_4: 0.9763 - precision_4: 0.9773 - f1_score: 0.9515 - val_loss: 0.1376 - val_acc: 0.9082 - val_recall_4: 0.9075 - val_precision_4: 0.9063 - val_f1_score: 0.8952\n",
      "Epoch 25/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0192 - acc: 0.9603 - recall_4: 0.9789 - precision_4: 0.9803 - f1_score: 0.9539\n",
      "Epoch 00025: val_f1_score did not improve from 0.90710\n",
      "290/290 [==============================] - 126s 434ms/step - loss: 0.0192 - acc: 0.9603 - recall_4: 0.9789 - precision_4: 0.9803 - f1_score: 0.9539 - val_loss: 0.1153 - val_acc: 0.9162 - val_recall_4: 0.9166 - val_precision_4: 0.9187 - val_f1_score: 0.9047\n",
      "Epoch 26/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0145 - acc: 0.9675 - recall_4: 0.9844 - precision_4: 0.9848 - f1_score: 0.9597\n",
      "Epoch 00026: val_f1_score did not improve from 0.90710\n",
      "290/290 [==============================] - 127s 439ms/step - loss: 0.0145 - acc: 0.9675 - recall_4: 0.9844 - precision_4: 0.9848 - f1_score: 0.9597 - val_loss: 0.1275 - val_acc: 0.9177 - val_recall_4: 0.9240 - val_precision_4: 0.9082 - val_f1_score: 0.9069\n",
      "Epoch 27/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0146 - acc: 0.9650 - recall_4: 0.9838 - precision_4: 0.9844 - f1_score: 0.9592\n",
      "Epoch 00027: val_f1_score did not improve from 0.90710\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.00020480002276599408.\n",
      "290/290 [==============================] - 127s 436ms/step - loss: 0.0146 - acc: 0.9650 - recall_4: 0.9838 - precision_4: 0.9844 - f1_score: 0.9592 - val_loss: 0.1216 - val_acc: 0.9189 - val_recall_4: 0.9226 - val_precision_4: 0.9113 - val_f1_score: 0.9062\n",
      "Epoch 28/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0134 - acc: 0.9680 - recall_4: 0.9851 - precision_4: 0.9862 - f1_score: 0.9615\n",
      "Epoch 00028: val_f1_score did not improve from 0.90710\n",
      "290/290 [==============================] - 126s 436ms/step - loss: 0.0134 - acc: 0.9680 - recall_4: 0.9851 - precision_4: 0.9862 - f1_score: 0.9615 - val_loss: 0.1224 - val_acc: 0.9162 - val_recall_4: 0.9189 - val_precision_4: 0.9112 - val_f1_score: 0.9067\n",
      "Epoch 29/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0105 - acc: 0.9694 - recall_4: 0.9879 - precision_4: 0.9883 - f1_score: 0.9655\n",
      "Epoch 00029: val_f1_score improved from 0.90710 to 0.90846, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_5.h5\n",
      "290/290 [==============================] - 128s 443ms/step - loss: 0.0105 - acc: 0.9694 - recall_4: 0.9879 - precision_4: 0.9883 - f1_score: 0.9655 - val_loss: 0.1350 - val_acc: 0.9214 - val_recall_4: 0.9134 - val_precision_4: 0.9240 - val_f1_score: 0.9085\n",
      "Epoch 30/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0112 - acc: 0.9661 - recall_4: 0.9870 - precision_4: 0.9880 - f1_score: 0.9630\n",
      "Epoch 00030: val_f1_score improved from 0.90846 to 0.90976, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_5.h5\n",
      "290/290 [==============================] - 129s 445ms/step - loss: 0.0112 - acc: 0.9661 - recall_4: 0.9870 - precision_4: 0.9880 - f1_score: 0.9630 - val_loss: 0.1278 - val_acc: 0.9239 - val_recall_4: 0.9157 - val_precision_4: 0.9242 - val_f1_score: 0.9098\n",
      "Epoch 31/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0101 - acc: 0.9696 - recall_4: 0.9899 - precision_4: 0.9886 - f1_score: 0.9631\n",
      "Epoch 00031: val_f1_score did not improve from 0.90976\n",
      "290/290 [==============================] - 127s 437ms/step - loss: 0.0101 - acc: 0.9696 - recall_4: 0.9899 - precision_4: 0.9886 - f1_score: 0.9631 - val_loss: 0.1355 - val_acc: 0.9162 - val_recall_4: 0.9070 - val_precision_4: 0.9148 - val_f1_score: 0.9004\n",
      "Epoch 32/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0113 - acc: 0.9668 - recall_4: 0.9875 - precision_4: 0.9877 - f1_score: 0.9632\n",
      "Epoch 00032: val_f1_score did not improve from 0.90976\n",
      "290/290 [==============================] - 129s 446ms/step - loss: 0.0113 - acc: 0.9668 - recall_4: 0.9875 - precision_4: 0.9877 - f1_score: 0.9632 - val_loss: 0.1310 - val_acc: 0.9162 - val_recall_4: 0.9130 - val_precision_4: 0.9206 - val_f1_score: 0.9037\n",
      "Epoch 33/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0098 - acc: 0.9700 - recall_4: 0.9887 - precision_4: 0.9891 - f1_score: 0.9635\n",
      "Epoch 00033: val_f1_score did not improve from 0.90976\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.00016384001355618238.\n",
      "290/290 [==============================] - 125s 431ms/step - loss: 0.0098 - acc: 0.9700 - recall_4: 0.9887 - precision_4: 0.9891 - f1_score: 0.9635 - val_loss: 0.1446 - val_acc: 0.9177 - val_recall_4: 0.9072 - val_precision_4: 0.9227 - val_f1_score: 0.9031\n",
      "Epoch 34/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0080 - acc: 0.9721 - recall_4: 0.9906 - precision_4: 0.9913 - f1_score: 0.9690\n",
      "Epoch 00034: val_f1_score did not improve from 0.90976\n",
      "290/290 [==============================] - 128s 441ms/step - loss: 0.0080 - acc: 0.9721 - recall_4: 0.9906 - precision_4: 0.9913 - f1_score: 0.9690 - val_loss: 0.1421 - val_acc: 0.9187 - val_recall_4: 0.9184 - val_precision_4: 0.9138 - val_f1_score: 0.9085\n",
      "Epoch 35/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0084 - acc: 0.9735 - recall_4: 0.9903 - precision_4: 0.9915 - f1_score: 0.9675\n",
      "Epoch 00035: val_f1_score did not improve from 0.90976\n",
      "290/290 [==============================] - 127s 437ms/step - loss: 0.0084 - acc: 0.9735 - recall_4: 0.9903 - precision_4: 0.9915 - f1_score: 0.9675 - val_loss: 0.1360 - val_acc: 0.9182 - val_recall_4: 0.9122 - val_precision_4: 0.9224 - val_f1_score: 0.9096\n",
      "Epoch 36/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0082 - acc: 0.9688 - recall_4: 0.9899 - precision_4: 0.9910 - f1_score: 0.9684\n",
      "Epoch 00036: val_f1_score did not improve from 0.90976\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.0001310720108449459.\n",
      "290/290 [==============================] - 128s 442ms/step - loss: 0.0082 - acc: 0.9688 - recall_4: 0.9899 - precision_4: 0.9910 - f1_score: 0.9684 - val_loss: 0.1457 - val_acc: 0.9221 - val_recall_4: 0.9100 - val_precision_4: 0.9199 - val_f1_score: 0.9091\n",
      "Epoch 37/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0076 - acc: 0.9717 - recall_4: 0.9911 - precision_4: 0.9907 - f1_score: 0.9682\n",
      "Epoch 00037: val_f1_score improved from 0.90976 to 0.91041, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_5.h5\n",
      "290/290 [==============================] - 128s 443ms/step - loss: 0.0076 - acc: 0.9717 - recall_4: 0.9911 - precision_4: 0.9907 - f1_score: 0.9682 - val_loss: 0.1317 - val_acc: 0.9226 - val_recall_4: 0.9163 - val_precision_4: 0.9250 - val_f1_score: 0.9104\n",
      "Epoch 38/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0057 - acc: 0.9733 - recall_4: 0.9939 - precision_4: 0.9939 - f1_score: 0.9724\n",
      "Epoch 00038: val_f1_score improved from 0.91041 to 0.91344, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_5.h5\n",
      "290/290 [==============================] - 130s 448ms/step - loss: 0.0057 - acc: 0.9733 - recall_4: 0.9939 - precision_4: 0.9939 - f1_score: 0.9724 - val_loss: 0.1522 - val_acc: 0.9229 - val_recall_4: 0.9155 - val_precision_4: 0.9246 - val_f1_score: 0.9134\n",
      "Epoch 39/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0066 - acc: 0.9729 - recall_4: 0.9916 - precision_4: 0.9922 - f1_score: 0.9735\n",
      "Epoch 00039: val_f1_score improved from 0.91344 to 0.91497, saving model to /app/_data/models/final/with_dup/eff4_ns_0891_kf_dup_5.h5\n",
      "290/290 [==============================] - 130s 447ms/step - loss: 0.0066 - acc: 0.9729 - recall_4: 0.9916 - precision_4: 0.9922 - f1_score: 0.9735 - val_loss: 0.1430 - val_acc: 0.9246 - val_recall_4: 0.9161 - val_precision_4: 0.9255 - val_f1_score: 0.9150\n",
      "Epoch 40/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0053 - acc: 0.9759 - recall_4: 0.9933 - precision_4: 0.9937 - f1_score: 0.9749\n",
      "Epoch 00040: val_f1_score did not improve from 0.91497\n",
      "290/290 [==============================] - 129s 446ms/step - loss: 0.0053 - acc: 0.9759 - recall_4: 0.9933 - precision_4: 0.9937 - f1_score: 0.9749 - val_loss: 0.1502 - val_acc: 0.9206 - val_recall_4: 0.9159 - val_precision_4: 0.9189 - val_f1_score: 0.9106\n",
      "Epoch 41/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0060 - acc: 0.9728 - recall_4: 0.9930 - precision_4: 0.9930 - f1_score: 0.9737\n",
      "Epoch 00041: val_f1_score did not improve from 0.91497\n",
      "290/290 [==============================] - 127s 439ms/step - loss: 0.0060 - acc: 0.9728 - recall_4: 0.9930 - precision_4: 0.9930 - f1_score: 0.9737 - val_loss: 0.1571 - val_acc: 0.9214 - val_recall_4: 0.9098 - val_precision_4: 0.9281 - val_f1_score: 0.9123\n",
      "Epoch 42/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0069 - acc: 0.9729 - recall_4: 0.9912 - precision_4: 0.9922 - f1_score: 0.9730\n",
      "Epoch 00042: val_f1_score did not improve from 0.91497\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.00010485760867595673.\n",
      "290/290 [==============================] - 125s 430ms/step - loss: 0.0069 - acc: 0.9729 - recall_4: 0.9912 - precision_4: 0.9922 - f1_score: 0.9730 - val_loss: 0.1434 - val_acc: 0.9221 - val_recall_4: 0.9166 - val_precision_4: 0.9220 - val_f1_score: 0.9102\n",
      "Epoch 43/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0050 - acc: 0.9734 - recall_4: 0.9939 - precision_4: 0.9929 - f1_score: 0.9729\n",
      "Epoch 00043: val_f1_score did not improve from 0.91497\n",
      "290/290 [==============================] - 128s 442ms/step - loss: 0.0050 - acc: 0.9734 - recall_4: 0.9939 - precision_4: 0.9929 - f1_score: 0.9729 - val_loss: 0.1536 - val_acc: 0.9229 - val_recall_4: 0.9150 - val_precision_4: 0.9297 - val_f1_score: 0.9109\n",
      "Epoch 44/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0047 - acc: 0.9762 - recall_4: 0.9948 - precision_4: 0.9943 - f1_score: 0.9757\n",
      "Epoch 00044: val_f1_score did not improve from 0.91497\n",
      "290/290 [==============================] - 128s 441ms/step - loss: 0.0047 - acc: 0.9762 - recall_4: 0.9948 - precision_4: 0.9943 - f1_score: 0.9757 - val_loss: 0.1658 - val_acc: 0.9266 - val_recall_4: 0.9201 - val_precision_4: 0.9241 - val_f1_score: 0.9148\n",
      "Epoch 45/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0043 - acc: 0.9792 - recall_4: 0.9944 - precision_4: 0.9948 - f1_score: 0.9809\n",
      "Epoch 00045: val_f1_score did not improve from 0.91497\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 8.388608694076538e-05.\n",
      "290/290 [==============================] - 126s 434ms/step - loss: 0.0043 - acc: 0.9792 - recall_4: 0.9944 - precision_4: 0.9948 - f1_score: 0.9809 - val_loss: 0.1753 - val_acc: 0.9204 - val_recall_4: 0.9175 - val_precision_4: 0.9164 - val_f1_score: 0.9111\n",
      "Epoch 46/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0053 - acc: 0.9794 - recall_4: 0.9940 - precision_4: 0.9939 - f1_score: 0.9787\n",
      "Epoch 00046: val_f1_score did not improve from 0.91497\n",
      "290/290 [==============================] - 129s 444ms/step - loss: 0.0053 - acc: 0.9794 - recall_4: 0.9940 - precision_4: 0.9939 - f1_score: 0.9787 - val_loss: 0.1635 - val_acc: 0.9271 - val_recall_4: 0.9166 - val_precision_4: 0.9238 - val_f1_score: 0.9144\n",
      "Epoch 47/100\n",
      "290/290 [==============================] - ETA: 0s - loss: 0.0044 - acc: 0.9813 - recall_4: 0.9943 - precision_4: 0.9946 - f1_score: 0.9802Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00047: val_f1_score did not improve from 0.91497\n",
      "290/290 [==============================] - 129s 444ms/step - loss: 0.0044 - acc: 0.9813 - recall_4: 0.9943 - precision_4: 0.9946 - f1_score: 0.9802 - val_loss: 0.1669 - val_acc: 0.9236 - val_recall_4: 0.9171 - val_precision_4: 0.9217 - val_f1_score: 0.9120\n",
      "Epoch 00047: early stopping\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=SEED, shuffle=True)\n",
    "\n",
    "for i, (train_index, valid_index) in enumerate(\n",
    "    skf.split(df_labels[\"image\"], df_labels[\"labels\"])\n",
    "):\n",
    "    train, valid = df_labels.loc[train_index], df_labels.loc[valid_index]\n",
    "    model_name = \"eff4_ns_0891_kf_dup_\" + str(i + 1) + \".h5\"\n",
    "    log_dir = 'logs_0891_1_'+str(i + 1)+'/'\n",
    "    callbacks = [\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_f1_score\",\n",
    "            patience=8,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1,\n",
    "            mode=\"max\",\n",
    "        ),\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            \"/app/_data/models/final/with_dup/\" + model_name,\n",
    "            monitor=\"val_f1_score\",\n",
    "            verbose=1,\n",
    "            save_best_only=True,\n",
    "            save_weights_only=False,\n",
    "            mode=\"max\",\n",
    "            save_freq=\"epoch\",\n",
    "        ),\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor=\"val_f1_score\",\n",
    "            factor=0.8,\n",
    "            patience=3,\n",
    "            verbose=1,\n",
    "            mode=\"max\",\n",
    "            min_delta=1e-4,\n",
    "            min_lr=0.00000001,\n",
    "        ),\n",
    "        keras.callbacks.TensorBoard(\n",
    "            log_dir=\"/app/.tensorboard/\"+log_dir, histogram_freq=0\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    gen_train = Generator(\n",
    "        df=train,\n",
    "        images_src_dir=TRAIN_IMG_PATH,\n",
    "        target_image_size=IMAGE_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        augment=True,\n",
    "        crop=False,\n",
    "        resize=False,\n",
    "    )\n",
    "    gen_valid = Generator(\n",
    "        df=valid,\n",
    "        images_src_dir=TRAIN_IMG_PATH,\n",
    "        target_image_size=IMAGE_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        augment=False,\n",
    "        crop=False,\n",
    "        resize=False,\n",
    "    )\n",
    "    model = get_model()\n",
    "    history = model.fit(\n",
    "        gen_train,\n",
    "        validation_data=gen_valid,\n",
    "        epochs=100,\n",
    "        steps_per_epoch=train.shape[0]//BATCH_SIZE,\n",
    "        validation_steps=valid.shape[0]//BATCH_SIZE,\n",
    "        verbose=1,\n",
    "        workers = 15,\n",
    "        callbacks=callbacks,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices(\"GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_all(file_path):\n",
    "    img = tf.io.read_file(TRAIN_IMG_PATH + file_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    return img\n",
    "\n",
    "\n",
    "def predict_new(path, model):\n",
    "    img = parse_all(path)\n",
    "    img = tf.expand_dims(img, axis=0)\n",
    "    pred = model.predict(img)\n",
    "    return pred_to_labels(pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  image                   labels\n",
      "0  bfc6d90f402f4c34.jpg  frog_eye_leaf_spot scab\n",
      "1  9eb93fe282326266.jpg           powdery_mildew\n",
      "2  f4cb3a8f41b413e4.jpg       frog_eye_leaf_spot\n",
      "3  98322eab16bef2c1.jpg                     rust\n",
      "4  dad5d6250cae80b7.jpg                  complex\n"
     ]
    }
   ],
   "source": [
    "df_sub = pd.DataFrame(columns=[\"image\", \"labels\"])\n",
    "for img_name in os.listdir(TRAIN_IMG_PATH):\n",
    "    pred = predict_new(img_name, model)\n",
    "\n",
    "    df_sub = df_sub.append({\"image\": img_name, \"labels\": pred}, ignore_index=True)\n",
    "\n",
    "print(df_sub.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = df_sub.merge(\n",
    "    labels_21_20[[\"image\", \"labels\"]],\n",
    "    on=\"image\",\n",
    "    how=\"left\",\n",
    "    suffixes=(\"_pred\", \"_true\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.to_csv(\"/app/sandbox/wrong_predictions/eff4/eff4_ns_cropped_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "complex                    22\n",
       "scab                       10\n",
       "rust                        7\n",
       "frog_eye_leaf_spot          5\n",
       "scab frog_eye_leaf_spot     1\n",
       "rust frog_eye_leaf_spot     1\n",
       "powdery_mildew complex      1\n",
       "powdery_mildew              1\n",
       "healthy                     1\n",
       "Name: labels_true, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub[df_sub[\"labels_pred\"] == \"\"][\"labels_true\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scab frog_eye_leaf_spot            682\n",
       "complex                            438\n",
       "scab frog_eye_leaf_spot complex    200\n",
       "frog_eye_leaf_spot complex         165\n",
       "scab                               124\n",
       "rust frog_eye_leaf_spot            118\n",
       "rust complex                        91\n",
       "powdery_mildew complex              87\n",
       "rust                                74\n",
       "frog_eye_leaf_spot                  71\n",
       "healthy                             19\n",
       "powdery_mildew                       7\n",
       "Name: labels_true, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub[df_sub[\"labels_pred\"] != df_sub[\"labels_true\"]][\"labels_true\"].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
