{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /app/kaggle.json'\n"
     ]
    }
   ],
   "source": [
    "import kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /app/kaggle.json'\n",
      "Data package template written to: /app/_data/models/final/eff7_0891/dataset-metadata.json\n"
     ]
    }
   ],
   "source": [
    "! kaggle datasets init -p /app/_data/models/final/eff7_0891/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /app/kaggle.json'\n",
      "Starting upload for file eff7_0891_1.h5\n",
      "100%|█████████████████████████████████████████| 734M/734M [36:00<00:00, 356kB/s]\n",
      "Upload successful: eff7_0891_1.h5 (734MB)\n",
      "Starting upload for file eff7_0891_4.h5\n",
      "100%|█████████████████████████████████████████| 734M/734M [27:00<00:00, 475kB/s]\n",
      "Upload successful: eff7_0891_4.h5 (734MB)\n",
      "Starting upload for file eff7_0891_2.h5\n",
      "100%|█████████████████████████████████████████| 734M/734M [18:28<00:00, 694kB/s]\n",
      "Upload successful: eff7_0891_2.h5 (734MB)\n",
      "Skipping folder: .ipynb_checkpoints; use '--dir-mode' to upload folders\n",
      "Starting upload for file eff7_0891_5.h5\n",
      "100%|█████████████████████████████████████████| 734M/734M [18:25<00:00, 696kB/s]\n",
      "Upload successful: eff7_0891_5.h5 (734MB)\n",
      "Starting upload for file eff7_0891_3.h5\n",
      "100%|█████████████████████████████████████████| 734M/734M [18:27<00:00, 695kB/s]\n",
      "Upload successful: eff7_0891_3.h5 (734MB)\n",
      "Your private Dataset is being created. Please check progress at https://www.kaggle.com/nataliayurasova/eff7Crop\n"
     ]
    }
   ],
   "source": [
    "! kaggle datasets create -p /app/_data/models/final/eff7_0891"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.891\n",
    "MODEL_BB_PATH= '../input/model-bb-1/bond_box_999_200.h5'\n",
    "MODEL_PATH = '../input/0865fulltrain/'\n",
    "IMAGE_SIZE = (380, 380)\n",
    "DF_PART = '../input/df-kf-plant/df_kf.csv'\n",
    "PATH = \"/kaggle/input/plant-pathology-2021-fgvc8/\"\n",
    "TRAIN_IMG_PATH = PATH+'train_images/'\n",
    "TEST_IMG_PATH = PATH+'test_images/'\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES=6\n",
    "SEED = 1488\n",
    "- replace ''-'scab'\n",
    "https://www.kaggle.com/nataliayurasova/plant-pathology0891/edit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting albumentations\n",
      "  Downloading albumentations-0.5.2-py3-none-any.whl (72 kB)\n",
      "\u001b[K     |████████████████████████████████| 72 kB 504 kB/s eta 0:00:011\n",
      "\u001b[?25hCollecting opencv-python-headless>=4.1.1\n",
      "  Downloading opencv_python_headless-4.5.1.48-cp38-cp38-manylinux2014_x86_64.whl (37.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 37.6 MB 12.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scikit-image>=0.16.1\n",
      "  Downloading scikit_image-0.18.1-cp38-cp38-manylinux1_x86_64.whl (30.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 30.2 MB 13.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from albumentations) (1.4.1)\n",
      "Collecting imgaug>=0.4.0\n",
      "  Downloading imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n",
      "\u001b[K     |████████████████████████████████| 948 kB 25.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.8/dist-packages (from albumentations) (1.17.3)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from albumentations) (5.3.1)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from imgaug>=0.4.0->albumentations) (8.1.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from imgaug>=0.4.0->albumentations) (1.15.0)\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.5.1.48-cp38-cp38-manylinux2014_x86_64.whl (50.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 50.4 MB 14.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting Shapely\n",
      "  Downloading Shapely-1.7.1-cp38-cp38-manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 19.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting imageio\n",
      "  Downloading imageio-2.9.0-py3-none-any.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 38.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from imgaug>=0.4.0->albumentations) (3.3.4)\n",
      "Collecting tifffile>=2019.7.26\n",
      "  Downloading tifffile-2021.4.8-py3-none-any.whl (165 kB)\n",
      "\u001b[K     |████████████████████████████████| 165 kB 18.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting PyWavelets>=1.1.1\n",
      "  Downloading PyWavelets-1.1.1-cp38-cp38-manylinux1_x86_64.whl (4.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.4 MB 31.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting networkx>=2.0\n",
      "  Downloading networkx-2.5.1-py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 19.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations) (2.8.1)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.8/dist-packages (from networkx>=2.0->scikit-image>=0.16.1->albumentations) (4.4.2)\n",
      "Installing collected packages: tifffile, PyWavelets, networkx, imageio, Shapely, scikit-image, opencv-python, opencv-python-headless, imgaug, albumentations\n",
      "Successfully installed PyWavelets-1.1.1 Shapely-1.7.1 albumentations-0.5.2 imageio-2.9.0 imgaug-0.4.0 networkx-2.5.1 opencv-python-4.5.1.48 opencv-python-headless-4.5.1.48 scikit-image-0.18.1 tifffile-2021.4.8\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install albumentations\n",
    "import albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import (\n",
    "    StratifiedKFold,\n",
    "    StratifiedShuffleSplit,\n",
    "    train_test_split,\n",
    ")\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB4, EfficientNetB7\n",
    "from tensorflow.keras.layers import (\n",
    "    AveragePooling2D,\n",
    "    AvgPool2D,\n",
    "    Conv2D,\n",
    "    Dense,\n",
    "    Flatten,\n",
    "    GlobalAveragePooling2D,\n",
    "    MaxPooling2D,\n",
    ")\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tqdm import notebook, tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/app/_data/\"\n",
    "BATCH_SIZE = 8\n",
    "SEED = 42\n",
    "IMAGE_SIZE = 600\n",
    "NUM_CLASSES = 6\n",
    "TRAIN_IMG_PATH = \"/app/_data/600_npy/\"\n",
    "TEST_IMG_PATH = \"/app/_data/test_images/\"\n",
    "feature_columns = [\n",
    "    \"complex\",\n",
    "    \"frog_eye_leaf_spot\",\n",
    "    \"healthy\",\n",
    "    \"powdery_mildew\",\n",
    "    \"rust\",\n",
    "    \"scab\",\n",
    "]\n",
    "wrong = ['ead085dfac287263.jpg', '95276ccd226ad933.jpg',\"da8770e819d2696d.jpg\", 'cd3a1d64e6806eb5.jpg', 'ccec54723ff91860.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f8228796cfdae848.npy'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(TRAIN_IMG_PATH)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 600, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.load(TRAIN_IMG_PATH+os.listdir(TRAIN_IMG_PATH)[0])\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = pd.read_csv(\"../_data/df_csv/labels_21_20.csv\", index_col=[0])\n",
    "df_labels = df_labels.query('image not in @wrong').reset_index(drop=True)\n",
    "df_labels[\"image\"] = df_labels[\"image\"].str.replace(\".jpg\", \".npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = df_labels.sample(frac=1, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20225, 8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complex</th>\n",
       "      <th>frog_eye_leaf_spot</th>\n",
       "      <th>healthy</th>\n",
       "      <th>powdery_mildew</th>\n",
       "      <th>rust</th>\n",
       "      <th>scab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20225.000000</td>\n",
       "      <td>20225.000000</td>\n",
       "      <td>20225.000000</td>\n",
       "      <td>20225.000000</td>\n",
       "      <td>20225.000000</td>\n",
       "      <td>20225.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.104821</td>\n",
       "      <td>0.214487</td>\n",
       "      <td>0.253103</td>\n",
       "      <td>0.062645</td>\n",
       "      <td>0.130680</td>\n",
       "      <td>0.310556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.306330</td>\n",
       "      <td>0.410476</td>\n",
       "      <td>0.434800</td>\n",
       "      <td>0.242330</td>\n",
       "      <td>0.337058</td>\n",
       "      <td>0.462733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            complex  frog_eye_leaf_spot       healthy  powdery_mildew  \\\n",
       "count  20225.000000        20225.000000  20225.000000    20225.000000   \n",
       "mean       0.104821            0.214487      0.253103        0.062645   \n",
       "std        0.306330            0.410476      0.434800        0.242330   \n",
       "min        0.000000            0.000000      0.000000        0.000000   \n",
       "25%        0.000000            0.000000      0.000000        0.000000   \n",
       "50%        0.000000            0.000000      0.000000        0.000000   \n",
       "75%        0.000000            0.000000      1.000000        0.000000   \n",
       "max        1.000000            1.000000      1.000000        1.000000   \n",
       "\n",
       "               rust          scab  \n",
       "count  20225.000000  20225.000000  \n",
       "mean       0.130680      0.310556  \n",
       "std        0.337058      0.462733  \n",
       "min        0.000000      0.000000  \n",
       "25%        0.000000      0.000000  \n",
       "50%        0.000000      0.000000  \n",
       "75%        0.000000      1.000000  \n",
       "max        1.000000      1.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels[feature_columns].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = labels_21_20.copy()\n",
    "# sss = StratifiedShuffleSplit(n_splits=1, test_size=0.07, random_state=SEED)\n",
    "\n",
    "# for train_index, valid_index in sss.split(df[\"image\"], df[\"labels\"]):\n",
    "#     train, valid = df.loc[train_index], df.loc[valid_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 380*380\n",
    "transform = albumentations.Compose(\n",
    "    [\n",
    "        albumentations.CLAHE(p=0.1, clip_limit=(1, 2), tile_grid_size=(8, 8)),\n",
    "        albumentations.OneOf(\n",
    "            [\n",
    "                albumentations.MotionBlur((3, 3)),\n",
    "                albumentations.MedianBlur(blur_limit=3),\n",
    "                albumentations.GaussianBlur(blur_limit=(3, 3), sigma_limit=0),\n",
    "                albumentations.Blur(blur_limit=(3, 3)),\n",
    "            ],\n",
    "            p=0.2,\n",
    "        ),\n",
    "        albumentations.OneOf(\n",
    "            [\n",
    "                albumentations.GaussNoise(var_limit=[10, 50], mean=1),\n",
    "                albumentations.ISONoise(intensity=(0.1, 1), color_shift=(0.01, 0.05)),\n",
    "                albumentations.ImageCompression(\n",
    "                    quality_lower=70, quality_upper=100, compression_type=1\n",
    "                ),\n",
    "                albumentations.MultiplicativeNoise(\n",
    "                    multiplier=(0.95, 1.05), per_channel=True, elementwise=True\n",
    "                ),\n",
    "                albumentations.Downscale(\n",
    "                    scale_min=0.6, scale_max=0.99, interpolation=4\n",
    "                ),\n",
    "            ],\n",
    "            p=0.5,\n",
    "        ),\n",
    "        albumentations.OneOf(\n",
    "            [\n",
    "                albumentations.HueSaturationValue(\n",
    "                    hue_shift_limit=(-7, 7),\n",
    "                    sat_shift_limit=(-10, 10),\n",
    "                    val_shift_limit=(-10, 10),\n",
    "                ),\n",
    "                albumentations.RandomBrightnessContrast(\n",
    "                    brightness_limit=0.15,\n",
    "                    contrast_limit=0.2,\n",
    "                    brightness_by_max=True,\n",
    "                ),\n",
    "            ],\n",
    "            p=0.5,\n",
    "        ),\n",
    "        albumentations.OneOf(\n",
    "            [\n",
    "                albumentations.OpticalDistortion(\n",
    "                    distort_limit=0.05,\n",
    "                    shift_limit=0.05,\n",
    "                    border_mode=2,\n",
    "                ),\n",
    "                albumentations.ElasticTransform(\n",
    "                    alpha=2.0,\n",
    "                    sigma=50.0,\n",
    "                    alpha_affine=10.0,\n",
    "                    interpolation=0,\n",
    "                    border_mode=2,\n",
    "                ),\n",
    "                albumentations.GridDistortion(\n",
    "                    num_steps=5, distort_limit=0.3, interpolation=0, border_mode=2\n",
    "                ),\n",
    "            ],\n",
    "            p=0.5,\n",
    "        ),\n",
    "        albumentations.OneOf(\n",
    "            [\n",
    "                albumentations.HorizontalFlip(),\n",
    "                albumentations.VerticalFlip(),\n",
    "            ],\n",
    "            p=0.5,\n",
    "        ),\n",
    "        albumentations.OneOf(\n",
    "            [\n",
    "                albumentations.Rotate(\n",
    "                    limit=(-180, 180), interpolation=0, border_mode=2\n",
    "                ),\n",
    "                albumentations.ShiftScaleRotate(\n",
    "                    shift_limit=0.05,\n",
    "                    scale_limit=0.05,\n",
    "                    rotate_limit=180,\n",
    "                    interpolation=0,\n",
    "                    border_mode=2,\n",
    "                ),\n",
    "            ],\n",
    "            p=0.5,\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(keras.utils.Sequence):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        images_src_dir,\n",
    "        batch_size,\n",
    "        target_image_size,\n",
    "        shuffle=False,\n",
    "        augment=True,\n",
    "        crop=False,\n",
    "        resize=False,\n",
    "        normalize=False,\n",
    "    ):\n",
    "        self.shuffle = shuffle\n",
    "        self.batch_size = BATCH_SIZE\n",
    "        self.df = df\n",
    "        self.images_dir = images_src_dir\n",
    "        self.target_image_size = (IMAGE_SIZE, IMAGE_SIZE)\n",
    "        self.augment = augment\n",
    "        self.crop = crop\n",
    "        self.resize = resize\n",
    "        self.normalize = normalize\n",
    "        # create label index map\n",
    "        self.labels = self._read_labels()\n",
    "        self.n_samples = self.df.shape[0]\n",
    "        self.n_batches = self.n_samples // self.batch_size\n",
    "        # shuffle data, also repeated after each epoch if needed\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.labels)\n",
    "\n",
    "    def _read_labels(self):\n",
    "        \"\"\"\n",
    "        Returns list images mapping to 1-hot label\n",
    "        \"\"\"\n",
    "\n",
    "        # label indexes\n",
    "        label_ixs = self.df[feature_columns].values\n",
    "        image_ixs = self.df[\"image\"].values\n",
    "        labels = []\n",
    "\n",
    "        for i in range(len(image_ixs)):\n",
    "            labels.append([image_ixs[i], label_ixs[i]])\n",
    "        return labels\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Length in batches\n",
    "        \"\"\"\n",
    "        return self.n_batches\n",
    "\n",
    "    def __getitem__(self, b_ix):\n",
    "        \"\"\"\n",
    "        Produce batch, by batch index\n",
    "        \"\"\"\n",
    "\n",
    "        assert b_ix < self.n_batches\n",
    "\n",
    "        b_X = np.zeros(\n",
    "            (self.batch_size, self.target_image_size[0], self.target_image_size[1], 3),\n",
    "            dtype=np.uint8,\n",
    "        )\n",
    "\n",
    "        b_Y = np.zeros(\n",
    "            (self.batch_size, self.df[feature_columns].shape[1]),\n",
    "            dtype=np.uint8,\n",
    "        )\n",
    "\n",
    "        for i in range(self.batch_size):\n",
    "            b_X[i], b_Y[i] = self.get_one(\n",
    "                i + self.batch_size * b_ix,\n",
    "            )\n",
    "\n",
    "        return (b_X, b_Y)\n",
    "\n",
    "    def get_one(self, one_ix):\n",
    "        \"\"\"\n",
    "        Get single item by absolute index\n",
    "        \"\"\"\n",
    "        id = self.labels[one_ix][0]\n",
    "        src_file = self.images_dir + id\n",
    "\n",
    "        # read file\n",
    "        x = np.load(src_file)\n",
    "        if self.crop:\n",
    "            coord = self.df[self.df[\"image\"] == id][\n",
    "                [\"x_min\", \"y_min\", \"x_max\", \"y_max\"]\n",
    "            ].values[0]\n",
    "            orig_hight = x.shape[0]\n",
    "            orig_width = x.shape[1]\n",
    "            x_min = coord[0]\n",
    "            y_min = coord[1]\n",
    "            x_max = coord[2]\n",
    "            y_max = coord[3]\n",
    "            x = x[\n",
    "                np.int(y_min * orig_hight) : np.int(y_max * orig_hight),\n",
    "                np.int(x_min * orig_width) : np.int(x_max * orig_width),\n",
    "            ]\n",
    "\n",
    "        y = self.labels[one_ix][1]\n",
    "\n",
    "        # augment\n",
    "        if self.augment:\n",
    "            x = self._augment_image(x)\n",
    "\n",
    "        # normalize (sample-wise)\n",
    "        if self.normalize:\n",
    "            x = x.astype(np.float32)\n",
    "            x = x - np.mean(x, axis=(0, 1))\n",
    "            x = x / np.std(x, axis=(0, 1))\n",
    "        return x.astype(np.uint8), y\n",
    "\n",
    "    def _augment_image(self, x):\n",
    "        \"\"\"\n",
    "        Randomply augment image\n",
    "        \"\"\"\n",
    "\n",
    "        x = transform(image=x)[\"image\"]\n",
    "        return x\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3090, compute capability 8.6\n"
     ]
    }
   ],
   "source": [
    "policy = keras.mixed_precision.experimental.Policy(\"mixed_float16\")\n",
    "keras.mixed_precision.experimental.set_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    inputs = keras.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "    base_model = keras.applications.EfficientNetB7(weights=None, include_top=False)\n",
    "    base_model.load_weights(\n",
    "        \"/app/_data/models/efficientnet-b7_noisy-student_notop.h5\",\n",
    "        by_name=True,\n",
    "        skip_mismatch=True,\n",
    "    )\n",
    "    x = base_model(inputs)\n",
    "    x = keras.layers.GlobalAveragePooling2D(name=\"avg_pool\")(x)\n",
    "    x = keras.layers.Flatten(name=\"flatten\")(x)\n",
    "    outputs = keras.layers.Dense(NUM_CLASSES, activation=\"sigmoid\")(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=Adam(lr=0.0005),\n",
    "        metrics=[\n",
    "            \"acc\",\n",
    "            keras.metrics.Recall(),\n",
    "            keras.metrics.Precision(),\n",
    "            tfa.metrics.F1Score(num_classes=NUM_CLASSES, average=\"weighted\"),\n",
    "        ],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50\n",
      "   1/2696 [..............................] - ETA: 0s - loss: 0.0972 - acc: 0.8333 - recall: 0.8333 - precision: 0.7143 - f1_score: 0.8889WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "   2/2696 [..............................] - ETA: 1:16:02 - loss: 0.1183 - acc: 0.7500 - recall: 0.8462 - precision: 0.7857 - f1_score: 0.7846WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 1.3264s vs `on_train_batch_end` time: 2.0593s). Check your callbacks.\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0856 - acc: 0.9074 - recall: 0.8944 - precision: 0.9149 - f1_score: 0.8946\n",
      "Epoch 00011: val_f1_score improved from -inf to 0.89309, saving model to /app/_data/models/final/eff7_0891/eff7_0891_4.h5\n",
      "2696/2696 [==============================] - 1537s 570ms/step - loss: 0.0856 - acc: 0.9074 - recall: 0.8944 - precision: 0.9149 - f1_score: 0.8946 - val_loss: 0.0956 - val_acc: 0.9073 - val_recall: 0.8832 - val_precision: 0.9187 - val_f1_score: 0.8931\n",
      "Epoch 12/50\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0819 - acc: 0.9070 - recall: 0.8973 - precision: 0.9163 - f1_score: 0.8955\n",
      "Epoch 00012: val_f1_score improved from 0.89309 to 0.90195, saving model to /app/_data/models/final/eff7_0891/eff7_0891_4.h5\n",
      "2696/2696 [==============================] - 1566s 581ms/step - loss: 0.0819 - acc: 0.9070 - recall: 0.8973 - precision: 0.9163 - f1_score: 0.8955 - val_loss: 0.0838 - val_acc: 0.9169 - val_recall: 0.9218 - val_precision: 0.8979 - val_f1_score: 0.9019\n",
      "Epoch 13/50\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0815 - acc: 0.9096 - recall: 0.9006 - precision: 0.9184 - f1_score: 0.8981\n",
      "Epoch 00013: val_f1_score improved from 0.90195 to 0.90243, saving model to /app/_data/models/final/eff7_0891/eff7_0891_4.h5\n",
      "2696/2696 [==============================] - 2057s 763ms/step - loss: 0.0815 - acc: 0.9096 - recall: 0.9006 - precision: 0.9184 - f1_score: 0.8981 - val_loss: 0.0881 - val_acc: 0.9206 - val_recall: 0.8975 - val_precision: 0.9249 - val_f1_score: 0.9024\n",
      "Epoch 14/50\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0779 - acc: 0.9131 - recall: 0.9023 - precision: 0.9210 - f1_score: 0.9023\n",
      "Epoch 00014: val_f1_score did not improve from 0.90243\n",
      "2696/2696 [==============================] - 2023s 750ms/step - loss: 0.0779 - acc: 0.9131 - recall: 0.9023 - precision: 0.9210 - f1_score: 0.9023 - val_loss: 0.5483 - val_acc: 0.8843 - val_recall: 0.8552 - val_precision: 0.8659 - val_f1_score: 0.8636\n",
      "Epoch 15/50\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0770 - acc: 0.9133 - recall: 0.9047 - precision: 0.9224 - f1_score: 0.9023\n",
      "Epoch 00015: val_f1_score did not improve from 0.90243\n",
      "2696/2696 [==============================] - 2524s 936ms/step - loss: 0.0770 - acc: 0.9133 - recall: 0.9047 - precision: 0.9224 - f1_score: 0.9023 - val_loss: 0.3346 - val_acc: 0.8519 - val_recall: 0.8533 - val_precision: 0.8730 - val_f1_score: 0.8468\n",
      "Epoch 16/50\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0749 - acc: 0.9144 - recall: 0.9074 - precision: 0.9218 - f1_score: 0.9040\n",
      "Epoch 00016: val_f1_score did not improve from 0.90243\n",
      "2696/2696 [==============================] - 2520s 935ms/step - loss: 0.0749 - acc: 0.9144 - recall: 0.9074 - precision: 0.9218 - f1_score: 0.9040 - val_loss: 0.0919 - val_acc: 0.9139 - val_recall: 0.8968 - val_precision: 0.9207 - val_f1_score: 0.8981\n",
      "Epoch 17/50\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0747 - acc: 0.9170 - recall: 0.9067 - precision: 0.9228 - f1_score: 0.9059\n",
      "Epoch 00017: val_f1_score did not improve from 0.90243\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "2696/2696 [==============================] - 2506s 930ms/step - loss: 0.0747 - acc: 0.9170 - recall: 0.9067 - precision: 0.9228 - f1_score: 0.9059 - val_loss: 0.2255 - val_acc: 0.8919 - val_recall: 0.8823 - val_precision: 0.9093 - val_f1_score: 0.8827\n",
      "Epoch 18/50\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0680 - acc: 0.9204 - recall: 0.9190 - precision: 0.9314 - f1_score: 0.9117\n",
      "Epoch 00018: val_f1_score did not improve from 0.90243\n",
      "2696/2696 [==============================] - 2505s 929ms/step - loss: 0.0680 - acc: 0.9204 - recall: 0.9190 - precision: 0.9314 - f1_score: 0.9117 - val_loss: 0.0919 - val_acc: 0.9152 - val_recall: 0.9011 - val_precision: 0.9172 - val_f1_score: 0.9018\n",
      "Epoch 19/50\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0652 - acc: 0.9220 - recall: 0.9195 - precision: 0.9325 - f1_score: 0.9126\n",
      "Epoch 00019: val_f1_score did not improve from 0.90243\n",
      "2696/2696 [==============================] - 2478s 919ms/step - loss: 0.0652 - acc: 0.9220 - recall: 0.9195 - precision: 0.9325 - f1_score: 0.9126 - val_loss: 0.1174 - val_acc: 0.9167 - val_recall: 0.8968 - val_precision: 0.9196 - val_f1_score: 0.8989\n",
      "Epoch 20/50\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0652 - acc: 0.9261 - recall: 0.9222 - precision: 0.9338 - f1_score: 0.9153\n",
      "Epoch 00020: val_f1_score improved from 0.90243 to 0.90540, saving model to /app/_data/models/final/eff7_0891/eff7_0891_4.h5\n",
      "2696/2696 [==============================] - 2488s 923ms/step - loss: 0.0652 - acc: 0.9261 - recall: 0.9222 - precision: 0.9338 - f1_score: 0.9153 - val_loss: 0.0798 - val_acc: 0.9177 - val_recall: 0.9028 - val_precision: 0.9290 - val_f1_score: 0.9054\n",
      "Epoch 21/50\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0627 - acc: 0.9286 - recall: 0.9238 - precision: 0.9347 - f1_score: 0.9180\n",
      "Epoch 00021: val_f1_score did not improve from 0.90540\n",
      "2696/2696 [==============================] - 2483s 921ms/step - loss: 0.0627 - acc: 0.9286 - recall: 0.9238 - precision: 0.9347 - f1_score: 0.9180 - val_loss: 0.0878 - val_acc: 0.9068 - val_recall: 0.9064 - val_precision: 0.9085 - val_f1_score: 0.8906\n",
      "Epoch 22/50\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0607 - acc: 0.9291 - recall: 0.9260 - precision: 0.9389 - f1_score: 0.9188\n",
      "Epoch 00022: val_f1_score improved from 0.90540 to 0.90811, saving model to /app/_data/models/final/eff7_0891/eff7_0891_4.h5\n",
      "2696/2696 [==============================] - 2009s 745ms/step - loss: 0.0607 - acc: 0.9291 - recall: 0.9260 - precision: 0.9389 - f1_score: 0.9188 - val_loss: 0.0802 - val_acc: 0.9184 - val_recall: 0.9156 - val_precision: 0.9186 - val_f1_score: 0.9081\n",
      "Epoch 23/50\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0593 - acc: 0.9271 - recall: 0.9275 - precision: 0.9368 - f1_score: 0.9187\n",
      "Epoch 00023: val_f1_score did not improve from 0.90811\n",
      "2696/2696 [==============================] - 2513s 932ms/step - loss: 0.0593 - acc: 0.9271 - recall: 0.9275 - precision: 0.9368 - f1_score: 0.9187 - val_loss: 0.0875 - val_acc: 0.9184 - val_recall: 0.9186 - val_precision: 0.9169 - val_f1_score: 0.9040\n",
      "Epoch 24/50\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0597 - acc: 0.9291 - recall: 0.9279 - precision: 0.9380 - f1_score: 0.9192\n",
      "Epoch 00024: val_f1_score did not improve from 0.90811\n",
      "2696/2696 [==============================] - 1606s 596ms/step - loss: 0.0597 - acc: 0.9291 - recall: 0.9279 - precision: 0.9380 - f1_score: 0.9192 - val_loss: 0.0782 - val_acc: 0.9201 - val_recall: 0.9287 - val_precision: 0.9048 - val_f1_score: 0.9052\n",
      "Epoch 25/50\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0566 - acc: 0.9315 - recall: 0.9313 - precision: 0.9409 - f1_score: 0.9222\n",
      "Epoch 00025: val_f1_score did not improve from 0.90811\n",
      "2696/2696 [==============================] - 1294s 480ms/step - loss: 0.0566 - acc: 0.9315 - recall: 0.9313 - precision: 0.9409 - f1_score: 0.9222 - val_loss: 0.0862 - val_acc: 0.9075 - val_recall: 0.9200 - val_precision: 0.9083 - val_f1_score: 0.8992\n",
      "Epoch 26/50\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0580 - acc: 0.9312 - recall: 0.9294 - precision: 0.9405 - f1_score: 0.9211\n",
      "Epoch 00026: val_f1_score did not improve from 0.90811\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.00032000001519918444.\n",
      "2696/2696 [==============================] - 1326s 492ms/step - loss: 0.0580 - acc: 0.9312 - recall: 0.9294 - precision: 0.9405 - f1_score: 0.9211 - val_loss: 0.0818 - val_acc: 0.9147 - val_recall: 0.9085 - val_precision: 0.9227 - val_f1_score: 0.9052\n",
      "Epoch 27/50\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0506 - acc: 0.9355 - recall: 0.9381 - precision: 0.9470 - f1_score: 0.9267\n",
      "Epoch 00027: val_f1_score improved from 0.90811 to 0.91230, saving model to /app/_data/models/final/eff7_0891/eff7_0891_4.h5\n",
      "2696/2696 [==============================] - 1313s 487ms/step - loss: 0.0506 - acc: 0.9355 - recall: 0.9381 - precision: 0.9470 - f1_score: 0.9267 - val_loss: 0.0823 - val_acc: 0.9290 - val_recall: 0.9145 - val_precision: 0.9329 - val_f1_score: 0.9123\n",
      "Epoch 28/50\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0494 - acc: 0.9395 - recall: 0.9395 - precision: 0.9507 - f1_score: 0.9299\n",
      "Epoch 00028: val_f1_score did not improve from 0.91230\n",
      "2696/2696 [==============================] - 1335s 495ms/step - loss: 0.0494 - acc: 0.9395 - recall: 0.9395 - precision: 0.9507 - f1_score: 0.9299 - val_loss: 0.0982 - val_acc: 0.9139 - val_recall: 0.8945 - val_precision: 0.9153 - val_f1_score: 0.8994\n",
      "Epoch 29/50\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0484 - acc: 0.9384 - recall: 0.9413 - precision: 0.9498 - f1_score: 0.9295\n",
      "Epoch 00029: val_f1_score did not improve from 0.91230\n",
      "2696/2696 [==============================] - 1340s 497ms/step - loss: 0.0484 - acc: 0.9384 - recall: 0.9413 - precision: 0.9498 - f1_score: 0.9295 - val_loss: 0.0864 - val_acc: 0.9224 - val_recall: 0.9085 - val_precision: 0.9290 - val_f1_score: 0.9090\n",
      "Epoch 30/50\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0470 - acc: 0.9407 - recall: 0.9460 - precision: 0.9526 - f1_score: 0.9321\n",
      "Epoch 00030: val_f1_score did not improve from 0.91230\n",
      "2696/2696 [==============================] - 1289s 478ms/step - loss: 0.0470 - acc: 0.9407 - recall: 0.9460 - precision: 0.9526 - f1_score: 0.9321 - val_loss: 0.0890 - val_acc: 0.9144 - val_recall: 0.9030 - val_precision: 0.9266 - val_f1_score: 0.9037\n",
      "Epoch 31/50\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0465 - acc: 0.9415 - recall: 0.9444 - precision: 0.9521 - f1_score: 0.9326\n",
      "Epoch 00031: val_f1_score did not improve from 0.91230\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0002560000168159604.\n",
      "2696/2696 [==============================] - 1285s 477ms/step - loss: 0.0465 - acc: 0.9415 - recall: 0.9444 - precision: 0.9521 - f1_score: 0.9326 - val_loss: 0.1174 - val_acc: 0.9048 - val_recall: 0.9048 - val_precision: 0.9160 - val_f1_score: 0.8979\n",
      "Epoch 32/50\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0415 - acc: 0.9441 - recall: 0.9502 - precision: 0.9567 - f1_score: 0.9353\n",
      "Epoch 00032: val_f1_score did not improve from 0.91230\n",
      "2696/2696 [==============================] - 1292s 479ms/step - loss: 0.0415 - acc: 0.9441 - recall: 0.9502 - precision: 0.9567 - f1_score: 0.9353 - val_loss: 0.0875 - val_acc: 0.9224 - val_recall: 0.9195 - val_precision: 0.9139 - val_f1_score: 0.9066\n",
      "Epoch 33/50\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0385 - acc: 0.9477 - recall: 0.9541 - precision: 0.9597 - f1_score: 0.9387\n",
      "Epoch 00033: val_f1_score did not improve from 0.91230\n",
      "2696/2696 [==============================] - 1287s 478ms/step - loss: 0.0385 - acc: 0.9477 - recall: 0.9541 - precision: 0.9597 - f1_score: 0.9387 - val_loss: 0.0903 - val_acc: 0.9127 - val_recall: 0.9126 - val_precision: 0.9183 - val_f1_score: 0.9024\n",
      "Epoch 34/50\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0385 - acc: 0.9457 - recall: 0.9548 - precision: 0.9615 - f1_score: 0.9391\n",
      "Epoch 00034: val_f1_score did not improve from 0.91230\n",
      "2696/2696 [==============================] - 1324s 491ms/step - loss: 0.0385 - acc: 0.9457 - recall: 0.9548 - precision: 0.9615 - f1_score: 0.9391 - val_loss: 0.0922 - val_acc: 0.9221 - val_recall: 0.9122 - val_precision: 0.9245 - val_f1_score: 0.9069\n",
      "Epoch 35/50\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0371 - acc: 0.9476 - recall: 0.9555 - precision: 0.9618 - f1_score: 0.9399\n",
      "Epoch 00035: val_f1_score did not improve from 0.91230\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.00020480002276599408.\n",
      "2696/2696 [==============================] - 1327s 492ms/step - loss: 0.0371 - acc: 0.9476 - recall: 0.9555 - precision: 0.9618 - f1_score: 0.9399 - val_loss: 0.1141 - val_acc: 0.9162 - val_recall: 0.9092 - val_precision: 0.9317 - val_f1_score: 0.9059\n",
      "Epoch 36/50\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0344 - acc: 0.9505 - recall: 0.9610 - precision: 0.9662 - f1_score: 0.9424\n",
      "Epoch 00036: val_f1_score did not improve from 0.91230\n",
      "2696/2696 [==============================] - 1351s 501ms/step - loss: 0.0344 - acc: 0.9505 - recall: 0.9610 - precision: 0.9662 - f1_score: 0.9424 - val_loss: 0.1639 - val_acc: 0.9120 - val_recall: 0.9083 - val_precision: 0.9210 - val_f1_score: 0.8997\n",
      "Epoch 37/50\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0330 - acc: 0.9517 - recall: 0.9609 - precision: 0.9655 - f1_score: 0.9435\n",
      "Epoch 00037: val_f1_score did not improve from 0.91230\n",
      "2696/2696 [==============================] - 1309s 486ms/step - loss: 0.0330 - acc: 0.9517 - recall: 0.9609 - precision: 0.9655 - f1_score: 0.9435 - val_loss: 0.1740 - val_acc: 0.9169 - val_recall: 0.9154 - val_precision: 0.9171 - val_f1_score: 0.9049\n",
      "Epoch 38/50\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0311 - acc: 0.9528 - recall: 0.9642 - precision: 0.9692 - f1_score: 0.9451Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00038: val_f1_score did not improve from 0.91230\n",
      "2696/2696 [==============================] - 1287s 478ms/step - loss: 0.0311 - acc: 0.9528 - recall: 0.9642 - precision: 0.9692 - f1_score: 0.9451 - val_loss: 0.2566 - val_acc: 0.9036 - val_recall: 0.9149 - val_precision: 0.9078 - val_f1_score: 0.9002\n",
      "Epoch 00038: early stopping\n",
      "Epoch 1/100\n",
      "   2/2696 [..............................] - ETA: 1:29:02 - loss: 0.6372 - acc: 0.3333 - recall: 0.4375 - precision: 0.2692 - f1_score: 0.3938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4546s vs `on_train_batch_end` time: 3.5117s). Check your callbacks.\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.1851 - acc: 0.7979 - recall: 0.7403 - precision: 0.8386 - f1_score: 0.7851\n",
      "Epoch 00001: val_f1_score improved from -inf to 0.84877, saving model to /app/_data/models/final/eff7_0891/eff7_0891_5.h5\n",
      "2696/2696 [==============================] - 1313s 487ms/step - loss: 0.1851 - acc: 0.7979 - recall: 0.7403 - precision: 0.8386 - f1_score: 0.7851 - val_loss: 0.1272 - val_acc: 0.8694 - val_recall: 0.8320 - val_precision: 0.9004 - val_f1_score: 0.8488\n",
      "Epoch 2/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.1360 - acc: 0.8561 - recall: 0.8219 - precision: 0.8796 - f1_score: 0.8446\n",
      "Epoch 00002: val_f1_score improved from 0.84877 to 0.87306, saving model to /app/_data/models/final/eff7_0891/eff7_0891_5.h5\n",
      "2696/2696 [==============================] - 1328s 493ms/step - loss: 0.1360 - acc: 0.8561 - recall: 0.8219 - precision: 0.8796 - f1_score: 0.8446 - val_loss: 0.0996 - val_acc: 0.8843 - val_recall: 0.8674 - val_precision: 0.9084 - val_f1_score: 0.8731\n",
      "Epoch 3/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.1231 - acc: 0.8689 - recall: 0.8429 - precision: 0.8877 - f1_score: 0.8579\n",
      "Epoch 00003: val_f1_score did not improve from 0.87306\n",
      "2696/2696 [==============================] - 1363s 505ms/step - loss: 0.1231 - acc: 0.8689 - recall: 0.8429 - precision: 0.8877 - f1_score: 0.8579 - val_loss: 0.1315 - val_acc: 0.8860 - val_recall: 0.8481 - val_precision: 0.8771 - val_f1_score: 0.8657\n",
      "Epoch 4/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.1124 - acc: 0.8781 - recall: 0.8545 - precision: 0.8961 - f1_score: 0.8684\n",
      "Epoch 00004: val_f1_score improved from 0.87306 to 0.87745, saving model to /app/_data/models/final/eff7_0891/eff7_0891_5.h5\n",
      "2696/2696 [==============================] - 1329s 493ms/step - loss: 0.1124 - acc: 0.8781 - recall: 0.8545 - precision: 0.8961 - f1_score: 0.8684 - val_loss: 0.1121 - val_acc: 0.8966 - val_recall: 0.8924 - val_precision: 0.8795 - val_f1_score: 0.8775\n",
      "Epoch 5/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.1074 - acc: 0.8838 - recall: 0.8613 - precision: 0.8966 - f1_score: 0.8716\n",
      "Epoch 00005: val_f1_score improved from 0.87745 to 0.88581, saving model to /app/_data/models/final/eff7_0891/eff7_0891_5.h5\n",
      "2696/2696 [==============================] - 1323s 491ms/step - loss: 0.1074 - acc: 0.8838 - recall: 0.8613 - precision: 0.8966 - f1_score: 0.8716 - val_loss: 0.0998 - val_acc: 0.9045 - val_recall: 0.8710 - val_precision: 0.9138 - val_f1_score: 0.8858\n",
      "Epoch 6/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.1013 - acc: 0.8906 - recall: 0.8715 - precision: 0.9030 - f1_score: 0.8799\n",
      "Epoch 00006: val_f1_score improved from 0.88581 to 0.89298, saving model to /app/_data/models/final/eff7_0891/eff7_0891_5.h5\n",
      "2696/2696 [==============================] - 1332s 494ms/step - loss: 0.1013 - acc: 0.8906 - recall: 0.8715 - precision: 0.9030 - f1_score: 0.8799 - val_loss: 0.0911 - val_acc: 0.9021 - val_recall: 0.8648 - val_precision: 0.9302 - val_f1_score: 0.8930\n",
      "Epoch 7/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0976 - acc: 0.8953 - recall: 0.8759 - precision: 0.9060 - f1_score: 0.8832\n",
      "Epoch 00007: val_f1_score did not improve from 0.89298\n",
      "2696/2696 [==============================] - 1306s 484ms/step - loss: 0.0976 - acc: 0.8953 - recall: 0.8759 - precision: 0.9060 - f1_score: 0.8832 - val_loss: 0.0896 - val_acc: 0.9080 - val_recall: 0.8938 - val_precision: 0.9150 - val_f1_score: 0.8921\n",
      "Epoch 8/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0960 - acc: 0.8952 - recall: 0.8796 - precision: 0.9069 - f1_score: 0.8839\n",
      "Epoch 00008: val_f1_score improved from 0.89298 to 0.90178, saving model to /app/_data/models/final/eff7_0891/eff7_0891_5.h5\n",
      "2696/2696 [==============================] - 1340s 497ms/step - loss: 0.0960 - acc: 0.8952 - recall: 0.8796 - precision: 0.9069 - f1_score: 0.8839 - val_loss: 0.0835 - val_acc: 0.9221 - val_recall: 0.8839 - val_precision: 0.9300 - val_f1_score: 0.9018\n",
      "Epoch 9/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0923 - acc: 0.8999 - recall: 0.8828 - precision: 0.9108 - f1_score: 0.8885\n",
      "Epoch 00009: val_f1_score did not improve from 0.90178\n",
      "2696/2696 [==============================] - 1280s 475ms/step - loss: 0.0923 - acc: 0.8999 - recall: 0.8828 - precision: 0.9108 - f1_score: 0.8885 - val_loss: 0.0891 - val_acc: 0.9137 - val_recall: 0.8733 - val_precision: 0.9297 - val_f1_score: 0.8986\n",
      "Epoch 10/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0906 - acc: 0.9004 - recall: 0.8865 - precision: 0.9105 - f1_score: 0.8879\n",
      "Epoch 00010: val_f1_score did not improve from 0.90178\n",
      "2696/2696 [==============================] - 1334s 495ms/step - loss: 0.0906 - acc: 0.9004 - recall: 0.8865 - precision: 0.9105 - f1_score: 0.8879 - val_loss: 0.0890 - val_acc: 0.9068 - val_recall: 0.8910 - val_precision: 0.9126 - val_f1_score: 0.8940\n",
      "Epoch 11/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0867 - acc: 0.9049 - recall: 0.8913 - precision: 0.9136 - f1_score: 0.8943\n",
      "Epoch 00011: val_f1_score did not improve from 0.90178\n",
      "2696/2696 [==============================] - 1390s 515ms/step - loss: 0.0867 - acc: 0.9049 - recall: 0.8913 - precision: 0.9136 - f1_score: 0.8943 - val_loss: 0.0844 - val_acc: 0.9107 - val_recall: 0.9025 - val_precision: 0.9196 - val_f1_score: 0.8984\n",
      "Epoch 12/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0855 - acc: 0.9038 - recall: 0.8943 - precision: 0.9160 - f1_score: 0.8945\n",
      "Epoch 00012: val_f1_score did not improve from 0.90178\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "2696/2696 [==============================] - 1306s 484ms/step - loss: 0.0855 - acc: 0.9038 - recall: 0.8943 - precision: 0.9160 - f1_score: 0.8945 - val_loss: 0.0856 - val_acc: 0.9095 - val_recall: 0.9245 - val_precision: 0.8890 - val_f1_score: 0.8907\n",
      "Epoch 13/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0785 - acc: 0.9097 - recall: 0.9026 - precision: 0.9201 - f1_score: 0.8999\n",
      "Epoch 00013: val_f1_score improved from 0.90178 to 0.90588, saving model to /app/_data/models/final/eff7_0891/eff7_0891_5.h5\n",
      "2696/2696 [==============================] - 1323s 491ms/step - loss: 0.0785 - acc: 0.9097 - recall: 0.9026 - precision: 0.9201 - f1_score: 0.8999 - val_loss: 0.0769 - val_acc: 0.9204 - val_recall: 0.9027 - val_precision: 0.9333 - val_f1_score: 0.9059\n",
      "Epoch 14/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0747 - acc: 0.9145 - recall: 0.9070 - precision: 0.9221 - f1_score: 0.9035\n",
      "Epoch 00014: val_f1_score improved from 0.90588 to 0.91160, saving model to /app/_data/models/final/eff7_0891/eff7_0891_5.h5\n",
      "2696/2696 [==============================] - 1295s 480ms/step - loss: 0.0747 - acc: 0.9145 - recall: 0.9070 - precision: 0.9221 - f1_score: 0.9035 - val_loss: 0.0875 - val_acc: 0.9280 - val_recall: 0.9064 - val_precision: 0.9233 - val_f1_score: 0.9116\n",
      "Epoch 15/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0739 - acc: 0.9152 - recall: 0.9090 - precision: 0.9241 - f1_score: 0.9046\n",
      "Epoch 00015: val_f1_score did not improve from 0.91160\n",
      "2696/2696 [==============================] - 1296s 481ms/step - loss: 0.0739 - acc: 0.9152 - recall: 0.9090 - precision: 0.9241 - f1_score: 0.9046 - val_loss: 0.0726 - val_acc: 0.9253 - val_recall: 0.9181 - val_precision: 0.9272 - val_f1_score: 0.9110\n",
      "Epoch 16/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0719 - acc: 0.9170 - recall: 0.9116 - precision: 0.9277 - f1_score: 0.9077\n",
      "Epoch 00016: val_f1_score did not improve from 0.91160\n",
      "2696/2696 [==============================] - 1323s 491ms/step - loss: 0.0719 - acc: 0.9170 - recall: 0.9116 - precision: 0.9277 - f1_score: 0.9077 - val_loss: 0.0856 - val_acc: 0.9189 - val_recall: 0.9227 - val_precision: 0.9093 - val_f1_score: 0.9026\n",
      "Epoch 17/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0712 - acc: 0.9165 - recall: 0.9111 - precision: 0.9281 - f1_score: 0.9059\n",
      "Epoch 00017: val_f1_score did not improve from 0.91160\n",
      "2696/2696 [==============================] - 1289s 478ms/step - loss: 0.0712 - acc: 0.9165 - recall: 0.9111 - precision: 0.9281 - f1_score: 0.9059 - val_loss: 0.0752 - val_acc: 0.9224 - val_recall: 0.9211 - val_precision: 0.9169 - val_f1_score: 0.9073\n",
      "Epoch 18/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0679 - acc: 0.9199 - recall: 0.9183 - precision: 0.9303 - f1_score: 0.9108\n",
      "Epoch 00018: val_f1_score did not improve from 0.91160\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.00032000001519918444.\n",
      "2696/2696 [==============================] - 1297s 481ms/step - loss: 0.0679 - acc: 0.9199 - recall: 0.9183 - precision: 0.9303 - f1_score: 0.9108 - val_loss: 0.0763 - val_acc: 0.9211 - val_recall: 0.9181 - val_precision: 0.9257 - val_f1_score: 0.9098\n",
      "Epoch 19/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0637 - acc: 0.9251 - recall: 0.9201 - precision: 0.9356 - f1_score: 0.9156\n",
      "Epoch 00019: val_f1_score did not improve from 0.91160\n",
      "2696/2696 [==============================] - 1350s 501ms/step - loss: 0.0637 - acc: 0.9251 - recall: 0.9201 - precision: 0.9356 - f1_score: 0.9156 - val_loss: 0.0795 - val_acc: 0.9169 - val_recall: 0.9048 - val_precision: 0.9243 - val_f1_score: 0.9080\n",
      "Epoch 20/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0627 - acc: 0.9267 - recall: 0.9221 - precision: 0.9360 - f1_score: 0.9172\n",
      "Epoch 00020: val_f1_score did not improve from 0.91160\n",
      "2696/2696 [==============================] - 1368s 507ms/step - loss: 0.0627 - acc: 0.9267 - recall: 0.9221 - precision: 0.9360 - f1_score: 0.9172 - val_loss: 0.0782 - val_acc: 0.9219 - val_recall: 0.9052 - val_precision: 0.9366 - val_f1_score: 0.9069\n",
      "Epoch 21/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0602 - acc: 0.9310 - recall: 0.9264 - precision: 0.9389 - f1_score: 0.9209\n",
      "Epoch 00021: val_f1_score did not improve from 0.91160\n",
      "2696/2696 [==============================] - 2491s 924ms/step - loss: 0.0602 - acc: 0.9310 - recall: 0.9264 - precision: 0.9389 - f1_score: 0.9209 - val_loss: 0.0754 - val_acc: 0.9196 - val_recall: 0.9137 - val_precision: 0.9248 - val_f1_score: 0.9043\n",
      "Epoch 22/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0579 - acc: 0.9303 - recall: 0.9300 - precision: 0.9405 - f1_score: 0.9207\n",
      "Epoch 00022: val_f1_score improved from 0.91160 to 0.91269, saving model to /app/_data/models/final/eff7_0891/eff7_0891_5.h5\n",
      "2696/2696 [==============================] - 2536s 941ms/step - loss: 0.0579 - acc: 0.9303 - recall: 0.9300 - precision: 0.9405 - f1_score: 0.9207 - val_loss: 0.0767 - val_acc: 0.9211 - val_recall: 0.9259 - val_precision: 0.9242 - val_f1_score: 0.9127\n",
      "Epoch 23/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0579 - acc: 0.9316 - recall: 0.9285 - precision: 0.9394 - f1_score: 0.9207\n",
      "Epoch 00023: val_f1_score improved from 0.91269 to 0.91315, saving model to /app/_data/models/final/eff7_0891/eff7_0891_5.h5\n",
      "2696/2696 [==============================] - 2538s 941ms/step - loss: 0.0579 - acc: 0.9316 - recall: 0.9285 - precision: 0.9394 - f1_score: 0.9207 - val_loss: 0.0779 - val_acc: 0.9340 - val_recall: 0.9101 - val_precision: 0.9327 - val_f1_score: 0.9131\n",
      "Epoch 24/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0567 - acc: 0.9293 - recall: 0.9278 - precision: 0.9412 - f1_score: 0.9199\n",
      "Epoch 00024: val_f1_score did not improve from 0.91315\n",
      "2696/2696 [==============================] - 2579s 956ms/step - loss: 0.0567 - acc: 0.9293 - recall: 0.9278 - precision: 0.9412 - f1_score: 0.9199 - val_loss: 0.0787 - val_acc: 0.9248 - val_recall: 0.9190 - val_precision: 0.9275 - val_f1_score: 0.9085\n",
      "Epoch 25/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0550 - acc: 0.9327 - recall: 0.9333 - precision: 0.9428 - f1_score: 0.9241\n",
      "Epoch 00025: val_f1_score did not improve from 0.91315\n",
      "2696/2696 [==============================] - 2559s 949ms/step - loss: 0.0550 - acc: 0.9327 - recall: 0.9333 - precision: 0.9428 - f1_score: 0.9241 - val_loss: 0.1065 - val_acc: 0.9120 - val_recall: 0.8958 - val_precision: 0.9158 - val_f1_score: 0.8960\n",
      "Epoch 26/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0528 - acc: 0.9363 - recall: 0.9362 - precision: 0.9462 - f1_score: 0.9272\n",
      "Epoch 00026: val_f1_score improved from 0.91315 to 0.91599, saving model to /app/_data/models/final/eff7_0891/eff7_0891_5.h5\n",
      "2696/2696 [==============================] - 2590s 961ms/step - loss: 0.0528 - acc: 0.9363 - recall: 0.9362 - precision: 0.9462 - f1_score: 0.9272 - val_loss: 0.0779 - val_acc: 0.9342 - val_recall: 0.9094 - val_precision: 0.9407 - val_f1_score: 0.9160\n",
      "Epoch 27/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0530 - acc: 0.9339 - recall: 0.9361 - precision: 0.9468 - f1_score: 0.9255\n",
      "Epoch 00027: val_f1_score did not improve from 0.91599\n",
      "2696/2696 [==============================] - 2521s 935ms/step - loss: 0.0530 - acc: 0.9339 - recall: 0.9361 - precision: 0.9468 - f1_score: 0.9255 - val_loss: 0.0768 - val_acc: 0.9238 - val_recall: 0.9275 - val_precision: 0.9281 - val_f1_score: 0.9144\n",
      "Epoch 28/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0518 - acc: 0.9348 - recall: 0.9373 - precision: 0.9464 - f1_score: 0.9263\n",
      "Epoch 00028: val_f1_score did not improve from 0.91599\n",
      "2696/2696 [==============================] - 2429s 901ms/step - loss: 0.0518 - acc: 0.9348 - recall: 0.9373 - precision: 0.9464 - f1_score: 0.9263 - val_loss: 0.0838 - val_acc: 0.9298 - val_recall: 0.9188 - val_precision: 0.9288 - val_f1_score: 0.9132\n",
      "Epoch 29/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0508 - acc: 0.9370 - recall: 0.9388 - precision: 0.9472 - f1_score: 0.9271\n",
      "Epoch 00029: val_f1_score did not improve from 0.91599\n",
      "2696/2696 [==============================] - 2367s 878ms/step - loss: 0.0508 - acc: 0.9370 - recall: 0.9388 - precision: 0.9472 - f1_score: 0.9271 - val_loss: 0.0767 - val_acc: 0.9177 - val_recall: 0.9298 - val_precision: 0.9272 - val_f1_score: 0.9124\n",
      "Epoch 30/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0490 - acc: 0.9368 - recall: 0.9398 - precision: 0.9488 - f1_score: 0.9280\n",
      "Epoch 00030: val_f1_score did not improve from 0.91599\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0002560000168159604.\n",
      "2696/2696 [==============================] - 2453s 910ms/step - loss: 0.0490 - acc: 0.9368 - recall: 0.9398 - precision: 0.9488 - f1_score: 0.9280 - val_loss: 0.0825 - val_acc: 0.9194 - val_recall: 0.9190 - val_precision: 0.9271 - val_f1_score: 0.9098\n",
      "Epoch 31/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0443 - acc: 0.9417 - recall: 0.9472 - precision: 0.9547 - f1_score: 0.9341\n",
      "Epoch 00031: val_f1_score did not improve from 0.91599\n",
      "2696/2696 [==============================] - 2459s 912ms/step - loss: 0.0443 - acc: 0.9417 - recall: 0.9472 - precision: 0.9547 - f1_score: 0.9341 - val_loss: 0.0911 - val_acc: 0.9209 - val_recall: 0.9165 - val_precision: 0.9237 - val_f1_score: 0.9068\n",
      "Epoch 32/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0418 - acc: 0.9441 - recall: 0.9509 - precision: 0.9571 - f1_score: 0.9361\n",
      "Epoch 00032: val_f1_score did not improve from 0.91599\n",
      "2696/2696 [==============================] - 2472s 917ms/step - loss: 0.0418 - acc: 0.9441 - recall: 0.9509 - precision: 0.9571 - f1_score: 0.9361 - val_loss: 0.0962 - val_acc: 0.9177 - val_recall: 0.9061 - val_precision: 0.9244 - val_f1_score: 0.9042\n",
      "Epoch 33/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0428 - acc: 0.9428 - recall: 0.9474 - precision: 0.9557 - f1_score: 0.9347\n",
      "Epoch 00033: val_f1_score did not improve from 0.91599\n",
      "2696/2696 [==============================] - 2452s 909ms/step - loss: 0.0428 - acc: 0.9428 - recall: 0.9474 - precision: 0.9557 - f1_score: 0.9347 - val_loss: 0.0960 - val_acc: 0.9241 - val_recall: 0.9034 - val_precision: 0.9270 - val_f1_score: 0.9060\n",
      "Epoch 34/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0399 - acc: 0.9481 - recall: 0.9528 - precision: 0.9593 - f1_score: 0.9390\n",
      "Epoch 00034: val_f1_score did not improve from 0.91599\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.00020480002276599408.\n",
      "2696/2696 [==============================] - 1570s 582ms/step - loss: 0.0399 - acc: 0.9481 - recall: 0.9528 - precision: 0.9593 - f1_score: 0.9390 - val_loss: 0.1058 - val_acc: 0.9179 - val_recall: 0.9158 - val_precision: 0.9126 - val_f1_score: 0.9052\n",
      "Epoch 35/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0364 - acc: 0.9504 - recall: 0.9563 - precision: 0.9634 - f1_score: 0.9417\n",
      "Epoch 00035: val_f1_score did not improve from 0.91599\n",
      "2696/2696 [==============================] - 1349s 500ms/step - loss: 0.0364 - acc: 0.9504 - recall: 0.9563 - precision: 0.9634 - f1_score: 0.9417 - val_loss: 0.0933 - val_acc: 0.9275 - val_recall: 0.9218 - val_precision: 0.9301 - val_f1_score: 0.9138\n",
      "Epoch 36/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0348 - acc: 0.9501 - recall: 0.9584 - precision: 0.9646 - f1_score: 0.9424\n",
      "Epoch 00036: val_f1_score did not improve from 0.91599\n",
      "2696/2696 [==============================] - 1365s 506ms/step - loss: 0.0348 - acc: 0.9501 - recall: 0.9584 - precision: 0.9646 - f1_score: 0.9424 - val_loss: 0.0962 - val_acc: 0.9315 - val_recall: 0.9211 - val_precision: 0.9262 - val_f1_score: 0.9136\n",
      "Epoch 37/100\n",
      "2696/2696 [==============================] - ETA: 0s - loss: 0.0328 - acc: 0.9537 - recall: 0.9602 - precision: 0.9663 - f1_score: 0.9438Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00037: val_f1_score did not improve from 0.91599\n",
      "2696/2696 [==============================] - 1341s 498ms/step - loss: 0.0328 - acc: 0.9537 - recall: 0.9602 - precision: 0.9663 - f1_score: 0.9438 - val_loss: 0.0917 - val_acc: 0.9191 - val_recall: 0.9266 - val_precision: 0.9207 - val_f1_score: 0.9104\n",
      "Epoch 00037: early stopping\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=SEED, shuffle=True)\n",
    "\n",
    "for i, (train_index, valid_index) in enumerate(\n",
    "    skf.split(df_labels[\"image\"], df_labels[\"labels\"])\n",
    "):\n",
    "    if i==3:\n",
    "        train, valid = df_labels.loc[train_index], df_labels.loc[valid_index]\n",
    "        model_name = \"eff7_0891_\" + str(i + 1) + \".h5\"\n",
    "        log_dir = 'logs_eff7_0891_'+str(i + 1)+'/'\n",
    "        callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor=\"val_f1_score\",\n",
    "                patience=11,\n",
    "                restore_best_weights=True,\n",
    "                verbose=1,\n",
    "                mode=\"max\",\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                \"/app/_data/models/final/eff7_0891/\" + model_name,\n",
    "                monitor=\"val_f1_score\",\n",
    "                verbose=1,\n",
    "                save_best_only=True,\n",
    "                save_weights_only=False,\n",
    "                mode=\"max\",\n",
    "                save_freq=\"epoch\",\n",
    "            ),\n",
    "            keras.callbacks.ReduceLROnPlateau(\n",
    "                monitor=\"val_f1_score\",\n",
    "                factor=0.8,\n",
    "                patience=4,\n",
    "                verbose=1,\n",
    "                mode=\"max\",\n",
    "                min_delta=1e-4,\n",
    "                min_lr=0.00000001,\n",
    "            ),\n",
    "            keras.callbacks.TensorBoard(\n",
    "                log_dir=\"/app/.tensorboard/\"+log_dir, histogram_freq=0\n",
    "            ),\n",
    "            keras.callbacks.experimental.BackupAndRestore(\n",
    "        '/app/_data/models/final/eff7_0891/backup/'\n",
    "    )\n",
    "        ]\n",
    "\n",
    "        gen_train = Generator(\n",
    "            df=train,\n",
    "            images_src_dir=TRAIN_IMG_PATH,\n",
    "            target_image_size=IMAGE_SIZE,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=True,\n",
    "            augment=True,\n",
    "            crop=False,\n",
    "            resize=False,\n",
    "        )\n",
    "        gen_valid = Generator(\n",
    "            df=valid,\n",
    "            images_src_dir=TRAIN_IMG_PATH,\n",
    "            target_image_size=IMAGE_SIZE,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=True,\n",
    "            augment=False,\n",
    "            crop=False,\n",
    "            resize=False,\n",
    "        )\n",
    "        model = get_model()\n",
    "        history = model.fit(\n",
    "            gen_train,\n",
    "            validation_data=gen_valid,\n",
    "            epochs=50,\n",
    "            steps_per_epoch=train.shape[0]//BATCH_SIZE,\n",
    "            validation_steps=valid.shape[0]//BATCH_SIZE,\n",
    "            verbose=1,\n",
    "            workers = 15,\n",
    "            callbacks=callbacks,\n",
    "        )\n",
    "        tf.keras.backend.clear_session()\n",
    "        \n",
    "        \n",
    "    if i>3:\n",
    "        train, valid = df_labels.loc[train_index], df_labels.loc[valid_index]\n",
    "        model_name = \"eff7_0891_\" + str(i + 1) + \".h5\"\n",
    "        log_dir = 'logs_eff7_0891_'+str(i + 1)+'/'\n",
    "        callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor=\"val_f1_score\",\n",
    "                patience=11,\n",
    "                restore_best_weights=True,\n",
    "                verbose=1,\n",
    "                mode=\"max\",\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                \"/app/_data/models/final/eff7_0891/\" + model_name,\n",
    "                monitor=\"val_f1_score\",\n",
    "                verbose=1,\n",
    "                save_best_only=True,\n",
    "                save_weights_only=False,\n",
    "                mode=\"max\",\n",
    "                save_freq=\"epoch\",\n",
    "            ),\n",
    "            keras.callbacks.ReduceLROnPlateau(\n",
    "                monitor=\"val_f1_score\",\n",
    "                factor=0.8,\n",
    "                patience=4,\n",
    "                verbose=1,\n",
    "                mode=\"max\",\n",
    "                min_delta=1e-4,\n",
    "                min_lr=0.00000001,\n",
    "            ),\n",
    "            keras.callbacks.TensorBoard(\n",
    "                log_dir=\"/app/.tensorboard/\"+log_dir, histogram_freq=0\n",
    "            ),\n",
    "            keras.callbacks.experimental.BackupAndRestore(\n",
    "        '/app/_data/models/final/eff7_0891/backup/'\n",
    "    )\n",
    "        ]\n",
    "\n",
    "        gen_train = Generator(\n",
    "            df=train,\n",
    "            images_src_dir=TRAIN_IMG_PATH,\n",
    "            target_image_size=IMAGE_SIZE,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=True,\n",
    "            augment=True,\n",
    "            crop=False,\n",
    "            resize=False,\n",
    "        )\n",
    "        gen_valid = Generator(\n",
    "            df=valid,\n",
    "            images_src_dir=TRAIN_IMG_PATH,\n",
    "            target_image_size=IMAGE_SIZE,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=True,\n",
    "            augment=False,\n",
    "            crop=False,\n",
    "            resize=False,\n",
    "        )\n",
    "        model = get_model()\n",
    "        history = model.fit(\n",
    "            gen_train,\n",
    "            validation_data=gen_valid,\n",
    "            epochs=100,\n",
    "            steps_per_epoch=train.shape[0]//BATCH_SIZE,\n",
    "            validation_steps=valid.shape[0]//BATCH_SIZE,\n",
    "            verbose=1,\n",
    "            workers = 15,\n",
    "            callbacks=callbacks,\n",
    "        )\n",
    "        tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices(\"GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_all(file_path):\n",
    "    img = tf.io.read_file(TRAIN_IMG_PATH + file_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    return img\n",
    "\n",
    "\n",
    "def predict_new(path, model):\n",
    "    img = parse_all(path)\n",
    "    img = tf.expand_dims(img, axis=0)\n",
    "    pred = model.predict(img)\n",
    "    return pred_to_labels(pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = pd.DataFrame(columns=[\"image\", \"labels\"])\n",
    "for img_name in os.listdir(TRAIN_IMG_PATH):\n",
    "    pred = predict_new(img_name, model)\n",
    "\n",
    "    df_sub = df_sub.append({\"image\": img_name, \"labels\": pred}, ignore_index=True)\n",
    "\n",
    "print(df_sub.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = df_sub.merge(\n",
    "    labels_21_20[[\"image\", \"labels\"]],\n",
    "    on=\"image\",\n",
    "    how=\"left\",\n",
    "    suffixes=(\"_pred\", \"_true\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.to_csv(\"/app/sandbox/wrong_predictions/eff4/eff4_ns_cropped_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub[df_sub[\"labels_pred\"] == \"\"][\"labels_true\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scab frog_eye_leaf_spot            682\n",
       "complex                            438\n",
       "scab frog_eye_leaf_spot complex    200\n",
       "frog_eye_leaf_spot complex         165\n",
       "scab                               124\n",
       "rust frog_eye_leaf_spot            118\n",
       "rust complex                        91\n",
       "powdery_mildew complex              87\n",
       "rust                                74\n",
       "frog_eye_leaf_spot                  71\n",
       "healthy                             19\n",
       "powdery_mildew                       7\n",
       "Name: labels_true, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub[df_sub[\"labels_pred\"] != df_sub[\"labels_true\"]][\"labels_true\"].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
