{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - MODEL_PATH = '/kaggle/input/eff4-ns-ups/eff4_ns_ups.h5'\n",
    " - fill '' with 'scab'\n",
    " - plants_eff4_tfdataset v 23\n",
    " - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from PIL import Image\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    f1_score,\n",
    "    plot_confusion_matrix,\n",
    "    precision_recall_curve,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    StratifiedKFold,\n",
    "    StratifiedShuffleSplit,\n",
    "    train_test_split,\n",
    ")\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB4, EfficientNetB7\n",
    "from tensorflow.keras.layers import (\n",
    "    AveragePooling2D,\n",
    "    AvgPool2D,\n",
    "    Conv2D,\n",
    "    Dense,\n",
    "    Flatten,\n",
    "    GlobalAveragePooling2D,\n",
    "    MaxPooling2D,\n",
    ")\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tqdm import notebook, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/app/_data/\"\n",
    "BATCH_SIZE = 32\n",
    "SEED = 1488\n",
    "IMAGE_SIZE = (380, 380)\n",
    "NUM_CLASSES = 6\n",
    "INPUT_SHAPE = (380, 380, 3)\n",
    "TRAIN_IMG_PATH = \"/app/_data/380/\"\n",
    "TEST_IMG_PATH = \"/app/_data/test_images/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(PATH + \"train_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(PATH + \"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.join(labels[\"labels\"].str.get_dummies(sep=\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>labels</th>\n",
       "      <th>complex</th>\n",
       "      <th>frog_eye_leaf_spot</th>\n",
       "      <th>healthy</th>\n",
       "      <th>powdery_mildew</th>\n",
       "      <th>rust</th>\n",
       "      <th>scab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>800113bb65efe69e.jpg</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  image   labels  complex  frog_eye_leaf_spot  healthy  \\\n",
       "0  800113bb65efe69e.jpg  healthy        0                   0        1   \n",
       "\n",
       "   powdery_mildew  rust  scab  \n",
       "0               0     0     0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['complex', 'frog_eye_leaf_spot', 'healthy', 'powdery_mildew', 'rust', 'scab']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns = labels.columns[2:].tolist()\n",
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['complex', 'frog_eye_leaf_spot', 'healthy', 'powdery_mildew', 'rust', 'scab']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>healthy</th>\n",
       "      <th>multiple_diseases</th>\n",
       "      <th>rust</th>\n",
       "      <th>scab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>Train_222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_id  healthy  multiple_diseases  rust  scab\n",
       "222  Train_222        0                  0     0     1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_2020 = pd.read_csv(PATH+'train_20.csv')\n",
    "labels_2020.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_2020['image_id'] = labels_2020['image_id']+'.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>e0eb8e90dd9a389a.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0\n",
       "164  e0eb8e90dd9a389a.jpg"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_wrong = pd.read_csv(PATH+\"all_wrong_7mod.csv\", index_col=[0])\n",
    "all_wrong.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>labels</th>\n",
       "      <th>complex</th>\n",
       "      <th>frog_eye_leaf_spot</th>\n",
       "      <th>healthy</th>\n",
       "      <th>powdery_mildew</th>\n",
       "      <th>rust</th>\n",
       "      <th>scab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>928524ea9778cb9e.jpg</td>\n",
       "      <td>complex</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f5cbd285dd1a1e10.jpg</td>\n",
       "      <td>scab frog_eye_leaf_spot complex</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fb9fd1486816f2a0.jpg</td>\n",
       "      <td>scab frog_eye_leaf_spot</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bd25252ff090b9e8.jpg</td>\n",
       "      <td>complex</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8d784bc9270bb2ab.jpg</td>\n",
       "      <td>scab frog_eye_leaf_spot complex</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  image                           labels  complex  \\\n",
       "0  928524ea9778cb9e.jpg                          complex        1   \n",
       "1  f5cbd285dd1a1e10.jpg  scab frog_eye_leaf_spot complex        1   \n",
       "2  fb9fd1486816f2a0.jpg          scab frog_eye_leaf_spot        0   \n",
       "3  bd25252ff090b9e8.jpg                          complex        1   \n",
       "4  8d784bc9270bb2ab.jpg  scab frog_eye_leaf_spot complex        1   \n",
       "\n",
       "   frog_eye_leaf_spot  healthy  powdery_mildew  rust  scab  \n",
       "0                   0        0               0     0     0  \n",
       "1                   1        0               0     0     1  \n",
       "2                   1        0               0     0     1  \n",
       "3                   0        0               0     0     0  \n",
       "4                   1        0               0     0     1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_wrong.columns = ['image']\n",
    "all_wrong = all_wrong.merge(labels, on='image', how='left')\n",
    "all_wrong.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_2020.columns = ['image', 'healthy', 'complex', 'rust', 'scab']\n",
    "feature_columns_20 = labels_2020.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in labels_2020.index:\n",
    "    labels_2020.loc[i, 'labels_20'] = ''.join(list(map(lambda x, y: x*y, labels_2020.loc[i,feature_columns_20].values, feature_columns_20)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_21_20 = pd.concat([labels, labels_2020], axis=0,\n",
    "    join='outer',\n",
    "    ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_21_20[feature_columns] = labels_21_20[feature_columns].fillna(0).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>labels</th>\n",
       "      <th>complex</th>\n",
       "      <th>frog_eye_leaf_spot</th>\n",
       "      <th>healthy</th>\n",
       "      <th>powdery_mildew</th>\n",
       "      <th>rust</th>\n",
       "      <th>scab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>800113bb65efe69e.jpg</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8002cb321f8bfcdf.jpg</td>\n",
       "      <td>scab frog_eye_leaf_spot complex</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  image                           labels  complex  \\\n",
       "0  800113bb65efe69e.jpg                          healthy        0   \n",
       "1  8002cb321f8bfcdf.jpg  scab frog_eye_leaf_spot complex        1   \n",
       "\n",
       "   frog_eye_leaf_spot  healthy  powdery_mildew  rust  scab  \n",
       "0                   0        1               0     0     0  \n",
       "1                   1        0               0     0     1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_21_20['labels'] = labels_21_20['labels'].fillna(labels_21_20['labels_20'])\n",
    "labels_21_20 = labels_21_20.drop('labels_20', axis=1)\n",
    "labels_21_20.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_long = pd.concat([labels_21_20, all_wrong, all_wrong, all_wrong, all_wrong], axis=0,\n",
    "    join='outer',\n",
    "    ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23105 entries, 0 to 23104\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   image               23105 non-null  object\n",
      " 1   labels              23105 non-null  object\n",
      " 2   complex             23105 non-null  int64 \n",
      " 3   frog_eye_leaf_spot  23105 non-null  int64 \n",
      " 4   healthy             23105 non-null  int64 \n",
      " 5   powdery_mildew      23105 non-null  int64 \n",
      " 6   rust                23105 non-null  int64 \n",
      " 7   scab                23105 non-null  int64 \n",
      "dtypes: int64(6), object(2)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "labels_long.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scab                               5461\n",
       "healthy                            5148\n",
       "frog_eye_leaf_spot                 3191\n",
       "rust                               2462\n",
       "complex                            2412\n",
       "scab frog_eye_leaf_spot            1354\n",
       "powdery_mildew                     1232\n",
       "scab frog_eye_leaf_spot complex     656\n",
       "rust frog_eye_leaf_spot             394\n",
       "frog_eye_leaf_spot complex          369\n",
       "powdery_mildew complex              235\n",
       "rust complex                        191\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_long['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_long_1 = labels_long.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['powdery_mildew',\n",
    " 'scab frog_eye_leaf_spot',\n",
    " 'scab frog_eye_leaf_spot complex',\n",
    " 'frog_eye_leaf_spot complex',\n",
    " 'rust frog_eye_leaf_spot',\n",
    " 'powdery_mildew complex',\n",
    " 'rust complex']:\n",
    "    n_count = labels_long['labels'].value_counts()[col]\n",
    "    samp = labels[labels['labels'] == col].sample(n=2000-n_count,\n",
    "    replace=True,\n",
    "    random_state=SEED,\n",
    "    axis=None,\n",
    ")\n",
    "    labels_long_1 = pd.concat([labels_long_1, samp], axis=0,\n",
    "    join='outer',\n",
    "    ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_long_1 = labels_long_1.sample(frac=1, random_state = SEED).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scab                               5461\n",
       "healthy                            5148\n",
       "frog_eye_leaf_spot                 3191\n",
       "rust                               2462\n",
       "complex                            2412\n",
       "powdery_mildew complex             2000\n",
       "rust complex                       2000\n",
       "frog_eye_leaf_spot complex         2000\n",
       "scab frog_eye_leaf_spot            2000\n",
       "powdery_mildew                     2000\n",
       "rust frog_eye_leaf_spot            2000\n",
       "scab frog_eye_leaf_spot complex    2000\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_long_1['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=SEED)\n",
    "X = labels_long_1[\"image\"]\n",
    "y = labels_long_1[feature_columns]\n",
    "for train_index, valid_index in sss.split(labels_long_1[\"image\"], labels_long_1['labels']):\n",
    "    train, valid = labels_long_1.loc[train_index], labels_long_1.loc[valid_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_to_labels(pred, thresh=0.5, labels=feature_columns):\n",
    "\n",
    "    pred = [labels[i] for i in range(len(labels)) if pred[i] > thresh]\n",
    "    pred = ' '.join(pred)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.experimental.preprocessing.RandomFlip(\n",
    "            \"horizontal_and_vertical\", seed=SEED\n",
    "        ),\n",
    "        keras.layers.experimental.preprocessing.RandomRotation(0.15, seed=SEED),\n",
    "        keras.layers.experimental.preprocessing.RandomZoom(0.25, 0.25, seed=SEED),\n",
    "        keras.layers.experimental.preprocessing.RandomContrast(factor=0.05, seed=SEED),\n",
    "        keras.layers.experimental.preprocessing.RandomTranslation(\n",
    "            height_factor=0.2, width_factor=0.2, seed=SEED\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from 380 uint8\n",
    "def parse_image2(file_path):\n",
    "    img = tf.io.read_file(PATH+'380/'+file_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v1 from orig\n",
    "def parse_image(file_path):\n",
    "    img = tf.io.read_file(TRAIN_IMG_PATH+file_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img = tf.image.resize(\n",
    "        img,\n",
    "        IMAGE_SIZE,\n",
    "    )\n",
    "    img = tf.image.convert_image_dtype(img, tf.uint8)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(df, augmentation=False):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (df[\"image\"].values, df[feature_columns].astype('uint8').values)\n",
    "    )\n",
    "    dataset = dataset.map(lambda x, y: (parse_image2(x), y))\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "\n",
    "    if augmentation:\n",
    "        dataset = dataset.map(\n",
    "            lambda x, y: (data_augmentation(x, training=True), y),\n",
    "            num_parallel_calls=AUTOTUNE,\n",
    "        )\n",
    "    dataset = dataset.repeat().prefetch(buffer_size=AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = prepare_dataset(train, augmentation = True)\n",
    "ds_valid = prepare_dataset(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dtype: 'uint8'> <dtype: 'uint8'>\n",
      "(380, 380, 3) (32, 6)\n"
     ]
    }
   ],
   "source": [
    "for a, b in ds_valid.take(1):\n",
    "    print(a[0].dtype, b.dtype)\n",
    "    print(a[0].shape, b.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_test_image(img_name):\n",
    "    img = tf.io.read_file(img_name)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img = tf.image.resize(\n",
    "        img,\n",
    "        IMAGE_SIZE,\n",
    "    )\n",
    "    img = tf.image.convert_image_dtype(img, tf.uint8)\n",
    "    return img\n",
    "\n",
    "\n",
    "def predict_new(path, model):\n",
    "    img = parse_test_image(path)\n",
    "    img = tf.expand_dims(img,axis = 0)\n",
    "    pred = model.predict(img)\n",
    "    return pred_to_labels(pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Quadro RTX 5000, compute capability 7.5\n"
     ]
    }
   ],
   "source": [
    "policy = keras.mixed_precision.experimental.Policy('mixed_float16')\n",
    "keras.mixed_precision.experimental.set_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 5:\n",
    "        return 0.01\n",
    "    elif 5 <= epoch <10:\n",
    "        return 0.001\n",
    "    elif 10 <= epoch <50:\n",
    "        return 0.0005\n",
    "    else:\n",
    "        return 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\", patience=20, restore_best_weights=True, verbose=0, mode='min',\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        \"/app/_data/models/eff4_ns_3.h5\",\n",
    "        monitor=\"val_loss\",\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        mode=\"min\",\n",
    "        save_freq=\"epoch\",\n",
    "    ),\n",
    "    keras.callbacks.LearningRateScheduler(schedule = scheduler, verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=INPUT_SHAPE)\n",
    "base_model = keras.applications.EfficientNetB4(weights=None, include_top=False)\n",
    "base_model.load_weights('/app/_data/models/efficientnet-b4_noisy-student_notop.h5', by_name=True, skip_mismatch = True)\n",
    "x = base_model(inputs)\n",
    "x = keras.layers.GlobalAveragePooling2D(name=\"avg_pool\")(x)\n",
    "x = keras.layers.Flatten(name=\"flatten\")(x)\n",
    "outputs = keras.layers.Dense(NUM_CLASSES, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=Adam(lr=0.0005),\n",
    "    metrics=['acc',\n",
    "        keras.metrics.Recall(),\n",
    "        keras.metrics.Precision(),\n",
    "        tfa.metrics.F1Score(num_classes=NUM_CLASSES, average=\"micro\"),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.01.\n",
      "Epoch 1/100\n",
      "735/735 [==============================] - 484s 658ms/step - loss: 0.3516 - acc: 0.5126 - recall_2: 0.5495 - precision_2: 0.7053 - f1_score: 0.5739 - val_loss: 0.6250 - val_acc: 0.4141 - val_recall_2: 0.4268 - val_precision_2: 0.5033 - val_f1_score: 0.4139\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.01.\n",
      "Epoch 2/100\n",
      "735/735 [==============================] - 478s 650ms/step - loss: 0.2693 - acc: 0.6053 - recall_2: 0.7070 - precision_2: 0.7816 - f1_score: 0.6704 - val_loss: 0.2671 - val_acc: 0.6016 - val_recall_2: 0.6799 - val_precision_2: 0.7739 - val_f1_score: 0.6496\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.01.\n",
      "Epoch 3/100\n",
      "735/735 [==============================] - 473s 644ms/step - loss: 0.2453 - acc: 0.6228 - recall_2: 0.7474 - precision_2: 0.8008 - f1_score: 0.6866 - val_loss: 0.3988 - val_acc: 0.5984 - val_recall_2: 0.7128 - val_precision_2: 0.6267 - val_f1_score: 0.6049\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.01.\n",
      "Epoch 4/100\n",
      "735/735 [==============================] - 474s 645ms/step - loss: 0.2301 - acc: 0.6362 - recall_2: 0.7736 - precision_2: 0.8092 - f1_score: 0.6984 - val_loss: 0.3413 - val_acc: 0.5484 - val_recall_2: 0.6254 - val_precision_2: 0.7055 - val_f1_score: 0.6124\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.01.\n",
      "Epoch 5/100\n",
      "735/735 [==============================] - 474s 645ms/step - loss: 0.2187 - acc: 0.6414 - recall_2: 0.7918 - precision_2: 0.8172 - f1_score: 0.7069 - val_loss: 0.3496 - val_acc: 0.5375 - val_recall_2: 0.5709 - val_precision_2: 0.7727 - val_f1_score: 0.6206\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 6/100\n",
      "735/735 [==============================] - 475s 646ms/step - loss: 0.1856 - acc: 0.6596 - recall_2: 0.8357 - precision_2: 0.8382 - f1_score: 0.7256 - val_loss: 0.1638 - val_acc: 0.6516 - val_recall_2: 0.8468 - val_precision_2: 0.8604 - val_f1_score: 0.7508\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 7/100\n",
      "735/735 [==============================] - 475s 646ms/step - loss: 0.1749 - acc: 0.6657 - recall_2: 0.8509 - precision_2: 0.8466 - f1_score: 0.7333 - val_loss: 0.1581 - val_acc: 0.6625 - val_recall_2: 0.8422 - val_precision_2: 0.8578 - val_f1_score: 0.7456\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 8/100\n",
      "735/735 [==============================] - 475s 646ms/step - loss: 0.1685 - acc: 0.6660 - recall_2: 0.8599 - precision_2: 0.8481 - f1_score: 0.7372 - val_loss: 0.1617 - val_acc: 0.6625 - val_recall_2: 0.8388 - val_precision_2: 0.8623 - val_f1_score: 0.7548\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 9/100\n",
      "735/735 [==============================] - 475s 646ms/step - loss: 0.1624 - acc: 0.6711 - recall_2: 0.8679 - precision_2: 0.8525 - f1_score: 0.7391 - val_loss: 0.1480 - val_acc: 0.6641 - val_recall_2: 0.8729 - val_precision_2: 0.8670 - val_f1_score: 0.7574\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 10/100\n",
      "735/735 [==============================] - 474s 645ms/step - loss: 0.1593 - acc: 0.6761 - recall_2: 0.8700 - precision_2: 0.8541 - f1_score: 0.7431 - val_loss: 0.1569 - val_acc: 0.6594 - val_recall_2: 0.8513 - val_precision_2: 0.8661 - val_f1_score: 0.7525\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 11/100\n",
      "735/735 [==============================] - 475s 647ms/step - loss: 0.1546 - acc: 0.6796 - recall_2: 0.8775 - precision_2: 0.8569 - f1_score: 0.7434 - val_loss: 0.1441 - val_acc: 0.6547 - val_recall_2: 0.8581 - val_precision_2: 0.8801 - val_f1_score: 0.7548\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 12/100\n",
      "735/735 [==============================] - 475s 646ms/step - loss: 0.1501 - acc: 0.6781 - recall_2: 0.8821 - precision_2: 0.8607 - f1_score: 0.7469 - val_loss: 0.1414 - val_acc: 0.6609 - val_recall_2: 0.8649 - val_precision_2: 0.8769 - val_f1_score: 0.7577\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 13/100\n",
      "735/735 [==============================] - 474s 644ms/step - loss: 0.1479 - acc: 0.6830 - recall_2: 0.8861 - precision_2: 0.8628 - f1_score: 0.7485 - val_loss: 0.1435 - val_acc: 0.6641 - val_recall_2: 0.8615 - val_precision_2: 0.8754 - val_f1_score: 0.7587\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 14/100\n",
      "735/735 [==============================] - 475s 646ms/step - loss: 0.1448 - acc: 0.6856 - recall_2: 0.8886 - precision_2: 0.8653 - f1_score: 0.7491 - val_loss: 0.1367 - val_acc: 0.6734 - val_recall_2: 0.8797 - val_precision_2: 0.8807 - val_f1_score: 0.7595\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 15/100\n",
      "735/735 [==============================] - 474s 645ms/step - loss: 0.1443 - acc: 0.6901 - recall_2: 0.8885 - precision_2: 0.8642 - f1_score: 0.7501 - val_loss: 0.1373 - val_acc: 0.6719 - val_recall_2: 0.8683 - val_precision_2: 0.8813 - val_f1_score: 0.7587\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 16/100\n",
      "735/735 [==============================] - 475s 647ms/step - loss: 0.1421 - acc: 0.6906 - recall_2: 0.8932 - precision_2: 0.8665 - f1_score: 0.7498 - val_loss: 0.1339 - val_acc: 0.6609 - val_recall_2: 0.8570 - val_precision_2: 0.8851 - val_f1_score: 0.7653\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 17/100\n",
      "735/735 [==============================] - 473s 644ms/step - loss: 0.1383 - acc: 0.6928 - recall_2: 0.8960 - precision_2: 0.8687 - f1_score: 0.7523 - val_loss: 0.1397 - val_acc: 0.6750 - val_recall_2: 0.8706 - val_precision_2: 0.8746 - val_f1_score: 0.7561\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 18/100\n",
      "735/735 [==============================] - 474s 644ms/step - loss: 0.1369 - acc: 0.6863 - recall_2: 0.8984 - precision_2: 0.8700 - f1_score: 0.7516 - val_loss: 0.1410 - val_acc: 0.6703 - val_recall_2: 0.8615 - val_precision_2: 0.8775 - val_f1_score: 0.7564\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 19/100\n",
      "735/735 [==============================] - 474s 644ms/step - loss: 0.1354 - acc: 0.6957 - recall_2: 0.8996 - precision_2: 0.8720 - f1_score: 0.7545 - val_loss: 0.1363 - val_acc: 0.6781 - val_recall_2: 0.8706 - val_precision_2: 0.8847 - val_f1_score: 0.7556\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 20/100\n",
      "735/735 [==============================] - 476s 647ms/step - loss: 0.1344 - acc: 0.6974 - recall_2: 0.8995 - precision_2: 0.8717 - f1_score: 0.7537 - val_loss: 0.1338 - val_acc: 0.6750 - val_recall_2: 0.8593 - val_precision_2: 0.8875 - val_f1_score: 0.7587\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 21/100\n",
      "735/735 [==============================] - 474s 645ms/step - loss: 0.1330 - acc: 0.6979 - recall_2: 0.9041 - precision_2: 0.8722 - f1_score: 0.7539 - val_loss: 0.1362 - val_acc: 0.6500 - val_recall_2: 0.8593 - val_precision_2: 0.8937 - val_f1_score: 0.7587\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 22/100\n",
      "735/735 [==============================] - 473s 644ms/step - loss: 0.1317 - acc: 0.6973 - recall_2: 0.9036 - precision_2: 0.8745 - f1_score: 0.7557 - val_loss: 0.1383 - val_acc: 0.6687 - val_recall_2: 0.8774 - val_precision_2: 0.8814 - val_f1_score: 0.7569\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 23/100\n",
      "735/735 [==============================] - 474s 645ms/step - loss: 0.1291 - acc: 0.6977 - recall_2: 0.9052 - precision_2: 0.8754 - f1_score: 0.7558 - val_loss: 0.1409 - val_acc: 0.6797 - val_recall_2: 0.8627 - val_precision_2: 0.8806 - val_f1_score: 0.7561\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 24/100\n",
      "735/735 [==============================] - 473s 644ms/step - loss: 0.1266 - acc: 0.7042 - recall_2: 0.9081 - precision_2: 0.8768 - f1_score: 0.7578 - val_loss: 0.1345 - val_acc: 0.6891 - val_recall_2: 0.8695 - val_precision_2: 0.8794 - val_f1_score: 0.7643\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 25/100\n",
      "735/735 [==============================] - 475s 647ms/step - loss: 0.1266 - acc: 0.7019 - recall_2: 0.9086 - precision_2: 0.8769 - f1_score: 0.7574 - val_loss: 0.1298 - val_acc: 0.6719 - val_recall_2: 0.8661 - val_precision_2: 0.8955 - val_f1_score: 0.7587\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 26/100\n",
      "735/735 [==============================] - 476s 647ms/step - loss: 0.1250 - acc: 0.7086 - recall_2: 0.9095 - precision_2: 0.8770 - f1_score: 0.7587 - val_loss: 0.1288 - val_acc: 0.6719 - val_recall_2: 0.8740 - val_precision_2: 0.8881 - val_f1_score: 0.7627\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 27/100\n",
      "735/735 [==============================] - 475s 646ms/step - loss: 0.1230 - acc: 0.7108 - recall_2: 0.9106 - precision_2: 0.8810 - f1_score: 0.7629 - val_loss: 0.1254 - val_acc: 0.6906 - val_recall_2: 0.8876 - val_precision_2: 0.8907 - val_f1_score: 0.7687\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 28/100\n",
      "735/735 [==============================] - 474s 644ms/step - loss: 0.1207 - acc: 0.7092 - recall_2: 0.9145 - precision_2: 0.8815 - f1_score: 0.7619 - val_loss: 0.1285 - val_acc: 0.7109 - val_recall_2: 0.8729 - val_precision_2: 0.8829 - val_f1_score: 0.7600\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 29/100\n",
      "735/735 [==============================] - 473s 644ms/step - loss: 0.1176 - acc: 0.7155 - recall_2: 0.9171 - precision_2: 0.8839 - f1_score: 0.7639 - val_loss: 0.1261 - val_acc: 0.6859 - val_recall_2: 0.8751 - val_precision_2: 0.8934 - val_f1_score: 0.7692\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 30/100\n",
      "735/735 [==============================] - 475s 646ms/step - loss: 0.1170 - acc: 0.7149 - recall_2: 0.9157 - precision_2: 0.8830 - f1_score: 0.7642 - val_loss: 0.1231 - val_acc: 0.6750 - val_recall_2: 0.8763 - val_precision_2: 0.8946 - val_f1_score: 0.7600\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 31/100\n",
      "735/735 [==============================] - 474s 644ms/step - loss: 0.1170 - acc: 0.7160 - recall_2: 0.9186 - precision_2: 0.8843 - f1_score: 0.7637 - val_loss: 0.1322 - val_acc: 0.6500 - val_recall_2: 0.8638 - val_precision_2: 0.8839 - val_f1_score: 0.7569\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 32/100\n",
      "735/735 [==============================] - 474s 644ms/step - loss: 0.1142 - acc: 0.7184 - recall_2: 0.9178 - precision_2: 0.8869 - f1_score: 0.7656 - val_loss: 0.1311 - val_acc: 0.6828 - val_recall_2: 0.8751 - val_precision_2: 0.8872 - val_f1_score: 0.7622\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 33/100\n",
      "735/735 [==============================] - 473s 644ms/step - loss: 0.1115 - acc: 0.7238 - recall_2: 0.9199 - precision_2: 0.8895 - f1_score: 0.7695 - val_loss: 0.1297 - val_acc: 0.6984 - val_recall_2: 0.8785 - val_precision_2: 0.8795 - val_f1_score: 0.7669\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 34/100\n",
      "735/735 [==============================] - 476s 648ms/step - loss: 0.1112 - acc: 0.7204 - recall_2: 0.9231 - precision_2: 0.8908 - f1_score: 0.7686 - val_loss: 0.1161 - val_acc: 0.6969 - val_recall_2: 0.8956 - val_precision_2: 0.8835 - val_f1_score: 0.7662\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 35/100\n",
      "735/735 [==============================] - 475s 647ms/step - loss: 0.1095 - acc: 0.7221 - recall_2: 0.9225 - precision_2: 0.8921 - f1_score: 0.7701 - val_loss: 0.1156 - val_acc: 0.6906 - val_recall_2: 0.8899 - val_precision_2: 0.8960 - val_f1_score: 0.7761\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 36/100\n",
      "735/735 [==============================] - 475s 647ms/step - loss: 0.1089 - acc: 0.7252 - recall_2: 0.9244 - precision_2: 0.8934 - f1_score: 0.7712 - val_loss: 0.1153 - val_acc: 0.7016 - val_recall_2: 0.8820 - val_precision_2: 0.9035 - val_f1_score: 0.7740\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 37/100\n",
      "735/735 [==============================] - 473s 644ms/step - loss: 0.1059 - acc: 0.7263 - recall_2: 0.9261 - precision_2: 0.8953 - f1_score: 0.7728 - val_loss: 0.1277 - val_acc: 0.6766 - val_recall_2: 0.8751 - val_precision_2: 0.8842 - val_f1_score: 0.7590\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 38/100\n",
      "735/735 [==============================] - 474s 645ms/step - loss: 0.1044 - acc: 0.7233 - recall_2: 0.9279 - precision_2: 0.8967 - f1_score: 0.7735 - val_loss: 0.1318 - val_acc: 0.6969 - val_recall_2: 0.8683 - val_precision_2: 0.8864 - val_f1_score: 0.7641\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 39/100\n",
      "735/735 [==============================] - 475s 646ms/step - loss: 0.1033 - acc: 0.7323 - recall_2: 0.9265 - precision_2: 0.8983 - f1_score: 0.7737 - val_loss: 0.1128 - val_acc: 0.7016 - val_recall_2: 0.8899 - val_precision_2: 0.8970 - val_f1_score: 0.7785\n",
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 40/100\n",
      "735/735 [==============================] - 474s 644ms/step - loss: 0.1029 - acc: 0.7315 - recall_2: 0.9286 - precision_2: 0.8996 - f1_score: 0.7744 - val_loss: 0.1152 - val_acc: 0.6828 - val_recall_2: 0.8854 - val_precision_2: 0.9059 - val_f1_score: 0.7764\n",
      "\n",
      "Epoch 00041: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 41/100\n",
      "735/735 [==============================] - 474s 645ms/step - loss: 0.1007 - acc: 0.7375 - recall_2: 0.9302 - precision_2: 0.9000 - f1_score: 0.7767 - val_loss: 0.1201 - val_acc: 0.6906 - val_recall_2: 0.8729 - val_precision_2: 0.8942 - val_f1_score: 0.7727\n",
      "\n",
      "Epoch 00042: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 42/100\n",
      "735/735 [==============================] - 474s 644ms/step - loss: 0.0990 - acc: 0.7285 - recall_2: 0.9310 - precision_2: 0.9025 - f1_score: 0.7767 - val_loss: 0.1145 - val_acc: 0.6969 - val_recall_2: 0.9024 - val_precision_2: 0.8923 - val_f1_score: 0.7719\n",
      "\n",
      "Epoch 00043: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 43/100\n",
      "735/735 [==============================] - 473s 644ms/step - loss: 0.0973 - acc: 0.7344 - recall_2: 0.9324 - precision_2: 0.9054 - f1_score: 0.7795 - val_loss: 0.1192 - val_acc: 0.6687 - val_recall_2: 0.8854 - val_precision_2: 0.8914 - val_f1_score: 0.7735\n",
      "\n",
      "Epoch 00044: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 44/100\n",
      "735/735 [==============================] - 473s 644ms/step - loss: 0.0941 - acc: 0.7358 - recall_2: 0.9334 - precision_2: 0.9080 - f1_score: 0.7795 - val_loss: 0.1131 - val_acc: 0.7063 - val_recall_2: 0.8910 - val_precision_2: 0.8971 - val_f1_score: 0.7761\n",
      "\n",
      "Epoch 00045: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 45/100\n",
      "735/735 [==============================] - 475s 647ms/step - loss: 0.0946 - acc: 0.7372 - recall_2: 0.9322 - precision_2: 0.9062 - f1_score: 0.7806 - val_loss: 0.1033 - val_acc: 0.7063 - val_recall_2: 0.9001 - val_precision_2: 0.9053 - val_f1_score: 0.7911\n",
      "\n",
      "Epoch 00046: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 46/100\n",
      "735/735 [==============================] - 474s 646ms/step - loss: 0.0932 - acc: 0.7461 - recall_2: 0.9348 - precision_2: 0.9086 - f1_score: 0.7826 - val_loss: 0.1096 - val_acc: 0.6891 - val_recall_2: 0.8944 - val_precision_2: 0.9026 - val_f1_score: 0.7811\n",
      "\n",
      "Epoch 00047: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 47/100\n",
      "735/735 [==============================] - 474s 644ms/step - loss: 0.0904 - acc: 0.7350 - recall_2: 0.9362 - precision_2: 0.9124 - f1_score: 0.7840 - val_loss: 0.1130 - val_acc: 0.7156 - val_recall_2: 0.8854 - val_precision_2: 0.8945 - val_f1_score: 0.7770\n",
      "\n",
      "Epoch 00048: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 48/100\n",
      "735/735 [==============================] - 474s 644ms/step - loss: 0.0889 - acc: 0.7364 - recall_2: 0.9373 - precision_2: 0.9125 - f1_score: 0.7854 - val_loss: 0.1284 - val_acc: 0.6797 - val_recall_2: 0.8763 - val_precision_2: 0.8843 - val_f1_score: 0.7742\n",
      "\n",
      "Epoch 00049: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 49/100\n",
      "735/735 [==============================] - 474s 644ms/step - loss: 0.0886 - acc: 0.7440 - recall_2: 0.9376 - precision_2: 0.9134 - f1_score: 0.7845 - val_loss: 0.1066 - val_acc: 0.7188 - val_recall_2: 0.9047 - val_precision_2: 0.8995 - val_f1_score: 0.7788\n",
      "\n",
      "Epoch 00050: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 50/100\n",
      "735/735 [==============================] - 475s 646ms/step - loss: 0.0883 - acc: 0.7456 - recall_2: 0.9397 - precision_2: 0.9153 - f1_score: 0.7866 - val_loss: 0.1018 - val_acc: 0.7063 - val_recall_2: 0.9081 - val_precision_2: 0.9060 - val_f1_score: 0.7851\n",
      "\n",
      "Epoch 00051: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 51/100\n",
      "735/735 [==============================] - 474s 646ms/step - loss: 0.0819 - acc: 0.7505 - recall_2: 0.9442 - precision_2: 0.9205 - f1_score: 0.7903 - val_loss: 0.1075 - val_acc: 0.6953 - val_recall_2: 0.8944 - val_precision_2: 0.9016 - val_f1_score: 0.7843\n",
      "\n",
      "Epoch 00052: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 52/100\n",
      "735/735 [==============================] - 474s 645ms/step - loss: 0.0780 - acc: 0.7504 - recall_2: 0.9469 - precision_2: 0.9250 - f1_score: 0.7923 - val_loss: 0.1058 - val_acc: 0.7250 - val_recall_2: 0.8910 - val_precision_2: 0.9013 - val_f1_score: 0.7859\n",
      "\n",
      "Epoch 00053: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 53/100\n",
      "735/735 [==============================] - 474s 645ms/step - loss: 0.0775 - acc: 0.7542 - recall_2: 0.9463 - precision_2: 0.9254 - f1_score: 0.7938 - val_loss: 0.1055 - val_acc: 0.6875 - val_recall_2: 0.8944 - val_precision_2: 0.9068 - val_f1_score: 0.7803\n",
      "\n",
      "Epoch 00054: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 54/100\n",
      "735/735 [==============================] - 473s 644ms/step - loss: 0.0764 - acc: 0.7564 - recall_2: 0.9488 - precision_2: 0.9262 - f1_score: 0.7933 - val_loss: 0.1065 - val_acc: 0.7063 - val_recall_2: 0.8956 - val_precision_2: 0.9027 - val_f1_score: 0.7793\n",
      "\n",
      "Epoch 00055: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 55/100\n",
      "735/735 [==============================] - 474s 644ms/step - loss: 0.0750 - acc: 0.7582 - recall_2: 0.9484 - precision_2: 0.9270 - f1_score: 0.7934 - val_loss: 0.1019 - val_acc: 0.7047 - val_recall_2: 0.8978 - val_precision_2: 0.9102 - val_f1_score: 0.7906\n",
      "\n",
      "Epoch 00056: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 56/100\n",
      "735/735 [==============================] - 474s 645ms/step - loss: 0.0750 - acc: 0.7578 - recall_2: 0.9490 - precision_2: 0.9273 - f1_score: 0.7948 - val_loss: 0.1082 - val_acc: 0.6953 - val_recall_2: 0.8888 - val_precision_2: 0.9073 - val_f1_score: 0.7840\n",
      "\n",
      "Epoch 00057: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 57/100\n",
      "735/735 [==============================] - 473s 644ms/step - loss: 0.0742 - acc: 0.7530 - recall_2: 0.9491 - precision_2: 0.9292 - f1_score: 0.7951 - val_loss: 0.1124 - val_acc: 0.7109 - val_recall_2: 0.8944 - val_precision_2: 0.9026 - val_f1_score: 0.7795\n",
      "\n",
      "Epoch 00058: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 58/100\n",
      "735/735 [==============================] - 474s 645ms/step - loss: 0.0732 - acc: 0.7597 - recall_2: 0.9492 - precision_2: 0.9300 - f1_score: 0.7984 - val_loss: 0.1063 - val_acc: 0.7094 - val_recall_2: 0.8990 - val_precision_2: 0.9041 - val_f1_score: 0.7927\n",
      "\n",
      "Epoch 00059: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 59/100\n",
      "735/735 [==============================] - 474s 645ms/step - loss: 0.0731 - acc: 0.7617 - recall_2: 0.9506 - precision_2: 0.9295 - f1_score: 0.7975 - val_loss: 0.1031 - val_acc: 0.7031 - val_recall_2: 0.9035 - val_precision_2: 0.9118 - val_f1_score: 0.7877\n",
      "\n",
      "Epoch 00060: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 60/100\n",
      "735/735 [==============================] - 474s 644ms/step - loss: 0.0724 - acc: 0.7558 - recall_2: 0.9523 - precision_2: 0.9307 - f1_score: 0.7989 - val_loss: 0.1072 - val_acc: 0.7078 - val_recall_2: 0.8876 - val_precision_2: 0.9168 - val_f1_score: 0.7880\n",
      "\n",
      "Epoch 00061: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 61/100\n",
      "638/735 [=========================>....] - ETA: 1:02 - loss: 0.0728 - acc: 0.7626 - recall_2: 0.9511 - precision_2: 0.9312 - f1_score: 0.7974"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_valid,\n",
    "    epochs=100,\n",
    "    steps_per_epoch=(train.shape[0]*0.8)//BATCH_SIZE, \n",
    "    validation_steps= (valid.shape[0]*0.2)//BATCH_SIZE,\n",
    "    verbose=1,\n",
    "    use_multiprocessing=True,\n",
    "    callbacks = callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"/app/_data/models/eff4_ns_3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_all(file_path):\n",
    "    img = tf.io.read_file(PATH+'380/'+file_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    return img\n",
    "def predict_new(path, model):\n",
    "    img = parse_all(path)\n",
    "    img = tf.expand_dims(img,axis = 0)\n",
    "    pred = model.predict(img)\n",
    "    return pred_to_labels(pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = pd.DataFrame(columns=['image','labels'])\n",
    "for img_name in os.listdir(PATH+'380/'):\n",
    "    pred = predict_new(img_name, model)\n",
    "    \n",
    "    df_sub = df_sub.append( {'image': img_name, 'labels': pred}, ignore_index = True )\n",
    "    \n",
    "print(df_sub.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = df_sub.merge(labels_21_20[['image', 'labels']], on='image', how='left', suffixes=('_pred', '_true'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.to_csv('/app/sandbox/wrong_predictions/eff4/eff4_20_21_ups_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scab                       81\n",
       "healthy                    78\n",
       "complex                    53\n",
       "frog_eye_leaf_spot         41\n",
       "rust                       33\n",
       "powdery_mildew             13\n",
       "scab frog_eye_leaf_spot     5\n",
       "rust complex                1\n",
       "Name: labels_true, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub[df_sub['labels_pred'] == '']['labels_true'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
